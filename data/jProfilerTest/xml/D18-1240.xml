<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 D:\Work\grobid-master\grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.5" ident="GROBID" when="2019-07-07T12:38+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Cross-Pair Text Representations for Answer Sentence Selection</title>
			</titleStmt>
			<publicationStmt>
				<publisher>Association for Computational Linguistics</publisher>
				<availability status="unknown"><p>Copyright Association for Computational Linguistics</p>
				</availability>
				<date>October 31 -November 4, 2018. 2018. 2162</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author role="corresp">
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kateryna</forename><surname>Tymoshenko</surname></persName>
							<email>kateryna.tymoshenko@unitn.it</email>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">DISI</orgName>
								<orgName type="institution" key="instit2">University of Trento (Adeptmind scholar</orgName>
								<address>
									<postCode>38123, 90266</postCode>
									<settlement>Povo (TN), Manhattan Beach</settlement>
									<region>CA</region>
									<country>Italy, USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alessandro</forename><surname>Moschitti</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">DISI</orgName>
								<orgName type="institution" key="instit2">University of Trento (Adeptmind scholar</orgName>
								<address>
									<postCode>38123, 90266</postCode>
									<settlement>Povo (TN), Manhattan Beach</settlement>
									<region>CA</region>
									<country>Italy, USA</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Cross-Pair Text Representations for Answer Sentence Selection</title>
					</analytic>
					<monogr>
						<title level="m">Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing</title>
						<meeting>the 2018 Conference on Empirical Methods in Natural Language Processing <address><addrLine>Brussels, Belgium</addrLine></address>
						</meeting>
						<imprint>
							<publisher>Association for Computational Linguistics</publisher>
							<biblScope unit="page" from="2162" to="2173"/>
							<date type="published">October 31 -November 4, 2018. 2018. 2162</date>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Abstract</head><p>High-level semantics tasks, e.g., paraphrasing, textual entailment or question answering, involve modeling of text pairs. Before the emergence of neural networks, this has been mostly performed using intra-pair features, which incorporate similarity scores or rewrite rules computed between the members within the same pair. In this paper, we compute scalar products between vectors representing similarity between members of different pairs, in place of simply using a single vector for each pair. This allows us to obtain a representation specific to any pair of pairs, which delivers the state of the art in answer sentence selection. Most importantly, our approach can outperform much more complex algorithms based on neural networks.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Answer sentence selection (AS) is an important subtask of open-domain Question Answering (QA). Its input are a question Q and a set of candidate answer passages A = {A 1 , A 2 , ..., A N }, which may, for example, be the output of a search engine. The objective consists in selecting A i , i ∈ {1, ..., N } that contain correct answers.</p><p>Pre-deep learning renaissance approaches to AS typically addressed the task by modeling Q-to-A (intra-pair) similarities <ref type="bibr" target="#b42">(Yih et al., 2013;</ref><ref type="bibr" target="#b35">Wang et al., 2007;</ref><ref type="bibr" target="#b10">Heilman and Smith, 2010;</ref><ref type="bibr" target="#b34">Wang and Manning, 2010)</ref>. Q-to-A similarity and alignment are indeed crucial, but, in practice, it is very difficult to automatically extract meaningful relations between Q and A. For example, consider two positive Q/A pairs in <ref type="table">Table 1</ref>. If we want to learn a model based only on the intra-pair Qto-A matches, simple lexical matching (marked with italics) will not be enough. One would need to conduct more complex processing and identify * Professor at the University of Trento.</p><p>that movie and film are synonyms, and that the ngram play in the movie or be in the movie can be paraphrased as star. While the former can be easily detected using an external lexical resource, e.g., WordNet <ref type="bibr" target="#b6">(Fellbaum, 1998)</ref>, the latter would require more complex inference.</p><p>On the other hand, Q 1 and Q 2 contain the same pattern who ... in the movie ..., and their respective answers contain film ... starring .... If we know that P 1 = (Q 1 , A 1 ) is a positive AS example and want to classify P 2 = (Q 2 , A 2 ), then high Q 2 -to-Q 1 and A 2 -to-A 1 cross-pair similarities can suggest that P 1 and P 2 are likely to have the same label. This idea, for example, was exploited by <ref type="bibr" target="#b21">Severyn and Moschitti (2012)</ref>, whose system measures syntactic-semantic similarities directly between structural syntactic tree representations of Q 1 /Q 2 and A 1 /A 2 . This model still exhibited state-of-the-art performance in 2016 <ref type="bibr" target="#b28">(Tymoshenko et al., 2016a)</ref>.</p><p>Deep neural networks (DNNs) also naturally use such cross-pair similarity when modeling two input texts, and then further combine it with intrapair similarity, for example, by means of attention mechanisms <ref type="bibr" target="#b26">(Shen et al., 2017)</ref>, compareaggregate architectures <ref type="bibr" target="#b3">(Bian et al., 2017;</ref><ref type="bibr" target="#b36">Wang and Jiang, 2017)</ref>, or fully-connected layers <ref type="bibr">Moschitti, 2015, 2016;</ref><ref type="bibr" target="#b20">Rao et al., 2016)</ref>.</p><p>In this work, we observe that: (i) the high accuracy of the kernel model by <ref type="bibr" target="#b21">Severyn and Moschitti (2012)</ref> was due not only to the use of syntactic structures, but also to the use of cross-pair similarities; and (ii) the success of DNNs for QA can be partially attributed to an implicit combination of cross-and intra-pair similarity.</p><p>More specifically, we investigate, whether simple similarity metrics, e.g., cosine similarity between standard vector representations, can perform competitively to the state-of-the-art neural models when employed as cross-pair kernels.  <ref type="table">Table 1</ref>: Question/Answer Sentence pairs from WikiQA corpus. We use italic font to mark intra-pair lexical matches between Q1 and A1, Q2 and A2, and bold font to mark the cross-pair matches between Q1 and Q2, A1 and A2.</p><p>To this end, we apply linear and cosine kernels to Q i /Q j and A i /A j pairs (i, j = 1, ..., N ) represented as a bag-of-words (BoW) or an averaged sum of their pretrained word embeddings. Then, we combine them with the cross-pair Tree Kernels (TKs) and kernels applied to the traditional Q/A intra-pair similarity feature vector representations in a composite kernel and use it in an SVM model.</p><p>We experiment with three reference datasets, WikiQA <ref type="bibr" target="#b40">(Yang et al., 2015)</ref>, TREC13 <ref type="bibr" target="#b41">(Yao et al., 2013;</ref><ref type="bibr" target="#b35">Wang et al., 2007)</ref> and SemEval-2016, Task 3.A <ref type="bibr" target="#b16">(Nakov et al., 2016)</ref>, using a number of lexical-overlap/syntactic kernels. The latter challenge refers to a community question answering (cQA) task. It consists in reranking the responses to user questions from online forums. It is the same setting as AS, but the text of questions and answer sentences can be ungrammatical due to the nature of the online forum language.</p><p>We obtain competitive results on WikiQA and SemEval tasks, showing that: (i) simple BoW representations, when used in cross-pair kernels, perform comparably to and even outperform handcrafted intra-pair features. (ii) In cQA, simple cross-pair embedding-and BoW-based similarity features outperform domain-specific similarity features, which are hand-crafted from intrapair members. The simple features also perform comparably to syntactic TKs. (iii) We show that a combination of simple cosine-intra-and crosspair kernels with TKs can outperform the most recent state-of-the-art DNN architectures.</p><p>Assuming the conjecture of our paper correct, cross-pair modeling is the major neural network contribution, the last point above is not surprising as on relatively small datasets kernels-based models can exploit syntactic information very effectively while neural models cannot.</p><p>The paper is structured as follows. We describe the kernels incorporating intra-and crosspair matches in Sec. 3.2, list the simple crossand intra-pair features in Sec. 3.3, describe strong hand-crafted baseline features in Sec. 4, and report the experimental results in Sec. 5.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Related work</head><p>Early approaches to AS typically focused on modeling intra-pair Q-to-A alignment similarities. For example, <ref type="bibr" target="#b42">Yih et al. (2013)</ref> proposed a latent alignment model that employed lexical-semantical Q-to-A alignments, <ref type="bibr" target="#b35">Wang et al. (2007)</ref> modeled syntactic alignments with probabilistic quasisynchronous grammar, and <ref type="bibr" target="#b10">Heilman and Smith (2010)</ref>; <ref type="bibr" target="#b41">Yao et al. (2013)</ref>; <ref type="bibr" target="#b34">Wang and Manning (2010)</ref> employed Tree Edit Distance-based Q-to-A alignments.</p><p>Originally, the idea of cross-pair similarity was proposed by <ref type="bibr" target="#b45">Zanzotto and Moschitti (2006)</ref> and applied to the recognizing textual entailment task, which consists in detecting whether a text T entails a hypothesis H. They assumed that if two H/T pairs H 1 , T 1 and H 2 , T 2 share the same T-to-H "rewrite rules", they are likely to share the same label. Based on this idea, they proposed an algorithm applying TKs to (H 1 , H 2 ) and (T 1 , T 2 ) syntactic tree representations, enriched with H-to-T intra-pair rewrite rule information. More concretely, such algorithm aligns the constituents of H with T and then marks them with symbols directly in the trees. This way the alignment information can be matched by tree kernels applied to cross-pair members.</p><p>Then, a line of work on AS, started by Severyn and <ref type="bibr" target="#b21">Moschitti (2012</ref>; , was inspired by a similar idea of incorporating "rewrite rules" directly into the tree representations of Q 1 /A 1 and Q 2 /A 2 . They represent Q and A as syntactic trees enhanced with Q-to-A relational information, and apply TKs <ref type="bibr" target="#b15">(Moschitti, 2006)</ref> to (Q 1 , Q 2 ) and (A 1 , A 2 ). Thus they model cross-pair similarity, and learn important patterns occurring in Q and A separately. As shown in <ref type="bibr" target="#b28">(Tymoshenko et al., 2016a)</ref>, this approach is competitive with convolutional neural networks (CNNs).</p><p>In our approach, instead of using only one TK, we employ a number of different word-based kernels, most of which can be computed more efficiently than TKs.</p><p>Most recent AS models are based on Deep Neural Networks (DNNs), which learn distributed representations of the input data. DNNs are trained to apply series of non-linear transformations to the input Q and A, represented as compositions of word or character embeddings. DNN architectures learn AS-relevant patterns using intra-pair similarities as well as cross-pair, Q-to-Q and A-to-A, similarities, when modeling the input texts. For example, the CNN network by <ref type="bibr" target="#b23">(Severyn and Moschitti, 2015)</ref> has two separate embedding layers for Q and A, which are followed by the respective convolution layers, whose output is concatenated and then passed through the final fully-connected joint layer. The weights in the Q and A convolution layers are learned by means of the backpropagation algorithm on the training Q/A pairs. Thus, obviously, classifying a new Q/A pair is partially equivalent to performing the implicit cross-pair Qto-Q and A-to-A comparison.</p><p>Additionally, the DNN approaches model the Q-to-A relatedness explicitly in a variety of ways, e.g., by: (i) using a Q-to-A transformation matrix and simple Q-to-A similarity features <ref type="bibr" target="#b44">(Yu et al., 2014;</ref><ref type="bibr" target="#b23">Severyn and Moschitti, 2015)</ref>, (ii) relying on RNN and LSTM architectures <ref type="bibr" target="#b33">(Wang and Nyberg, 2015;</ref><ref type="bibr" target="#b26">Shen et al., 2017)</ref>, (iii) employing attention components <ref type="bibr" target="#b43">(Yin et al., 2016;</ref><ref type="bibr" target="#b26">Shen et al., 2017;</ref><ref type="bibr" target="#b32">Wang et al., 2016a)</ref>, (iv) decomposing input into similarity and dissimilarity matches <ref type="bibr">(Wang et al., 2016b) or (v)</ref> using the compare-aggregate method <ref type="bibr" target="#b36">(Wang and Jiang, 2017;</ref><ref type="bibr" target="#b3">Bian et al., 2017)</ref>.</p><p>We believe that the ability of DNNs to implicitly capture cross-pair relational matching, i.e., the capacity of learning from (Q 1 , Q 2 ) and (A 1 , A 2 ), is a very important factor to their high performance. This is of course paired with their ability to learn non-linear patterns and capture Q-to-A relatedness by means of attention mechanisms. It should be noted that the latter are typically hard-coded in kernel models as lexical matching/similarity <ref type="bibr" target="#b21">(Severyn and Moschitti, 2012)</ref>. This is effective as much as the attention approach, at least with standard-size dataset, also in neural models <ref type="bibr" target="#b24">(Severyn and Moschitti, 2016)</ref>.</p><p>In our work, we model Q-to-A, Q-to-Q and Ato-A similarities with intra-and cross-pair kernels and show that such combination also exhibits state-of-the-art performance on the reference corpora. In addition, our approach can be applied to smaller datasets as it utilizes less parameters, and can provide insights on future DNN design.</p><p>3 Cross-pair similarity kernels for text</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Background on Kernel Machines</head><p>Kernel Machines (KMs) allow for replacing the dot product with kernel functions directly applied to examples, i.e., they avoid mapping examples into vectors. The main advantage of KMs is a much lower computational complexity than the dot product as the kernel computation does not depend on the size of the feature space.</p><p>KMs are linear classifiers: given a labeled training dataset S = {(x i , y i ) : i = 1, . . . , n}, their classification function can be defined as:</p><formula xml:id="formula_0">f (x) = w · x + b = n i=1 α i y i x i · x + b.</formula><p>where x is a classification example, w is the gradient of the separating hyperplane, and b its bias. The equation shows that the gradient is a linear combination of the training points x i ∈ R n multiplied by their labels y i ∈ {−1, 1} and their weights α i ∈ R + . Note that the latter are different from zero only for the support vectors: this reduces the classification complexity, which will be lower than O(n) for each example.</p><p>We can replace the scalar product with a kernel function directly defined over a pair of ob-</p><formula xml:id="formula_1">jects, K(o i , o) = φ(o i )φ(o)</formula><p>, where φ : O → R n maps from objects to vectors of the final feature space. The new classification function becomes:</p><formula xml:id="formula_2">f (o) = n i=1 α i y i K(o i , o) + b,</formula><p>which only needs the initial input objects.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Inter-and intra-pair match kernel</head><p>We cast AS as a text pair classification task: given a pair, P = (Q, A), constituted by a question (Q) and a candidate answer sentence (A), we classify it as either correct or incorrect. We used KMs, where K (·, ·) operates on two pairs, P 1 = (Q 1 , A 1 ) and P 2 = (Q 2 , A 2 ).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.1">Intra-pair similarity</head><p>A traditional baseline approach would (i) represent Q/A pairs as feature vectors, where the components are similarity metrics applied to Q and A, e.g., a world overlap-based similarity; and (ii) train a classification model, e.g., an SVM using the following kernel:</p><formula xml:id="formula_3">K IP (P 1 , P 2 ) = K v V Q 1 ,A 1 , V Q 2 ,A 2 , (1)</formula><p>where K v can be any kernel operating on the feature vectors, e.g., the polynomial or linear (as in our work) kernel. V T 1 ,T 2 is a vector built on N similarity features, f 1 (·, ·), f 2 (·, ·), ..., f N (·, ·) , extracted by applying similarity metrics to two texts, T 1 and T 2 (see Sec. 3.3 for the list of the similarity metrics we used). K IP merely uses intrapair similarities.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.2">Cross-pair similarity</head><p>We incorporate the intuition, similar questions are likely to demand similar answer patterns, by means of a cross-pair kernel, which measures similarity between questions and answers from P 1 and P 2 as follows:</p><formula xml:id="formula_4">K CP (P 1 , P 2 ) = V Q 1 ,Q 2 · V A 1 ,A 2 = N i=1 f i (Q 1 , Q 2 ) · f i (A 1 , A 2 )<label>(2)</label></formula><p>K CP measures P 1 -to-P 2 similarity in terms of a sum of the products of Q 1 -to-Q 2 and A 1 -to-A 2 similarities. Note, that within</p><formula xml:id="formula_5">K IP , f i (Q i , A i )</formula><p>is merely an i-th feature in the V Q i ,A i feature vector. At the same time, within K CP , f i (·, ·) becomes a kernel, which takes the (Q 1 , Q 2 ) or (A 1 , A 2 ) pairs as input. In other words, V Q 1 ,Q 2 · V A 1 ,A 2 is a sum of products of f i (·, ·) kernels applied to the (Q 1 , Q 2 ) and (A 1 , A 2 ) pairs. K CP is a valid kernel if the similarity metrics used to compute the f i (·, ·) are valid kernel functions. Finally, combining K IP and K CP enables learning of two different kinds of valuable crossand intra-pair AS patterns. We combine various K IP and K CP by summing them or by training a meta-classifier on their outputs. See Section 5.4 for more details. <ref type="figure" target="#fig_0">Figure 1</ref> summarizes the differences between the K IP and K CP computation processes described above.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Similarity features</head><p>We employ three similarity feature types as f i (·, ·). Two of them are computed using the cosine similarity metrics and differ only in terms of the input texts, T 1 and T 2 , representations. The other type is constituted by TKs applied to the structural representations of T 1 and T 2 . Note that, since cosine similarity and TKs are valid kernels, and P2. VT 1 ,T 2 is a vector of similarity features extracted for a pair of texts T1, T2, the respective dashed boxes show from which pair of input texts they are extracted.</p><p>K CP is also guaranteed to be a valid kernel when computed using these similarity features.</p><p>3.3.1 Bag-of-n-grams overlap (B)</p><formula xml:id="formula_6">f t,l,s B (T 1 , T 2 )</formula><p>is a cosine similarity metric applied to the bag-of-n-grams vector representations of T i , BOW {t,l,s} (T i ), i = 1, 2. The {t, l, s} index describes an n-gram representation configuration: t denotes whether the n-grams are assembled of word lemmas (L), or their part-of-speech tags (P OS), or lemmas concatenated with their respective POS-tags (L P OS ); l is a (n 1 , n 2 ) tuple, with n 1 and n 2 being the minimal and maximal length of n-grams considered, respectively; and s is Y ES if the representation discards the stopwords and N O, otherwise.</p><p>We used {t, l, s} configurations from the following set:</p><formula xml:id="formula_7">C = ({L, L P OS } × {(1, 2), (1, 3), (1, 4), (2, 4), (2, 3)} × {Y ES, N O}) ∪ ({P OS} × {(1, 4), (2, 4)} × {Y ES}).</formula><p>It follows that |C| = 23, which means we have 23 similarity features, f t,l,s B (T 1 , T 2 ), in total, in the intra-pair setting. The respective cross-pair kernels are a composite kernel summing 23 products of cosine kernels applied to 23 different (Q 1 , Q 2 ) and (A 1 , A 2 ) bag-of-ngram representations.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.2">Embedding-based similarities (E).</head><p>We represent an input text as an average of embeddings of its lemmas from pre-trained word embedding models. Then, the embedding feature f E model (T 1 , T 2 ) is the cosine kernel applied to the embedding-based representations of T 1 and T 2 . We use two pretrained embeddings: Word2Vec <ref type="bibr" target="#b14">(Mikolov et al., 2013)</ref> and GloVe <ref type="bibr" target="#b19">(Pennington et al., 2014)</ref>, resulting in three 1 embedding-based features (see Sec. 5 for more technical details).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.3">Tree-kernel based similarities</head><p>Following the framework defined in <ref type="bibr" target="#b28">Tymoshenko et al., 2016a)</ref>, we represent T 1 and T 2 as syntactico-semantic structures and use TKs as semantic similarity metrics. When computing K CP with TK as similarities, in Eq.2, we employ summation instead of multiplication 2 .</p><p>More specifically, we represent T 1 and T 2 as (i) constituency trees and apply subset TK (SST); or (ii) shallow chunk-based trees, similar to the one presented in <ref type="figure" target="#fig_2">Figure 2</ref>, and apply partial tree (PTK) kernel. In the shallow trees, lemmas are leaves and POS tags are pre-terminals. POS nodes are grouped under chunk nodes, and then under the sentences nodes. These representations encode also some intra-pair similarity information, e.g., prefix REL denotes the lexical Q-to-A match. In a structural representation, we prepend it to the parent and grand-parent nodes of lemmas which occur both in Q and A, e.g., "Mary" in the first example of <ref type="table">Table 1</ref>.</p><p>Then, for factoid QA 3 , we mark focus words in Q and entities in A, if the answer contains any named entities of types matching the question expected answer type (EAT) 4 . More specifically, we mark the semantic Q-to-A match by prepending the REL-FOCUS-&lt;EAT&gt; label to the answer chunk nodes that contain such named entities and also to the question focus word. Here, &lt;EAT&gt; stands for the EAT label. For example, in the Q 1 /A 1 pair in <ref type="table">Table 1</ref>, the Q 1 EAT is HUMan, and the matching named entities include "Julie Andrews", "David Tomlinson" and others. <ref type="figure" target="#fig_2">Figure 2</ref> depicts Q 1 annotated both with REL-and REL-FOCUS links. We detect both question focus and EAT automatically. Due to the space limita-1 We use Word2Vec embeddings trained on two different corpora, which result in two features, and GloVe trained on one corpus. <ref type="bibr">2</ref> We have opted to use summation in this case to follow the earlier work.</p><p>3 WikiQA and TREC13 are the factoid AS datasets, as their questions ask for a specific fact, e.g. date or a name. <ref type="bibr">4</ref> For example, the PERson named entity type matches the HUMan EAT. More specifically, we employ the following NER-to-EAT matching rules: PERson, ORGanization → HUMan; LOCation → LOCation; DATE, TIME, MONEY, PERCENTAGE, DURATION, NUMBER, SET → NUM; ORGanization, PERson, MISCellanious → ENTiTY. We employ the <ref type="bibr" target="#b11">(Li and Roth, 2002)</ref>    <ref type="table">Table 1</ref> (i) cosine similarity applied to the BoW representations of T1 and T2 in terms of word lemmas, bi-, three-, four-grams (computed twice with and without stopwords); POS-tags; dependency triplets; (ii) longest common string subsequence measure w. and w/out stopwords; (iii) Jaccard similarity metric applied to one-, two-, four, three-grams w. and w/out stopwords; (iv) word n-gram containment measure on uni-and bi-grams w. and w/out stopwords (Broder, 1997); (v) greedy string tiling (Wise, 1996) with minimum matching length of 3 ; (vi) string kernel similarity <ref type="bibr" target="#b12">(Lodhi et al., 2002)</ref>; (vii) expected answer type match: percentage of named entities (NE) in the answer passage compatible with the question class 5 ; (viii) WordNet-based similarity. WordNet T1/T2 common lemma/synonym/hypernym overlap ratio; (ix) PTK <ref type="bibr" target="#b15">(Moschitti, 2006</ref>) similarity between constituency or dependency tree representations of input texts; <ref type="table">Table 2</ref>: Strong baseline fatures tions, we do not describe the structural representations and matching algorithms in more detail, but refer the reader to the works above.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Strong baseline feature vector</head><p>As a strong baseline, we use similarity feature vectors and intra-pair K IP kernel. For the factoid answer sentence selection task, we use 47 strong features listed in <ref type="table">Table 2</ref>. This is a compilation of features used in the topperforming system at SemEval-2012 Semantic Text Similarity workshop <ref type="bibr" target="#b0">(Bär et al., 2012)</ref> and earlier factoid QA work <ref type="bibr" target="#b21">(Severyn and Moschitti, 2012)</ref>, extended with few additional features.</p><p>For the community question answering (cQA) task, we employ instead a combination of similarity-based and thread-level features shown to be very effective for the cQA task <ref type="bibr" target="#b17">(Nicosia et al., 2015;</ref><ref type="bibr" target="#b2">Barrón-Cedeño et al., 2016)</ref>. We use the exact feature combination from (Barrón-Cedeño et al., 2016), which includes both lexical and syntactic similarity measures (cosine similarity of bag-of-words, PTK similarity over syntactic tree representations of the input texts) and thread-  We cannot directly use these feature vectors in the K CP kernels, as not all functions used to compute features are valid kernels, e.g., the longest common string subsequence is not a kernel function. Moreover, some of them can be computed only on the (Q, A) pairs, e.g., the expected type match feature (vii) in Tab. 2, or many of the cQA domain-specific features.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Experiments</head><p>We conduct experiments on three corpora, namely TREC13, WikiQA and SemEval, and evaluate the results in terms of Mean Average Precision (MAP) and Mean Reciprocal Rank (MRR). Our code is available at https://github.com/ iKernels/RelTextRank.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Datasets</head><p>WikiQA dataset. WikiQA <ref type="bibr" target="#b40">(Yang et al., 2015</ref>) is a factoid answer sentence selection dataset with Bing query logs as questions. Candidate answer sentences are extracted from Wikipedia and labeled manually. Some of the questions have no correct answer sentence (all − ) or have only correct answer sentences (all + ). <ref type="table" target="#tab_2">Table 3</ref> reports the statistics of the WikiQA corpus as distributed (raw), without all − questions, and without both all − and all + questions (clean). We train in the "no all − " mode using 10 answer sentences per question 6 and test in the "clean" mode.</p><p>TREC13 dataset. A factoid answer sentence selection dataset originally presented in <ref type="bibr" target="#b35">(Wang et al., 2007)</ref>  <ref type="bibr">7</ref> , also frequently called QASent <ref type="bibr" target="#b40">(Yang et al., 2015)</ref>. We train on 1,229 automatically labeled TREC8-12 questions. We use only 10 candidate answer sentences per question. We test in the "clean" setting defined in <ref type="bibr" target="#b20">(Rao et al., 2016)</ref>, i.e., we discard the all + and all − questions, resulting in 65 DEV and 68 TEST <ref type="bibr">6</ref> The 10 answer sentences per question limit speeds up training time without loss in performance <ref type="bibr">7</ref> We use the version distributed by <ref type="bibr" target="#b41">(Yao et al., 2013)</ref>  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Models</head><p>We used the following notation: B, E. Intra-pair K IP kernels (see Sec. 3.2) using the eponymous similarity features from Sec. 3.3. V. Linear kernel applied to the strong intra-pair feature vector representation defined in Section 4. Note that, as already mentioned in Sec. 4, due to the slightly different nature of the factoid and community question answering tasks, we used different strong feature groups for WikiQA, TREC13 <ref type="table">(Table 2)</ref> and SemEval-2016. B cr , E cr . Cross-pair K CP kernel applied to B and E similarity feature vectors respectively. More specifically, B cr and E cr are a sum of 23 and 3 cross-pair kernel products, respectively (see Eq. 2 and Sec. 3.2). PTK, SST are the cross-pair PTK and SST tree kernels applied to the shallow chunk-and constituency-based representations (see Sec. 3.3). "+" denotes kernel summation. We use this symbol to denote that we sum the gram-matrices for the distinct standalone kernels, and use the resulting kernel matrix as input to SVMs. META BASE;P T K , META BASE;SST . Logistic regression metaclassifiers trained on the outputs of two standalone systems, namely (i) V+B cr +E cr +E (we denote it as BASE to simplify the notation), and (ii) PTK or SST, respectively. We ran 10-fold cross-validation on the training set and used the resulting predictions as training data for the ensemble classifier. We did not use the development or training sets for any parameter tuning, thus we report the results both on the DEV and TEST sets. SUM BASE;P T K , SUM BASE;SST . Simple metaclassifiers, summing the output of the BASE and PTK or SST systems, respectively.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">Toolkits</head><p>We trained the models using scikit-learn 8 by <ref type="bibr" target="#b18">Pedregosa et al. (2012)</ref> using the SVC version of SVM with precomputed K IP and K CP kernel matrices and default parameters. We trained the ensemble model using the scikit LogisticRegression classifier implementation with the default parameters. We used spaCy library 9 and scikit to obtain bag-of-n-gram representations for the B similarity features, and to compute B-and E-base gram matrices.</p><p>We used the RelTextRank framework 10 (Tymoshenko et al., 2017b) to generate the structural representations for the TK similarity features and to extract the strong baseline feature vectors from Sec. 4. We used KeLP <ref type="bibr">(Filice et al.)</ref> to compute the TK gram matrices.</p><p>Regarding the Embedding-based similarities (E), we obtain three similarity features by using three word embedding models to generate the representations of the input texts, T 1 and T 2 , namely GloVe vectors trained on common crawl data 11 , Word2Vec vectors pre-trained on Google News 12 , and another Word2Vec vectors model 13 pre-trained on Aquaint 14 plus Wikipedia. <ref type="table" target="#tab_5">Table 4</ref> reports the results obtained with the intraand cross-pair kernels K IP , K CP and their combinations. In the following, we describe the results according to the model categories above.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.4">Results and discussion</head><p>Intra-pair kernels. Taking into account intrapair similarity is the standard approach in the majority of the previous non-DNN work. In our experiments, we implement this approach as K IP using B, E, V groups of similarity features. K IP performs worse than the state-of-art (SoA) DNN systems on all the datasets (see tables 5, 6 and 7, for the SoA systems).</p><p>The results on WikiQA are particularly low even when the best K IP system, B+V+E, is used, which scores up to 15 points less than the state of the art. This confirms the <ref type="bibr" target="#b40">Yang et al. (2015)</ref> observation on WikiQA, according to which, simple word matching methods are likely to underperform on its data, considering how it was built. Nevertheless, despite its simplicity, B+V+E performs comparably to the <ref type="bibr" target="#b40">Yang et al. (2015)</ref> reimplementation of LCLR, the complex latent structured approach employing rich lexical and semantic intra-pair similarity features <ref type="bibr" target="#b42">(Yih et al., 2013)</ref>. <ref type="bibr" target="#b40">Yang et al. (2015)</ref> report that on WikiQA LCLR obtains MRR of 60.86 and MAP of 59.93.</p><p>Then, on TREC13 and SemEval-2016, the intra-pair V, V+E and B+V+E kernels exhibit rather high performance, however, they are still significantly below the state of the art, thus confirming our hypothesis that intra-pair similarity alone does not guarantee top results.</p><p>Cross-pair kernels. B cr and E cr obtain rather high results on WikiQA and SemEval. On WikiQA, both B cr and B cr + E cr outperform all the intra-pair kernels by a large margin, while, on SemEval, they perform comparably to the manually engineered domain-specific V features of <ref type="bibr" target="#b17">Nicosia et al. (2015)</ref>. On the contrary, on TREC13, V outperforms both B cr and E cr , thus showing that TREC13 is indeed biased towards intra-pair relatedness features by construction.</p><p>More complex PTK and SST cross-pair kernels, both alone and combined with B cr , E cr , typically outperform the standalone B cr and E cr on all the corpora (PTK on TREC13 and WikiQA, and SST and B cr +E cr +PTK on SemEval). This can be explained by the fact that PTK and SST are able to learn complex syntactic patterns and also contain some information about intra-pair relations, namely REL-labels described in Sec. 3.2. Thus, it is natural that they outperform simpler cross-pair kernels. Nevertheless, on WikiQA-DEV, B cr +E cr performs very close to PTK. Moreover, on SemEval, B cr +E cr outperforms PTK and is behind SST for less than 1 point in terms of MAP. This can be explained by the fact that Q and A, in SemEval, are frequently ungrammatical as the cQA corpus is collected from online forums.</p><p>Finally, note that the B cr +E cr +PTK system, which does not use any cQA domain-specific features, is only 0.56 MAP points behind KeLP, the best-performing system in the SemEval competition (see Line 1 of <ref type="table" target="#tab_10">Table 7)</ref>.</p><p>Kernels combining the intra-and cross-pair similarities. The V+B cr +E cr +E combination (we  will refer to it as BASE), outperforms the standalone domain-specific handcrafted cQA features, V, and both PTK and SST on SemEval 2016 TEST and DEV by at least 2.3 points in all metrics. Moreover, V+B cr +E cr +E is only less than 0.5 points behind the #1 system of the SemEval-2016 competition (see Tab. 7). We recall that V+B cr +E cr +E only uses basic n-gram overlapbased cross-and intra-similarity features and embedding-based cosine similarities.</p><p>Finally, when we add tree kernel models to the combination, i.e., V+B cr +E cr +E+PTK or V+B cr +E cr +E+SST, we note improvement for SemEval and TREC13 tasks.</p><p>Ensemble models. We ensemble cross-and intra-pair kernels-based models by summing the predictions of the standalone SVM classifiers (SUM models) or by training a logistic regression meta-classifier on them (META models). We build the meta-classifiers on the outputs of the standalone system BASE and TKs, namely PTK and SST. The "Ensemble" section of <ref type="table" target="#tab_5">Table 4</ref> shows that meta-system combinations mostly outperform the standalone kernels.</p><p>In general, combining cross-pair and intra-pair similarities (with kernel sum or meta-classifiers) provides state-of-the-art results without using deep learning. Additionally, the outcome is deterministic, while the DNN accuracy may vary depending on the type of the hardware used or the random initialization parameters <ref type="bibr" target="#b5">(Crane, 2018)</ref>. <ref type="table" target="#tab_7">Tables 5, 6</ref> and 7 report the performance of the most recent state-of-the-art systems on WikiQA, TREC13 and SemEval in comparison with our best results. We discuss them with respect to the different datasets.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.5">Comparison with the state of the art</head><p>WikiQA. As already mentioned earlier, WikiQA contains many questions without correct answer (see <ref type="table">Tab.</ref> 3). When evaluated on the full data, even the oracle system will achieve at most 38.38 points of MAP. Moreover, as originally observed in <ref type="bibr" target="#b35">(Wang et al., 2007)</ref>, the questions that do not have either correct answers or incorrect answers are not useful for comparing the performance of different answer sentence selection systems. Therefore, they are typically removed from WikiQA and TREC13 before the evaluation.</p><p>There has been some discrepancy in the community when evaluating on WikiQA. The original baselines proposed for the corpus in <ref type="bibr" target="#b40">(Yang et al., 2015)</ref> were evaluated in the "clean" setting <ref type="bibr">15</ref> . We no all − clean MRR MAP MRR MAP LCLR <ref type="bibr" target="#b40">(Yang et al., 2015)</ref> impl. of <ref type="bibr" target="#b42">(Yih et al., 2013)</ref>    <ref type="bibr" target="#b26">(Shen et al., 2017)</ref> 88.9 82.2 BIMPM  87.5 80.2 C/A, k-threshold <ref type="bibr" target="#b3">(Bian et al., 2017)</ref> 89.9 82.1 C/A-listwise <ref type="bibr" target="#b3">(Bian et al., 2017)</ref> 88.9 81.0 HyperQA <ref type="bibr" target="#b27">(Tay et al., 2018)</ref> 86.5 78.   <ref type="bibr" target="#b29">(Tymoshenko et al., 2016b)</ref> 86.26 78.78 HyperQA <ref type="bibr" target="#b27">(Tay et al., 2018)</ref> n/a 79.5 AI-CNN <ref type="bibr" target="#b46">(Zhang et al., 2017)</ref> n/a 80.14 Our model (V+Bcr+Ecr+E+SST) 86.52 79.79 also evaluate in the "clean" setting. However, the performance of the most recent state-of-theart systems listed in the Tab. 5 is reported in the "no all − " setting, in the respective papers, i.e., they keep the all + questions 16 . Thus, they have 6 extra questions always answered correctly by default. To account for this discrepancy, in Tab. 5, we report the results in both settings. It is trivial to convert the performance figures from one setting to another. In the table, we mark the conversion results with italic. Our SUM BASE;P T K system (i) outperforms all the state-of-the-art systems, including the sophisticated architectures with attention, such as IWANatt <ref type="bibr" target="#b26">(Shen et al., 2017)</ref>, and compare-aggregate (C/A) frameworks <ref type="bibr" target="#b36">(Wang and Jiang, 2017;</ref><ref type="bibr" target="#b3">Bian et al., 2017)</ref> in terms of MRR; and (ii) has the same MAP as <ref type="bibr" target="#b3">(Bian et al., 2017)</ref>. Obviously, this improvement is not statistically significant with re- <ref type="bibr">16</ref> We deduced that from the corpus statistics reported by the authors of the papers. They all report having 243 test questions, which corresponds to the "no all − " setting spect to C/A systems by <ref type="bibr" target="#b3">Bian et al. (2017)</ref>. Nevertheless, ours is a very promising result, considering that we only use linear models with simple kernels and do not tune any learning parameter of such models. TREC13. As shown in Tab. 6, our models do not outperform the state of the art on TREC13, but they still perform comparably to the recent DNN HyperQA model <ref type="bibr" target="#b27">(Tay et al., 2018)</ref>. In general, our model is behind the state-of-the-art IWAN-att system by 4.55 points in terms of MAP. Note, however, that TREC13 test set contains only 68 questions, therefore this difference in performance is not likely to be statistically significant 17 .</p><p>Semeval. <ref type="table" target="#tab_10">Table 7</ref> compares performance of B cr + E cr + V + E + SST system on Semeval to that of KeLP and ConvKN, the two top systems in the SemEval 2016 competition, and also to the performance of the recent DNN-based HyperQA and AI-CNN systems. In the Semeval 2016 competition, our model would have been the first 18 , with #1 KeLP system being 0.6 MAP points behind. Then, it would have outperformed the state-of-theart AI-CNN system by 0.35 MAP points.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Conclusions</head><p>This work proposes a simple, yet effective approach to the task of answer sentence selection based on the intuition that similar patterns in questions are likely to demand similar patterns in answers. We showed that this hypothesis provides an improvement on three benchmark datasets, WikiQA, TREC13, Semeval-2016, and, moreover, it enables simple features to achieve the state of the art on WikiQA and Semeval-2016, outperforming many of state-of-the-art DNN-based systems. There is significant room for further elaboration of this approach, for example, by expanding feature spaces with more syntactic and semantic features, employing new types of kernels for measuring the inter-question/answer pair similarity or trying to implement the same idea in DNN architectures.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Feature extraction schema for two Q/A pairs, P1</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head></head><label></label><figDesc>coarse-grained EAT taxonomy and Stanford CoreNLP (Manning et al., 2014) entity types.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: Shallow syntactic representation of A1 from the running example in Table 1</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" validated="false"><head></head><label></label><figDesc>A1 Mary Poppins is a 1964 musical film starring Julie Andrews, Dick Van Dyke, David Tomlinson, and Glynis Johns, produced by Walt Disney, and based on the Mary Poppins books series by P. L. Travers.A2 I Confess is a 1953 drama film directed by Alfred Hitchcock, and starring Montgomery Clift as Fr. Michael William Lo- gan, a Catholic priest, Anne Baxter as Ruth Grandfort, and Karl Malden as Inspector Larrue .</figDesc><table>Question 
Answer 
Label 
Q1 who 
plays 
mary poppins 
in the movie? 

TRUE 

Q2 WHO WAS IN THE MOVIE 
I CONFESS 
WITH 
MONTGOMERY CLIFT 

TRUE 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" validated="false"><head>Table 3 :</head><label>3</label><figDesc>WikiQA corpus statistics level domain specific features (are the question and comment authored by the same person?, does the comment contain any questions?, and so on.).</figDesc><table></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" validated="false"><head></head><label></label><figDesc>SemEval cQA dataset is a benchmark dataset in the Se- mEval 2016 Task 3. A question-to-comment sim- ilarity competition. It is a collection of user ques- tions and the respective answer comment threads from Qatar Living forum, where the user com- ments to questions were manually labeled as cor- rect or incorrect. Each question has 10 respective candidate answers. The training, dev and test sets have 1790, 244 and 327 questions, respectively. The AS task consists in reranking comments with respect to the question: most questions are non- factoid and the text is often noisy.</figDesc><table>in 

https://code.google.com/p/jacana/ 

questions, respectively. DEV and TEST contain 
1117 and 1442 candidate associated answer 
sentences, respectively. 
SemEval-2016, Task 3.A dataset. </table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5" validated="false"><head>Table 4 :</head><label>4</label><figDesc>Results on TREC13, WikiQA and SemEval-2016 datasets. Best results in each feature category are highlighted with bold, overall best results are underlined. TK is SST for Semeval and PTK for WikiQA and TREC13. BASE refers to the V+B cr +E cr +E configuration.</figDesc><table></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6" validated="false"><head></head><label></label><figDesc>61.83 60.92 60.86 59.93 HybridTK-NN (Tymoshenko et al., 2017a) 74.72 72.88 74.08 72.19 IWAN-att (Shen et al., 2017) 75.00 73.30 74.37 72.62 C/A, MULT (Wang and Jiang, 2017) 75.45 74.33 74.83 73.68 C/A, k-max (Bian et al., 2017) 76.40 75.40 75.80 74.78 C/A, listwise (Bian et al., 2017) 75.90 74.60 75.29 73.96 HyperQA (Tay et al., 2018) 72.70 71.20 72.01 70.47 Our model (PTK) 76.21 75.29 75.60 74.67 Our model (SUMBASE;P T K ) 77.57 76.19 77.00 75.59</figDesc><table></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7" validated="false"><head>Table 5 :</head><label>5</label><figDesc>Comparison to the SoA on WikiQA MRR MAP Noise-contrastive estim. (Rao et al., 2016) 87.7 80.1 IWAN-att</figDesc><table></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_9" validated="false"><head>Table 6 :</head><label>6</label><figDesc>Comparison to the SoA on TREC13 MRR MAP Kelp [#1] (Filice et al., 2016) 86.42 79.19 Conv-KN [#2] (Barrón-Cedeño et al., 2016) 84.93 77.6 CTKC +VQF</figDesc><table></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_10" validated="false"><head>Table 7 :</head><label>7</label><figDesc>Comparison to the SoA on SemEval-2016</figDesc><table></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="8">http://scikit-learn.org/ 9 https://spacy.io/ 10 This tool employs Stanford CoreNLP 3.6.0 (Manning et al., 2014) for text processing; and DKProSimilarity (Bär et al., 2013) to extract features (ii)-(v). 11 http://nlp.stanford.edu/data/glove.42B.300d.zip 12 https://code.google.com/archive/p/word2vec/ 13 https://github.com/aseveryn/deep-qa 14 https://catalog.ldc.upenn.edu/LDC2002T31</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="15">According to the WikiQA gold reference files at https://www.microsoft.com/en-us/download/details. aspx?id=52419</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="17">We cannot conduct the test since we do not have the outputs of such systems. However, 4 points more correspond to just a couple of correct questions more. 18 Ranking available in (Nakov et al., 2016)</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgments</head><p>The first author is supported by Adeptmind. Many thanks to the Area chairs, PC chairs and anonymous reviewers for their professional work and valuable suggestions.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Ukp: Computing semantic textual similarity by combining multiple content similarity measures</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Bär</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Biemann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Gurevych</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Zesch</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">First Joint Conference on Lexical and Computational Semantics (*SEM 2012)</title>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="page" from="435" to="440" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">DKPro Similarity: An Open Source Framework for Text Similarity</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Bär</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Torsten</forename><surname>Zesch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Iryna</forename><surname>Gurevych</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics: System Demonstrations</title>
		<meeting>the 51st Annual Meeting of the Association for Computational Linguistics: System Demonstrations<address><addrLine>Sofia, Bulgaria</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="121" to="126" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">ConvKN at SemEval-2016 task 3: Answer and question selection for question answering on Arabic and English fora</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Barrón-Cedeño</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Bonadiman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Da San</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Martino</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Joty</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><forename type="middle">A</forename><surname>Moschitti</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Obaidli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Romeo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Tymoshenko</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Uva</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SemEval 2016 -10th International Workshop on Semantic Evaluation, Proceedings</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">A Compare-Aggregate Model with Dynamic-Clip Attention for Answer Selection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Weijie</forename><surname>Bian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Si</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhao</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guang</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhiqing</forename><surname>Lin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2017 ACM on Conference on Information and Knowledge Management, CIKM &apos;17</title>
		<meeting>the 2017 ACM on Conference on Information and Knowledge Management, CIKM &apos;17<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2017" />
			<biblScope unit="page" from="1987" to="1990" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">On the resemblance and containment of documents</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Andrei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Broder</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Compression and Complexity of Sequences 1997. Proceedings</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="1997" />
			<biblScope unit="page" from="21" to="29" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Questionable Answers in Question Answering Research: Reproducibility and Variability of Published Results</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matt</forename><surname>Crane</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Transactions of the Association for Computational Linguistics</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page" from="241" to="252" />
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<title level="m" type="main">WordNet: An Electronic Lexical Database</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christiane</forename><surname>Fellbaum</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1998" />
			<biblScope unit="volume">71</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">KeLP: a Kernel-based Learning Platform in Java, year = 2015</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Simone</forename><surname>Filice</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Giuseppe</forename><surname>Castellucci</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Danilo</forename><surname>Croce</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Giovanni</forename><surname>Da San</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alessandro</forename><surname>Martino</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Roberto</forename><surname>Moschitti</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Basili</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The workshop on Machine Learning Open Source Software (MLOSS): Open Ecosystems</title>
		<meeting><address><addrLine>Lille, France</addrLine></address></meeting>
		<imprint/>
	</monogr>
	<note>International Conference of Machine Learning</note>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Simone</forename><surname>Filice</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Danilo</forename><surname>Croce</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alessandro</forename><surname>Moschitti</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Roberto</forename><surname>Basili</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
			</analytic>
	<monogr>
		<title level="m">Learning Semantic Relations between Questions and Answers. Proceedings of the 10th International Workshop on Semantic Evaluation (SemEval-2016)</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="1116" to="1123" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Tree edit models for recognizing textual entailments, paraphrases, and answers to questions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Heilman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Noah</forename><forename type="middle">A</forename><surname>Smith</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The 2010 Annual Conference of the North American Chapter of the ACL</title>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="page" from="1011" to="1019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Learning question classifiers</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xin</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Roth</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">COLING 2002: The 19th International Conference on Computational Linguistics</title>
		<imprint>
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Text Classification using String Kernels</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Huma</forename><surname>Lodhi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Craig</forename><surname>Saunders</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Shawe-Taylor</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nello</forename><surname>Cristianini</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Watkins</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="419" to="444" />
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">The Stanford CoreNLP Natural Language Processing Toolkit</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Christopher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mihai</forename><surname>Manning</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Surdeanu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jenny</forename><surname>Bauer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Finkel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Steven</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Bethard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Mcclosky</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Distributed representations of words and phrases and their compositionality</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tomas</forename><surname>Mikolov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kai</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Greg</forename><surname>Corrado</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeffrey</forename><surname>Dean</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS</title>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="1" to="9" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Efficient Convolution Kernels for Dependency and Constituent Syntactic Trees</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alessandro</forename><surname>Moschitti</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Machine Learning ECML</title>
		<imprint>
			<biblScope unit="volume">4212</biblScope>
			<biblScope unit="page" from="318" to="329" />
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Hamdy Mubarak, abed Alhakim Freihat, Jim Glass, and Bilal Randeree</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Preslav</forename><surname>Nakov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lluís</forename><surname>Màrquez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alessandro</forename><surname>Moschitti</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Walid</forename><surname>Magdy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SemEval-2016 Task 3: Community Question Answering. Proceedings of the 10th International Workshop on Semantic Evaluation (SemEval-2016)</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="525" to="545" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">QCRI: Answer selection for community question answering-experiments for Arabic and English</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Massimo</forename><surname>Nicosia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Simone</forename><surname>Filice</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alberto</forename><surname>Barrón-Cedeno</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Iman</forename><surname>Saleh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hamdy</forename><surname>Mubarak</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Preslav</forename><surname>Nakov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Giovanni</forename><surname>Da San</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alessandro</forename><surname>Martino</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kareem</forename><surname>Moschitti</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Others</forename><surname>Darwish</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 9th International Workshop on Semantic Evaluation</title>
		<meeting>the 9th International Workshop on Semantic Evaluation</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="203" to="209" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Scikit-learn: Machine Learning in Python</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fabian</forename><surname>Pedregosa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gaël</forename><surname>Varoquaux</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexandre</forename><surname>Gramfort</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vincent</forename><surname>Michel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bertrand</forename><surname>Thirion</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Olivier</forename><surname>Grisel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mathieu</forename><surname>Blondel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peter</forename><surname>Prettenhofer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ron</forename><surname>Weiss</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vincent</forename><surname>Dubourg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jake</forename><surname>Vanderplas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexandre</forename><surname>Passos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Cournapeau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthieu</forename><surname>Brucher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthieu</forename><surname>Perrot</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Duchesnay</forename><surname>Andédouard</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="page" from="2825" to="2830" />
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Glove: Global Vectors for Word Representation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeffrey</forename><surname>Pennington</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Socher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><surname>Manning</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP)</title>
		<meeting>the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP)</meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="1532" to="1543" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">NoiseContrastive Estimation for Answer Selection with Deep Neural Networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jinfeng</forename><surname>Rao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hua</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jimmy</forename><surname>Lin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 25th ACM International on Conference on Information and Knowledge Management -CIKM &apos;16</title>
		<meeting>the 25th ACM International on Conference on Information and Knowledge Management -CIKM &apos;16</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="1913" to="1916" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Structural relationships for large-scale learning of answer re-ranking</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aliaksei</forename><surname>Severyn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alessandro</forename><surname>Moschitti</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 35th international ACM SIGIR conference on Research and development in information retrieval -SIGIR &apos;12</title>
		<meeting>the 35th international ACM SIGIR conference on Research and development in information retrieval -SIGIR &apos;12</meeting>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="page" from="741" to="750" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Automatic Feature Engineering for Answer Selection and Extraction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aliaksei</forename><surname>Severyn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alessandro</forename><surname>Moschitti</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Empirical Methods in Natural Language Processing</title>
		<meeting>Empirical Methods in Natural Language essing</meeting>
		<imprint>
			<date type="published" when="2013-10" />
			<biblScope unit="page" from="458" to="467" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Learning to Rank Short Text Pairs with Convolutional Deep Neural Networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aliaksei</forename><surname>Severyn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alessandro</forename><surname>Moschitti</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 38th International ACM SIGIR Conference on Research and Development in Information Retrieval, SIGIR &apos;15</title>
		<meeting>the 38th International ACM SIGIR Conference on Research and Development in Information Retrieval, SIGIR &apos;15<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2015" />
			<biblScope unit="page" from="373" to="382" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<monogr>
		<title level="m" type="main">Modeling relational information in question-answer pairs with convolutional neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aliaksei</forename><surname>Severyn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alessandro</forename><surname>Moschitti</surname></persName>
		</author>
		<idno>abs/1604.01178</idno>
		<imprint>
			<date type="published" when="2016" />
			<publisher>CoRR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Learning adaptable patterns for passage reranking</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aliaksei</forename><surname>Severyn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Massimo</forename><surname>Nicosia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alessandro</forename><surname>Moschitti</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Seventeenth Conference on Computational Natural Language Learning (CoNLL)</title>
		<meeting>the Seventeenth Conference on Computational Natural Language Learning (CoNLL)</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2013" />
			<biblScope unit="page" from="75" to="83" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Inter-Weighted Alignment Network for Sentence Pair Modeling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gehui</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yunlun</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhi-Hong</forename><surname>Deng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2017 Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="1179" to="1189" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Hyperbolic Representation Learning for Fast and Efficient Neural Question Answering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yi</forename><surname>Tay</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anh</forename><surname>Luu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Siu Cheung</forename><surname>Tuan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Hui</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Eleventh ACM International Conference on Web Search and Data Mining, WSDM &apos;18</title>
		<meeting>the Eleventh ACM International Conference on Web Search and Data Mining, WSDM &apos;18<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2018" />
			<biblScope unit="page" from="583" to="591" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Convolutional neural networks vs. convolution kernels: Feature engineering for answer sentence reranking</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Tymoshenko</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Bonadiman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Moschitti</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2016 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, NAACL HLT 2016 -Proceedings of the Conference</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Learning to rank non-factoid answers: Comment selection in Web forums</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Tymoshenko</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Bonadiman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Moschitti</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CIKM</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Ranking Kernels for Structures and Embeddings: A Hybrid Preference and Classification Model</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kateryna</forename><surname>Tymoshenko</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniele</forename><surname>Bonadiman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alessandro</forename><surname>Moschitti</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2017 Conference on Empirical Methods in Natural Language Processing<address><addrLine>Copenhagen, Denmark</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">RelTextRank: An Open Source Framework for Building Relational Syntactic-Semantic Text Pair Representations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kateryna</forename><surname>Tymoshenko</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alessandro</forename><surname>Moschitti</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Massimo</forename><surname>Nicosia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aliaksei</forename><surname>Severyn</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ACL 2017, System Demonstrations</title>
		<meeting>ACL 2017, System Demonstrations</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="79" to="84" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Inner Attention based Recurrent Neural Networks for Answer Selection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bingning</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kang</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jun</forename><surname>Zhao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 54th Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<publisher>Long Papers</publisher>
			<date type="published" when="2016" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="1288" to="1297" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<monogr>
		<title level="m" type="main">A Long Short-Term Memory Model for Answer Sentence Selection in Question Answering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Di</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eric</forename><surname>Nyberg</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="707" to="712" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Probabilistic Tree-Edit Models with Structured Latent Variables for Textual Entailment and Question Answering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mengqiu</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Christopher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Manning</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 23rd International Conference on Computational Linguistics</title>
		<meeting>the 23rd International Conference on Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2010-08" />
			<biblScope unit="page" from="1164" to="1172" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mengqiu</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Noah</forename><forename type="middle">A</forename><surname>Smith</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Teruko</forename><surname>Mitamura</surname></persName>
		</author>
		<title level="m">What is the Jeopardy Model? A QuasiSynchronous Grammar for QA. Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning</title>
		<imprint>
			<date type="published" when="2007" />
			<biblScope unit="page" from="22" to="32" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<monogr>
		<title level="m" type="main">A compareaggregate model for matching text sequences</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shuohang</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jing</forename><surname>Jiang</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note>ICLR</note>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Bilateral multi-perspective matching for natural language sentences</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhiguo</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wael</forename><surname>Hamza</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Radu</forename><surname>Florian</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IJCAI International Joint Conference on Artificial Intelligence</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="4144" to="4150" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Sentence Similarity Learning by Lexical Decomposition and Composition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhiguo</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Haitao</forename><surname>Mi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Abraham</forename><surname>Ittycheriah</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of COLING 2016, the 26th International Conference on Computational Linguistics: Technical Papers</title>
		<meeting>COLING 2016, the 26th International Conference on Computational Linguistics: Technical Papers<address><addrLine>Osaka, Japan</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="1340" to="1349" />
		</imprint>
	</monogr>
	<note>The COLING 2016 Organizing Committee</note>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">YAP3: Improved detection of similarities in computer program and other texts</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Michael</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Wise</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM SIGCSE Bulletin</title>
		<imprint>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page">28</biblScope>
			<date type="published" when="1996" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">WIKIQA: A Challenge Dataset for Open-Domain Question Answering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yi</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wen-Tau</forename><surname>Yih</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><surname>Meek</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of EMNLP 2015</title>
		<meeting>EMNLP 2015</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="2013" to="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<monogr>
		<title level="m" type="main">Answer Extraction as Sequence Tagging with Tree Edit Distance</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xuchen</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Benjamin</forename><surname>Van Durme</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Callisonburch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peter</forename><surname>Clark</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<monogr>
		<title level="m" type="main">Question Answering Using Enhanced Lexical Semantic Models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ming-Wei</forename><surname>Wen-Tau Yih</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrzej</forename><surname>Meek</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Pastusiak</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="1744" to="1753" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">ABCNN: Attention-Based Convolutional Neural Network for Modeling Sentence Pairs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wenpeng</forename><surname>Yin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hinrich</forename><surname>Schütze</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bing</forename><surname>Xiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bowen</forename><surname>Zhou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Transactions of the Association for Computational Linguistics</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="page" from="259" to="272" />
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lei</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Karl</forename><forename type="middle">Moritz</forename><surname>Hermann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Phil</forename><surname>Blunsom</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stephen</forename><surname>Pulman</surname></persName>
		</author>
		<title level="m">Deep Learning for Answer Sentence Selection. NIPS Deep Learning and Representation Learning Workshop</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Automatic Learning of Textual Entailments with Cross-Pair Similarities</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fabio</forename><surname>Massimo Zanzotto</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alessandro</forename><surname>Moschitti</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 21st International Conference on Computational Linguistics and 44th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 21st International Conference on Computational Linguistics and 44th Annual Meeting of the Association for Computational Linguistics<address><addrLine>Sydney, Australia</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2006" />
			<biblScope unit="page" from="401" to="408" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b46">
	<monogr>
		<title level="m" type="main">Attentive Interactive Neural Networks for Answer Selection in Community Question Answering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaodong</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sujian</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lei</forename><surname>Sha</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Houfeng</forename><surname>Wang</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017" />
			<publisher>AAAI</publisher>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="page" from="505" to="509" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
