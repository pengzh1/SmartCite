<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 D:\Work\grobid-master\grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.5" ident="GROBID" when="2019-07-07T09:42+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">A Minimum Error Weighting Combination Strategy for Chinese Semantic Role Labeling</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date type="published" when="2010-08">Coling 2010. August 2010</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tao</forename><surname>Zhuang</surname></persName>
							<email>tzhuang@nlpr.ia.ac.cn</email>
							<affiliation key="aff0">
								<orgName type="department">Institute of Automation</orgName>
								<orgName type="laboratory">National Laboratory of Pattern Recognition</orgName>
								<orgName type="institution">Chinese Academy of Sciences</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chengqing</forename><surname>Zong</surname></persName>
							<email>cqzong@nlpr.ia.ac.cn</email>
							<affiliation key="aff0">
								<orgName type="department">Institute of Automation</orgName>
								<orgName type="laboratory">National Laboratory of Pattern Recognition</orgName>
								<orgName type="institution">Chinese Academy of Sciences</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">A Minimum Error Weighting Combination Strategy for Chinese Semantic Role Labeling</title>
					</analytic>
					<monogr>
						<title level="m">Proceedings of the 23rd International Conference on Computational Linguistics</title>
						<meeting>the 23rd International Conference on Computational Linguistics <address><addrLine>Beijing</addrLine></address>
						</meeting>
						<imprint>
							<biblScope unit="page" from="1362" to="1370"/>
							<date type="published" when="2010-08">Coling 2010. August 2010</date>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Abstract</head><p>Many Semantic Role Labeling (SRL) combination strategies have been proposed and tested on English SRL task. But little is known about how much Chinese SRL can benefit from system combination. And existing combination strategies trust each individual system's output with the same confidence when merging them into a pool of candidates. In our approach, we assign different weights to different system outputs, and add a weighted merging stage to the conventional SRL combination architecture. We also propose a method to obtain an appropriate weight for each system's output by minimizing some error function on the development set. We have evaluated our strategy on Chinese Proposition Bank data set. With our minimum error weighting strategy, the F 1 score of the combined result achieves 80.45%, which is 1.12% higher than baseline combination method's result, and 4.90% higher than the best individual system's result.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>In recent years, Chinese Semantic Role Labeling has received much research effort <ref type="bibr" target="#b13">(Sun and Jurafsky, 2004;</ref><ref type="bibr" target="#b18">Xue, 2008;</ref><ref type="bibr" target="#b1">Che et al., 2008;</ref><ref type="bibr" target="#b3">Ding and Chang, 2008;</ref><ref type="bibr" target="#b14">Sun et al., 2009;</ref><ref type="bibr" target="#b8">Li et al., 2009)</ref>. And Chinese SRL is also included in CoNLL-2009 shared task <ref type="bibr" target="#b4">(Hajič et al., 2009</ref>). On the data set used in <ref type="bibr" target="#b18">(Xue, 2008)</ref>, the F 1 score of the SRL results using automatic syntactic analysis is still in low 70s <ref type="bibr" target="#b18">(Xue, 2008;</ref><ref type="bibr" target="#b1">Che et al., 2008;</ref><ref type="bibr" target="#b14">Sun et al., 2009</ref>). As pointed out by Xue <ref type="bibr" target="#b18">(Xue, 2008)</ref>, the SRL errors are mainly caused by the errors in automatic syntactic analysis. In fact, Chinese SRL suffers from parsing errors even more than English SRL, because the state-of-the-art parser for Chinese is still not as good as that for English. And previous research on English SRL shows that combination is a robust and effective method to alleviate SRL's dependency on parsing results <ref type="bibr" target="#b9">(Màrquez et al., 2005;</ref><ref type="bibr" target="#b6">Koomen et al., 2005;</ref><ref type="bibr" target="#b11">Pradhan et al., 2005;</ref><ref type="bibr" target="#b15">Surdeanu et al., 2007;</ref><ref type="bibr" target="#b16">Toutanova et al., 2008)</ref>. However, the effect of combination for Chinese SRL task is still unknown. This raises two questions at least: (1) How much can Chinese SRL benefit from combination? (2) Can existing combination strategies be improved? All existing combination strategies trust each individual system's output with the same confidence when putting them into a pool of candidates. But according to our intuition, different systems have different performance. And the system that have better performance should be trusted with more confidence. We can use our prior knowledge about the combined systems to do a better combination.</p><p>The observations above motivated the work in this paper. Instead of directly merging outputs with equal weights, different outputs are assigned different weights in our approach. An output's weight stands for the confidence we have in that output. We acquire these weights by minimizing an error function on the development set. And we use these weights to merge the outputs. In this paper, outputs are generated by a full parsing based Chinese SRL system and a shallow parsing based SRL system. The full parsing based system use multiple parse trees to generate multiple SRL outputs. Whereas the shallow parsing based system only produce one SRL output. After merging all SRL outputs, we use greedy and integer linear programming combination methods to combine the merged outputs.</p><p>We have evaluated our combination strategy on Chinese Propbank data set used in <ref type="bibr" target="#b18">(Xue, 2008)</ref> and get encouraging results. With our minimum error weighting (MEW) strategy, the F 1 score of the combined result achieves 80.45%. This is a significant improvement over the best reported SRL performance on this data set, which is 74.12% in the literature <ref type="bibr" target="#b14">(Sun et al., 2009)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Related work</head><p>A lot of research has been done on SRL combination. Most of them focused on English SRL task. But the combination methods are general. And they are closely related to the work in this paper. <ref type="bibr" target="#b12">Punyakanok et al. (2004)</ref> formulated an Integer Linear Programming (ILP) model for SRL. Based on that work, <ref type="bibr" target="#b6">Koomen et al. (2005)</ref> combined several SRL outputs using ILP method. <ref type="bibr" target="#b9">Màrquez et al. (2005)</ref> proposed a combination strategy that does not require the individual system to give a score for each argument. They used a binary classifier to filter different systems' outputs. Then they used a greedy method to combine the candidates that pass the filtering process. <ref type="bibr" target="#b11">Pradhan et al. (2005)</ref> combined systems that are based on phrase-structure parsing, dependency parsing, and shallow parsing. They also used greedy method when combining different outputs. <ref type="bibr" target="#b15">Surdeanu et al. (2007)</ref> did a complete research on a variety of combination strategies. All these research shows that combination can improve English SRL performance by 2∼5 points on F 1 score. However, little is known about how much Chinese SRL can benefit from combination. And, as we will show, existing combination strategies can still be improved.</p><p>3 Individual SRL Systems</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Full Parsing Based System</head><p>The full parsing based system utilize full syntactic analysis to perform semantic role labeling.</p><p>We implemented a Chinese semantic role labeling system similar to the one described in <ref type="bibr" target="#b18">(Xue, 2008)</ref>. Our system consists of an argument identification stage and an argument classification stage. In the argument identification stage, a number of argument locations are identified in a sentence. In the argument classification stage, each location identified in the first stage is assigned a semantic role label. The features used in this paper are the same with those used in <ref type="bibr" target="#b18">(Xue, 2008)</ref>.</p><p>Maximum entropy classifier is employed for both the argument identification and classification tasks. And Zhang Le's MaxEnt toolkit 1 is used for implementation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Shallow Parsing Based System</head><p>The shallow parsing based system utilize shallow syntactic information at the level of phrase chunks to perform semantic role labeling. <ref type="bibr" target="#b14">Sun et al. (2009)</ref> proposed such a system on Chinese SRL and reported encouraging results. The system used in this paper is based on their approach. For Chinese chunking, we adopted the method used in <ref type="bibr" target="#b2">(Chen et al., 2006)</ref>, in which chunking is regarded as a sequence labeling task with IBO2 representation. The features used for chunking are the uni-gram and bi-gram word/POS tags with a window of size 2. The SRL task is also regarded as a sequence labeling problem. For an argument with label ARG*, we assign the label B-ARG* to its first chunk, and the label I-ARG* to its rest chunks. The chunks outside of any argument are assigned the label O. The features used for SRL are the same with those used in the onestage method in <ref type="bibr" target="#b14">(Sun et al., 2009)</ref>.</p><p>In this paper, we employ Tiny SVM along with Yamcha <ref type="bibr" target="#b7">(Kudo and Matsumoto, 2001)</ref> for Chinese chunking, and CRF++ 2 for SRL.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Individual systems' outputs</head><p>The maximum entropy classifier used in full parsing based system and the CRF model used in shallow paring based system can both output classification probabilities. For the full parsing based system, the classification probability of the ar-gument classification stage is used as the argument's probability. Whereas for the shallow parsing based system, an argument is usually comprised of multiple chunks. For example, an argument with label ARG0 may contain three chunks labeled as: B-ARG0, I-ARG0, I-ARG0. And each chunk has a label probability. Thus we have three probabilities p 1 , p 2 , p 3 for one argument. In this case, we use the geometric mean of individual chunks' probabilities (p 1 · p 2 · p 3 ) 1/3 as the argument's probability.</p><p>As illustrated in <ref type="figure">Figure 1</ref>, in an individual system's output, each argument has three attributes: its location in sentence loc, represented by the number of its first word and last word; its semantic role label l; and its probability p.</p><p>Sent:</p><formula xml:id="formula_0">Args: [ ARG0 ] [pred] [ ARG1 ] loc: (0, 2) (4, 7) l: ARG0 ARG1 p: 0.94 0.92</formula><p>Figure 1: Three attributes of an output argument: location loc, label l, and probability p.</p><p>So each argument outputted by a system is a triple (loc, l, p). For example, the ARG0 in Figure 1 is ((0, 2), ARG0, 0.94). Because the outputs of baseline systems are to be combined, we call such triple a candidate for combination.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Approach Overview</head><p>As illustrated in <ref type="figure" target="#fig_0">Figure 2</ref>, the architecture of our system consists of a candidates generation stage, a weighted merging stage, and a combination stage. In the candidates generation stage, the baseline systems are run individually and their outputs are collected. We use 2-best parse trees of Berkeley parser <ref type="bibr" target="#b10">(Petrov and Klein, 2007)</ref> and 1-best parse tree of Bikel parser <ref type="bibr" target="#b0">(Bikel, 2004)</ref> and Stanford parser  as inputs to the full parsing based system. The second best parse tree of Berkeley parser is used here for its good quality. So together we have four different outputs from the full parsing based system. From the shallow parsing based system, we have only one output. In the weighted merging stage, each system output is assigned a weight according to our prior knowledge obtained on the development set. Details about how to obtain appropriate weights will be explained in Section 6. Then all candidates with the same loc and l are merged to one by weighted summing their probabilities. Specifically, suppose that there are n system outputs to be combined, with the i-th output's weight to be w i . And the candidate in the i-th output with loc and l is (loc, l, p i ) (If there is no candidate with loc and l in the i-th output, p i is 0.). Then the merged candidate is (loc, l, p),</p><formula xml:id="formula_1">where p = n i=1 w i p i .</formula><p>After the merging stage, a pool of merged candidates is obtained. In the combination stage, candidates in the pool are combined to form a consistent SRL result. Greedy and integer linear programming combination methods are experimented in this paper.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Combination Methods</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Global constraints</head><p>When combining the outputs, two global constraints are enforced to resolve the conflict between outputs. These two constraints are:</p><p>1. No duplication: There is no duplication for key arguments: ARG0 ∼ ARG5.</p><p>2. No overlapping: Arguments cannot overlap with each other.</p><p>We say two argument candidates conflict with each other if they do not satisfy the two constraints above.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Two combination methods</head><p>Under these constraints, two methods are explored to combine the outputs. The first one is a greedy method. In this method, candidates with probability below a threshold are deleted at first. Then the remaining candidates are inspected in descending order according to their probabilities. And each candidate will be put into a solution set if it does not conflict with candidates already in the set. This greedy combination method is very simple and has been adopted in previous research <ref type="bibr" target="#b11">(Pradhan et al., 2005;</ref><ref type="bibr" target="#b9">Màrquez et al., 2005)</ref>.</p><p>The second combination method is integer linear programming (ILP) method. ILP method was first applied to SRL in <ref type="bibr" target="#b12">(Punyakanok et al., 2004)</ref>. Here we formulate an ILP model whose form is different from the model in <ref type="bibr" target="#b12">(Punyakanok et al., 2004;</ref><ref type="bibr" target="#b6">Koomen et al., 2005)</ref>. For convenience, we denote the whole label set as {l 1 , l 2 , . . . , l n }. And let l 1 ∼ l 6 stand for the key argument labels ARG0 ∼ ARG5 respectively. Suppose there are m different locations, denoted as loc 1 , . . . , loc m , among all candidates in the pool. And the probability of assigning l j to loc i is p ij . A binary variable x ij is defined as:</p><formula xml:id="formula_2">x ij = 1 if loc i is assigned label l j , 0 otherwise.</formula><p>The objective of the ILP model is to maximize the sum of arguments' probabilities:</p><formula xml:id="formula_3">max m i=1 n j=1 (p ij − T )x ij<label>(1)</label></formula><p>where T is a threshold to prevent including too many candidates in solution. T is similar to the threshold in greedy combination method. In this paper, both thresholds are empirically tuned on development data, and both are set to be 0.2. The inequalities in equation (2) make sure that each loc is assigned at most one label.</p><formula xml:id="formula_4">∀1 ≤ i ≤ m : n j=1 x ij ≤ 1<label>(2)</label></formula><p>The inequalities in equation <ref type="formula" target="#formula_5">(3)</ref> satisfy the No duplication constraint.</p><formula xml:id="formula_5">∀1 ≤ j ≤ 6 : m i=1 x ij ≤ 1<label>(3)</label></formula><p>For any location loc i , let C i denote the index set of the locations that overlap with it. Then the No overlapping constraint means that if loc i is assigned a label, i.e., n j=1 x ij = 1, then for any k ∈ C i , loc k cannot be assigned any label, i.e., n j=1 x kj = 0. A common technique in ILP modeling to form such a constraint is to use a sufficiently large auxiliary constant M . And the constraint is formulated as:</p><formula xml:id="formula_6">∀1 ≤ i ≤ m : k∈C i n j=1 x kj ≤ (1 − n j=1 x ij )M (4)</formula><p>In this case, M only needs to be larger than the number of candidates to be combined. In this paper, M = 500 is large enough. And we employ lpsolve 3 to solve the ILP model.</p><p>Note that the form of the ILP model in this paper is different from that in <ref type="bibr" target="#b12">(Punyakanok et al., 2004;</ref><ref type="bibr" target="#b6">Koomen et al., 2005)</ref> in three aspects: (1) A special label class null, which means no label is assigned, was added to the label set in <ref type="bibr" target="#b12">(Punyakanok et al., 2004;</ref><ref type="bibr" target="#b6">Koomen et al., 2005)</ref>. Whereas no such special class is needed in our model, because if no label is assigned to loc i , with the greedy combination method, the ILP model in this paper conforms to exactly the same constraints as the greedy method. Whereas many more global constraints were taken into account in <ref type="bibr" target="#b12">(Punyakanok et al., 2004;</ref><ref type="bibr" target="#b6">Koomen et al., 2005)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Train Minimum Error Weights</head><p>The idea of minimum error weighting is straightforward.</p><p>Individual outputs O 1 , O 2 , . . . , O n are assigned weights w 1 , w 2 , . . . , w n respectively. These weights are normalized, i.e., n i=1 w i = 1. An output's weight can be seen as the confidence we have in that output. It is a kind of prior knowledge we have about that output. We can gain this prior knowledge on the development set. As long as the data of the development set and the test set are similar, this prior knowledge should be able to help to guide SRL combination on test set. In this section, we discuss how to obtain appropriate weights.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.1">Training model</head><p>Suppose the golden answer and SRL result on development set are d and r respectively. An error function Er(r, d) is a function that measures the error contained in r in reference to d. An error function can be defined as the number of wrong arguments in r. It can also be defined using precision, recall, or F 1 score. For example, Er(r, d) = 1 − P recision(r, d), or Er(r, d) = 1 − F 1 (r, d).</p><p>Smaller value of error function means less error in r.</p><p>The combination process can also be seen as a function, which maps the outputs and weights to the combined result r: r = Comb(O n 1 , w n 1 ). Therefore, the error function of our system on development set is:</p><formula xml:id="formula_7">Er(r, d) = Er(Comb(O n 1 , w n 1 ), d)<label>(5)</label></formula><p>From equation <ref type="formula" target="#formula_7">(5)</ref>, it can be seen that: Given development set d, if the outputs to be combined O n 1 and the combination method Comb are fixed, the error function is just a function of the weights. So we can obtain appropriate weights by minimizing the error function: w 1 ← w 6:</p><formula xml:id="formula_8">w n 1 = arg min w n 1 Er(Comb(O n 1 , w n 1 ), d)<label>(6)</label></formula><p>for i ← 1, . . . , n: 7:</p><formula xml:id="formula_9">α i ← arg min α f (w i + αd i ) 8: w i+1 ← w i + α i d i 9: d n+1 ← w n+1 − w 10: α * ← arg min α f (w + αd n+1 ) 11: w ← w + α * d n+1 12:</formula><p>∆Er ← Er(w) − Er(w ) 13:</p><formula xml:id="formula_10">i ← arg max 1≤j≤n Er(w j ) − Er(w j+1 ) 14: if (α * ) 2 ≥ ∆Er Er(wi) − Er(wi+1) : 15:</formula><p>for j ← i, . . . , n: 16:</p><formula xml:id="formula_11">d j ← d j+1 17:</formula><p>w ← w 18: while ∆Er &gt; δ 19: Output: The minimum error weights w.</p><p>There are two difficulties to solve the optimization problem in equation 6. The first one is that the error function cannot be written to an analytical form. This is because the Comb function, which stands for the combination process, cannot be written as an analytical formula. So the problem cannot be solved using canonical gradientbased optimization algorithms, because the gradient function cannot be derived. The second difficulty is that, according to our experience, the error function has many local optima, which makes it difficult to find a global optima.</p><p>To resolve the first difficulty, Modified Powell's method <ref type="bibr" target="#b19">(Yuan, 1993</ref>) is employed to solve the optimization problem. Powell's method is a heuristic search method that does not require the objective function to have an explicit analytical form. The training algorithm is presented in Algorithm 1. In Algorithm 1, the line search problem in steps 7 and 10 is solved using Brent's method <ref type="bibr" target="#b19">(Yuan, 1993)</ref>. And the temination threshold δ is empirically set to be 0.001 in this paper.</p><p>To resolve the second difficulty, we perform multiple searches using different start points, and then choose the best solution found.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">Experiments</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.1">Experimental setup</head><p>We use Chinese Proposition Bank (CPB) 1.0 and Chinese Tree Bank (CTB) 5.0 of Linguistic Data Consortium corpus in our experiments. The training set is comprised of 648 files(chtb 081.fid to chtb 885.fid). The development set is comprised of 40 files(chtb 041.fid to chtb 080.fid). The test set is comprised of 72 files(chtb 001.fid to chtb 040.fid and chtb 900.fid to chtb 931.fid).</p><p>The same data setting has been used in <ref type="bibr" target="#b18">(Xue, 2008;</ref><ref type="bibr" target="#b3">Ding and Chang, 2008;</ref><ref type="bibr" target="#b14">Sun et al., 2009</ref>). <ref type="bibr" target="#b14">Sun et al. (2009)</ref> used sentences with golden segmentation and POS tags as input to their SRL system. However, we use sentences with only golden segmentation as input. Then we perform automatic POS tagging using Stanford POS tagger <ref type="bibr" target="#b17">(Toutanova et al., 2003)</ref>. In <ref type="bibr" target="#b18">(Xue, 2008)</ref>, the parser used by the SRL system is trained on the training and development set plus 275K words of broadcast news. In this paper, all parsers used by the full parsing based system are trained on the training set plus the broadcast news portion of CTB6.0. And the chunker used in the shallow parsing based system is trained just on the training set.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.2">Individual outputs' performance</head><p>In this paper the four outputs of the full parsing based system are represented by FO1 ∼ FO4 respectively. Among them, FO1 and FO2 are the outputs using the first and second best parse trees of Berkeley parser, FO3 and FO4 are the outputs using the best parse trees of Stanford parser and Bikel parser respectively. The output of the shallow parsing based system is represented by SO. The individual outputs' performance on development and test set are listed in <ref type="table">Table 1</ref>.</p><p>From <ref type="table">Table 1</ref> we can see that the performance of individual outputs are similar on development set and test set. On both sets, the F 1 scores of individual outputs are in the same order: FO1 &gt; FO2 &gt; SO &gt; FO3 &gt; FO4.  <ref type="table">Table 1</ref>: The results of individual systems on development and test set.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.3">Combining outputs of full parsing based system</head><p>In order to investigate the benefit that the full parsing based system can get from using multiple parsers, we combine the four outputs FO1 ∼ FO4. The combination results are listed in Table 2. In tables of this paper, "Grd" and "ILP" stand for greedy and ILP combination methods respectively, and "+MEW" means the combination is performed with MEW strategy.    <ref type="table">Table 3</ref>: The minimum error weights for the results in <ref type="table" target="#tab_3">Table 2</ref>.</p><formula xml:id="formula_12">P (%) R(%) F1 Grd</formula><p>From <ref type="table" target="#tab_3">Table 2 and Table 1</ref>, we can see that, without MEW strategy, the F 1 score of combination result is about 2.3% higher than the best individual output. With MEW strategy, the F 1 score is improved about 0.5% further. That is to say, with MEW strategy, the benefit of combination is improved by about 20%. Therefore, the effect of MEW is very encouraging.</p><p>Here the error function for MEW training is chosen to be 1 − F 1 . And the trained weights for greedy and ILP methods are listed in <ref type="table">Table 3</ref> separately. In tables of this paper, the column Er corresponds to the error function used for MEW strategy.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.4">Combining all outputs</head><p>We have also combined all five outputs. The results are listed in <ref type="table">Table 4</ref>. Compared with the results in <ref type="table" target="#tab_3">Table 2</ref>, we can see that the combination results is largely improved, especially the recall.  <ref type="table">Table 4</ref>: The results of combining all outputs on test set.</p><formula xml:id="formula_13">P (%) R(%) F1</formula><p>From <ref type="table">Table 4</ref> and <ref type="table">Table 1</ref> we can see that without MEW strategy, the F 1 score of combination result is about 3.8% higher than the best individual output. With MEW, the F 1 score is improved further by more than 1%. That means the benefit of combination is improved by over 25% with MEW strategy.</p><p>Here the error function for MEW training is still 1 − F 1 , and the trained weights are listed in <ref type="table">Table 5</ref>.  <ref type="table">Table 5</ref>: The minimum error weights for the results in <ref type="table">Table 4</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.5">Using alternative error functions for minimum error weights training</head><p>In previous experiments, we use 1 − F 1 as error function. As pointed out in Section 6, the definition of error function is very general. So we have experimented with two other error functions, which are 1 − P recision, and 1 − Recall. Obviously, these two error functions favor precision and recall separately. The results of combining all five outputs using these two error functions are listed in <ref type="table" target="#tab_6">Table 6</ref>, and the trained weights are listed in <ref type="table">Table 7</ref>. From <ref type="table" target="#tab_6">Table 6</ref> and <ref type="table">Table 4</ref>, we can see that when 1 − P recison is used as error function, the pre-    <ref type="table">Table 7</ref>: The minimum error weights for the results in <ref type="table" target="#tab_6">Table 6</ref>. cision of combination result is largely improved. But the recall decreases a lot. Similar effect of the error function 1 − Recall is also observed.</p><formula xml:id="formula_14">Er P (%) R(%) F1 Grd+MEW 1 − P 85</formula><p>The results of this subsection reflect the flexibility of MEW strategy. This flexibility comes from the generality of the definition of error function. The choice of error function gives us some control over the results we want to get. We can define different error functions to favor precision, or recall, or some error counts such as the number of misclassified arguments.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.6">Discussion</head><p>In this paper, the greedy and ILP combination methods conform to the same simple constraints specified in Section 5. From the experiment results, we can see that ILP method generates slightly better results than greedy method.</p><p>In Subsection 7.4, we see that combining all outputs using ILP method with MEW strategy yields 4.90% improvement on F 1 score over the best individual output FO1. In order to understand each output's contribution to the improvement over FO1. We compare the differences between outputs.</p><p>Let C O denote the set of correct arguments in an output O. Then we get the following statistics when comparing two outputs A and B: (1) the number of common correct arguments in A and B, i.e., |C A ∩ C B | ; (2) the number of correct arguments in A and not in B, i.e., |C A \ C B |; (3) the number of correct arguments in B and not in A, i.e., |C B \ C A |. The comparison results between some outputs on test set are listed in <ref type="table" target="#tab_8">Table 8</ref>  From <ref type="table" target="#tab_8">Table 8</ref> we can see that the output SO has 4826 common correct arguments with FO1, which is relatively small. And, more importantly, SO contains 920 correct arguments not in FO1, which is much more than any other output contains. Therefore, SO is more complementary to FO1 than other outputs. On the contrary, FO2 is least complementary to FO1. Even compared with the union of FO1 ∼ FO4, SO still contains 435 correct arguments not in the union. This shows that the output of shallow parsing based system is a good complement to the outputs of full parsing based system. This explains why recall is largely improved when SO is combined in Subsection 7.4. From the analysis above we can also see that the weights in <ref type="table">Table 5</ref> are quite reasonable. In Table 5, SO is assigned the largest weight and FO2 is assigned the smallest weight.</p><p>In Subsection 7.3, the MEW strategy improves the benefit of combination by about 20%. And in Subsection 7.4, the MEW strategy improves the benefit of combination by over 25%. This shows that the MEW strategy is very effective for Chinese SRL combination.</p><p>To our best knowledge, no results on Chinese SRL combination has been reported in the literature. Therefore, to compare with previous results, the top two results of single SRL system in the literature and the result of our combination system on this data set are listed in <ref type="table">Table 9</ref>. For the results in <ref type="table">Table 9</ref>, the system of Sun et al. uses sentences with golden POS tags as input. Xue's system and our system both use sentences with automatic POS tags as input. The result of <ref type="bibr" target="#b14">Sun et al. (2009)</ref> is the best reported result on this data set in the literature.  <ref type="table">Table 9</ref>: Previous best single system's results and our combination system's result on this data set.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8">Conclusions</head><p>In this paper, we propose a minimum error weighting strategy for SRL combination and investigate the benefit that Chinese SRL can get from combination. We assign different weights to different system outputs and add a weighted merging stage to conventional SRL combination system architecture. And we also propose a method to train these weights on development set. We evaluate the MEW strategy on Chinese Propbank data set with greedy and ILP combination methods.</p><p>Our experiments have shown that the MEW strategy is very effective for Chinese SRL combination, and the benefit of combination can be improved over 25% with this strategy. And also, the MEW strategy is very flexible. With different definitions of error function, this strategy can favor precision, or recall, or F 1 score. The experiments have also shown that Chinese SRL can benefit a lot from combination, especially when systems based on different syntactic views are combined. The SRL result with the highest F 1 score in this paper is generated by ILP combination together with MEW strategy. In fact, the MEW strategy is easy to incorporate with other combination methods, just like incorporating with the greedy and ILP combination methods in this paper.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: The overall architecture of our system.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head></head><label></label><figDesc>ij = 0 would simply indicate this case. This makes our model contain fewer variables. (2) Without null class in our model, we need to use a different technique to formulate the No- overlapping constraint. (3) In order to compare</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" validated="false"><head>Table 2 :</head><label>2</label><figDesc>The results of combining outputs of full parsing based system on test set.</figDesc><table></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6" validated="false"><head>Table 6 :</head><label>6</label><figDesc>The results of combining all outputs with alternative error functions.</figDesc><table></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7" validated="false"><head></head><label></label><figDesc>. In this table, UF stands for the union of the 4 outputs FO1 ∼ FO4.</figDesc><table>A 
B 
|CA ∩ CB| |CA \ CB| |CB \ CA| 
FO2 
5498 
508 
372 
FO3 
5044 
962 
552 
FO4 
4815 
1191 
512 
FO1 

SO 
4826 
1180 
920 
UF 
SO 
5311 
1550 
435 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_8" validated="false"><head>Table 8 :</head><label>8</label><figDesc>Comparison between outputs on test set.</figDesc><table></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1">http://homepages.inf.ed.ac.uk/lzhang10/maxent toolkit .html 2 http://crfpp.sourceforge.net/</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3">http://lpsolve.sourceforge.net/</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgment</head><p>The research work has been partially funded by the Natural Science </p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Intricacies of Collins Parsing Model</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Bikel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computational Linguistics</title>
		<imprint>
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="480" to="511" />
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Using a Hybrid Convolution Tree Kernel for Semantic Role Labeling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wanxiang</forename><surname>Che</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Min</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ai</forename><forename type="middle">Ti</forename><surname>Aw</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chew</forename><surname>Lim Tan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ting</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sheng</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Transactions on Asian Language Information Processing</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="issue">4</biblScope>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">An empirical study of Chinese chunking</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wenliang</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yujie</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hitoshi</forename><surname>Isahara</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of COLING/ACL-2006</title>
		<meeting>COLING/ACL-2006</meeting>
		<imprint>
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Improving Chinese Semantic Role Classification with Hierarchical Feature Selection Strategy</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Weiwei</forename><surname>Ding</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Baobao</forename><surname>Chang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of EMNLP-2008</title>
		<meeting>EMNLP-2008</meeting>
		<imprint>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">The CoNLL-2009 Shared Task: Syntactic and Semantic Dependencies in Multiple Languages</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jan</forename><surname>Hajič</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Massimiliano</forename><surname>Ciaramita</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Johansson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daisuke</forename><surname>Kawahara</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maria</forename><forename type="middle">Antònia</forename><surname>Martí</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lluís</forename><surname>Màrquez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adam</forename><surname>Meyers</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joakim</forename><surname>Nivre</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sebastian</forename><surname>Padó</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pavel</forename><surname>Janštěpánek</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mihai</forename><surname>Straňák</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nianwen</forename><surname>Surdeanu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yi</forename><surname>Xue</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of CoNLL-2009</title>
		<meeting>CoNLL-2009</meeting>
		<imprint>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Accurate unlexicalized parsing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Klein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><forename type="middle">D</forename><surname>Manning</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ACL-2003</title>
		<meeting>ACL-2003</meeting>
		<imprint>
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Generalized Inference with Multiple Semantic Role Labeling Systems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vasin</forename><surname>Peter Koomen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Punyakanok</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wen-Tau</forename><surname>Roth</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Yih</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of CoNLL-2005 shared task</title>
		<meeting>CoNLL-2005 shared task</meeting>
		<imprint>
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Chunking with Support Vector Machines</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Taku</forename><surname>Kudo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuji</forename><surname>Matsumoto</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of NAACL</title>
		<meeting>NAACL</meeting>
		<imprint>
			<date type="published" when="2001" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Improving Nominal SRL in Chinese Language with Verbal SRL Information and Automatic Predicate Recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Junhui</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guodong</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hai</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qiaoming</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peide</forename><surname>Qian</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of EMNLP</title>
		<meeting>EMNLP</meeting>
		<imprint>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">A Robust Combination Strategy for Semantic Role Labeling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lluís</forename><surname>Màrquez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mihai</forename><surname>Surdeanu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pere</forename><surname>Comas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jordi</forename><surname>Turmo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of EMNLP-2005</title>
		<meeting>EMNLP-2005</meeting>
		<imprint>
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Improved Inference for Unlexicalized parsing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Slav</forename><surname>Petrov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Klein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ACL-2007</title>
		<meeting>ACL-2007</meeting>
		<imprint>
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Semantic Role Labeling Using Different Syntactic Views</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Sameer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wayne</forename><surname>Pradhan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kadri</forename><surname>Ward</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">James</forename><forename type="middle">H</forename><surname>Hacioglu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Martin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Jurafsky</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ACL-2005</title>
		<meeting>ACL-2005</meeting>
		<imprint>
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Semantic Role Labeling via Integer Linear Programming Inference</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vasin</forename><surname>Punyakanok</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Roth</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wen-Tau</forename><surname>Yih</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dav</forename><surname>Zimak</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of COLING-2004</title>
		<meeting>COLING-2004</meeting>
		<imprint>
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Shallow semantic parsing of Chinese</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Honglin</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Jurafsky</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of NAACL-2004</title>
		<meeting>NAACL-2004</meeting>
		<imprint>
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Chinese Semantic Role Labeling with Shallow Parsing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Weiwei</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhifang</forename><surname>Sui</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Meng</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xin</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of EMNLP-2009</title>
		<meeting>EMNLP-2009</meeting>
		<imprint>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Combination Strategies for Semantic Role Labeling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mihai</forename><surname>Surdeanu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lluís</forename><surname>Màrquez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xavier</forename><surname>Carreras</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pere</forename><forename type="middle">R</forename><surname>Comas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Artificial Intelligence Research (JAIR)</title>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="page" from="105" to="151" />
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">A Global Joint Model for Semantic Role Labeling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kristina</forename><surname>Toutanova</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aria</forename><surname>Haghighi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><forename type="middle">D</forename><surname>Manning</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computational Linguistics</title>
		<imprint>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="145" to="159" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Feature-Rich Part-ofSpeech Tagging with a Cyclic Dependency Network</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kristina</forename><surname>Toutanova</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Klein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><surname>Manning</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoram</forename><surname>Singer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of HLT-NAACL-2003</title>
		<meeting>HLT-NAACL-2003</meeting>
		<imprint>
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Labeling Chinese Predicates with Semantic Roles</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nianwen</forename><surname>Xue</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computational Linguistics</title>
		<imprint>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="225" to="255" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
		<title level="m" type="main">Numerical Methods for Nonlinear Programming. Shanghai Scientific and Technical Pulishers</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yaxiang</forename><surname>Yuan</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1993" />
			<pubPlace>Shanghai</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
