<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 D:\Work\grobid-master\grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.5" ident="GROBID" when="2019-07-07T09:44+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Improving Graph-based Dependency Parsing with Decision History</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date type="published" when="2010-08">August 2010</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wenliang</forename><surname>Chen</surname></persName>
							<email>chenwl@nict.go.jp‡</email>
							<affiliation key="aff0">
								<orgName type="department">School of Information Science</orgName>
								<orgName type="laboratory">Language Infrastructure Group</orgName>
								<orgName type="institution" key="instit1">MASTAR Project</orgName>
								<orgName type="institution" key="instit2">JAIST</orgName>
								<address>
									<region>NICT</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Jun&amp;apos;ichi Kazama</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">School of Information Science</orgName>
								<orgName type="laboratory">Language Infrastructure Group</orgName>
								<orgName type="institution" key="instit1">MASTAR Project</orgName>
								<orgName type="institution" key="instit2">JAIST</orgName>
								<address>
									<region>NICT</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshimasa</forename><surname>Tsuruoka</surname></persName>
							<email>tsuruoka@jaist.ac.jp</email>
							<affiliation key="aff0">
								<orgName type="department">School of Information Science</orgName>
								<orgName type="laboratory">Language Infrastructure Group</orgName>
								<orgName type="institution" key="instit1">MASTAR Project</orgName>
								<orgName type="institution" key="instit2">JAIST</orgName>
								<address>
									<region>NICT</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kentaro</forename><surname>Torisawa</surname></persName>
							<email>torisawa@nict.go.jp‡</email>
							<affiliation key="aff0">
								<orgName type="department">School of Information Science</orgName>
								<orgName type="laboratory">Language Infrastructure Group</orgName>
								<orgName type="institution" key="instit1">MASTAR Project</orgName>
								<orgName type="institution" key="instit2">JAIST</orgName>
								<address>
									<region>NICT</region>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Improving Graph-based Dependency Parsing with Decision History</title>
					</analytic>
					<monogr>
						<title level="m">Coling 2010: Poster Volume</title>
						<meeting> <address><addrLine>Beijing</addrLine></address>
						</meeting>
						<imprint>
							<biblScope unit="page" from="126" to="134"/>
							<date type="published" when="2010-08">August 2010</date>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Abstract</head><p>This paper proposes an approach to improve graph-based dependency parsing by using decision history. We introduce a mechanism that considers short dependencies computed in the earlier stages of parsing to improve the accuracy of long dependencies in the later stages. This relies on the fact that short dependencies are generally more accurate than long dependencies in graph-based models and may be used as features to help parse long dependencies. The mechanism can easily be implemented by modifying a graphbased parsing model and introducing a set of new features. The experimental results show that our system achieves state-ofthe-art accuracy on the standard PTB test set for English and the standard Penn Chinese Treebank (CTB) test set for Chinese.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Dependency parsing is an approach to syntactic analysis inspired by dependency grammar. In recent years, interest in this approach has surged due to its usefulness in such applications as machine translation <ref type="bibr" target="#b15">(Nakazawa et al., 2006)</ref>, information extraction <ref type="bibr" target="#b5">(Culotta and Sorensen, 2004)</ref>.</p><p>Graph-based parsing models <ref type="bibr" target="#b12">(McDonald and Pereira, 2006;</ref><ref type="bibr" target="#b1">Carreras, 2007)</ref> have achieved state-of-the-art accuracy for a wide range of languages as shown in recent CoNLL shared tasks <ref type="bibr" target="#b0">(Buchholz et al., 2006;</ref><ref type="bibr" target="#b18">Nivre et al., 2007)</ref>. However, to make parsing tractable, these models are forced to restrict features over a very limited history of parsing decisions <ref type="bibr" target="#b12">(McDonald and Pereira, 2006;</ref><ref type="bibr" target="#b11">McDonald and Nivre, 2007)</ref>. Previous work showed that rich features over a wide range of decision history can lead to significant improvements in accuracy for transition-based models <ref type="bibr" target="#b21">(Yamada and Matsumoto, 2003a;</ref><ref type="bibr" target="#b17">Nivre et al., 2004)</ref>.</p><p>In this paper, we propose an approach to improve graph-based dependency parsing by using decision history. Here, we make an assumption: the dependency relations between words with a short distance are more reliable than ones between words with a long distance. This is supported by the fact that the accuracy of short dependencies is in general greater than that of long dependencies as reported in <ref type="bibr" target="#b11">McDonald and Nivre (2007)</ref> for graph-based models. Our idea is to use decision history, which is made in previous scans in a bottom-up procedure, to help parse other words in later scans. In the bottom-up procedure, short dependencies are parsed earlier than long dependencies. Thus, we introduce a mechanism in which we treat short dependencies built earlier as decision history to help parse long dependencies in later stages. It can easily be implemented by modifying a graph-based parsing model and designing a set of features for the decision history.</p><p>To demonstrate the effectiveness of the proposed approach, we present experimental results on English and Chinese data. The results indicate that the approach greatly improves the accuracy and that richer history-based features indeed make large contributions. The experimental results show that our system achieves state-of-theart accuracy on the data.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Motivation</head><p>In this section, we present an example to show the idea of using decision history in a dependency parsing procedure.</p><p>Suppose we have two sentences in Chinese, as shown in <ref type="figure" target="#fig_0">Figures 1 and 2</ref>, where the correct dependencies are represented by the directed links. For example, in <ref type="figure">Figure 1</ref> the directed link from w 3 :买(bought) to w 5 :书(books) mean that w 3 is the head and w 5 is the dependent. In Chinese, the relationship between clauses is often not made explicit and two clauses may simply be put together with only a comma <ref type="bibr" target="#b9">(Li and Thompson, 1997)</ref>. This makes it hard to parse Chinese sentences with several clauses.</p><p>ROOT (last year) (I) (bought) (NULL) (books) (,) (this year) (he) (also) (bought) (NULL) (books) w1 w2 w3 w4 w5 w6 w7 w8 w9 w10 w11 w12 (Last year I bought some books and this year he also bought some books.) <ref type="figure">Figure 1</ref>: Example A ROOT (last year) (I) (bought) (NULL) (books) (,) (this year) (also) (bought) (NULL) (books) w1 w2 w3 w4 w5 w6 w7 w8 w9 w10 w11 (Last year I bought some books and this year too) (Last year I bought some books and this year too) If we employ a graph-based parsing model, such as the model of <ref type="bibr" target="#b12">(McDonald and Pereira, 2006;</ref><ref type="bibr" target="#b1">Carreras, 2007)</ref>, it is difficult to assign the relations between w 3 and w 10 in Example A and between w 3 and w 9 in Example B. For simplicity, we use w A i to refer to w i of Example A and w B i to refer to w i of Example B in what follows.</p><p>The key point is whether the second clauses are independent in the sentences. The two sentences are similar except that the second clause of Example A is an independent clause but that of Example B is not. w A 10 is the root of the second clause of Example A with subject w A 8 , while w B 9 is the root of the second clause of Example B, but the clause does not have a subject. These mean that the correct decisions are to assign w A 10 as the head of w A 3 and w B 3 as the head of w B 9 , as shown by the dash-dot-lines in <ref type="figure" target="#fig_0">Figures 1 and 2</ref> (last year) (I) (bought) (NULL) (books) (,) (this year) (he) (also) (bought) (NULL) (books) w1 w2 w3 w4 w5 w6 w7 w8 w9 w10 w11 w12</p><p>Figure 5: Example A: first step Then given those inside relations, we choose the inside structure with the highest score for each direction of the dependency relation between w A 3 and w A 10 . <ref type="figure">Figure 6</ref> shows the chosen structures. Note that the chosen structures for two directions could either be identical or different. In <ref type="figure">Figure  6</ref>-(a) and -(b), they are different.</p><p>(last year) (I) (bought) (NULL) (books) (,) (this year) (he) (also) (bought) (NULL) (books) w1 w2 w3 w4 w5 w6 w7 w8 w9 w10 w11 w12</p><p>(a) w1 w2 w3 w4 w5 w6 w7 w8 w9 w10 w11 w12</p><p>(b) (last year) (I) (bought) (NULL) (books) (,) (this year) (he) (also) (bought) (NULL) (books) w1 w2 w3 w4 w5 w6 w7 w8 w9 w10 w11 w12</p><p>(b)</p><p>Figure 6: Example A: second step Finally, we use the chosen structures as decision history to help parse w A 3 and w A 10 . For example, the fact that w A 8 is a dependent of w A 10 is a clue that suggests that the second clause may be independent. This results in w A 10 being the head of w A</p><p>3 . This simple example shows how to use the decision history to help parse the long distance dependencies.</p><p>3 Background: graph-based parsing models</p><p>Before we describe our method, we briefly introduce the graph-based parsing models. We denote input sentence w by w = (w 0 , w 1 , ..., w n ), where w 0 = ROOT is an artificial root token inserted at the beginning of the sentence and does not depend on any other token in w and w i refers to a word. We employ the second-order projective graphbased parsing model of <ref type="bibr" target="#b1">Carreras (2007)</ref>, which is an extension of the projective parsing algorithm of <ref type="bibr" target="#b6">Eisner (1996)</ref>.</p><p>The parsing algorithms used in Carreras (2007) independently find the left and right dependents of a word and then combine them later in a bottomup style based on <ref type="bibr" target="#b6">Eisner (1996)</ref>. A subtree that spans the words in [s, t] (and roots at s or t) is represented by chart item [s, t, right/lef t, C/I], where right (left) indicates that the root of the subtree is s (t) and C means that the item is complete while I means that the item is incomplete <ref type="bibr" target="#b13">(McDonald, 2006)</ref>. Here, complete item in the right (left) direction means that the words other than s (t) cannot have dependents outside [s, t] and incomplete item in the right (left) direction, on the other hand, means that t (s) may have dependents outside <ref type="bibr">[s, t]</ref>. In addition, t (s) is the direct dependent of s (t) in the incomplete item with the right (left) direction.</p><p>Larger chart items are created from pairs of smaller chart items by the bottom-up procedure. <ref type="figure">Figure 7</ref> illustrates the cubic parsing actions of the Eisner's parsing algorithm <ref type="bibr" target="#b6">(Eisner, 1996)</ref> in the right direction, where s, r, and t refer to the start and end indices of the chart items. In <ref type="figure">Figure 7</ref> Once the parser has considered the dependency relations between words of distance 1, it goes on to dependency relations between words of distance 2, and so on by the parsing actions. For words of distance 2 and greater, it considers every possible partition of the structures into two parts and chooses the one with the highest score for each direction. The score is the sum of the feature weights of the chart items. The features are designed over edges of dependency trees and the weights are given by model parameters <ref type="bibr" target="#b12">(McDonald and Pereira, 2006;</ref><ref type="bibr" target="#b1">Carreras, 2007)</ref>. We store the obtained chart items in a table. The chart item includes the information on the optimal splitting point of itself. Thus, by looking up the table, we can obtain the best tree structure (with the highest score) of any chart item. Figure 7: Cubic parsing actions of <ref type="bibr" target="#b6">Eisner (1996)</ref> 4 Parsing with decision history</p><p>As mentioned above, the actions for creating the incomplete items build the relations between words. In this study, we only consider using history information when creating incomplete items.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Decision history</head><p>Suppose we are going to compute the scores of the relations between w s and w t . There are two possible directions for them. By using the bottom-up style algorithm, the scores of the structures between words with distance &lt; |s−t| are computed in previous scans and the structures are stored in the table. We divide the decision history into two types: history-inside and history-outside. The history-inside type is the decision history made inside <ref type="bibr">[s,t]</ref> and the historyoutside type is the history made outside <ref type="bibr">[s,t]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.1">History-inside</head><p>We obtain the structure with the highest score for each direction of the dependency between w s and w t . <ref type="figure" target="#fig_3">Figure 8-(b)</ref> shows the best solution (with the highest score) of the left direction, where the structure is split into two parts, [s, r 1 , →, C] and [r 1 + 1, t, ←, C]. <ref type="figure" target="#fig_3">Figure 8-(c)</ref> shows the best solution of the right case, where the structure is split into two parts, [s, r 2 , →, C] and [r 2 + 1, t, ←, C]. By looking up the table, we have a subtree that roots at w s on the right side of w s and a subtree that roots at w t on the left side of w t . We use these structures as the information on history-inside.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.2">History-outside</head><p>For history-outside, we try to obtain the subtree that roots at w s on the left side of w s and the one that roots at w t on the right side of w t . However, compared to history-inside, obtaining history-outside is more complicated because we do not know the boundaries and the proper structures of the subtrees. Here, we use an simple heuristic method to find a subtree whose root is at w s on the left side of w s and one whose root is at w t on the right side of w t .</p><p>We introduce two assumptions: 1) The structure within a sub-sentence 2 is more reliable than the one that goes across from sub-sentences. 2) More context (more words) can result in a better solution for determining subtree structures.</p><p>Algorithm 1 Searching for history-outside boundaries 1: Input: w, s, t 2: for k = s − 1 to 1 do 3:</p><p>if(isPunct(w k )) break; 4:</p><p>if(s − k &gt;= t − s − 1) break 5: end for 6: bs = k 7: for k = t + 1 to |w| do 8:</p><p>if(isPunct(w k )) break; 9:</p><p>if(k − t &gt;= t − s − 1) break 10: end for 11: bt = k 12: Output: bs, bt Under these two assumptions, Algorithm 1 shows the procedure for searching for historyoutside boundaries, where b s is the boundary for for the descendants on the left side of w s , b t is the boundary for searching the descendants on the right side of w t , and isPunct is the function that checks if the word is a punctuation mark. b s should be in the same sub-sentence with s and |s − b s | should be less than |t − s|. b t should be in the same sub-sentence with t and |b t − t| should be less than |t − s|.</p><p>Next we try to find the subtree structures. First, we collect the part-of-speech (POS) tags of the heads of all the POS tags in training data and remove the tags that occur fewer than 10 times. Then, we determine the directions of the relations by looking up the collected list. For b s and s, we check if the POS tag of w s could be the head tag of the POS tag of w bs by looking up the list. If so, the direction d is ←. Otherwise, we check if the POS tag of w bs could be the head tag of the POS tag of w s . If so, d is →, else d is ←. Finally, we obtain the subtree of w s from chart item [b s , s, d, I]. Similarly, we obtain the subtree of w t . <ref type="figure" target="#fig_4">Figure 9</ref> shows the history-outside information for w s and w t , where the relation between w bs and w s and the relation between w bt and w t will be determined by the above method. We have subtree [r s , s, lef t, C] that roots at w s on the left side of w s and subtree [t, r t , right, C] that roots at w t on the right side of w t in <ref type="figure" target="#fig_4">Figure 9</ref>-(b) and (c).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Parsing algorithm</head><p>Then, we explain how to use these decision history in the parsing algorithm. We use L st to rep- </p><formula xml:id="formula_0">L + st = L st + L df st (1) R + st = R st + R df st<label>(2)</label></formula><p>where L % Update the scores of incomplete chart items 10:</p><formula xml:id="formula_1">V [s, t, ←, I]=L + st =Lst + L df st 11: V [s, t, →, I]=R + st =Rst + R df st</formula><p>12: % Create complete items 13:</p><formula xml:id="formula_2">V [s, t, ←, C]= max s≤r&lt;t V C(r); 14: V [s, t, →, C]= max s&lt;r≤t V C(r); 15:</formula><p>end for 16: end for Algorithm 2 is the parsing algorithm with the history-based features, where V [s, t, dir, I/C] refers to the score of chart item [s, t, dir, I/C], V I(r) is a function to search for the optimal sibling and grandchild nodes for the incomplete items (line 6 and 7) <ref type="bibr" target="#b1">(Carreras, 2007)</ref> given the splitting point r and return the score of the structure, and V C(r) is a function to search for the optimal grandchild node for the complete items (line 13 and 14). Compared with the parsing algorithms of <ref type="bibr" target="#b1">Carreras (2007)</ref>, Algorithm 2 uses history information by adding line 8, 10, and 11.</p><p>In Algorithm 2, it first creates chart items with distance 1, then goes on to chart items with distance 2, and so on. In each round, it searches for the structures with the highest scores for incomplete items shown at line 6 and 7 of Algorithm 2. Then we update the scores with the history-based features by Equation 1 and Equation 2 at line 10 and 11 of Algorithm 2. However, note that we can not guarantee to find the candidate with the highest score with Algorithm 2 because new features violate the assumptions of dynamic programming.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">History-based features</head><p>In this section, we design features that capture the history information in the recorded decisions.</p><p>For a dependency between two words, say s and t, there are four subtrees that root at s or t. We design the features by combining s, t with each child of s and t in the subtrees. The feature templates are shown as follows: (In the following, c means one of the children of s and t, and the nodes in the templates are expanded to their lexical form and POS tags to obtain actual features.):</p><p>C+Dir this feature template is a 2-tuple consisting of (1) a c node and (2) the direction of the dependency.</p><p>C+Dir+S/C+Dir+T this feature template is a 3-tuple consisting of (1) a c node, (2) the direction of the dependency, and (3) a s or t node.</p><p>C+Dir+S+T this feature template is a 4-tuple consisting of (1) a c node, (2) the direction of the dependency, (3) a s node, and (4) a t node. We use SHI to represent the subtree of s in the history-inside, T HI to represent the one of t in the history-inside, SHO to represent the one of s in the history-outside, and T HO to represent the one of t in the history-outside. Based on the subtree types, the features are divided into four sets: F SHI , F T HI , F SHO , and F T HO refer to the features related to the children that are in subtrees SHI, T HI, SHO, and T HO respectively. <ref type="figure" target="#fig_6">Figure 10</ref> shows the structure of decision history of a left dependency (between s and t) relation. For the right case, the structure is similar. In the figure, SHI is chart item [s, r 1 , →, C], T HI is chart item [r 1 + 1, t, ←, C], SHO is chart item [r 2 , s, ←, C], and T HO is chart item [t, r 3 , →, C]. We use c si , c ti , c so , and c to to represent a child of s/t in subtrees SHI, T HI, SHO, and T HO respectively. The lexical form features of F SHI and F SHO are listed as examples in <ref type="table" target="#tab_1">Table  1</ref>, where "L" refers to the left direction. We can also expand the nodes in the templates to the POS tags. Compared with the algorithm of <ref type="bibr" target="#b1">Carreras (2007)</ref> that only considers the furthest children of s and t, Algorithm 2 considers all the children. word-csi+L word-cso+L C+DIR+S word-csi+L+word-s word-cso+L+word-s C+DIR+T word-c si +L+word-t word-c so +L+word-t C+DIR word-c si +L word-c so +L +S+T +word-s+word-t +word-s+word-t</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4">Policy of using history</head><p>In practice, we define several policies to use the history information for different word pairs as follows:</p><p>• All: Use the history-based features for all the word pairs without any restriction.</p><p>• Sub-sentences: use the history-based features only for the relation of two words from sub-sentences. Here, we use punctuation marks to split sentences into sub-sentences.</p><p>• Distance: use the history-based features for the relation of two words within a predefined distance. We set the thresholds to 3, 5, and 10.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Experimental results</head><p>In order to evaluate the effectiveness of the history-based features, we conducted experiments on Chinese and English data. For English, we used the Penn Treebank <ref type="bibr" target="#b10">(Marcus et al., 1993)</ref> in our experiments and the tool "Penn2Malt" 3 to convert the data into dependency structures using a standard set of head rules <ref type="bibr" target="#b21">(Yamada and Matsumoto, 2003a)</ref>. To match previous work <ref type="bibr" target="#b12">(McDonald and Pereira, 2006;</ref><ref type="bibr" target="#b8">Koo et al., 2008)</ref>, we split the data into a training set (sections 2-21), a development set (Section 22), and a test set (section 23). Following the work of <ref type="bibr" target="#b8">Koo et al. (2008)</ref>, we used the MXPOST <ref type="bibr" target="#b19">(Ratnaparkhi, 1996)</ref> tagger trained on training data to provide part-of-speech tags for the development and the test set, and we used 10-way jackknifing to generate tags for the training set.</p><p>For Chinese, we used the Chinese Treebank (CTB) version 4.0 4 in the experiments. We also used the "Penn2Malt" tool to convert the data and created a data split: files 1-270 and files 400-931 for training, files 271-300 for testing, and files 301-325 for development. We used gold standard segmentation and part-of-speech tags in the CTB. The data partition and part-of-speech settings were chosen to match previous work <ref type="bibr" target="#b2">(Chen et al., 2008;</ref><ref type="bibr" target="#b23">Yu et al., 2008)</ref>.</p><p>We measured the parser quality by the unlabeled attachment score (UAS), i.e., the percentage of tokens with the correct HEAD 5 . And we also evaluated on complete dependency analysis.</p><p>In our experiments, we implemented our systems on the MSTParser 6 and extended with the parent-child-grandchild structures <ref type="bibr" target="#b12">(McDonald and Pereira, 2006;</ref><ref type="bibr" target="#b1">Carreras, 2007)</ref>. For the baseline systems, we used the first-and second-order (parent-sibling) features that were used in <ref type="bibr" target="#b12">McDonald and Pereira (2006)</ref> and other second-order features (parent-child-grandchild) that were used in <ref type="bibr" target="#b1">Carreras (2007)</ref>. In the following sections, we call the second-order baseline systems Baseline and our new systems OURS.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Results with different feature settings</head><p>In this section, we test our systems with different settings on the development data.  <ref type="table" target="#tab_2">Table 2</ref> shows the parsing results when we used different policies defined in Section 4.4 with all the types of features, where D sub refers to applying the policy: sub-sentence, D 1 refers to applying the policy: all, and D 3|5|10 refers to applying the policy: distance with the predefined distance 3, 5, or 10. The results indicated that the accuracies of our systems decreased if we used the history information for short distance words. The system with D sub performed the best. Then we investigated the effect of different types of the history-based features. <ref type="table" target="#tab_3">Table 3</ref> shows the results with policy D sub . From the table, we found that F T HI provided the largest improvement for Chinese and F T HO performed the best for English.</p><p>In what follows, we used D sub as the policy for all the languages, the features F SHI + F T HI + F SHO for Chinese, and the features F SHI + F SHO + F T HO for English.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Main results</head><p>The main results are shown in the upper parts of <ref type="table" target="#tab_4">Tables 4 and 5</ref>, where the improvements by OURS over the Baselines are shown in parentheses. The results show that OURS provided better performance over the Baselines by 1.02 points for Chi- nese and 0.29 points for English. The improvements of (OURS) were significant in McNemar's Test with p &lt; 10 −4 for Chinese and p &lt; 10 −3 for English. <ref type="table" target="#tab_4">Table 4</ref> shows the comparative results for Chinese, where Zhao2009 refers to the result of <ref type="bibr" target="#b25">(Zhao et al., 2009)</ref>, Yu2008 refers to the result of <ref type="bibr" target="#b23">Yu et al. (2008)</ref>, Chen2009 refers to the result of <ref type="bibr" target="#b3">Chen et al. (2009)</ref> that is the best reported result on this data, and STACK refers to our implementation of the combination parser of Nivre and McDonald (2008) using our baseline system and the MALTParser 7 . The results indicated that OURS performed better than Zhao2009, Yu2008, and STACK, but worse than Chen2009 that used largescale unlabeled data <ref type="bibr" target="#b3">(Chen et al., 2009)</ref>. We also implemented the combination system of OURS and the MALTParser, referred as OURS+STACK in <ref type="table" target="#tab_4">Table 4</ref>. The new system achieved further improvement. In future work, we can combine our approach with the parser of <ref type="bibr" target="#b3">Chen et al. (2009)</ref>. <ref type="table" target="#tab_5">Table 5</ref> shows the comparative results for English, where Y&amp;M2003 refers to the parser of <ref type="bibr" target="#b22">Yamada and Matsumoto (2003b)</ref>, CO2006 refers to the parser of <ref type="bibr" target="#b4">Corston-Oliver et al. (2006)</ref>, Z&amp;C 2008 refers to the combination system of <ref type="bibr" target="#b24">Zhang and Clark (2008)</ref>, STACK refers to our implementation of the combination parser of <ref type="bibr" target="#b16">Nivre and McDonald (2008)</ref>, KOO2008 refers to the parser of <ref type="bibr" target="#b8">Koo et al. (2008)</ref>, Chen2009 refers to the parser of <ref type="bibr" target="#b3">Chen et al. (2009)</ref>, and Suzuki2009 refers to the parser of <ref type="bibr" target="#b20">Suzuki et al. (2009)</ref> that is the best reported result for this data. The results shows that OURS outperformed the first two systems that were based on single models. Z&amp;C 2008 and STACK were the combination systems of graph-7 http://www.maltparser.org/ </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">Comparative results</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Related work</head><p>There are several studies that tried to overcome the limited feature scope of graph-based dependency parsing models . <ref type="bibr" target="#b14">Nakagawa (2007)</ref> proposed a method to deal with the intractable inference problem in a graphbased model by introducing the Gibbs sampling algorithm. Compared with their approach, our approach is much simpler yet effective. <ref type="bibr" target="#b7">Hall (2007)</ref> used a re-ranking scheme to provide global features while we simply augment the features of an existing parser. <ref type="bibr" target="#b16">Nivre and McDonald (2008)</ref> and <ref type="bibr" target="#b24">Zhang and Clark (2008)</ref> proposed stacking methods to combine graph-based parsers with transition-based parsers. One parser uses dependency predictions made by another parser. Our results show that our approach can be used in the stacking frameworks to achieve higher accuracy.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">Conclusions</head><p>This paper proposes an approach for improving graph-based dependency parsing by using the decision history. For the graph-based model, we design a set of features over short dependencies computed in the earlier stages to improve the accuracy of long dependencies in the later stages. The results demonstrate that our proposed approach outperforms baseline systems by 1.02 points for Chinese and 0.29 points for English.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: Example B</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head></head><label></label><figDesc>- (a), all the items on the left side are complete and represented by triangles, where the triangle of [s, r] is complete item [s, r, →, C] and the triangle of [r + 1, t] is complete item [r + 1, t, ←, C]. Then the algorithm creates incomplete item [s, t, →, I] (trapezoid on the right side of Figure 7-(a)) by combining the chart items on the left side. This action builds the dependency from s to t. In Fig- ure 7-(b), the item of [s, r] is incomplete and the item of [r, t] is complete. Then the algo- rithm creates complete item [s, t, →, C]. For the left direction case, the actions are similar. Note that only the actions of creating the incomplete chart items build new dependency relations be- tween words, while the ones of creating the com- plete items merge the existing structures without building new relations.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 8 :</head><label>8</label><figDesc>Figure 8: History-inside</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 9 :</head><label>9</label><figDesc>Figure 9: History-outside</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head></head><label></label><figDesc>Initialization: V [s, s, dir, I/C] = 0.0 ∀s, dir 2: for k = 1 to n do 3: for s = 0 to n − k do 4: t = s + k 5: % Create incomplete items 6: Lst=V [s, t, ←, I]= max s≤r&lt;t V I(r); 7: Rst=V [s, t, →, I]= max s≤r&lt;t V I(</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Figure 10 :</head><label>10</label><figDesc>Figure 10: Structure of decision history</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" validated="false"><head></head><label></label><figDesc>Word distance between w i and w j is |j − i|.</figDesc><table>. 
However, the model can use very limited infor-
mation. Figures 3-(a) and 4-(a) show the right 
dependency relation cases and Figures 3-(b) and 
4-(b) show the left direction cases. For the right 
direction case of Example A, the model has the 
information about w A 
3 's rightmost child w A 
5 and 
w A 
10 's leftmost child w A 
6 inside w A 
3 and w A 
10 , but it 
does not have information about the other children 

(last year) (I) (bought) (NULL) (books) (,) (this year) (he) (also) (bought) (NULL) (books) 
w1 
w2 w3 
w4 
w5 
w6 w7 
w8 w9 w10 
w11 
w12 

(a) 

(last year) (I) (bought) (NULL) (books) (,) (this year) (he) (also) (bought) (NULL) (books) 

(b) 

( 
y ) ( ) ( 
g ) ( 
) ( 
) (,) ( 
y ) ( ) ( 
) ( 
g ) ( 
) ( 
) 
w1 
w2 w3 
w4 
w5 
w6 w7 
w8 w9 w10 
w11 
w12 

Figure 3: Example A: two directions 

(last year) (I) (bought) (NULL) (books) (,) (this year) (also) (bought) (NULL) (books) 
w1 
w2 w3 
w4 
w5 
w6 w7 
w8 
w9 
w10 
w11 

(a) 

(last year) (I) (bought) (NULL) (books) ( ) (this year) (also) (bought) (NULL) (books) 

(b) 

(last year) (I) (bought) (NULL) (books) (,) (this year) (also) (bought) (NULL) (books) 
w1 
w2 w3 
w4 
w5 
w6 w7 
w8 
w9 
w10 
w11 

Figure 4: Example B: two directions 

(such as w A 
8 ) of w A 
3 and w A 
10 , which may be useful 
for judging the relation between w A 
3 and w A 
10 . The 
parsing model can not find the difference between 
the syntactic structures of two sentences for pairs 
(w A 
3 , w A 
10 ) and (w B 
3 , w B 
9 ). If we can provide the in-
formation about the other children of w A 
3 and w A 

10 

to the model, it becomes easier to find the correct 
direction between w A 
3 and w A 
10 . 
Next, we show how to use decision history to 
help parse w A 
3 and w A 
10 of Example A. 
In a bottom up procedure, the relations between 
the words inside [w A 
3 , w A 
10 ] are built as follows 
before the decision for w A 
3 and w A 
10 . In the first 
round, we build relations for neighboring words 
(word distance 1 =1), such as the relations between 
w A 
3 and w A 
4 and between w A 
4 and w A 
5 . In the sec-
ond round, we build relations for words of dis-
tance 2, and then for longer distance words until 
all the possible relations between the inside words 
are built. Figure 5 shows all the possible relations 
inside [w A 
3 , w A 
10 ] that we can build. To simplify, 
we use undirected links to refer to both directions 

1 of dependency relations between words in the fig-
ure. 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" validated="false"><head>Table 1 :</head><label>1</label><figDesc>Lexical form features of F SHI and F SHO</figDesc><table>template 
FSHI 
FSHO 
C+DIR 
</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" validated="false"><head>Table 2 :</head><label>2</label><figDesc>Results with different policies</figDesc><table>Chinese English 
Baseline 89.04 
92.43 
D1 
88.73 
92.27 
D3 
88.90 
92.36 
D5 
89.10 
92.59 
D10 
89.32 
92.57 
D sub 
89.57 
92.63 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" validated="false"><head>Table 3 :</head><label>3</label><figDesc>Results with different types of Features</figDesc><table>Chinese English 
Baseline 89.04 
92.43 
+FSHI 
89.14 
92.53 
+FT HI 
89.33 
92.35 
+FSHO 
89.25 
92.47 
+FT HO 
88.99 
92.54 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4" validated="false"><head>Table 4 :</head><label>4</label><figDesc>Results for Chinese</figDesc><table>UAS 
Complete 
Baseline 
88.41 
48.85 
OURS 
89.43(+1.02) 50.86 
OURS+STACK 89.53 
49.42 
Zhao2009 
87.0 
-
Yu2008 
87.26 
-
STACK 
88.95 
49.42 
Chen2009 
89.91 
48.56 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5" validated="false"><head>Table 5 :</head><label>5</label><figDesc>Results for Englishbased and transition-based models. OURS per- formed better than Z&amp;C 2008, but worse than STACK. The last three systems that used large- scale unlabeled data performed better than OURS.</figDesc><table>UAS 
Complete 
Baseline 
91.92 
44.28 
OURS 
92.21 (+0.29) 45.24 
Y&amp;M2003 
90.3 
38.4 
CO2006 
90.8 
37.6 
Z&amp;C2008 
92.1 
45.4 
STACK 
92.53 
47.06 
KOO2008 
93.16 
-
Chen2009 
93.16 
47.15 
Suzuki2009 93.79 
-

</table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2">To simplify, we split one sentence into sub-sentences with punctuation marks.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3">http://w3.msi.vxu.se/˜nivre/research/Penn2Malt.html 4 http://www.cis.upenn.edu/˜chinese/. 5 As in previous work, English evaluation ignores any token whose gold-standard POS tag is one of {´´``: , .} and Chinese evaluation ignores any token whose tag is "PU". 6 http://mstparser.sourceforge.net</note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">CoNLL-X shared task on multilingual dependency parsing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Buchholz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Marsi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Dubey</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Krymolowski</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of CoNLL-X</title>
		<meeting>CoNLL-X</meeting>
		<imprint>
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Experiments with a higher-order projective dependency parser</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Carreras</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the CoNLL Shared Task Session of EMNLP-CoNLL</title>
		<meeting>the CoNLL Shared Task Session of EMNLP-CoNLL</meeting>
		<imprint>
			<date type="published" when="2007" />
			<biblScope unit="page" from="957" to="961" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Dependency parsing with short dependency relations in unlabeled data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><forename type="middle">L</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Kawahara</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Uchimoto</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><forename type="middle">J</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Isahara</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of IJCNLP</title>
		<meeting>IJCNLP</meeting>
		<imprint>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Improving dependency parsing with subtrees from auto-parsed data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><forename type="middle">L</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Kazama</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Uchimoto</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Torisawa</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of EMNLP 2009</title>
		<meeting>EMNLP 2009<address><addrLine>Singapore</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2009-08" />
			<biblScope unit="page" from="570" to="579" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Multilingual dependency parsing using bayes point machines</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Corston-Oliver</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Aue</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kevin</forename><surname>Duh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eric</forename><surname>Ringger</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">HLT-NAACL2006</title>
		<imprint>
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Dependency tree kernels for relation extraction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Culotta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Sorensen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ACL 2004</title>
		<meeting>ACL 2004</meeting>
		<imprint>
			<date type="published" when="2004" />
			<biblScope unit="page" from="423" to="429" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Three new probabilistic models for dependency parsing: An exploration</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Eisner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of COLING</title>
		<meeting>of COLING</meeting>
		<imprint>
			<date type="published" when="1996" />
			<biblScope unit="page" from="340" to="345" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">K-best spanning tree parsing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Keith</forename><surname>Hall</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Association for Computational Linguistics</title>
		<meeting><address><addrLine>Prague, Czech Republic</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2007-06" />
			<biblScope unit="page" from="392" to="399" />
		</imprint>
	</monogr>
	<note>Proc. of ACL 2007</note>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Simple semi-supervised dependency parsing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Koo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Carreras</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Collins</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ACL-08: HLT</title>
		<meeting>ACL-08: HLT<address><addrLine>Columbus, Ohio</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2008-06" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<title level="m" type="main">Mandarin Chinese -A Functional Reference Grammar</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Charles</forename><forename type="middle">N</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sandra</forename><forename type="middle">A</forename><surname>Thompson</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1997" />
			<publisher>University of California Press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Building a large annotated corpus of English: the Penn Treebank</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Marcus</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Santorini</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Marcinkiewicz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computational Linguisticss</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="313" to="330" />
			<date type="published" when="1993" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Characterizing the errors of data-driven dependency parsing models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Mcdonald</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Nivre</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of EMNLP-CoNLL</title>
		<meeting>EMNLP-CoNLL</meeting>
		<imprint>
			<date type="published" when="2007" />
			<biblScope unit="page" from="122" to="131" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Online learning of approximate dependency parsing algorithms</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Mcdonald</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Pereira</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of EACL2006</title>
		<meeting>of EACL2006</meeting>
		<imprint>
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
		<title level="m" type="main">Discriminative Training and Spanning Tree Algorithms for Dependency Parsing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ryan</forename><surname>Mcdonald</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2006" />
		</imprint>
		<respStmt>
			<orgName>University of Pennsylvania</orgName>
		</respStmt>
	</monogr>
<note type="report_type">Ph.D. thesis</note>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Multilingual dependency parsing using global features</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tetsuji</forename><surname>Nakagawa</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the CoNLL Shared Task Session of EMNLP-CoNLL</title>
		<meeting>the CoNLL Shared Task Session of EMNLP-CoNLL</meeting>
		<imprint>
			<date type="published" when="2007" />
			<biblScope unit="page" from="952" to="956" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Example-based machine translation based on deeper NLP</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Nakazawa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Kawahara</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Kurohashi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of IWSLT 2006</title>
		<meeting>IWSLT 2006<address><addrLine>Kyoto, Japan</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2006" />
			<biblScope unit="page" from="64" to="70" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Integrating graphbased and transition-based dependency parsers</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Nivre</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Mcdonald</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ACL-08: HLT</title>
		<meeting>ACL-08: HLT<address><addrLine>Columbus, Ohio</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2008-06" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Memorybased dependency parsing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Nivre</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Hall</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Nilsson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of CoNLL</title>
		<meeting>of CoNLL</meeting>
		<imprint>
			<date type="published" when="2004" />
			<biblScope unit="page" from="49" to="56" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">The CoNLL 2007 shared task on dependency parsing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Nivre</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Hall</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Kübler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Mcdonald</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Nilsson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Riedel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Yuret</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the CoNLL Shared Task Session of EMNLPCoNLL</title>
		<meeting>the CoNLL Shared Task Session of EMNLPCoNLL</meeting>
		<imprint>
			<date type="published" when="2007" />
			<biblScope unit="page" from="915" to="932" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">A maximum entropy model for part-of-speech tagging</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Ratnaparkhi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of EMNLP</title>
		<meeting>EMNLP</meeting>
		<imprint>
			<date type="published" when="1996" />
			<biblScope unit="page" from="133" to="142" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">An empirical study of semisupervised structured conditional models for dependency parsing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jun</forename><surname>Suzuki</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hideki</forename><surname>Isozaki</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xavier</forename><surname>Carreras</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Collins</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of EMNLP 2009</title>
		<meeting>of EMNLP 2009<address><addrLine>Singapore, August</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2009" />
			<biblScope unit="page" from="551" to="560" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Statistical dependency analysis with support vector machines</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Yamada</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Matsumoto</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of IWPT2003</title>
		<meeting>IWPT2003</meeting>
		<imprint>
			<date type="published" when="2003" />
			<biblScope unit="page" from="195" to="206" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Statistical dependency analysis with support vector machines</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Yamada</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Matsumoto</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of IWPT2003</title>
		<meeting>IWPT2003</meeting>
		<imprint>
			<date type="published" when="2003" />
			<biblScope unit="page" from="195" to="206" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Chinese dependency parsing with large scale automatically constructed case structures</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Kawahara</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Kurohashi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of Coling</title>
		<meeting>Coling<address><addrLine>Manchester, UK</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2008-08" />
			<biblScope unit="page" from="1049" to="1056" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">A tale of two parsers: Investigating and combining graph-based and transition-based dependency parsing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Clark</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of EMNLP 2008</title>
		<meeting>EMNLP 2008<address><addrLine>Hawaii</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2008-10" />
			<biblScope unit="page" from="562" to="571" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Cross language dependency parsing using a bilingual lexicon</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hai</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yan</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chunyu</forename><surname>Kit</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guodong</forename><surname>Zhou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ACL-IJCNLP2009</title>
		<meeting>ACL-IJCNLP2009<address><addrLine>Suntec, Singapore, August</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2009" />
			<biblScope unit="page" from="55" to="63" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
