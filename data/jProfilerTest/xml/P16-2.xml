<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 D:\Work\grobid-master\grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.5" ident="GROBID" when="2019-07-07T21:00+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Computational</forename><surname>Linguistics</surname></persName>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">Chinese Academy of Sciences Sabine Schulte im Walde, IMS Stuttgart</orgName>
								<orgName type="department" key="dep2">Willem Zuidema</orgName>
								<orgName type="department" key="dep3">Yulia Grishina</orgName>
								<orgName type="department" key="dep4">Seminar für Sprachwissenschaft Wilhemstraße</orgName>
								<orgName type="laboratory" key="lab1">LIMSI-CNRS Student Research Workshop Chairs Humboldt-Universität zu Berlin Tao Lei, Massachusetts Institute of Technology He He</orgName>
								<orgName type="laboratory" key="lab2">Joint Word Segmentation and Phonetic Category Induction</orgName>
								<orgName type="laboratory" key="lab3">Multiplicative Representations for Unsupervised Semantic Role Induction User Embedding for Scholarly Microblog Recommendation</orgName>
								<orgName type="institution" key="instit1">Humboldt University Maja Popović</orgName>
								<orgName type="institution" key="instit2">Humboldt University</orgName>
								<orgName type="institution" key="instit3">University of Potsdam Anke Lüdeling</orgName>
								<orgName type="institution" key="instit4">Humboldt University</orgName>
								<orgName type="institution" key="instit5">University of Edinburgh</orgName>
								<orgName type="institution" key="instit6">University of Amsterdam</orgName>
								<orgName type="institution" key="instit7">University of Maryland</orgName>
								<orgName type="institution" key="instit8">Tsinghua University</orgName>
								<orgName type="institution" key="instit9">Technische Universität Darmstadt</orgName>
								<orgName type="institution" key="instit10">University of Groningen</orgName>
								<orgName type="institution" key="instit11">University of Potsdam</orgName>
								<orgName type="institution" key="instit12">University of Groningen</orgName>
								<address>
									<addrLine>19</addrLine>
									<postCode>72072</postCode>
									<settlement>Tübingen</settlement>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff1">
								<orgName type="institution">Universität Tubingen</orgName>
								<address>
									<settlement>Tübingen</settlement>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff2">
								<orgName type="institution">Microsoft Corporation</orgName>
								<address>
									<settlement>Redmond</settlement>
									<region>WA</region>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff3">
								<orgName type="institution">Columbia University</orgName>
								<address>
									<settlement>New York</settlement>
									<region>NY</region>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff4">
								<orgName type="department">Human Language Technology Center of Excellence Center for Language and Speech Processing</orgName>
								<orgName type="institution">Johns Hopkins University Baltimore</orgName>
								<address>
									<postCode>21218</postCode>
									<region>MD</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff5">
								<orgName type="department" key="dep1">Bloomberg LP</orgName>
								<orgName type="department" key="dep2">Department of Computer Science and Information Engineering</orgName>
								<orgName type="department" key="dep3">School of Electrical Engineering and Computer Science</orgName>
								<orgName type="laboratory">Xerox Research Centre Europe 6 chemin Maupertuis</orgName>
								<orgName type="institution">National Taiwan University</orgName>
								<address>
									<postCode>10022</postCode>
									<settlement>New York, Bilmes, Taipei, Meylan</settlement>
									<region>NY</region>
									<country>Taiwan, France</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff6">
								<orgName type="institution">Oregon State University Corvallis</orgName>
								<address>
									<settlement>Oregon</settlement>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff7">
								<orgName type="department" key="dep1">Faculty of Mathematics and Physics Institute of Formal and Applied Linguistics Malostranské</orgName>
								<orgName type="department" key="dep2">Department of Computer Science</orgName>
								<orgName type="laboratory">Ubiquitous Knowledge Processing Lab</orgName>
								<orgName type="institution" key="instit1">Informatics Institute University of Amsterdam</orgName>
								<orgName type="institution" key="instit2">Informatics Institute University of Amsterdam</orgName>
								<orgName type="institution" key="instit3">Charles University</orgName>
								<address>
									<addrLine>náměstí 25</addrLine>
									<postCode>CZ-11800</postCode>
									<settlement>Prague, Prague</settlement>
									<country key="CZ">Czech Republic</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff8">
								<orgName type="department">Department of Computer Science Goethe-Universität</orgName>
								<orgName type="laboratory">Text Technology Lab</orgName>
								<orgName type="institution">Technische Universität</orgName>
								<address>
									<settlement>Darmstadt, Frankfurt am Main</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff9">
								<orgName type="department" key="dep1">Dept. of Linguistics</orgName>
								<orgName type="department" key="dep2">Dept. of Linguistics</orgName>
								<orgName type="laboratory">Dept. of Linguistics The Ohio State University melsner0@gmail</orgName>
								<orgName type="institution" key="instit1">The Ohio State University</orgName>
								<orgName type="institution" key="instit2">UMIACS University of Maryland</orgName>
								<address>
									<country key="JP">Japan</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff10">
								<orgName type="institution">Harbin Institute of Technology</orgName>
								<address>
									<settlement>Harbin</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff11">
								<orgName type="department">Computer Science Department Bar</orgName>
								<orgName type="institution">Rensselaer Polytechnic Institute</orgName>
								<address>
									<settlement>Troy</settlement>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff12">
								<orgName type="department">Computer Science Department Bar</orgName>
								<orgName type="institution">Ilan University</orgName>
								<address>
									<country key="IL">Israel</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff13">
								<orgName type="department">Institute for Applied Linguistics Pompeu</orgName>
								<orgName type="institution">Ilan University</orgName>
								<address>
									<country key="IL">Israel</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff14">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="institution">Fabra University</orgName>
								<address>
									<country key="ES">Spain</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff15">
								<orgName type="institution">University of Sheffield</orgName>
								<address>
									<country key="GB">UK</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff16">
								<orgName type="department">Department of Electrical Engineering</orgName>
								<orgName type="institution" key="instit1">Google Inc</orgName>
								<orgName type="institution" key="instit2">NTT Communication Science Laboratories</orgName>
								<orgName type="institution" key="instit3">NTT Corporation</orgName>
								<address>
									<addrLine>2-4 Hikaridai, Seika-cho, Soraku-gun, Kyoto</addrLine>
									<postCode>619-0237</postCode>
									<country key="JP">Japan</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff17">
								<orgName type="institution">University of Washington</orgName>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff18">
								<orgName type="department" key="dep1">School of Interactive Computing</orgName>
								<orgName type="department" key="dep2">Institute of Technology ♣ Disney Research</orgName>
								<orgName type="institution">University of Geneva</orgName>
								<address>
									<country key="GE">Georgia</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff19">
								<orgName type="institution">FTI/TIM</orgName>
								<address>
									<country key="CH">Switzerland</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff20">
								<orgName type="department" key="dep1">Institute of Computational Linguistics</orgName>
								<orgName type="department" key="dep2">Institute of Automation</orgName>
								<orgName type="institution">University of Zurich</orgName>
								<address>
									<country key="CH">Switzerland</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff21">
								<orgName type="institution">Chinese Academy of Sciences</orgName>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff22">
								<orgName type="department">School of Information Science and Engineering</orgName>
								<orgName type="institution">Yunnan University</orgName>
								<address>
									<settlement>Yunnan</settlement>
									<country key="CN">P.R. China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff23">
								<orgName type="department">Department of Information Management</orgName>
								<orgName type="institution">Yuan Ze University</orgName>
								<address>
									<country key="TW">Taiwan</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff24">
								<orgName type="department">Department of Computer Science &amp; Engineering</orgName>
								<orgName type="institution">Yuan Ze University</orgName>
								<address>
									<country key="TW">Taiwan</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff25">
								<orgName type="department">Innovation Center for Big Data and Digital Convergence</orgName>
								<orgName type="institution">Yuan Ze University</orgName>
								<address>
									<country key="TW">Taiwan</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff26">
								<orgName type="department">Graduate School of Informatics</orgName>
								<orgName type="institution" key="instit1">University of Copenhagen</orgName>
								<orgName type="institution" key="instit2">Ilan University</orgName>
								<orgName type="institution" key="instit3">Kyoto University</orgName>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff27">
								<orgName type="department" key="dep1">Institut für Maschinelle Sprachverarbeitung</orgName>
								<orgName type="department" key="dep2">Human Language Technology and Pattern Recognition</orgName>
								<orgName type="department" key="dep3">Computer Science Department</orgName>
								<orgName type="laboratory">† † Graduate School of Science and Engineering, Ehime University † † † Academic Center for Computing and Media Studies</orgName>
								<orgName type="institution" key="instit1">Kyoto University</orgName>
								<orgName type="institution" key="instit2">Columbia University</orgName>
								<orgName type="institution" key="instit3">Columbia University</orgName>
								<orgName type="institution" key="instit4">Columbia University</orgName>
								<orgName type="institution" key="instit5">IBM Watson</orgName>
								<orgName type="institution" key="instit6">Universität Stuttgart</orgName>
								<address>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff28">
								<orgName type="department">Department of Engineering</orgName>
								<orgName type="institution">RWTH Aachen University</orgName>
								<address>
									<postCode>52056</postCode>
									<settlement>Aachen</settlement>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff29">
								<orgName type="institution">University of Cambridge</orgName>
								<address>
									<country key="GB">UK</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff30">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="laboratory">Ubiquitous Knowledge Processing Lab</orgName>
								<orgName type="institution">SDL Research</orgName>
								<address>
									<settlement>Cambridge</settlement>
									<country key="GB">UK</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff31">
								<orgName type="department">Computer &amp; Information Science</orgName>
								<orgName type="institution">Technische Universität</orgName>
								<address>
									<settlement>Darmstadt</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff32">
								<orgName type="department">Centre for Language Technology</orgName>
								<orgName type="laboratory">Xerox Research Centre Europe 6 chemin Maupertuis, Meylan</orgName>
								<orgName type="institution">University of Pennsylvania</orgName>
								<address>
									<country key="FR">France</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff33">
								<orgName type="department" key="dep1">Centre for Language Technology</orgName>
								<orgName type="department" key="dep2">Computing and Information Systems</orgName>
								<orgName type="department" key="dep3">English and Comparative Literature</orgName>
								<orgName type="institution" key="instit1">University of Copenhagen</orgName>
								<orgName type="institution" key="instit2">University of Copenhagen</orgName>
								<orgName type="institution" key="instit3">The University of Melbourne</orgName>
								<orgName type="institution" key="instit4">San Diego State University</orgName>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff34">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="institution">University of Illinois at Urbana-Champaign</orgName>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff35">
								<orgName type="department">Department of Computer Science and Engineering, HKUST</orgName>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff36">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="institution">The University of Sheffield</orgName>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff37">
								<orgName type="department">Department of Computing and Information Systems</orgName>
								<orgName type="institution">The University of Melbourne</orgName>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff38">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="institution" key="instit1">The University of Warwick</orgName>
								<orgName type="institution" key="instit2">University of Groningen</orgName>
								<address>
									<country key="NL">The Netherlands</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff39">
								<orgName type="institution">University of Copenhagen</orgName>
								<address>
									<country key="DK">Denmark</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff40">
								<orgName type="institution">Ilan University</orgName>
								<address>
									<country>Israel, Brazil</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff41">
								<orgName type="department" key="dep1">Departamento de Computación</orgName>
								<orgName type="department" key="dep2">School of Information Technologies</orgName>
								<orgName type="institution" key="instit1">Grupo LyS</orgName>
								<orgName type="institution" key="instit2">Universidade da Coruña</orgName>
								<address>
									<addrLine>Campus de A Coruña s/n</addrLine>
									<postCode>15071</postCode>
									<region>A Coruña</region>
									<country key="ES">Spain</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff42">
								<orgName type="institution">University of Sydney</orgName>
								<address>
									<postCode>2006</postCode>
									<region>NSW</region>
									<country key="AU">Australia</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff43">
								<orgName type="department" key="dep1">Computer Science Department</orgName>
								<orgName type="department" key="dep2">Center for Language Technology</orgName>
								<orgName type="laboratory">College of Information Sciences and Technology The Pennsylvania State University University Park</orgName>
								<orgName type="institution">Carnegie Mellon University</orgName>
								<address>
									<addrLine>5000 Forbes Avenue Pittsburgh</addrLine>
									<postCode>15213, 16802</postCode>
									<settlement>Bar-Ilan University</settlement>
									<region>PA, PA</region>
									<country>USA, USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff44">
								<orgName type="department">Ethics &amp; Philosophy of Technology Delft</orgName>
								<orgName type="institution">University of Copenhagen Copenhagen</orgName>
								<address>
									<country key="DK">Denmark</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff45">
								<orgName type="department">Shannon L</orgName>
								<orgName type="institution">University of Technology Delft</orgName>
								<address>
									<addrLine>Meni, 474 Agić, Željko, 561 Alonso, Miguel A., 425 Antetomaso, Stephanie, 59 Araki, Jun, 506 Arora, Raman, 14 Aziz, Wilker, 169 Baldwin, Timothy, 344 Bánréti, Zoltán, 181 Bapteste, Eric, Eduard, 287 Baroni, Marco, 213 Barrett, Maria, 537 Beigman Klebanov, Beata, 101 Benton, Adrian, 14 Bilu, Yonatan, 525 Bingel, Joachim, 337, 579 Biran, Or, Kalina, 393 Bouillon, Pierrette, 162 Brooke, Julian, 344 Byrne, Bill, 299 Callison-Burch, Chris, 143 Carlini, Roberto, 499 Carpuat, Marine, 362 Chang, Ming-Wei, 201 Chen, Hsin-Hsi, 20 Chen, Huan-Yuan, 20 Cheung, Jackie Chi Kit, 112 Chidlovskii, Boris, 26, 326 Clark, Stephen, 188 Clinchant, Stephane, 26, William, 269 Cohn, Trevor, Ronan, 573 Cordeiro, Silvio, 156 Costa-jussà, Marta R., 357 Croijmans, Ilja, 306 Cross, James, 32 Csurka, Gabriela, 26, 326 Dagan, Ido, 249, 474 Dakwale, 38 de Kok, Daniël, 1 Dhingra, Bhuwan, 269 Dredze, Mark, 14, 149 Dubey, Kumar, 467 Duh, Kevin, 531 Dušek, Ondřej, 45 Ebling, Sarah, 162 Eger, Steffen, 52 Elgohary, Ahmed, 362 Elsner, Micha, 59 Espinosa Anke, Luis, 499 Fang, Yimai, 479 Feldman, Naomi, 59 Feng, Xiaocheng, 66 Fern, Xiaoli, 369 Ficler, Jessica, 72 Fitzpatrick, Lucie, 313 Flor, Michael, 101 Fomicheva, Marina, 77 Fonollosa, José A. R., 357 Fukui, Kazuki, 493 Gerlach, Johanna, 162 Gershman, Sam, 537 Gfeller, Beat, 83 Ghaeini, Debanjan, 549 Gkatzia, Dimitra, 264 Gliozzo, Alfio, 243 Goldberg, Yoav, 72, 231, 412 Gómez-Rodríguez, Carlos, 425 Gosztolya, Gábor, 181 Gu, 89 Guo, Weiwei, 107 Gutierrez, E. Dario, 101 Guzmán, Francisco, 460 Hajishirzi, Hannaneh, 118 Hall, Keith, 83 Hammond, Adam, 344 Han, Yubo, 549 607 Hao, Hongwei, 207 Hasler, Eva, 299 Hayashi, 95 Hendrickx, Iris, 306 Hinrichs, Erhard, 1 Hoffmann, Ildikó, 181 Hovy, Dirk, 351, 591 Hu, Weihua, 380 Huang, Liang, 32, 369 Huang, Lifu, 66 Idiart, Marco, 156, 419 Ittycheriah, Abe, 124 Jalili Sabet, Masoud, 287 Ji, Heng, 66 Ji, Yangfeng, 118 Jin, Zhi, 130 Johannsen, Anders, 561 Jurcicek, Filip, 45 Kálmán, János, 181 Kann, Katharina, 555 Keller, Frank, 579 Khanam, Aquila, 549 Kiela, Douwe, 188 Kim, Young-Bum, 8 Klakow, Dietrich, 175 Komura, Maximilian, 256 Korhonen, Anna, Zornitsa, 107, 332 Kumar, Abhishek, 506 Lai, K. Robert, 225 Lazaridou, Angeliki, 213 Lefever, Els, 306 Legrand, Joël, 573 Lemon, Oliver, 264 Leong, Chee Wee, 101 Levy, Omer, 249 Li, Bingchen, 207 Li, Boyang, 118 Li, Ge, 130 Li, Liangyou, 275 Li, Qi, 107 Li, Yi, 195 Ling, Shaoshi, 387 List, Johann-Mattis, 599 Liu, Huan, 543 Liu, Qun, 275 Liu, Ting, 66 Liu, Yang, 195 Logacheva, Varvara, 585 Long, Ryan, 112 Luan, Yi, 118 Lukasik, Michal, 393, 585 Luo, Zhiyuan, 374 Majid, Asifa, 306 Màrquez, Lluís, 460 Matsumoto, Yuji, 531 McKeown, Kathleen, 243 Meek, Alexander, 52 Men, Rui, 130 Mi, 124 Mihalcea, Rada, 320 Mihaylov, Todor, 399 Moens, Marie-Francine, 188 Monz, Christof, 38 Mori, Shinsuke, 236 Morstatter, Fred, 543 Mou, Lili, 130 Muehl, Michael, 269 Muresan, Smaranda, 549 Nagata, Masaaki, 95, 406 Nakov, Preslav, 399, 460 Narasimhan, Sudip Kumar, 281 Negri, Matteo, 287 Ney, Hermann, 293 Nguyen, Kim Anh, 454 Ninomiya, Takashi, 236 Nishino, Masaaki, 406 Nothman, Joel, 432 Onrust, Louis, 137 Oshikiri, Takamasa, 493 Pákáski, Magdolna, 181 Pal, Santanu, 281 Pavlick, Ellie, 143 Peng, Nanyun, 149 Peter, Jan-Thorsten, 293 Pham, Nghia The, 213 Plank, Daniel, 313 Qi, Zhenyu, 207 Qin, Bing, 66 Qu, Weiguang, 89 Ramisch, Carlos, 156 Rayner, David, 443 Richardson, Matthew, 201 Rieser, Verena, 264 Rodríguez-Fernández, Sara, 499 Roth, Dan, 387 Rothe, Sascha, 512 Ruan, Xianzhi, 320 Sachan, Mrinmaya, 467, 486 Saeedi, Ardavan, 537 Saldanha, Gavin, 243 Salle, Alexandre, 419 Sarikaya, Ruhi, 8 Schogol, Vlad, 83 Schulte im Walde, Sabine, 256, 454 Schulz, Philip, 169 Schütze, Hinrich, 512, 555 Søgaard, Anders, 231, 337, 412, 561, 579 Shi, Wei, 207 Shi, Xingtian, 89 Shimodaira, Hidetoshi, 493 Shutova, Ekaterina, 101 Sima&apos;an, Khalil, 169 Slonim, Noam, 525 Song, Yangqiu, 387 Specia, Lucia, 77, 393 Stahlberg, Felix, 299 Stanovsky, Gabriel, 474 Strasly, Irene, 162 Stratos, Karl, 8 Suh, Jina, 201 Sun, Xu, 567 Suzuki, Jun, 406 Szatlóczki, 181 Tadepalli, Prasad, 369 Tang, Duyu, 66 Teufel, Simone, 479 Tian, Jun, 207 Tomori, Suzushi, 236 Tóth, László, 181 Tsourakis, Nikos, 162 Tsujii, Jun&apos;ichi, 380 Turchi, 287 Ungar, Lyle, 313 van den Bosch, Antal, 137, 306 van Genabith, Josef, 281 Van hamme, Hugo, 137 Varjokallio, Matti, 175 Vela, 374 Vilares, David, 425 Villavicencio, Aline, 156, 419 Vincze, Veronika, 181 Vo, Duy Tin, 219 Vu, Duy, 393 Vu, Ngoc Thang, 454 Vulić, Ivan, 188, 518 Waite, Aurelien, 299 Wan, Xiaojun, 449 Wang, Jin, 225 Wang, Weiyue, 293 Wang, Zhiguo, 124 Wanner, Leo, 499 Way, Andy, 275 Webster, Kellie, 432 Wei, 89 Wei, Zhongyu, 195 Wilson, Steven, 320 Woods, Aubrie, 438 Xing, Eric, 467, 486 Xu, Bo, 207 Xu, Jingjing, 567 Xu, Yan, 130 Xu, Yang, 443 Yamada, Makoto, 332 Yan, Rui, 130 Yang, Zhenglu, 89 Yih, Wen-tau, 201 Yu, Liang-Chih, 225 Yu, Yang, 449 Yung, Frances, 531 Zhai, Ke, 107 Zhang, Lu, 130 Zhang, Xuejie, 225 Zhang, Yue, 219 Zhou, Junsheng, 89 Zhou, Peng, 207 Zhou, Xinjie, 449 Zhou, Zhong, 269 Zilio, Leonardo, 156 Zubiaga, Arkaitz, 393 Zukov Gregoric</addrLine>
									<postCode>599, 579, 243, 326, 393, 269, 369, 531, 518, 112, 599, 201, 537, 412, 112, 162, 585, 591, 281, 374</postCode>
									<settlement>Barbu, Batmanghelich, Kayhan, Bontcheva, Cohen, Collobert, Praveen, Dylan, Flekova, Reza, Ghosh, Yanhui, Katsuhiko, Taku, Köper, Kozareva, Lopez, Philippe, Lowe, Chris, Mehler, Haitao, Karthik, Naskar, Barbara, Precup, Doina, Preoţiuc-Pietro, Manny, Reitter, Spruit, Srijith, Gréta, Marco, Mihaela, Veyhe, Bartal, Jinmao, Andrej</settlement>
									<region>Teng, P. K</region>
									<country key="NL">The Netherlands</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<note>iii</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract/>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>The topological field model <ref type="bibr">(Herling, 1821;</ref><ref type="bibr">Erdmann, 1886;</ref><ref type="bibr">Drach, 1937;</ref><ref type="bibr">Höhle, 1986</ref>) has traditionally been used to account for regularities in word order across different clause types of German. This model assumes that each clause type contains a left bracket (LK) and a right bracket (RK), which appear to the left and the right of the middle field (MF). Additionally, in a verb-second declarative clause, the LK is preceded by the initial field (VF) with the RK optionally followed by the final field (NF). <ref type="bibr">1</ref>  <ref type="table" target="#tab_10">Table 1</ref> gives examples of topological fields in verb-second declarative (MC) and verb-final relative (RC) clauses.</p><p>Certain syntactic restrictions can be described in terms of topological fields. For instance, only a single constituent is typically allowed in the VF, while multiple constituents are allowed in the MF and the NF. Many ordering preferences can also be stated using the model. For example, in a main clause, placing the subject in the VF and the direct object in the MF is preferred over the opposite order.</p><p>In parsing, topological field analysis is often seen as a task that is embedded in parsing itself. For instance, <ref type="bibr">Kübler (2005)</ref>, <ref type="bibr">Maier (2006)</ref>, and Cheung and Penn (2009) train PCFG parsers on <ref type="bibr">1</ref> The abbreviations are derived from the German terms linke Klammer, rechte Klammer, Mittelfeld, Vorfeld, and Nachfeld.</p><p>treebanks that annotate topological fields as interior nodes. It is perhaps not surprising that this approach works effectively for phrase structure parsing, because topological fields favor annotations that do not rely on crossing or discontinuous dependencies <ref type="bibr">(Telljohann et al., 2006)</ref>.</p><p>However, the possible role of topological fields in statistical dependency parsing <ref type="bibr">(Kübler et al., 2009)</ref> has not been explored much. We will show that statistical dependency parsing of German can benefit from knowledge of clause structure as provided by the topological field model.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Motivation and corpus analysis</head><p>Transition-based dependency parsers <ref type="bibr">(Nivre, 2003;</ref><ref type="bibr">Kübler et al., 2009</ref>) typically use two transitions (LEFT ARC and RIGHT ARC) to introduce a dependency relation between the token that is on top of the processing stack and the next token on the buffer of unprocessed tokens. The decision to make an attachment, the direction of attachment, and the label of the attachment is made by a classifier. Consequently, a good classifier is tasked to learn syntactic constraints, ordering preferences, and selectional preferences.</p><p>Since transition-based dependency parsers process sentences in one deterministic linear-time left-to-right sweep, the classifier typically has little global information. One popular approach for reducing the effect of early attachment errors is to retain some competition between alternative parses using a globally optimized model with beam search <ref type="bibr">(Zhang and Clark, 2008)</ref>. Beam search presents a trade-off between speed (smaller beam) and higher accuracy (larger beam). More recently,  have proposed to use Long short-term memory networks (LSTMs) to maintain (unbounded) representations of the buffer of unprocessed words, previous parsing ac- tions, and constructed tree fragments. We believe that in the case of German, the topological field model can provide a linguisticallymotivated approach for providing the parser with more global knowledge of the sentence structure. More concretely, if we give the transition classifier access to topological field annotations, it can learn regularities with respect to the fields wherein the head and dependent of a particular dependency relations lie.</p><p>In the remainder of this section, we provide a short (data-driven) exploration of such regularities. Since there is a myriad of possible triples 2 consisting of relation, head field, and dependent field, we will focus on dependency relations that virtually never cross a field and relations that nearly always cross a field. <ref type="table" target="#tab_5">Table 2</ref> lists the five dependency relation that cross fields the least often in the TüBa-D/Z treebank <ref type="bibr">(Telljohann et al., 2006;</ref><ref type="bibr">Versley, 2005)</ref> of German newspaper text. Using these statistics, a classifier could learn hard constraints with regard to these dependency relations -they should never be used to attach heads and dependents that are in different fields.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Dependency label</head><p>Cross-field (%) Particles 0.00 Determiner 0.03 Adjective or attr. pronoun 0.04 Prepositional complement 0.04 Genetive attribute 0.07 <ref type="table" target="#tab_5">Table 2</ref>: The five dependency relations that most rarely cross fields in the TüBa-D/Z. <ref type="table" target="#tab_6">Table 3</ref> lists the five dependency relations that cross fields most frequently. <ref type="bibr" target="#b471">3</ref> These relations (virtually) always cross fields because they are verbal attachments and verbs typically form the LK and RK. This information is somewhat informative, since a classifier should clearly avoid to attach tokens within the same field using one of these relations. However, we can gain more interesting insights by looking at the dependents' fields.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Dependency label</head><p>Cross-field (%) Expletive es 100.00 Separated verb prefix 100.00 Subject 100.00 Prepositional object 99.80 Direct object 99.51 <ref type="table" target="#tab_6">Table 3</ref>: The five dependency relations that most frequently cross fields in the TüBa-D/Z. <ref type="table" target="#tab_42">Table 4</ref> enumerates the three (where applicable) most frequent head and dependent field combinations of the five relations that always cross fields. As expected, the head is always in the LK or RK. Moreover, the dependents are in VF or MF in the far majority of cases. The actual distributions provides some insights with respect to these dependency relations. We will discuss the direct object, prepositional object, and separated verb prefix relations in some more detail.</p><p>Direct objects In German, direct objects can be put in the VF. However, we can see that direct object fronting only happens very rarely in the TüBa-D/Z. This is in line with earlier observations in corpus-based studies (c.f. <ref type="bibr">Weber and Müller (2004)</ref>). Since the probability of having a subject in the VF is much higher, the parser should attach the head of a noun phrase in the VF as a subject, unless there is overwhelming evidence to the contrary, such as case markers, verb agreement, or other cues <ref type="bibr">(Uszkoreit, 1984;</ref><ref type="bibr">Müller, 1999)</ref>.</p><p>Prepositional objects The dependency annotation scheme used by the TüBa-D/Z makes a distinction between prepositional phrases that are a required complement of a verb (prepositional objects) and other prepositional phrases. Since a statistical dependency parser does not typically have access to a valency dictionary, it has difficulty de-  <ref type="table" target="#tab_42">Table 4</ref>: The three most frequent head-dependent field combinations of the five relations that always cross fields.</p><p>ciding whether a prepositional phrase is a prepositional object or not. Topological field information can complement verb-preposition co-occurrence statistics in deciding between these two different relations. The prepositional object mainly occurs in MF, while a prepositional phrase headed by the LK is almost as likely to be in the VF as in the MF (42.12% and 55.70% respectively).</p><p>Separated verb prefixes Some verbs in German have separable prefixes. A complicating factor in parsing is that such prefixes are often words that can also be used by themselves. For example, in (1-a) fest is a separated prefix of bindet (present tense third person of festbinden), while in (1-b) fest is an optional adverbial modifier of gebunden (the past participle of binden).</p><p>(1) a. Sie Similarly to prepositional objects, a statistical parser is handicapped by not having an extensive lexicon. Again, topological fields can complement co-occurence statistics. In (1-a), fest is in the RK.</p><p>As we can see in <ref type="table" target="#tab_42">Table 4</ref>, the separated verb prefix is always in the RK. In contrast, an adverbial modifier as in (1-b) is rarely in the RK (0.35% of the adverbs cases in the TüBa-D/Z).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Predicting fields</head><p>As mentioned in Section 1, topological field annotation has often been performed as a part of phrase structure parsing. In order to test our hypothesis that topological field annotation could inform dependency parsing, it would be more appropriate to use a syntax-less approach. Several shallow approaches have been tried in the past. For instance, <ref type="bibr">Veenstra et al., (2002)</ref> compare three different chunkers (finite state, PCFG, and classification using memory-based learning). <ref type="bibr" target="#b0">Becker and Frank (2002)</ref> predict topological fields using a PCFG specifically tailored towards topological fields. <ref type="bibr">Finally, Liepert (2003)</ref> proposes a chunker that uses support vector machines.</p><p>In the present work, we will treat the topological field annotation as a sequence labeling task. This is more useful in the context of dependency parsing because it allows us to treat the topological field as any other property of a token.</p><p>Topological field projection In order to obtain data for training, validation, and evaluation, we use the TüBa-D/Z treebank. Topological fields are only annotated in the constituency version of the TüBa-D/Z, where the fields are represented as special constituent nodes. To obtain token-level field annotations for the dependency version of the treebank, we project the topological fields of the constituency trees on the tokens. The recursive projection function for projection is provided in Appendix B. The function is initially called with the root of the tree and a special unknown field marker, so that tokens that are not dominated by a topological field node (typically punctuation) also receive the topological field feature.</p><p>We should point out that our current projection method results in a loss of information when a sentence contains multiple clauses. For instance, an embedded clause is in a topological field of the main clause, but also has its own topological structure. In our projection method, the topological field features of tokens in the embedded clause reflect the topological structure of the embedded clause.</p><p>Model Our topological field labeler uses a recurrent neural network. The inputs consist of concatenated word and part-of-speech embeddings. The embeddings are fed to a bidirectional LSTM <ref type="bibr" target="#b644">(Graves and Schmidhuber, 2005)</ref>, on which we stack a regular LSTM <ref type="bibr">(Hochreiter and Schmidhu-ber, 1997)</ref>, and finally an output layer with the softmax activation function. The use of a recurrent model is motivated by the necessity to have long-distance memory. For example, (2-a) consists of a main clause with the LK wird and RK begrünt and an embedded clause wie geplant with its own clausal structure. When the labeler encounters jetzt, it needs to 'remember' that it was in the MF field of the main clause. Moreover, the use of a bidirectional LSTM is motivated by the need for backwards-flowing information to make some labeling decisions. For instance, die Siegerin is in the VF of the verb-second clause <ref type="bibr">(3-a)</ref>, while it is in the MF of the verbfinal clause <ref type="bibr">(3-b)</ref>. The labeller can only make such choices by knowing the position of the finite verb. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Parsing with topological fields</head><p>To evaluate the effectiveness of adding topological fields to the input, we use the publicly available neural network parser described by De <ref type="bibr">Kok (2015)</ref>. This parser uses an architecture that is similar to that of <ref type="bibr" target="#b496">Chen and Manning (2014)</ref>. However, it learns morphological analysis as an embedded task of parsing. Since most inflectional information that can be relevant for parsing German is available in the prefix or suffix, this parser learns morphological representations over character embeddings of prefixes and suffixes. We use the same parser configuration as that of De <ref type="bibr">Kok (2015)</ref>, with the addition of topological field annotations. We encode the topological fields as one-hot vectors in the input of the parser. This information is included for the four tokens on top of the stack and the next three tokens on the buffer.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Evaluation and results</head><p>To evaluate the proposed topological field model, we use the same partitioning of TüBa-D/Z and the word and tag embeddings as De <ref type="bibr">Kok (2015)</ref>. For training, validation, and evaluation of the parser, we use these splits as-is. Since we want to test the parser with non-gold topological field annotations as well, we swapped the training and validation data for training our topological field predictor.</p><p>The parser was trained using the same hyperparameters and embeddings as in De <ref type="bibr">Kok (2015)</ref>. Our topological field predictor is trained using <ref type="bibr">Keras (Chollet, 2015)</ref>. <ref type="bibr">4</ref> The hyperparameters that we use are summarized in Appendix A. The topological field predictor uses the same word and tag embeddings as the parser.</p><p>In <ref type="table" target="#tab_22">Table 5</ref>, we show the accuracy of the topological field labeler. The use of a bi-directional LSTM is clearly justified, since it outperforms the stacked unidirectional LSTM by a wide margin.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Parser</head><p>Accuracy (%) LSTM + LSTM 93.33 Bidirectional LSTM + LSTM 97.24 <ref type="table" target="#tab_22">Table 5</ref>: Topological field labeling accuracies. The addition of backward flowing information improves accuracy considerably. <ref type="table" target="#tab_23">Table 6</ref> shows the labeled attachment scores (LAS) for parsing with topological fields. As we can see, adding gold topological field annotations provides a marked improvement over parsing without topological fields. Although the parser does not achieve quite the same performance with the output of the LSTM-based sequence labeler, it is still a relatively large improvement over the parser of De <ref type="bibr">Kok (2015)</ref>. All differences are significant at p &lt; 0.0001. 5 <ref type="bibr">De Kok (2015)</ref> 89.49 91.88 Neural net + TFs 90.00 92.36 Neural net + gold TFs 90.42 92.76 <ref type="table" target="#tab_23">Table 6</ref>: Parse results with topological fields and gold topological fields. Parsers that use topological field information outperform parsers without access to such information.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Parser LAS UAS</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Result analysis</head><p>Our motivation for introducing topological fields in dependency parsing is to provide the parser with a more global view of sentence structure (Section 2). If this is indeed the case, we expect the parser to improve especially for longer-distance relations. <ref type="figure" target="#fig_3">Figure 1</ref> shows the improvement in LAS as a result of adding gold-standard topological fields. We see a strong relation between the relation length and the improvement in accuracy. The introduction of topological fields clearly benefits the attachment of longer-distance dependents. Since the introduction of topological fields has very little impact on short-distance relations, the differences in the attachment of relations that virtually never cross fields <ref type="table" target="#tab_5">(Table 2</ref>) turn out to be negligable. However, for the relations that cross fields frequently, we see a marked improvements <ref type="table" target="#tab_2">(Table 7)</ref> for every relation except the prepositional object. In hindsight, this difference should not be surprising -the relations that never cross fields are usually very local, while those that almost always cross fields tend to have longer distances and/or are subject to relatively free ordering.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Dependency label LAS ∆ Expletive es</head><p>2.71 Separated verb prefix 1.64 Subject 1.22 Prepositional object -0.29 Direct object 1.59  <ref type="table">Table 8</ref>: The ten dependency relations with the highest LAS ∆ of the parser with access to gold topological fields compared to the <ref type="bibr">(de Kok, 2015)</ref> parser.</p><p>The ten dependency relations with the highest overall improvement in LAS are shown in <ref type="table">Table 8</ref>. Many of these relations are special when it comes to topological field structure and were not discussed in Section 2. The relations parenthesis, dependent clause, and sentence link two clauses; the sentence root marks the root of the dependency tree; and the coordinating conjunction (clausal) relation attaches a token that is always in its own field. <ref type="bibr">6</ref> This confirms that the addition of topological fields also improves the analysis of the overall clausal structure.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">Conclusion and outlook</head><p>In this paper, we have argued and shown that access to topological field information can improve the accuracy of transition-based dependency parsers. In future, we plan to see how competitive the bidirectional LSTM-based sequence labeling approach is compared to existing approaches. Moreover, we plan to evaluate the use of topological fields in the architecture proposed by  to see how many of these regularities that approach captures. <ref type="bibr">Yue Zhang and Stephen Clark. 2008</ref>. A tale of two parsers: investigating and combining graphbased and transition-based dependency parsing using beam-search. In Proceedings of the Conference on Empirical Methods in Natural Language Processing, pages 562-571. Association for Computational Linguistics.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A Hyperparameters</head><p>The topological field labeler was trained using Keras <ref type="bibr">(Chollet, 2015)</ref>. Here, we provide a short overview the hyperparameters that we used:</p><p>• Solver: rmsprop, this solver is recommended by the Keras documentation for recurrent neural networks. The solver is used with its default parameters.</p><p>• Learning rate: the learning rate was determined by the function 0.01(1 + 0.02 i ) −2 , where i is the epoch. The intuition was to start with some epochs with a high learning rate, dropping the learning rate quickly. The results were not drastically different when using a constant learning rate of 0.001.</p><p>• Epochs: The models was trained for 200 epochs, then we picked the model of the epoch with the highest performance on the validation data (27 epochs for the unidirectional LSTM, 124 epochs for the bidirectional LSTM).</p><p>• LSTM layers: all LSTM layers were trained with 50 output dimensions. Increasing the number of output dimensions did not provide an improvement.</p><p>• Regularization: 10% dropout <ref type="bibr">(Srivastava et al., 2014)</ref> was used after each LSTM layer for regularization. A stronger dropout did not provide better performance.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B Topological field projection algorithm</head><p>Algorithm 1 Topological field projection. function <ref type="bibr">PROJECT(node,field)</ref> if IS TERMINAL NODE(node) then node.field ← field else if IS TOPO NODE(node) then field ← node.field end if for child ∈ node do <ref type="bibr">PROJECT(child,field)</ref> end for end if end function</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>The large amount of high quality unlabeled data available today provides an opportunity to improve performance in tasks with limited supervision through a semi-supervised framework: learn useful representations from the unlabeled data and use them to augment supervised models. Unfortunately, conventional exact methods are no longer feasible on such data due to scalability issues. Even algorithms that are considered relatively scalable (e.g., the Lanczos algorithm <ref type="bibr">(Cullum and Willoughby, 2002)</ref> for computing eigenvalue decomposition of large sparse matrices) fall apart in this scenario, since the data cannot be stored in the memory of a single machine. Consequently, approximate methods are needed.</p><p>In this paper, we are interested in improving the performance for sentence classification task by leveraging unlabeled data. For this task, supervision is precious but the amount of unlabeled sentences is essentially unlimited. We aim to learn sentence representations from as many unlabeled queries as possible via principal component analysis (PCA): specifically, learn a projection matrix for embedding a bag-of-words vector into a lowdimensional dense feature vector. However, it is not clear how we can compute an effective PCA when we are unable to even store the data in the memory.</p><p>Recently, Liberty (2013) proposed a scheme, called matrix sketching, for approximating a matrix while preserving its covariance structure. This algorithm, given a memory budget, deterministically processes a stream of data points while never exceeding the memory bound. It does so by occasionally computing singular value decomposition (SVD) on a small matrix. Importantly, the algorithm has a theoretical guarantee on the accuracy of the approximated matrix in terms of its covariance structure, which is the key quantity in PCA calculation.</p><p>We propose to combine the matrix sketching algorithm with random hashing to completely remove limitations on data sizes. In experiments, we significantly improve the intent classification accuracy by learning sentence representations from huge amounts of unlabeled sentences, outperforming a strong baseline based on word embeddings trained on 840 billion tokens .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Deterministic Matrix Sketching</head><p>PCA is typically performed to reduce the dimension of each data point. Let X ∈ R n×d be a data matrix whose n rows correspond to n data points in R d . For simplicity, assume that X is preprocessed to have zero column means. The key quantity in PCA is the empirical covariance matrix X X ∈ R d×d (up to harmless scaling). It is well-known that the m length-normalized eigenvectors u 1 . . . u m ∈ R d of X X corresponding to the largest eigenvalues are orthogonal directions along which the variance of the data is maximized. Then if Π ∈ R d×m be a matrix whose i-th column is u i , the PCA representation of X is given by XΠ. PCA has been a workhorse in representation learning, e.g., inducing features for face recognition <ref type="bibr">(Turk et al., 1991)</ref>.</p><p>Frequently, however, the number of samples n is simply too large to work with. As n tends to billions and trillions, storing the entire matrix X in memory is practically impossible. Processing large datasets often require larger memory than the capacity of a typical single enterprise server. Clusters may enable a aggregating many boxes of memory on different machines, to build distributed memory systems achieving large memory capacity. However, building and maintaining these industry grade clusters is not trivial and thus not accessible to everyone. It is critical to have techniques that can process large data within a limited memory budget available in most typical enterprise servers.</p><p>One solution is to approximate the matrix with some Y ∈ R l×d where l n. Many matrix approximation techniques have been proposed, such as random projection <ref type="bibr">(Papadimitriou et al., 1998;</ref><ref type="bibr">Vempala, 2005)</ref>, sampling <ref type="bibr">(Drineas and Kannan, 2003;</ref><ref type="bibr">Rudelson and Vershynin, 2007;</ref><ref type="bibr">Kim and Snyder, 2013;</ref><ref type="bibr">Kim et al., 2015b)</ref>, and hashing <ref type="bibr" target="#b485">(Weinberger et al., 2009)</ref>. Most of these techniques involve randomness, which can be undesirable in certain situations (e.g., when experiments need to be exactly reproducible). Moreover, many are not designed directly for the objective that we care about: namely, ensuring that the covariance matrices X X and Y Y remain "similar".  <ref type="bibr">(2013)</ref>. In the output, X ∈ R n×d denotes the data matrix with rows x 1 . . . x n .</p><p>A recent result by Liberty (2013) gives a deterministic matrix sketching algorithm that tightly preserves the covariance structure needed for PCA. Specifically, given a sketch size l, the algorithm computes Y ∈ R l×d such that</p><formula xml:id="formula_0">X X − Y Y 2 ≤ 2 ||X|| 2 F /l<label>(1)</label></formula><p>This result guarantees that the error decreases in O(1/l); in contrast, other approximation techniques have a significantly worse convergence bound of O(1/ √ l). The algorithm is pleasantly simple and is given in <ref type="figure" target="#fig_3">Figure 1</ref> for completeness. It processes one data point at a time to update the sketch Y in an online fashion. Once the sketch is "full", its SVD is computed and the rows that fall below a threshold given by the median singular value are eliminated. This operation ensures that every time SVD is performed at least a half of the rows are discarded. Consequently, we perform no more than O(2n/l) SVDs on a small matrix Y ∈ R l×d . The analysis of the bound (1) is an extension of the "median trick" for count sketching and is also surprisingly elementary; we refer to Liberty (2013) for details.</p><p>for intent classification. We do so by learning a PCA projection matrix Π from the unlabeled data and applying it on both training and test sentences. The matrix sketching algorithm in <ref type="figure" target="#fig_3">Figure 1</ref> enables us to compute Π on arbitrarily large data.</p><p>There are many design considerations for using the sketching algorithm for our task.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Original sentence representations</head><p>We use a bag-of-words vector to represent a sentence. Specifically, each sentence is a ddimensional vector x ∈ R d where d is the size of the vocabulary and x i is the count of an n-gram i in the sentence (we use up to n = 3 in experiments); we denote this representation by SENT. In experiments, we also use a modification of this representation, denoted by SENT+, in which we explicitly define features over the first two words in a query and also use intent predictions made by a supervised model.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Random hashing</head><p>When we process an enormous corpus, it can be computationally expensive just to obtain the vocabulary size d in the corpus. We propose using random hashing to avoid this problem. Specifically, we pre-define the hash size H we want, and then on encountering any word w we map w → {1 . . . H} using a fixed hash function. This allows us to compute a bag-of-words vector for any sentence without knowing the vocabulary size. See <ref type="bibr" target="#b485">Weinberger et al. (2009)</ref> for a justification of the hashing trick for kernel methods (applicable in our setting since PCA has a kernel (dual) interpretation).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Parallelization</head><p>The sketching algorithm works in a sequential manner, processing each sentence at a time. While it leaves a small memory footprint, it can take prohibitively long time to process a large corpus. <ref type="bibr">Liberty (2013)</ref> shows it is trivial to parallelize the algorithm: one can compute several sketches in parallel and then sketch the conjoined sketches. The theory guarantees that such layered sketches does not degrade the bound (1). We implement this parallelization to obtain an order of magnitude speedup.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">Final sentence representation:</head><p>Once we learn a PCA projection matrix Π, we use it in both training and test times to obtain a dense feature vector of a bag-of-words sentence representation. Specifically, if x is the original bag-ofwords sentence vector, the new representation is given by</p><formula xml:id="formula_1">x new = x ||x|| ⊕ xΠ ||xΠ||<label>(2)</label></formula><p>where ⊕ is the vector concatenation operation. This representational scheme is shown to be effective in previous work (e.g., see <ref type="bibr">Stratos and Collins (2015)</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.5">Experiment</head><p>To test our proposed method, we conduct intent classification experiments <ref type="bibr">(Hakkani-Tür et al., 2013;</ref><ref type="bibr" target="#b332">Celikyilmaz et al., 2011;</ref><ref type="bibr">Ji et al., 2014;</ref><ref type="bibr">El-Kahky et al., 2014;</ref><ref type="bibr">Chen et al., 2016</ref>) across a suite of 22 domains shown in <ref type="table" target="#tab_10">Table 1</ref>. An intent is defined as the type of content the user is seeking. This task is part of the spoken language understanding problem <ref type="bibr">(Li et al., 2009;</ref><ref type="bibr">Tur and De Mori, 2011;</ref><ref type="bibr">Kim et al., 2015c;</ref><ref type="bibr">Mesnil et al., 2015;</ref><ref type="bibr">Kim et al., 2015a;</ref><ref type="bibr">Xu and Sarikaya, 2014;</ref><ref type="bibr">Kim et al., 2015b;</ref><ref type="bibr">Kim et al., 2015d)</ref>. The amount of training data we used ranges from 12k to 120k (in number of queries) across different domains, the test data was from 2k to 20k. The number of intents ranges from 5 to 39 per domains. To learn a PCA projection matrix from the unlabeled data, we collected around 17 billion unlabeled queries from search logs, which give the original data matrix whose columns are bag-of-n-grams vector (up to trigrams) and has dimensions approximately 17 billions by 41 billions, more specifically, X ∈ R <ref type="bibr">17,032,086,719×40,986,835,008</ref> We use a much smaller sketching matrix Y ∈ R 1,000,000×1,000,000 to approximate X. Note that column size is hashing size. We parallelized the sketching computation over 1,000 machines; we will call the number of machines parallelized over "batch". In all our experiments, we train a linear multi-class SVM <ref type="bibr">(Crammer and Singer, 2002</ref>). <ref type="table" target="#tab_10">Task   Table 1</ref> shows the performance of intent classification across domains. For the baseline, SVM without embedding (w/o Embed) achieved 91.99% accuracy, which is already very competitive. However, the models with word embedding trained on 6 billion tokens (6B-50d) and 840 billion tokens (840B-300d)  achieved 92.89% and 93.00%, respectively. 50d and 300d denote size of embedding dimension. To use word embeddings as a sentence representation, we simply use averaged word vectors over a sentence, normalized and conjoined with the original representation as in <ref type="bibr">(2)</ref>. Surprisingly, when we use sentence representation (SENT) induced from the sketching method with our data set, we can boost the performance up to 93.49%, corresponding to a 18.78% decrease in error relative to a SVM without representation. Also, we see that the extended sentence representation (SENT+) can get additional gains.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.6">Results of Intent Classification</head><p>As in <ref type="table" target="#tab_5">Table 2</ref> , we also measured performance of our method (SENT+) as a function of the percentage of unlabeled data we used from total unlabeled sentences. The overall trend is clear: as the number of sentences are added to the data for inducing sentence representation, the test performance improves because of both better coverage and better quality of embedding. We believe that if we consume more data, we can boost up the performance even more. <ref type="table" target="#tab_6">Table 3</ref> shows the sketching results for various batch size. To evaluate parallelization, we first randomly generate a matrix R 1,000,000×100 and it is sketched to R 100×100 . And then we sketch run with different batch size. The results show that as the number of batch increases, we can speed up dramatically, keeping residual value X X − Y Y 2 . It indeed satisfies the bound value, ||X|| 2 F /l, which was 100014503.16.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.7">Results of Parallelization</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Conclusion</head><p>We introduced how to use matrix sketching algorithm of <ref type="bibr">(Liberty, 2013)</ref> for scalable semisupervised sentence classification. This algorithm approximates the data within a specified memory bound while preserving the covariance structure necessary for PCA. Using matrix sketching, we significantly improved the classification accuracy by leveraging very large amounts of unlabeled sentences.   </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Dense, low-dimensional vector representations (embeddings) have a long history in NLP, and recent work on neural models have provided new and popular algorithms for training representations for word types , sentences <ref type="bibr">(Kiros et al., 2015)</ref>, and entire documents <ref type="bibr" target="#b233">(Le and Mikolov, 2014)</ref>. These embeddings often have nice properties, such as capturing some aspects of syntax or semantics and outperforming their sparse counterparts at downstream tasks. While there are many approaches to generating embeddings of text, it is not clear how to learn embeddings for social media users. There are several different types of data (views) we can use to build user representations: the text of messages they post, neighbors in their local network, articles they link to, images they upload, etc. We propose unsupervised learning of representations of users with a variant of Generalized Canonical Correlation Analysis (GCCA) <ref type="bibr">(Carroll, 1968;</ref><ref type="bibr">Van De Velden and Bijmolt, 2006;</ref><ref type="bibr">Arora and Livescu, 2014;</ref><ref type="bibr">Rastogi et al., 2015)</ref>, a multiview technique that learns a single, low-dimensional vector for each user best capturing information from each of their views. We believe this is more appropriate for learning user embeddings than concatenating views into a single vector, since views may correspond to different modalities (image vs. text data) or have very different distributional properties. Treating all features as equal in this concatenated vector is not appropriate.</p><p>We offer two main contributions: (1) an application of GCCA to learning vector representations of social media users that best accounts for all aspects of a user's online life, and (2) an evaluation of these vector representations for a set of Twitter users at three different tasks: user engagement, friend, and demographic attribute prediction.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Twitter User Data</head><p>We begin with a description of our dataset, which is necessary for understanding the data available to our multiview model. We uniformly sampled 200,000 users from a stream of publicly available tweets from the 1% Twitter stream from April 2015. To include typical, English speaking users we removed users with verified accounts, more than 10,000 followers, or nonEnglish profiles <ref type="bibr">1</ref> . For each user we collected their 1,000 most recent tweets, and then filtered out nonEnglish tweets. Users without English tweets in January or February 2015 were omitted, yielding a total of 102,328 users. Although limiting tweets to only these two months restricted the number of tweets we were able to work with, it also ensured that our data are drawn from a narrow time window, controlling for differences in user activity over time. This allows us to learn distinctions between users, and not temporal distinctions of content. We will use this set of users to learn representations for the remainder of this paper.</p><p>Next, we expand the information available about these users by collecting information about their social networks. Specifically, for each user mentioned in a tweet by one of the 102,328 users, we collect up to the 200 most recent English tweets for these users from January and February 2015. Similarly, we collected the 5,000 most recently added friends and followers of each of the 102,328 users. We then sampled 10 friends and 10 followers for each user and collected <ref type="bibr">1</ref> Identified with langid <ref type="bibr">(Lui and Baldwin, 2012).</ref> 14 up to the 200 most recent English tweets for these users from January and February 2015. Limits on the number of users and tweets per user were imposed so that we could operate within Twitter's API limits. This data supports several of our prediction tasks, as well as the four sources for each user: their tweets, tweets of mentioned users, friends and followers.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">User Views</head><p>Our user dataset provides several sources of information on which we can build user views: text posted by the user (ego) and people that are mentioned, friended or followed by the user and their posted text.</p><p>For each text source we can aggregate the many tweets into a single document, e.g. all tweets written by accounts mentioned by a user. We represent this document as a bag-of-words (BOW) in a vector space model with a vocabulary of the 20,000 most frequent word types after stopword removal. We will consider both count and TF-IDF weighted vectors.</p><p>A common problem with these high dimensional representations is that they suffer from the curse of dimensionality. A natural solution is to apply a dimensionality reduction technique to find a compact representation that captures as much information as possible from the original input. Here, we consider principal components analysis (PCA), a ubiquitous linear dimensionality reduction technique, as well as word2vec , a technique to learn nonlinear word representations.</p><p>We consider the following views for each user. BOW: We take the bag-of-words (both count and TF-IDF weighted) representation of all tweets made by users in that view (ego, mention, friend, or follower) following the above pre-processing. BOW-PCA: We run PCA and extract the top principal components for each of the above views. We also consider all possible combinations of views obtained by concatenating views before applying PCA, and concatenating PCA-projected views. By considering all possible concatenation of views, we ensure that this method has access to the same information as multiview methods. Both the raw BOW and BOW-PCA representations have been explored in previous work for demographic prediction <ref type="bibr" target="#b802">(Volkova et al., 2014;</ref><ref type="bibr">Al Zamal et al., 2012)</ref> and recommendation systems <ref type="bibr">(Abel et al., 2011;</ref><ref type="bibr">Zangerle et al., 2013)</ref>. Word2Vec: BOW-PCA is limited to linear representations of BOW features. Modern neural network based approaches to learning word embeddings, including word2vec continuous bag of words and skipgram models, can learn nonlinear representations that also capture local context around each word . We represent each view as the simple average of the word embeddings for all tokens within that view (e.g., all words written by the ego user). Word embeddings are learned on a sample of 87,755,398 tweets and profiles uniformly sampled from the 1% Twitter stream in April 2015 along with all the tweets/profiles collected for our set of users -a total of over a billion tokens. We use the word2vec tool, select either skipgram or continuous bag-of-words embeddings on dev data for each prediction task, and train for 50 epochs. We use the default settings for all other parameters. NetSim: An alternative to text based representations is to use the social network of users as a representation. We encode a user's social network as a vector by treating the users as a vocabulary, where users with similar social networks have similar vector representations (NetSim). An n-dimensional vector then encodes the user's social network as a bag-of-words over this user vocabulary. In other words, a user is represented by a summation of the one-hot encodings of each neighboring user in their social network. In this representation, the number of friends two users have in common is equal to the dot product between their social network vectors. We define the social network may be as one's followers, friends, or the union of both. The motivation behind this representation is that users who have similar networks may behave in similar ways. Such network features are commonly used to construct user representations as well as to make user recommendations <ref type="bibr">(Lu et al., 2012;</ref><ref type="bibr">Kywe et al., 2012)</ref>. NetSim-PCA: The PCA-projected representations for each NetSim vector. This may be important for computing similarity, since users are now represented as dense vectors capturing linear correlations in the friends/followers a user has. NetSim-PCA is to NetSim as BOW-PCA is to BOW-we apply PCA directly to the user's social network as opposed to the BOW representations of users in that network.</p><p>Each of these views can be treated independently as a user representation. However, different downstream tasks may favor different views. For example, the friend network is useful at recommending new friends, whereas the ego tweet view may be better at predicting what content a user will post in the future. Picking a single view may ignore valuable information as views may contain complementary information, so using multiple views improves on a single view. One approach is to concatenate multiple views together, but this further increases the size of the user embeddings. In the next section, we propose an alternate approach for learning a single embedding from multiple views.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Learning Multiview User Embeddings</head><p>We use Generalized Canonical Correlation Analysis (GCCA) <ref type="bibr">(Carroll, 1968)</ref> to learn a single embedding from multiple views. GCCA finds G,U i that minimize:</p><formula xml:id="formula_2">arg min G,Ui i G − X i U i 2 F s.t. G G = I<label>(1)</label></formula><p>where X i ∈ R n×di corresponds to the data matrix for the ith view, U i ∈ R di×k maps from the latent space to observed view i, and G ∈ R n×k contains all user representations <ref type="bibr">(Van De Velden and Bijmolt, 2006)</ref>.</p><p>Since each view may be more or less helpful for a downstream task, we do not want to treat each view equally in learning a single embedding. Instead, we weigh each view differently in the objective: arg min G,Ui i</p><formula xml:id="formula_3">w i G − X i U i 2 F s.t. G G = I, w i ≥ 0 (2)</formula><p>where w i explicitly expresses the importance of the ith view in determining the joint embedding. The columns of G are the eigenvectors of i w i X i (X i X i ) −1 X i , and the solution for U i = (X i X i ) −1 X i G. In our experiments, we use the approach of <ref type="bibr">Rastogi et al. (2015)</ref> to learn G and U i , since it is more memory-efficient than decomposing the sum of projection matrices.</p><p>GCCA embeddings were learned over combinations of the views in §3. When available, we also consider GCCA-net, where in addition to the four text views, we also include the follower and friend network views used by NetSim-PCA. For computational efficiency, each of these views was first reduced in dimensionality by projecting its BOW TF-IDF-weighted representation to a 1000-dimensional vector through PCA. <ref type="bibr">2</ref> We add an identity matrix scaled by a small amount of regularization, 10 −8 , to the per-view covariance matrices before inverting, for numerical stability, and use the formulation of GCCA reported in <ref type="bibr">Van De Velden and Bijmolt (2006)</ref>, which ignores rows with missing data (some users had no data in the mention tweet view and some users accounts were private). We tune the weighting of each view i, w i ∈ {0.0, 0.25, 1.0}, discriminatively for each task, although the GCCA objective is unsupervised once the w i are fixed.</p><p>We also consider a minor modification of GCCA, where G is scaled by the square-root of the singular values of i w i X i X i , GCCA-sv. This is inspired by previous work showing that scaling each feature of multiview embeddings by the singular values of the data matrix can improve performance at downstream tasks such as image or caption retrieval <ref type="bibr">(Mroueh et al., 2015)</ref>. Note that if we only consider a single view, X 1 , with weight w 1 = 1, then the solution to GCCA-sv is identical to the PCA solution for data matrix X 1 , without mean-centering.</p><p>When we compare representations in the following tasks, we sweep over embedding width in {10, 20, 50, 100, 200, 300, 400, 500, 1000} for all methods. This applies to GCCA, BOW-PCA, NetSim-PCA, and Word2Vec. We also consider concatenations of vectors for every possible subset of views: singletons, pairs, triples, and all views. We tried applying PCA directly to the concatenation of all 1000-dimensional BOW-PCA views, but this did not perform competitively in our experiments. <ref type="bibr">2</ref> We excluded count vectors from the GCCA experiments for computational efficiency since they performed similarly to TF-IDF representations in initial experiments.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Experimental Setup</head><p>We selected three user prediction tasks to demonstrate the effectiveness of the multi-view embeddings: user engagement prediction, friend recommendation and demographic characteristics inference. Our focus is to show the performance of multiview embeddings compared to other representations, not on building the best system for a given task. User Engagement Prediction The goal of user engagement prediction is to determine which topics a user will likely tweet about, using hashtag as a proxy. This task is similar to hashtag recommendation for a tweet based on its contents <ref type="bibr">(Kywe et al., 2012;</ref><ref type="bibr">She and Chen, 2014;</ref><ref type="bibr">Zangerle et al., 2013)</ref>. <ref type="bibr">Purohit et al. (2011)</ref> presented a supervised task to predict if a hashtag would appear in a tweet using features from the user's network, previous tweets, and the tweet's content.</p><p>We selected the 400 most frequently used hashtags in messages authored by our users and which first appeared in March 2015, randomly and evenly dividing them into dev and test sets. We held out the first 10 users who tweeted each hashtag as exemplars of users that would use the hashtag in the future. We ranked all other users by the cosine distance of their embedding to the average embedding of these 10 users. Since embeddings are learned on data pre-March 2015, the hashtags cannot impact the learned representations. Performance is measured using precision and recall at k, as well as mean reciprocal rank (MRR), where a user is marked as correct if they used the hashtag. Note that this task is different than that reported in <ref type="bibr">Purohit et al. (2011)</ref>, since we are making recommendations at the level of users, not tweets. Friend Recommendation The goal of friend recommendation/link prediction is to recommend/predict other accounts for a user to follow <ref type="bibr">(Liben-Nowell and Kleinberg, 2007)</ref>.</p><p>We selected the 500 most popular accounts -which we call celebrities -followed by our users, randomly, and evenly divided them into dev and test sets. We randomly select 10 users who follow each celebrity and rank all other users by cosine distance to the average of these 10 representations. The tweets of selected celebrities are removed during embedding training so as not to influence the learned representations. We use the same evaluation as user engagement prediction, where a user is marked as correct if they follow the given celebrity.</p><p>For both user engagement prediction and friend recommendation we z-score normalize each feature, subtracting off the mean and scaling each feature independently to have unit variance, before computing cosine similarity. We select the approach and whether to zscore normalize based on the development set performance. Demographic Characteristics Inference Our final task is to infer the demographic characteristics of a user <ref type="bibr">(Al Zamal et al., 2012;</ref>.  We use the dataset from <ref type="bibr" target="#b802">Volkova et al. (2014;</ref><ref type="bibr" target="#b803">Volkova (2015)</ref> which annotates 383 users for age (old/young), 383 for gender (male/female), and 396 political affiliation (republican/democrat), with balanced classes. Predicting each characteristic is a binary supervised prediction task. Each set is partitioned into 10 folds, with two folds held out for test, and the other eight for tuning via cross-fold validation. The provided dataset contained tweets from each user, mentioned users, friends and follower networks. It did not contain the actual social networks for these users, so we did not evaluate NetSim, NetSim-PCA, or GCCA-net at these prediction tasks.</p><p>Each feature was z-score normalized before being passed to a linear-kernel SVM where we swept over 10 −4 , . . . , 10 4 for the penalty on the error term, C.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Results</head><p>User Engagement Prediction <ref type="table" target="#tab_10">Table 1</ref> shows results for user engagement prediction and <ref type="figure" target="#fig_3">Figure 1</ref> the precision and recall curves as a function of number of recommendations. GCCA outperforms other methods for precision and recall at 1000, and does close to the best in terms of MRR. Including network views (GCCA-   <ref type="table" target="#tab_6">Table 3</ref>: Average CV/test accuracy for inferring demographic characteristics.</p><p>net and GCCA-sv) improves the performance further. The best performing GCCA setting placed weight 1 on the ego tweet view, mention view, and friend view, while BOW-PCA concatenated these views, suggesting that these were the three most important views but that GCCA was able to learn a better representation. <ref type="figure" target="#fig_8">Figure  2</ref> compares performance of different view subsets for GCCA and BOW-PCA, showing that GCCA uses information from multiple views more effectively for predicting user engagement. <ref type="table" target="#tab_5">Table 2</ref> shows results for friend prediction and <ref type="figure" target="#fig_6">Figure 3</ref> similarly shows that performance differences between approaches are consistent across k (number of recommendations.) Adding network views to GCCA, GCCA-net, improves performance, although it cannot contend with NetSim or NetSim-PCA, although GCCA-sv is able to meet the performance of NetSim-PCA. The best GCCA placed non-zero weight on the friend tweets view, and GCCAnet only places weight on the friend network view; the other views were not informative. BOW-PCA and Word2Vec only used the friend tweet view. This suggests that the friend view is the most important for this task, and multiview techniques cannot exploit additional views to improve performance. GCCA-sv performs identically to GCCA-net, since it only placed weight on the friend network view, learning identical embeddings to GCCA-net.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Friend Recommendation</head><p>Demographic Characteristics Prediction <ref type="table" target="#tab_6">Table 3</ref> shows the average cross-fold validation and test accuracy on the demographic prediction task. GCCA + BOW and BOW-PCA + BOW are the concatenation of BOW features with GCCA and BOW-PCA, respectively. The wide variation in performance is due to the small size of the datasets, thus it's hard to draw many conclusions other than that GCCA seems to perform well compared to other linear methods. Word2Vec surpasses other representations in two out of three datasets.</p><p>It is difficult to compare the performance of the methods we evaluate here to that reported in previous work, <ref type="bibr">(Al Zamal et al., 2012)</ref>. This is because they report cross-fold validation accuracy (not test), they consider a wider range of hand-engineered features, different subsets of networks, radial basis function kernels for SVM, and find that accuracy varies wildly across different feature sets. They report cross-fold validation accuracy ranging from 0.619 to 0.805 for predicting age, 0.560 to 0.802 for gender, and 0.725 to 0.932 for politics.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">Conclusion</head><p>We have proposed several representations of Twitter users, as well as a multiview approach that combines these views into a single embedding. Our multiview embeddings achieve promising results on three different prediction tasks, making use of both what a user writes as well as the social network. We found that each task relied on different information, which our method successfully combined into a single representation.</p><p>We plan to consider other means for learning user representations, including comparing nonlinear dimensionality reduction techniques such as kernel PCA <ref type="bibr">(Schölkopf et al., 1997)</ref> and deep canonical correlation analysis . Recent work on learning user representations with multitask deep learning techniques <ref type="bibr" target="#b109">(Li et al., 2015)</ref>, suggests that learning a nonlinear mapping from observed views to the latent space can learn high quality user representations. One issue with GCCA is scalability: solving for G relies on an SVD of a large matrix that must be loaded into memory. Online variants of GCCA would allow this method to scale to larger training sets and incrementally update representations. The PCA-reduced views for all 102,328 Twitter users can be found here: http://www.dredze.com/ datasets/multiview_embeddings/.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Opinions are classified into explicit and implicit ones depending on the subjectivity and objectivity <ref type="bibr">(Liu, 2012;</ref><ref type="bibr">Zhang and Liu, 2014)</ref>. It is more challenging to detect implicit opinions than explicit ones due to the lack of explicit opinion words in the sentences. Aspects refer to facets of the target entities in opinions. They are also categorized into explicit and implicit ones depending on the occurrences of aspect terms. Recognizing implicit aspects in implicit opinions is much more challenging because both opinion words and aspect terms are absent in opinionated statements.</p><p>Implicit opinions often describe the situations at which persons concern in their reviews. (S1) and (S2) are two examples selected from positive and negative rating rows respectively in hotel reviews. They do not mention any explicit opinion words and aspect terms. The situation of "many restaurants nearby" infers the convenience for eating, while the situation of "a lot of ants" infers the dirtiness of a room. The implicit opinion describes not only the situation at which customers feel, but also infers the reason why they have such feelings. Implicit opinions are positive in (S1) and negative in (S2), and the implied aspects are location and cleanness.</p><p>(S1) 附近有很多餐廳。(There are many restaurants nearby.) (S2) 房間裡有很多螞蟻。(There are a lot of ants in the room.)</p><p>The implicit opinions may be subjective in some cases. For example, (S1) may be placed in negative rating row in a hotel review. Its implicit interpretation will become "There are many restaurants nearby, and thus the air pollution is severe and the smell of the air is very bad."</p><p>People may describe a situation first, and then reveal their attitudes and judgments. (S3) is an example. The first clause (only ten meters to the subway entrance) describes a situation, while the second clause (the location is good) is an explicit opinion. In Chinese review, an explicit opinion can also be specified before a situation description. (S4) is an example. In both cases, the polarity and the aspect of the situation are consistent with those of the explicit opinions.</p><p>(S3) 到地鐵出入口僅十米，地段好。(Only ten meters to the subway entrance, good location.) (S4) 地點不錯，可步行至周圍三個捷運站。 (Location is good, within walking distance of three <ref type="bibr">MRTs around.)</ref> This paper aims at extracting implicit opinions and identifying their implicit aspects and polarity. We will extract opinions from Chinese hotel reviews, then transfer polarity and aspect from explicit expressions to the corresponding implicit opinions, and train aspect and polarity classifiers. We evaluate the performance of polarity and aspect recognition on implicit opinions.</p><p>Almost all previous approaches identify implicit aspects in explicit opinions. They extract opinion words from opinionated sentences, regard them as implicit aspect clues, and find aspects through opinion word-aspect term mapping. The lack of opinion words in implicit opinions results in no indicators in mapping. To the best of our knowledge, this paper is the first one to resolve a doubleimplicit problem in opinion mining and sentiment analysis.</p><p>This paper is organized as follows. Section 2 gives a survey on implicit aspect recognition in opinion mining and sentiment analysis. Section 3 constructs an implicit opinions corpus labelled with aspect classes and polarity automatically. Section 4 presents classifiers for implicit polarity and implicit aspect recognition. Section 5 shows and discusses the experimental results.  present the first feature-based opinion summarization system. They point out explicit and implicit product features, and extract explicit features by using association miner and pruning strategies. The opinionated sentences along with their polarity are listed under individual product features. <ref type="bibr">Popescu and Etzioni (2005)</ref> introduce an opinion extraction system OPINE. OPINE extracts explicit product features based on Point-wise Mutual Information. This work does not discuss the implicit feature generation. <ref type="bibr">Liu et al. (2005)</ref> present an association mining approach to extract both explicit and implicit features in their opinion observer, but the implicit features discussed occur explicitly in an overt form, e.g., <ref type="bibr">[MB]</ref> indicates a product feature &lt;memory&gt;. <ref type="bibr">Su et al. (2008)</ref> define an implicit feature as the product feature which does not occur explicitly, but can be inferred from the surrounding opinion word. They propose a mutual reinforcement approach to cluster product features and opinion words simultaneously, and extract implicit features based on opinion words. In the subsequent work, different methodologies are proposed to identify the association between opinion words and aspect terms (called also product features), thus implicit aspects are inferred from opinion word-aspect term mapping <ref type="bibr">(Bagheri et al., 2013)</ref>. <ref type="bibr">Zhen et al. (2011)</ref> propose a two-phase cooccurrence association rule mining approach. <ref type="bibr">Yu et al. (2011)</ref> generate a review hierarchy based on aspects. Implicit aspect of a review can be determined by the cosine similarity of the review vector and the vector for each aspect node in the review hierarchy. <ref type="bibr">Zeng and Li (2013)</ref> regard identification of implicit features as a classification problem, and consider reviews for each clustered opinion-pair as training set.  employ five collocation methods including frequency, PMI, frequency⁄PMI, t-test and chi-square test to measure the association between opinion words and aspect terms. <ref type="bibr">Cruz et al. (2014)</ref> manually annotate implicit aspects and implicit aspect indicators (IAI) on the customer review datasets in , and employ Conditional Random Fields to recognize IAI. <ref type="bibr">Poria et al. (2014)</ref> identify implicit aspect clues (IACs) in a document. Both approaches establish IAI (IAC) and aspect mapping. <ref type="bibr">Mukherjee and Liu (2012)</ref> propose two statistical models to deal with aspect categorization problem. They use hotel reviews from tripadvisor.com, and point out categorizing aspects is a subjective task. Total 9 major aspects based on commonsense knowledge, including Dining, Staff, Maintenance, Check In, Cleanliness, Comfort, Amenities, Location and Value for Money, are considered. <ref type="bibr">Kim et al. (2013)</ref> further analyze general aspects and specific aspects, and discuss how aspect structure is helpful.  present a fine-grained corpus for sentiment analysis.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Related Work</head><p>Our work is different from the previous ones in two-fold: (1) opinion is implicit, so that no opinion words can be used as clues; and (2) aspect is implicit, so that no aspect terms can be found. The direct opinion word and aspect mapping is not feasible in implicit polarity and implicit aspect recognition. We focus on the construction of an implicit opinions corpus for double-implicit recognition. The aspect categorization is not the major concern.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Constructing Implicit Opinions Corpus</head><p>This section first defines the implicit opinions, collects a Chinese hotel dataset, identifies opinion and aspect clusters from the dataset, and constructs implicit opinion corpus labelled with aspect class and polarity.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Definitions of Implicit Opinions</head><p>A sentence in a review can be partitioned into several segments separated by punctuation marks. The following show four possible types of segments based on the occurrences of opinion words and aspect terms, where + and -denote occurrence and non-occurrence. Segments of types (T1) and (T2) contain explicit opinion words, while segments of types (T3) and (T4) contain no opinion words. They appear together with and without aspect terms.</p><p>(T1) (+opinion word, +aspect term) e.g., 地點不錯 (location is good) (T2) (+opinion word, -aspect term) e.g., 很便宜 (very cheap) (T3) <ref type="bibr">(-opinion word, +aspect term)</ref> e.g., 地理位置 (location) (T4) <ref type="bibr">(-opinion word,-aspect term)</ref> e.g., 到油麻地地鐵站只要兩分鐘 (Just two minutes to Yau Ma Tei MRT Station) Segments of either type can not only appear individually, but also can be combined with other types of segments to form a sentence. Segments of types (T1) and (T2) are opinionated. Segments of type (T3) are opinionated implicitly when they appear in positive/negative rating row. Segments of type (T4) can be opinionated or non-opinionated. It is interpreted as an opinionated segment clearly when it is placed in rating row individually.</p><p>(S5) is a sentence consisting of 5 segments of types T3, T2, T1, T4 and T3, respectively. The 4 th segment, i.e., feeling a little like shanty towns, is a double-implicit opinion. Its polarity and aspect (negative and environment) can be inferred from the 3 rd segment, i.e., the surrounding environment is really bad.</p><p>(</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>S5) [T3 旅館在小巷子裡]，[T2 安全沒有問題]， [T1 但附近環境確實不好]，[T4 有點棚戶區的感 覺]，[T3 周圍沒有飯店]。([T3 hotel in the alley]， [T2 security is no problem]，[T1 but the surrounding environment is really bad]，[T4 feeling a little like shanty towns]，[T3 no hotels around])</head><p>In this paper, we deal with opinionated segments of type (T4). On the one hand, we extract pairs of segments of types T1-T4 or T4-T1 from a Chinese hotel review dataset. The segments of type T4 will be annotated with opinion words and aspect terms extracted from their paired segments of type T1. The segments of type T4 along with their annotations form a training corpus. On the other hand, the test segments of types (T4) will be labelled with polarity and aspect by polarity and aspect classifiers.</p><p>At first glance, we do not need to perform the classification task on T4 segments since we can directly use polarity and aspect of T1 segments. The scenario is just for test purpose because we do not have large-scale manually-labelled data. In the latter experiments, we will also consider the cases of T4 segments existing individually in rating rows. That will reflect the real situations.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Extraction of Implicit Opinions</head><p>Opinion words and aspect terms are the indicators to define the four types (T1)-(T4). As a case study, we collect a Chinese hotel review dataset from booking.com. It consists of 144,158 positive reviews and 113,844 negative reviews about 20,973 hotels from 49 international cities. Here only Chinese reviews are kept. We use Stanford NLP tools to segment, POS tag, and parse all the reviews.</p><p>At first, we construct an opinion dictionary from this dataset. Words of POS tags VA, VV, AD, and JJ are candidates of opinion words. We adopt Chisquare test and point-wise mutual information to filter out less confident words from the candidate set, respectively. We examine the union of the remaining words manually and construct an opinion dictionary consisting of 374 positive and 408 negative opinion words.</p><p>Then, we construct an aspect dictionary based on opinion words. A word meeting the following four conditions is regarded as an aspect term candidate: (1) its POS is NN, (2) it occurs at least 100 times, <ref type="bibr" target="#b471">(3)</ref> it is accompanied with an opinion word within the same segment, and (4) their dependency is nsubj. We examine 183 proposed candidates manually and construct an aspect dictionary consisting of 153 aspect terms.</p><p>In an extreme case, a review does not contain any opinion words and aspect terms. It may be a single segment or multiple segments of type T4. Reviews are listed under positive and negative rating rows, so we know their polarity, but not aspect. <ref type="table" target="#tab_10">Table 1</ref> shows the statistics of such kinds of reviews in the hotel dataset. Interestingly, 2.07% of positive reviews are pure T4, and 7.29% of negative reviews are pure T4. That demonstrates double-implicit is a practical issue and customers tend to express negative opinions implicitly. The pure single multiple total # pure T4 (positive reviews) 2,266 717 2,983 # pure T4 (negative reviews) 5,847 2,451 8,298  T4 reviews set consisting of single segments only is called PT4S hereafter. <ref type="table" target="#tab_5">Table 2</ref> shows the statistics of segments of types T1, T2, T3, and T4. Only 21.01% of segments contain both opinion words and aspect terms, and 33.14% of segments do not contain any opinion words and aspect terms. We further examine the type combinations of two successive segments. There are 103 possible punctuation marks between any two segments, including common ones like "，", "。", "?", and "!", and some special ones like "~~~". To avoid misinterpretation of the special marks, we considers only those segment pairs linked by commas. Moreover, to obtain an automatically labelled dataset, the ambiguous sequence of segments, X-T4-Y, where X and Y of types T1, T2, or T3, are removed. Total 31,136 T4-T1/T1-T4 segment pairs remain. They are used to derive an implicit opinions corpus for learning and testing polarity classifier and aspect classifiers. This data set is called T41 hereafter.</p><p>In most of the cases we observed, segment of type T2 or T3 does not pass its aspect or opinion to nearby segments of type T4. (S6) is an example of a triple of segments of type T1-T4-T3, which introduces ambiguity between aspect and opinion assignment. The aspect of segment of type T1, i.e., the equipment, competes with that of segment of type T3, the toilet. In this case, the safety deposit box, which is the undetected aspect of the segment of type T4, and the toilet are two sub-aspects of the equipment. The latter two clauses are supplementary description of the first clause.</p><p>(S6) 設施比較舊，保險箱不好使，馬桶上水 時有故障 (The equipment is old, the safety deposit box is hard to use, and the toilet sometimes stucks while refilling.)</p><p>This work bases on the postulation -say, an implicit opinion and its neighbor explicit opinion tending to have the same aspect and polarity, to construct a training corpus automatically. We randomly sampled 1% of pairs of segments of type T1-T4 or T4-T1 in a training corpus (see Section 4) to verify whether our assumption holds. In this setup, we discard clauses that contain parsing errors and those are too short to represent both aspects and opinions. The result is promising. On average, 70.46% of the pairs follow the observation. In particular, the pairs keep the property more often (i.e., 74.51%) when the polarity of T1 is negative.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Double-Implicit Opinion Analysis</head><p>We assign polarity and aspect of a T4-type segment in T41 dataset based on the information from its paired T1-type segment. Negation in the T1-type segment will reverse the polarity. To avoid data sparseness, 153 aspect terms are partitioned into 10 aspect classes based on common sense knowledge, including food, hotel, price, room, internet, staff, services, facilities, neighborhood, and general. The criterion in the selection of the category of aspects is not the major concern in this paper. For example, facilities and services may be merged into the same aspect category. The 31,136 labelled T4-type segments in T41 dataset are divided into training and test sets consisting of 23,352 and 7,784 segments, respectively. <ref type="figure" target="#fig_3">Figure 1</ref> shows the segment length distribution of T41-train, T41-test, T41, and PT4S datasets. The length is measured by number of Chinese words in a segment. X-axis and Y-axis denote length of segments and ratio, respectively. Segments in PT4S dataset are shorter than those in T41 dataset. Segments of 2 and 3 words occupy 48.61%. <ref type="table" target="#tab_6">Table 3</ref> shows the polarity distribution in these datasets. Because T41 dataset is divided into T41-train and T41-test datasets uniformly, their polarity distribution is the same, i.e., positive:    <ref type="table" target="#tab_42">Table 4</ref>: Accuracy of implicit polarity and aspect recognition.</p><p>negative=4:1. Comparatively, positive:negative= 1:2.58 in PT4S dataset. The two test sets bias toward different polarities. We employ T41-train dataset to train binary polarity classifier and 10-way aspect classifiers, and test on T41-test dataset. We also explore T41 dataset to train polarity classifier, and test on PT4S dataset. T41-testing evaluates both implicit polarity and implicit aspect recognition. Note the ground truth is generated automatically. PT4S-testing evaluates implicit polarity only based on the human-annotated ground truth.</p><p>We consider bag of words (BOW) and word vectors generated by word2vec (W2V) as features, where word vectors are pre-trained by using the part-of-tagged Chinese sentences extracted from the ClueWeb09 dataset <ref type="bibr">(CMU, 2009;</ref><ref type="bibr" target="#b230">Yu et al., 2012)</ref>. Moreover, we adopt SVM with linear kernel and SVM with RBF kernel learning algorithms in Scikit-Learn library , and run cross-validation multiple times on the training set to facilitate a grid search on hyperparameters with F-measure as the metric to optimize.</p><p>Besides, we also explore Convolutional Neural Networks (CNN) <ref type="bibr">(Kim, 2014)</ref>. <ref type="table" target="#tab_42">Table 4</ref> summarizes the accuracy of implicit polarity and implicit aspect recognition, where (p) and (a) after dataset denote polarity and aspect performance of that dataset, respectively. CNN achieves the best implicit polarity and aspect recognition in T41-test dataset. However, its implicit polarity accuracy is decreased to 67.96%. It may be due to overfitting in small amount of training data. Different dropout rates <ref type="bibr">(Srivastava et al., 2014)</ref> can be explored. SVM with linear kernel (BOW) gets the best micro average accuracy (77.91%) in implicit polarity recognition. <ref type="figure" target="#fig_8">Figure 2</ref> shows the accuracies of the implicit polarity recognition on segments of different lengths. It is challenging to predict the implicit polarity and aspect for segments of very short length. <ref type="figure" target="#fig_3">Figure 1</ref> depicts one-word segments occupy 5%-10%. One word segment like "旺角" (Mong Kok) is ambiguous. If we neglect such segments, the micro average accuracy in implicit polarity recognition using SVM with linear kernel (BOW) is increased to 79.94%, and the accuracy in implicit aspect recognition (10-way classification) becomes 46.01%.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Conclusion and Future Work</head><p>In this paper, we address the double-implicit issue in opinion mining and sentiment analysis, and propose a protocol to derive a labelled corpus for implicit polarity and implicit aspect analysis. SVM with linear kernel (BOW) is robust in implicit polarity recognition. Ten-way classification for implicit aspect recognition still has space to improve.</p><p>This work bases on the aspect-and-polaritytransfer postulation to construct a training corpus automatically. We randomly sample T4 segments from T4-T1 or T1-T4 pairs and check them manually. We find that 70.46% of the pairs follow the observation. The experimental setup is reasonable for evaluation with PT4S dataset because it is labelled by users themselves. To derive a more reliable training set, distinguishing if T4 is nonopinionated needs to be investigated further.</p><p>Moreover, we neglect the cases T4-X (X-T4), where X is either T2 or T3, in the selection of training set. It is also challenging when either opinion word or aspect term is absent from the cue segment. In this paper, we provide some case studies of these scenarios, but how to utilize the partial information in implicit polarity and implicit aspect recognition is a future work.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>24</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Domain Adaptation problem arises each time when we need to leverage labeled data in one or more related source domains, to learn a classifier for unseen data in a target domain. It has been studied for more than a decade, with applications in statistical machine translation, opinion mining, part of speech tagging, named entity recognition and document ranking <ref type="bibr">(Daumé and Marcu, 2006;</ref><ref type="bibr">Pan and Yang, 2010;</ref><ref type="bibr">Zhou and Chang, 2014)</ref>.</p><p>The idea of finding domain invariant features underpins numerous works in domain adaptation. A shared representation eases prediction tasks, and theoretical analyses uphold such hypotheses (Ben- <ref type="bibr">David et al., 2007)</ref>. For instance, <ref type="bibr">(Daumé and Marcu, 2006;</ref> have shown that replicating features in three main subspaces (source, common and target) yields improved accuracy as the classifier can subsequently pick the most relevant common features. With the pivoting technique <ref type="bibr">(Blitzer et al., 2006;</ref><ref type="bibr">Pan et al., 2010)</ref>, the bag of words features are projected on a subspace that captures the relations between some central pivot features and the remaining words. Similarly, there are several extensions of topic models and matrix factorization techniques where the latent factors are shared by source and target collections <ref type="bibr">(Chen and Liu, 2014;</ref>.</p><p>More recently, deep learning has been proposed as a generic solution to domain adaptation and transfer learning problems by demonstrating their ability to learn invariant features. On one hand, unsupervised models such as denoising autoencoders <ref type="bibr">(Glorot et al., 2011)</ref> or models built on word embeddings <ref type="bibr">(Bollegala et al., 2015)</ref> are shown to be effective for domain adaptation. On the other hand, supervised deep models <ref type="bibr">(Long et al., 2015)</ref> can be designed to select an appropriate feature space for classification. Adaptation to a new domain can also be performed by fine tuning the neural network on the target task <ref type="bibr">(Chopra et al., 2013)</ref>. While such solutions perform relatively well, the refinement may require a significant amount of new labeled data. Recent work by <ref type="bibr">(Ganin and Lempitsky, 2015)</ref> has proposed a better strategy; they proposed to regularize intermediate layers with a domain prediction task, i.e. deciding whether an object comes from the source or target domain. This paper proposes to combine the domain prediction regularization idea of <ref type="bibr">(Ganin and Lempitsky, 2015)</ref> with the denoising autoencoders. More precisely, we build on stacked Marginalized Denoising Autoencoders (sMDA) , which can be learned efficiently with a closed form solution. We show that such domain adaptation regularization keeps the benefits of the sMDA and yields results competitive to the state of the art results of <ref type="bibr">(Ganin and Lempitsky, 2015)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>26</head><p>2 Target Regularized MDA Stacked Denoising Autoencoders (sDA) <ref type="bibr">(Vincent et al., 2008)</ref> are multi-layer neural networks trained to reconstruct input data from partial random corruption. The random corruption, called blank-out noise or dropout, consists in randomly setting to zero some input nodes with probability p; it has been shown to act as a regularizer <ref type="bibr">(Wager et al., 2013)</ref>. The sDA is composed of a set of stacked one-layer linear denoising autoencoder components, which consider a set of N input documents (represented by d-dimensional features x n ) to be corrupted M times by random feature dropout and then reconstructed with a linear mapping W ∈ R d×d by minimizing the squared reconstruction loss:</p><formula xml:id="formula_4">L(W) = N n=1 M m=1 ||x n −x nm W|| 2 .<label>(1)</label></formula><p>As explicit corruption comes at a high computational cost,  propose to marginalize the loss (1) by considering the limiting case when M → ∞ and reducing de facto the learning cost. The main advantage of this method is a closed form solution for W, which depends only on the uncorrupted inputs (x n ) and the dropout probability. Several Marginalized Denoising Autoencoders (MDA) can be then stacked together to create a deep architecture where the representations of the (l − 1) th layer serves as inputs to the l th layer 1 .</p><p>In the case of domain adaptation, the idea is to apply MDA (or sMDA) to the union of unlabeled source X s and target X t examples. Then, a standard learning algorithm such as SVM or Logistic Regression is trained on the labeled source data using the new feature representations (x s n W) which captures better the correlation between the source and target data.</p><p>In <ref type="figure" target="#fig_3">Figure 1</ref>, we illustrate the effect of the MDA; it shows the relation between the word log document frequency (x-axes) and the expansion mass defined as the total mass of words transformed into word i by MDA and represented by j W ji . We can see that the mapping W learned by MDA is heavily influenced by frequent words. In fact, MDA behaves similarly to document expansion on text documents: it adds new words with a very small frequency and sometimes words with a small negative weight. As the figure shows, MDA promotes common words (despite the use of tf-idf weighting scheme) that are frequent both in source and target domains and hence aims to be domain invariant.</p><p>This is in line with the work of <ref type="bibr">(Ganin et al., 2015)</ref>. To strengthen the invariance effect, they suggested a deep neural architecture which embeds a domain prediction task in intermediate layers, in order to capture domain invariant features. In this paper we go a step further and refine this argument by claiming that we want to be domain invariant but also to be as close as possible to the target domain distribution. We want to match the target feature distribution because it is where the classification takes place.</p><p>We therefore propose a regularization for the denoising autoencoders, in particular for MDA, with the aim to make source data resemble the target data and hence to ease the adaptation.</p><p>We describe here the case of two domains, but it can be easily generalized to multiple domains. Let D be the vector of size N indicating for each document its domain, e.g. taking values of '−1' for source and '+1' for target examples. Let c be a linear classifier represented as a d dimensional vector trained to distinguish between source and target, e.g. a ridge classifier that minimizes the loss R(c, α) = ||D − Xc || 2 + α||c|| 2 .</p><p>We guide the mapping W in such a way that the denoised data points xW go towards the target side, i.e. xWc = 1 for both source and target samples. Hence, we can extend each term of the loss (1) as follows:</p><formula xml:id="formula_5">||x n −x nm W|| 2 + λ||1 −x nm Wc || 2 . (2)</formula><p>The first term here represents the reconstruction loss of the original input, like in MDA. In the second term,x mn Wc is the domain classifier prediction for the denoised objects forced to be close to 1, the target domain indicator, and λ &gt; 0.</p><p>LetX be the concatenation of M replicated version of the original data X, andX be the matrix representation of the M corrupted versions. Taking into account the domain prediction term, the loss can be written as:</p><formula xml:id="formula_6">L R (W) = ||X −XW|| 2 + λ||R −XWc || 2 ,<label>(3)</label></formula><p>where R is a vector of size N , indicating a desired regularization objective, andR its M -replicated version. Loss (3) represents a generic form to capture three different ideas:</p><p>• If R = 1, the model incites the reconstructed features moving towards target specific features.</p><p>• If R = −D, the model aims to promote domain invariant features as in <ref type="bibr">(Ganin et al., 2015)</ref>.</p><p>• If R = [0; 1], where 0 values are used for source data, the model penalizes the source specific features.</p><p>Learning the mapping W.  observed that the random corruption from equation (1) could be marginalized out from the reconstruction loss, yielding a unique and optimal solution. Furthermore, the mapping W can be expressed in closed form as W = PQ −1 , with:</p><formula xml:id="formula_7">Q ij = S ij q i q j , if i = j, S ij q i , if i = j, P ij = S ij q j ,<label>(4)</label></formula><p>where 2 q = [1 − p, . . . , 1 − p] ∈ R d , p is the dropout probability, and S = XX T is the covariance matrix of the uncorrupted data X.</p><p>The domain regularization term in (3) is quadratic in W, the random corruption can still be marginalized out and the expectations obtained in closed form. Indeed, the mapping W which minimizes the expectation of 1 M L R (W) is the solution of the following linear system 3 :</p><p>(P + λ(1 − p)X Rc )(I + λcc ) −1 = QW.</p><p>(5) In (5), parameter λ controls the effect of the proposed target regularization in the MDA and the regularization on c is controlled by parameter α. This approach preserves the good properties of MDA, i.e. the model is unsupervised and can be computed in closed form. In addition, we can easily stack several layers together and add nonlinearities between layers.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Experiments</head><p>We conduct unsupervised domain adaptation experiments on two standard collections: the Amazon reviews <ref type="bibr">(Blitzer et al., 2011)</ref> and the 20News-group <ref type="bibr">(Pan and Yang, 2010)</ref> datasets.</p><p>From the Amazon dataset we consider the four most used domains: dvd (D), books (B), electronics (E) and kitchen (K), and adopt the settings of <ref type="bibr">(Ganin et al., 2015)</ref> with the 5000 most frequent common features selected for each adaptation task and a tf-idf weighting. We then use the Logistic Regression (LR) to classify the reviews.</p><p>Our previous experiments with MDA revealed that the MDA noise probability p needs to be set to high values (e.g. 0.9). A possible explanation is that document representations are already sparse and adding low noise has no effect on the features already equal to zero. <ref type="figure" target="#fig_8">Figure 2</ref> shows the average accuracy for the twelve Amazon tasks, when we vary the noise probability p.</p><p>In addition, we observed that a single layer with a tanh activation function is sufficient to achieve top performance; stacking several layers and/or concatenating the outputs with the original features yields no improvement but increases the computational time.</p><p>The dropout probability p is fixed to 0.9 in all experiments, for both the MDA baseline and our model; we test the performance with a single layer and a tanh activation function. Stacking several layers is left for future experiments. Parameters α and λ are tuned on a grid of values 4 by cross validation on the source data. In other words, we select the LR parameters and the parameters α, λ by cross validating the classification results using only the "reconstructed" source data; for estimating W we used the source with an unlabeled target set (excluded at test time). This corresponds to the setting used in <ref type="bibr">(Ganin et al., 2015)</ref>, with the difference that they use SVM and reverse crossvalidation 5 . <ref type="table" target="#tab_6">Table 3</ref> shows the results for twelve adaptation tasks on the Amazon review dataset for the four following methods. Columns 1 and 2 show the LR classification results on the target set for the single layer MDA and the proposed target regularized MDA <ref type="bibr">(MDA+TR)</ref>. Column 3 reports the SVM result on the target from <ref type="bibr">(Ganin et al., 2015)</ref>. They used a 5 layers sMDA where the 5 outputs are concatenated with input to generate 30,000 features, on which the SVM is then trained and tested <ref type="bibr">(G-sMDA)</ref>. Finally, column 4 shows the current state of the art results obtained with Domain-Adversarial Training of Neural Networks (DA NN) instead of SVM <ref type="bibr">(Ganin et al., 2015)</ref>.</p><p>Despite a single layer and LR trained on the source only, the MDA baseline (80.15% on average) is very close to the G-sMDA results obtained with 5 layer sMDA and 6 times larger feature set (80.18%). Furthermore, adding the target regularization allows to significantly outperform in many <ref type="bibr">5</ref> It consists in using self training on the target validation set and calibrating parameters on a validation set from the source labeled data. cases the baseline and the state of the art DA NN. We note that our method has a much lower cost, as it uses the closed form solution for the reconstruction and a simple LR on the reconstructed source data, instead of domain-adversarial training of deep neural networks.</p><p>We also look at the difference between the previously introduced expansion mass for the MDA and MDA+TR. In the adaptation task from dvd (D) to electronics (E), the words for which the mass changed the most are the following 6 : worked, to use, speakers, i have, work, mouse, bought, cable, works, quality, unit, ipod, price, number , sound, card, phone, use, product, my. These words are mostly target specific and the results confirm that they get promoted by the new model.</p><p>Our model favors features which are more likely to appear in target examples, while DA NN seeks domain invariant features. Despite this difference, the two approaches achieve similar results. It is surprising, and we argue that eventually both approaches penalize source specific features. To test this hypothesis, we use MDA with R = [0; 1] (case 3) that penalizes source specific features and we obtain again similar performances.</p><p>Finally, we test our approach on the 20News-group adaptation tasks described in <ref type="bibr">(Pan and Yang, 2010)</ref>. We first filter out rare words and keep at most 10,000 features. Then, we apply both MDA and MDA+TR as above. <ref type="table" target="#tab_6">Table 3</ref> shows results for ten adaptation tasks. As we can see, in all cases the target regularization (MDA+TR) helps improve the classification accuracy. <ref type="bibr">6</ref> In ascending order of the differences.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Conclusion</head><p>This paper proposes a domain adaptation regularization for denoising autoencoders, in particular for marginalized ones. One limitation of our model is the linearity assumption for the domain classifier, but for textual data, linear classifiers are the state of the art technique. As new words and expressions become more frequent in a new domain, the idea of using the dropout regularization that forces the reconstruction of initial objects to resemble target domain objects is rewarding. The main advantage of the new model is in the closed form solution. It is also unsupervised, as it does not require labeled target examples and yields performance results comparable with the current state of the art. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Recently, neural network-based parsers have become popular, with the promise of reducing the burden of manual feature engineering. For example, <ref type="bibr" target="#b496">Chen and Manning (2014)</ref> and subsequent work replace the huge amount of manual feature combinations in non-neural network efforts <ref type="bibr" target="#b188">(Nivre et al., 2006;</ref><ref type="bibr">Zhang and Nivre, 2011)</ref> by vector embeddings of the atomic features. However, this approach has two related limitations. First, it still depends on a large number of carefully designed atomic features. For example, <ref type="bibr" target="#b496">Chen and Manning (2014)</ref> and subsequent work such as <ref type="bibr">Weiss et al. (2015)</ref> use 48 atomic features from <ref type="bibr">Zhang and Nivre (2011)</ref>, including select thirdorder dependencies. More importantly, this approach inevitably leaves out some nonlocal information which could be useful. In particular, though such a model can exploit similarities between words and other embedded categories, and learn interactions among those atomic features, it cannot exploit any other details of the text. We aim to reduce the need for manual induction of atomic features to the bare minimum, by using bi-directional recurrent neural networks to automatically learn context-sensitive representations for each word in the sentence. This approach allows the model to learn arbitrary patterns from the entire sentence, effectively extending the generalization power of embedding individual words to longer sequences. Since such a feature representation is less dependent on earlier parser decisions, it is also more resilient to local mistakes.</p><p>With just three positional features we can build a greedy shift-reduce dependency parser that is on par with the most accurate parser in the published literature for English Treebank. This effort is similar in motivation to the stack-LSTM of , but uses a much simpler architecture.</p><p>We also extend this model to predict phrasestructure trees with a novel shift-promote-adjoin system tailored to greedy constituency parsing, and with just two more positional features (defining tree span) and nonterminal label embeddings we achieve the most accurate greedy constituency parser for both English and Chinese.  The central idea behind this approach is exploiting the power of recurrent neural networks to let the model decide what apsects of sentence context are important to making parsing decisions, rather than relying on fallible linguistic information (which moreover requires leaving out information which could be useful). In particular, we model an input sentence using Long Short-Term Memory networks (LSTM), which have made a recent resurgence after being initially formulated by <ref type="bibr">Hochreiter and Schmidhuber (1997)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">LSTM Position Features</head><p>The input at each time step is simply a vector representing the word, in this case an embedding for the word form and one for the part-of-speech tag. These embeddings are learned from random initialization together with other network parameters in this work. In our initial experiments, we used one LSTM layer in each direction (forward and backward), and then concatenate the output at each time step to represent that sentence position: that word in the entire context of the sentence. This network is illustrated in <ref type="figure" target="#fig_3">Figure 1</ref>. It is also common to stack multiple such LSTM layers, where the output of the forward and backward networks at one layer are concatenated to form the input to the next. We found that parsing performance could be improved by using two bidirectional LSTM layers in this manner, and concatenating the output of both layers as the positional feature representation, which becomes the input to the fully-connected layer. This architec- The arc-standard dependency parsing system <ref type="bibr" target="#b189">(Nivre, 2008</ref>) (re omitted). Stack S is a list of heads, j is the start index of the queue, and s 0 and s 1 are the top two head indices on S.  ture is shown in <ref type="figure" target="#fig_8">Figure 2</ref>. Intuitively, this represents the sentence position by the word in the context of the sentence up to that point and the sentence after that point in the first layer, as well as modeling the "higher-order" interactions between parts of the sentence in the second layer. In Section 5 we report results using only one LSTM layer ("Bi-LSTM") as well as with two layers where output from each layer is used as part of the positional feature ("2-Layer Bi-LSTM").</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Shift-Reduce Dependency Parsing</head><p>We use the arc-standard system for dependency parsing (see <ref type="figure" target="#fig_15">Figure 4)</ref>. By exploiting the LSTM architecture to encode context, we found that we were able to achieve competitive results using only three sentence-position features to model parser state: the head word of each of the top two trees on the stack (s 0 and s 1 ), and the next word on the queue (q 0 ); see <ref type="table" target="#tab_10">Table 1</ref>.</p><p>The usefulness of the head words on the stack is clear enough, since those are the two words that are linked by a dependency when taking a reduce action. The next incoming word on the queue is also important because the top tree on the stack should not be reduced if it still has children which have not yet been shifted. That feature thus allows the model to learn to delay a right-reduce until the top tree on the stack is fully formed, shifting instead.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Hierarchical Classification</head><p>The structure of our network model after computing positional features is fairly straightforward and similar to previous neural-network parsing approaches such as <ref type="bibr" target="#b496">Chen and Manning (2014)</ref> and <ref type="bibr">Weiss et al. (2015)</ref>. It consists of a multilayer perceptron using a single ReLU hidden layer followed by a linear classifier over the action space, with the training objective being negative log softmax.</p><p>We found that performance could be improved, however, by factoring out the decision over structural actions (i.e., shift, left-reduce, or rightreduce) and the decision of which arc label to assign upon a reduce. We therefore use separate classifiers for those decisions, each with its own fully-connected hidden and output layers but sharing the underlying recurrent architecture. This structure was used for the results reported in Section 5, and it is referred to as "Hierarchical Actions" when compared against a single action classifier in <ref type="table" target="#tab_6">Table 3</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Shift-Promote-Adjoin</head><p>Constituency Parsing</p><p>To further demonstrate the advantage of our idea of minimal features with bidirectional sentence representations, we extend our work from dependency parsing to constituency parsing. However, the latter is significantly more challenging than the former under the shift-reduce paradigm because: 1 shift (I) 6 pro (NP) 2 pro (NP) 7 adj 3 shift (like) 8 pro (S) 4 pro (VP) 9 adj 5 shift (sports) <ref type="figure" target="#fig_170">Figure 5</ref>: Shift-Promote-Adjoin parsing example. Upward and downward arrows indicate promote and (sister-)adjunction actions, respectively.</p><p>• we also need to predict the nonterminal labels</p><p>• the tree is not binarized (with many unary rules and more than binary branching rules)</p><p>While most previous work binarizes the constituency tree in a preprocessing step <ref type="bibr" target="#b169">(Zhu et al., 2013;</ref><ref type="bibr">Wang and Xue, 2014;</ref><ref type="bibr">Mi and Huang, 2015)</ref>, we propose a novel "Shift-PromoteAdjoin" paradigm which does not require any binariziation or transformation of constituency trees (see <ref type="figure" target="#fig_170">Figure 5</ref>). Note in particular that, in our case only the Promote action produces a new tree node (with a non-terminal label), while the Adjoin action is the linguistically-motivated "sisteradjunction" operation, i.e., attachment <ref type="bibr">(Chiang, 2000;</ref><ref type="bibr">Henderson, 2003)</ref>. By comparison, in previous work, both Unary-X and Reduce-L/R-X actions produce new labeled nodes (some of which are auxiliary nodes due to binarization). Thus our paradigm has two advantages:</p><p>• it dramatically reduces the number of possible actions, from 3X + 1 or more in previous work to 3 + X, where X is the number of nonterminal labels, which we argue would simplify learning;</p><p>• it does not require binarization <ref type="bibr" target="#b169">(Zhu et al., 2013;</ref><ref type="bibr">Wang and Xue, 2014)</ref> or compression of unary chains <ref type="bibr">(Mi and Huang, 2015)</ref> There is, however, a more closely-related "shiftproject-attach" paradigm by <ref type="bibr">Henderson (2003)</ref>. For the example in <ref type="figure" target="#fig_170">Figure 5</ref> he would use the following actions:</p><p>shift(I), project(NP), project(S), shift(like), project(VP), shift(sports), project(NP), attach, attach.</p><p>The differences are twofold: first, our Promote action is head-driven, which means we only promote the head child (e.g., VP to S) whereas his Project action promotes the first child (e.g., NP to S); and secondly, as a result, his Attach action is always right-attach whereas our Adjoin action could be either left or right. The advantage of our method is its close resemblance to shift-reduce dependency parsing, which means that our constituency parser is jointly performing both tasks and can produce both kinds of trees. This also means that we use head rules to determine the correct order of gold actions.</p><p>We found that in this setting, we did need slightly more input features. As mentioned, node labels are necessary to distinguish whether a tree has been sufficiently promoted, and are helpful in any case. We used 8 labels: the current and immediate predecessor label of each of the top two stacks on the tree, as well as the label of the leftand rightmost adjoined child for each tree. We also found it helped to add positional features for the leftmost word in the span for each of those trees, bringing the total number of positional features to five. See <ref type="table" target="#tab_10">Table 1</ref> for details.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Experimental Results</head><p>We report both dependency and constituency parsing results on both English and Chinese.</p><p>All experiments were conducted with minimal hyperparameter tuning. The settings used for the reported results are summarized in <ref type="table" target="#tab_23">Table 6</ref>. Networks parameters were updated using gradient backpropagation, including backpropagation through time for the recurrent components, using ADADELTA for learning rate scheduling <ref type="bibr" target="#b656">(Zeiler, 2012)</ref>. We also applied dropout <ref type="bibr" target="#b682">(Hinton et al., 2012</ref>) (with p = 0.5) to the output of each LSTM layer (separately for each connection in the case of the two-layer network).</p><p>We tested both types of parser on the Penn Treebank (PTB) and Penn Chinese Treebank (CTB-5), with the standard splits for each of training, development, and test sets. Automatically predicted part of speech tags with 10-way jackknifing were used as inputs for all tasks except for Chinese dependency parsing, where we used gold tags, following the traditions in literature. <ref type="table" target="#tab_5">Table 2</ref> shows results for English Penn Treebank using Stanford dependencies. Despite the minimally designed feature representation, relatively few training iterations, and lack of precomputed embeddings, the parser performed on par with state-of-the-art incremental dependency parsers, and slightly outperformed the state-ofthe-art greedy parser.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Dependency Parsing: English &amp; Chinese</head><p>The ablation experiments shown in the  <ref type="table" target="#tab_6">Table 3</ref>: Ablation studies on PTB dev set (wsj 22). Forward and backward context, and part-ofspeech input were all critical to strong performace.</p><p>Figure 6 compares our parser with that of <ref type="bibr" target="#b496">Chen and Manning (2014)</ref> in terms of arc recall for various arc lengths. While the two parsers perform similarly on short arcs, ours significantly outpeforms theirs on longer arcs, and more interestingly our accuracy does not degrade much after length 6. This confirms the benefit of having a global sentence repesentation in our model. <ref type="table" target="#tab_42">Table 4</ref> summarizes the Chinese dependency parsing results. Again, our work is competitive with the state-of-the-art greedy parsers.  <ref type="table" target="#tab_42">Table 4</ref>: Development and test set results for shiftreduce dependency parser on Penn Chinese Treebank (CTB-5) using only (s 1 , s 0 , q 0 ) position features (trained and tested with gold POS tags). <ref type="table" target="#tab_22">Table 5</ref> compares our constituency parsing results with state-of-the-art incremental parsers. Although our work are definitely less accurate than those beam-search parsers, we achieve the highest accuracy among greedy parsers, for both English and Chinese. <ref type="bibr">1</ref>   </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Constituency Parsing: English &amp; Chinese</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Related Work</head><p>Because recurrent networks are such a natural fit for modeling languages (given the sequential nature of the latter), bi-directional LSTM networks are becoming increasingly common in all sorts of linguistic tasks, for example event detection in <ref type="bibr">Ghaeini et al. (2016)</ref>. In fact, we discovered after submission that <ref type="bibr">Kiperwasser and Goldberg (2016)</ref> have concurrently developed an extremely similar approach to our dependency parser. Instead of extending it to constituency parsing, they also apply the same idea to graph-based dependency parsing.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">Conclusions</head><p>We have presented a simple bi-directional LSTM sentence representation model for minimal features in both incremental dependency and incremental constituency parsing, the latter using a novel shift-promote-adjoint algorithm. Experiments show that our method are competitive with the state-of-the-art greedy parsers on both parsing tasks and on both English and Chinese.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>In phrase-based SMT, the phrase pairs in the translation model are traditionally trained by applying a heuristic extraction method <ref type="bibr">(Och and Ney, 2000)</ref> which extracts phrase pairs based on consistency of word alignments from a word-aligned bilingual training data. The probabilities of the translation model are then calculated based on the relative frequencies of the extracted phrase pairs. A notable shortcoming of this approach is that the translation model probabilities thus calculated from the training bitext can be unintuitive and unreliable <ref type="bibr">(Marcu and Wong, 2002;</ref><ref type="bibr">Foster et al., 2006)</ref> as they reflect only the distribution over the phrase pairs observed in the training data.</p><p>However, from an SMT perspective it is important that the models reflect probability distributions which are preferred by the decoding process, i.e., phrase translations which are likely to be used frequently to achieve better translations should get higher scores and phrases which are less likely to be used should get low scores. In addition, the heuristic extraction algorithm generates all possible, consistent phrases including overlapping phrases. This means that translation probabilities are distributed over a very large number of phrase translation candidates most of which never lead to the best possible translation of a sentence.</p><p>In this paper, we propose a novel solution which is to re-estimate the models from the best BLEU translation of each source sentence in the bitext. An important contribution of our approach is that unlike previous approaches such as forced alignment <ref type="bibr">(Wuebker et al., 2010)</ref>, reordering and language models can also be re-estimated.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Related Work</head><p>The forced alignment technique of <ref type="bibr">Wuebker et al. (2010)</ref> forms the main motivation for our work. In forced alignment, given a sentence pair <ref type="bibr">(F, E)</ref>, a decoder determines the best phrase segmentation and alignment which will result in a translation of F into E. The best segmentation is defined as the one which maximizes the probability of translating the source sentence into the given target sentence. At the end, the phrase table is re-estimated using the phrase pair segmentations obtained from forced decoding. Thus forced alignment is a reestimation technique where translation probabilities are calculated based on their frequency in best-scoring hypotheses instead of the frequencies of all possible phrase pairs in the bitext. However, one limitation of forced alignment is that only the phrase translation model can be re-estimated since it is restricted to align the source sentence to the given target reference, thus fixing the choice of reordering decisions.</p><p>A similar line of work is proposed by <ref type="bibr">Lambert et al. (2011)</ref> and <ref type="bibr">Schwenk et al. (2011)</ref> who use a self-enhancing strategy to utilize additional mono- lingual source language data by aligning it to its target language translation obtained by using an SMT system to rank sentence translation probabilities. However, the main focus of their work is translation model adaptation by augmenting the bitext with additional training data and not the reestimation of the translation models trained on the parallel data.</p><p>In this work, we propose that aligning source sentences to their oracle BLEU translations provides a more realistic estimate of the models from the decoding perspective instead of aligning them to high quality human translations as in forced decoding.</p><p>Another relevant line of research relates tuning (weight optimisation), where our work lies between forced decoding <ref type="bibr">(Wuebker et al., 2010)</ref> and the bold updating approach of <ref type="bibr" target="#b18">(Liang et al., 2006)</ref>. However, our approach specifically proposes a novel method for training models using oracle BLEU translations.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Model Re-estimation</head><p>The idea of our approach is to re-estimate the models with n-best oracle-BLEU translations and sentence alignments resulting from decoding the source sentence. Given a source and its reference translation, the oracle-BLEU translation is defined as the translation output with highest BLEU score. Oracle BLEU translations have been previously used for different analytical purposes in SMT <ref type="bibr">(Srivastava et al., 2011;</ref><ref type="bibr">Dreyer et al., 2007;</ref><ref type="bibr">Wisniewski et al., 2010)</ref>. <ref type="figure" target="#fig_3">Figure 1</ref> shows example of word alignment obtained from EM training, segmentations and alignment obtained from forced decoding and oracle-BLEU re-estimation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Oracle BLEU</head><p>Ideally, one would like to re-estimate translation models directly from the n-best BLEU translations. However there are two problems in calculating BLEU for individual sentence: First, as discussed in <ref type="bibr">(Chiang et al., 2008)</ref>, BLEU is not designed to be used for sentences in isolation where it can exhibit rather volatile behavior. Hence, following their work and <ref type="bibr">(Watanabe et al., 2007)</ref>, we calculate BLEU for a sentence in the context of a exponentially-weighted moving average of previous translations. We briefly discuss the computation from <ref type="bibr">(Chiang et al., 2008)</ref> as follows: Given a source sentence f, and its reference translation r, for an n-best translation e * , let c(e) be defined as the vector of target length |e|, source length |f|, reference length |r|, and the number of n-gram matches between e and r, then two pseudo document parameters O and O f are defined as:</p><formula xml:id="formula_8">O ← 0.9 · (O + c(e * )), O f ← 0.9 · (O f + |f |) (1)</formula><p>O is an exponentially-weighted moving average of the vectors from previous sentences and O f is the correction of source length with respect to the previous sentences. Then the BLEU score for a sentence pairs (f,r) and translation e * is defined as:</p><p>B(e; f, r) = (O f + |f |) · BLEU (O + c(e * ; r)) (2)</p><p>The second problem as discussed in <ref type="bibr">Chiang et al. (2008)</ref> is that due to noise in the training data, a high-BLEU translation may contain certain rules which are unlikely to be used by the model. Hence following them, we use a weighted combination of BLEU and model score to select the n-best list: e * = argmax e (B(e) − µ · (B(e) − h(e).w)) <ref type="bibr" target="#b471">(3)</ref> where B(e) and h(e) are the BLEU and model scores of the candidate translation and w is the optimised weights for the models, µ controls the preference between BLEU and model scores to determine oracle translations. We set µ=0.5 to balance between BLEU scores almost as high as the max-BLEU translations, while staying close to translations preferred by the model. We also conducted a set of experiments with µ=0 (pure or absolute BLEU) in order to verify the necessity for the optimal combination. The lower scores for this setting as compared to the baseline verified that using only the best BLEU translation indeed degrades the performance of the re-estimated models. This finding for the optimal value of µ has also been established in <ref type="bibr">(Chiang et al., 2008)</ref> through a series of experiments.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Training</head><p>For obtaining the oracle-BLEU translations, we first train the translation models from the bitext using the standard pipeline of word alignment and heuristic extraction. Along with the phrase translation and language models, we also train a bilingual language model (BiLM) <ref type="bibr">(Niehues et al., 2011;</ref><ref type="bibr">Garmash and Monz, 2014)</ref>, as well as lexicalized <ref type="bibr">(Tillman, 2004)</ref> and hierarchical reordering models <ref type="bibr" target="#b308">(Galley and Manning, 2008)</ref>. We use a BiLM specifically as an instance of a reordering model in order to determine the effect of re-estimating re-ordering decisions from oracle-BLEU translations.</p><p>We use the decoder trained on these models to translate the training bitext. Along with the 1-best translation (based on model scores), we also store search graphs or lattices generated during the translations process. Using the target sentences, we convert the translation lattice to an isomorphic oracle-BLEU lattice which has the same set of nodes but the edges represent BLEU score differences corresponding to each transition. Finally, we extract n-best candidate translations from the graphs ranked on BLEU score as defined in Equation <ref type="bibr" target="#b471">(3)</ref>. Using the word alignments from the initial phrase table, we extract the alignments between each source sentence and each of their n-best oracle-BLEU translations. Finally, we re-train the phrase translations, re-ordering and BiLM on these translations and alignments.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Avoiding over-fitting</head><p>Re-estimation of the translation models from the n-best translation of the bitext could re-enforce the probabilities of the low frequency phrase pairs in the re-estimated models leading to over-fitting. Within forced decoding, <ref type="bibr">Wuebker et al. (2010)</ref> address this problem by using a leave-one-out approach where they modify the phrase translation probabilities for each sentence pair by removing the counts of all phrases that were extracted from that particular sentence. However, in our approach, we do not impose a constraint to produce the exact translation, instead we use the highest BLEU translations which may be very different from the references. Thus it is not strictly necessary to apply leave-one-out in our approach as a solution to over-fitting. Instead, we handle the problem by simply removing all the phrase pairs below a threshold count which in our case is 2,</p><formula xml:id="formula_9">φ init = φ baseline − φ C(e,f )&lt;2<label>(4)</label></formula><p>therefore removing phrase pairs with high probability but low frequency.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Experimental set up</head><p>Our experiments are carried out for an ArabicEnglish parallel corpus of approximately 1 million sentence pairs. We establish a baseline system by training models on this bitext and then compare this to a forced decoding implementation and to oracle-BLEU re-estimation using the same bitext.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Baseline and forced decoding</head><p>The initial training corpus we use is a collection of parallel sentences taken from OpenMT data sources released by the LDC. Phrase table, distortion models and the lexical BiLM are trained with initial alignments obtained using GIZA++ <ref type="bibr">(Och and Ney, 2003)</ref>. The English 5-gram target language model is trained with Kneser-Ney smoothing on news data of nearly 1.6B tokens. We use an in-house phrase-based SMT system similar to Moses. For all settings in this paper, weights were optimized on NIST's MT04 data set using pairwise ranked optimization <ref type="bibr">(Hopkins and May, 2011)</ref>.</p><p>For forced alignment we use the existing implementation within the Moses SMT toolkit (Koehn  <ref type="table" target="#tab_10">Table 1</ref>: Performance of our oracle-BLEU reestimation with varying size n of n-best lists for the MT09 test set. / indicates a statistically significant gain/drop at p &lt; 0.01 and / at p &lt; 0.05. Values in brackets show gains over the <ref type="bibr">baseline. et al., 2007)</ref> trained on the baseline phrase translation model. In order to increase the chances of producing the exact reference, we follow Foster and <ref type="bibr">Kuhn (2012)</ref> and relax the standard decoding parameters as follows: distortion limit=∞, stack size=2000, beam width=10e-30, and no threshold pruning of the translation model.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Oracle BLEU re-estimation</head><p>To obtain oracle-BLEU translations, we first train an initial SMT system and use it to decode the bitext. This system is identical to the baseline system except for the removal of low-frequency phrase pairs from the baseline phrase table as described in Section 3.3. To obtain the n-best oracle-BLUE translations, we experiment with different values of n, where n ∈ {1, 10, 100}. From these oracle-BLEU translations and alignments all phrases that were used in the derivation of these nbest sentences are extracted and the models are reestimated by re-calculating the translation probabilities. Hierarchical and lexicalized re-ordering models as well as the BiLM are re-trained using the source sentences, oracle-BLEU translations and word alignments. For testing the performance of the re-estimated models, we tune different systems while replacing the baseline models with the corresponding re-estimated models. We also experiment with the interpolation of re-estimated models with the respective baseline models. We evaluate against 4 test sets: MT05, MT06, MT08, and MT09. Case-insensitive 4-gram BLEU <ref type="bibr" target="#b284">(Papineni et al., 2002</ref>) is used as evaluation metric. Approximate randomization <ref type="bibr">(Noreen., 1989;</ref><ref type="bibr">Riezler and Maxwell, 2005</ref>) is used to detect statistically significant differences.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Results</head><p>We discuss the experimental results of our oracle-BLEU re-estimation approach for different models and settings and provide a comparison with the baseline (heuristic training) and forced alignment.</p><p>Re-estimated models with three different values of n ∈ {1, 10, 100} were evaluated under three settings: phrase table re-estimation, interpolation, and BiLM re-estimation. The best improvements over the baseline are obtained by using only 1-best (n= 1) alignments as shown in <ref type="table" target="#tab_10">Table 1</ref>. Surprisingly, this is in contrast with forced decoding as discussed in <ref type="bibr">Wuebker et al. (2010)</ref>, where the best improvements are obtained for n = 100. <ref type="table" target="#tab_5">Table 2</ref> provides a comparison between BLEU improvements achieved by forced decoding (n = 100 best) and our oracle-BLEU re-estimation approach (n = 1 best) over the baseline for different models. One can see in <ref type="table" target="#tab_5">Table 2</ref> that while phrase table re-estimation drops substantially for forced decoding for all test sets (up to -1.4 for MT09), oracle-BLEU phrase table re-estimation shows either slight improvements or negligible drops compared to the baseline. For the linear interpolation of the re-estimated phrase table with the baseline, forced decoding shows only a slight improvement for MT06, MT08 and MT09 and still suffers from a substantial drop for MT05. On the other hand, oracle-BLEU re-estimation shows consistent improvements for all test sets with a maximum gain of up to +0.7 for MT06. It is important to note here that although linear interpolation extinguishes the advantage of a smaller phrase table size obtained by re-estimation, the improvement achieved by interpolation for oracle-BLEU re-estimation are significantly higher as compared to forced decoding.</p><p>An important novelty of oracle-BLEU reestimation is that it also allows for re-training of other models alongside the phrase table. Here we provide the results for the re-estimation of a BiLM. For all test sets, BiLM re-estimation provides additional improvements over simple phrase table interpolation, demonstrating that reestimation of re-ordering models can further improve translation performance. The last row of <ref type="table" target="#tab_5">Table 2</ref> shows that the re-estimated BiLM on its own adds BLEU improvement of up to +0.5 (for MT09). The highest BLEU improvement of +0.8 is achieved by using a re-estimated BiLM and an interpolated phrase table. Note that re-estimation of BiLM or re-ordering models is not possible for forced decoding due to the constraint of having to match the exact reference. <ref type="bibr">For</ref>     <ref type="table" target="#tab_42">Table 4</ref>: Phrase table sizes compared to baseline for Oracle-BLUE re-estimation and Forced decoding for different n-best list sizes, FD LO = Forced decoding with leave-one-out.</p><p>ysis, we experimented with the interpolation of both the re-estimated phrase table (forced decoding and oracle-BLEU) with the baseline. However, improvements achieved with this interpolation did not surpass the best result obtained for the oracle-BLEU re-estimation. Additionally, we also compare oracle-BLEU re-estimation to forced decoding with leave-oneout <ref type="bibr">(Wuebker et al., 2010)</ref> by evaluating both on a concatenation of 5 test sets (MT03, MT05-MT09). As shown in <ref type="table" target="#tab_6">Table 3</ref>, even with leaveone-out, forced decoding performance drops below the baseline by -0.3 BLEU. In contrast, phrase tables re-estimated from oracle-BLEU translation achieves the same performance as the baseline. When interpolated with the baseline phrase table, both approaches show significant improvements over the baseline. This implies that only in combination with the original phrase table does forced-decoding with leave-one-out outperform the baseline. On the other hand, oracle-BLEU re-estimation by its own not only performs better than forced decoding, but also gives a performance equal to forced decoding with leave-oneout when interpolated with baseline phrase table. In addition to the BLEU improvements, our approach also results in a re-estimated phrase table with a significantly reduced size as compared to the baseline. As shown in <ref type="table" target="#tab_42">Table 4</ref>, out of all the settings, the minimum phrase table size after oracle-BLEU re-estimation is only 3.28% of baseline (i.e., a reduction of 96.72%) while it is 7.6% for forced decoding.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Conclusions</head><p>In this paper, we proposed a novel technique for improving the reliability of SMT models by model re-estimation from oracle-BLEU translations of the source sentences in the bitext. Our experimental results show BLEU score improvements of up to +0.8 points for oracle-BLEU re-estimation over a strong baseline along with a substantially reduced size of the re-estimated phrase table (3.3% of the baseline). An important novelty of our approach is that it also allows for the re-estimation of re-ordering models which can yield further improvements in SMT performance as demonstrated by the re-estimation of a BiLM. <ref type="bibr">David Chiang, Yuval Marton, and Philip Resnik. 2008</ref>.</p><p>Online large-margin training of syntactic and structural translation features. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>In spoken dialogue systems (SDS), the task of natural language generation (NLG) is to convert a meaning representation (MR) produced by the dialogue manager into one or more sentences in a natural language. It is traditionally divided into two subtasks: sentence planning, which decides on the overall sentence structure, and surface realization, determining the exact word forms and linearizing the structure into a string <ref type="bibr" target="#b536">(Reiter and Dale, 2000)</ref>. While some generators keep this division and use a two-step pipeline <ref type="bibr">(Walker et al., 2001;</ref><ref type="bibr">Rieser et al., 2010;</ref><ref type="bibr">Dethlefs et al., 2013)</ref>, others apply a joint model for both tasks <ref type="bibr">(Wong and Mooney, 2007;</ref><ref type="bibr">Konstas and Lapata, 2013)</ref>. We present a new, conceptually simple NLG system for SDS that is able to operate in both modes: it either produces natural language strings or generates deep syntax dependency trees, which are subsequently processed by an external surface realizer <ref type="bibr">(Dušek et al., 2015)</ref>. This allows us to show a direct comparison of two-step generation, where sentence planning and surface realization are separated, with a joint, one-step approach.</p><p>Our generator is based on the sequence-tosequence (seq2seq) generation technique , combined with beam search and an n-best list reranker to suppress irrelevant information in the outputs. Unlike most previous NLG systems for <ref type="bibr">SDS (e.g., (Stent et al., 2004;</ref><ref type="bibr">Raux et al., 2005;</ref><ref type="bibr">Mairesse et al., 2010)</ref>), it is trainable from unaligned pairs of MR and sentences alone. We experiment with using much less training data than recent systems based on recurrent neural networks (RNN) <ref type="bibr">(Wen et al., 2015b;</ref><ref type="bibr">Mei et al., 2015)</ref>, and we find that our generator learns successfully to produce both strings and deep syntax trees on the BAGEL restaurant information dataset <ref type="bibr">(Mairesse et al., 2010)</ref>. It is able to surpass n-gram-based scores achieved previously by <ref type="bibr">Dušek and Jurčíček (2015)</ref>, offering a simpler setup and more relevant outputs.</p><p>We introduce the generation setting in Section 2 and describe our generator architecture in Section 3. Section 4 details our experiments, Section 5 analyzes the results. We summarize related work in Section 6 and offer conclusions in Section 7.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Generator Setting</head><p>The input to our generator are dialogue acts (DA) <ref type="bibr">(Young et al., 2010)</ref> representing an action, such as inform or request, along with one or more attributes (slots) and their values. Our generator operates in two modes, producing either deep syntax trees <ref type="bibr">(Dušek et al., 2012)</ref> or natural language strings (see <ref type="figure" target="#fig_3">Fig. 1</ref>). The first mode corresponds to the sentence planning NLG stage as it decides the syntactic shape of the output sentence; the resulting deep syntax tree involves content words (lemmas) and their syntactic form (formemes, purple in <ref type="figure" target="#fig_3">Fig. 1</ref>). The trees are linearized to strings using a  surface realizer from the TectoMT translation system <ref type="bibr">(Dušek et al., 2015)</ref>. The second generator mode joins sentence planning and surface realization into one step, producing natural language sentences directly. Both modes offer their advantages: The twostep mode simplifies generation by abstracting away from complex surface syntax and morphology, which can be handled by a handcrafted, domain-independent module to ensure grammatical correctness at all times <ref type="bibr">(Dušek and Jurčíček, 2015)</ref>, and the joint mode does not need to model structure explicitly and avoids accumulating errors along the pipeline <ref type="bibr">(Konstas and Lapata, 2013</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">The Seq2seq Generation Model</head><p>Our generator is based on the seq2seq approach , a type of an encoder-decoder RNN architecture operating on variable-length sequences of tokens. We address the necessary conversion of input DA and output trees/sentences into sequences in Section 3.1 and then describe the main seq2seq component in Section 3.2. It is supplemented by a reranker, as explained in Section 3.3.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Sequence Representation of DA, Trees,</head><p>and Sentences We represent DA, deep syntax trees, and sentences as sequences of tokens to enable their usage in the sequence-based RNN components of our generator (see <ref type="bibr">Sections 3.2 and 3.3)</ref>. Each token is represented by its embedding -a vector of floatingpoint numbers .</p><p>To form a sequence representation of a DA, we create a triple of the structure "DA type, slot, value" for each slot in the DA and concatenate the triples (see <ref type="figure" target="#fig_6">Fig. 3</ref>). The deep syntax tree output from the seq2seq generator is represented in a bracketed notation similar to the one used by <ref type="bibr">Vinyals et al. (2015, see Fig. 2)</ref>. The inputs to the reranker are always a sequence of tokens; structure is disregarded in trees, resulting in a list of lemma-formeme pairs (see <ref type="figure" target="#fig_8">Fig. 2</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Seq2seq Generator</head><p>Our seq2seq generator with attention <ref type="bibr">(Bahdanau et al., 2015, see Fig. 3)</ref> 1 starts with the encoder stage, which uses an RNN to encode an input sequence x = {x 1 , . . . , x n } into a sequence of encoder outputs and hidden states h = {h 1 , . . . , h n }, where h t = lstm(x t , h t−1 ), a non-linear function represented by the long-short-term memory (LSTM) cell <ref type="bibr" target="#b645">(Graves, 2013)</ref>.</p><p>The decoder stage then uses the hidden states to generate a sequence y = {y 1 , . . . , y m } with a second LSTM-based RNN. The probability of each output token is defined as: p(y t |y 1 , . . . , y t−1 , x) = softmax((s t • c t )W Y )</p><p>Here, s t is the decoder state where s 0 = h n and s t = lstm((y t−1 • c t )W S , s t−1 ), i.e., the decoder is initialized by the last hidden state and uses the previous output token at each step. W Y and W S are learned linear projection matrices and "•" denotes concatenation. c t is the context vector -a weighted sum of the encoder hidden states c t = n i=1 α ti h i , where α ti corresponds to an alignment model, represented by a feed-forward network with a single tanh hidden layer.</p><p>On top of this basic seq2seq model, we implemented a simple beam search for decoding <ref type="bibr" target="#b80">Bahdanau et al., 2015)</ref>. It proceeds left-to-right and keeps track of log probabilities of top n possible output sequences, expanding them one token at a time.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Reranker</head><p>To ensure that the output trees/strings correspond semantically to the input DA, we implemented a classifier to rerank the n-best beam search outputs and penalize those missing required information and/or adding irrelevant one. Similarly to <ref type="bibr">Wen et al. (2015a)</ref>, the classifier provides a binary decision for an output tree/string on the presence of all dialogue act types and slot-value combinations seen in the training data, producing a 1-hot vector.</p><p>( &lt;root&gt; &lt;root&gt; ( ( X-name n:subj ) be v:fin ( ( Italian adj:attr ) restaurant n:obj ( river n:near+X ) ) ) ) X-name n:subj be v:fin Italian adj:attr restaurant n:obj river n:near+X The reranker The input DA is converted to a similar 1-hot vector and the reranking penalty of the sentence is the Hamming distance between the two vectors (see <ref type="figure" target="#fig_15">Fig. 4</ref>). Weighted penalties for all sentences are subtracted from their n-best list log probabilities.</p><p>We employ a similar architecture for the classifier as in our seq2seq generator encoder (see Section 3.2), with an RNN encoder operating on the output trees/strings and a single logistic layer for classification over the last encoder hidden state. Given an output sequence representing a string or a tree y = {y 1 , . . . , y n } (cf. Section 3.1), the encoder again produces a sequence of hidden states h = {h 1 , . . . , h n } where h t = lstm(y t , h t−1 ).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>The output binary vector o is computed as:</head><p>o i = sigmoid((h n · W R + b) i ) Here, W R is a learned projection matrix and b is a corresponding bias term.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Experiments</head><p>We perform our experiments on the BAGEL data set of <ref type="bibr">Mairesse et al. (2010)</ref>, which contains 202 DA from the restaurant information domain with two natural language paraphrases each, describing restaurant locations, price ranges, food types etc. Some properties such as restaurant names or phone numbers are delexicalized (replaced with "X" symbols) to avoid data sparsity. <ref type="bibr">2</ref> Unlike <ref type="bibr">Mairesse et al. (2010)</ref>, we do not use <ref type="bibr">2</ref> We adopt the delexicalization scenario used by <ref type="bibr">Mairesse et al. (2010)</ref> and <ref type="bibr">Dušek and Jurčíček (2015)</ref>. manually annotated alignment of slots and values in the input DA to target words and phrases and let the generator learn it from data, which simplifies training data preparation but makes our task harder. We lowercase the data and treat plural -s as separate tokens for generating into strings, and we apply automatic analysis from the Treex NLP toolkit <ref type="bibr">(Popel andŽabokrtský, 2010)</ref> to obtain deep syntax trees for training tree-based generator setups. <ref type="bibr" target="#b471">3</ref> Same as <ref type="bibr">Mairesse et al. (2010)</ref>, we apply 10-fold cross-validation, with 181 training DA and 21 testing DA. In addition, we reserve 10 DA from the training set for validation. <ref type="bibr">4</ref> To train our seq2seq generator, we use the Adam optimizer <ref type="bibr">(Kingma and Ba, 2015)</ref> to minimize unweighted sequence cross-entropy. <ref type="bibr">5</ref> We perform 10 runs with different random initialization of the network and up to 1,000 passes over the training data, 6 validating after each pass and selecting the parameters that yield the highest BLEU score on the validation set. Neither beam search nor the reranker are used for validation.</p><p>We use the Adam optimizer minimizing crossentropy to train the reranker as well. <ref type="bibr">7</ref> We perform a single run of up to 100 passes over the data, and we also validate after each pass and select the parameters giving minimal Hamming distance on both validation and training set. 8 <ref type="bibr" target="#b471">3</ref> The input vocabulary size is around 45 (DA types, slots, and values added up) and output vocabulary sizes are around 170 for string generation and 180 for tree generation (45 formemes and 135 lemmas). <ref type="bibr">4</ref> We treat the two paraphrases for the same DA as separate instances in the training set but use them together as two references to measure BLEU and NIST scores <ref type="bibr" target="#b284">(Papineni et al., 2002;</ref><ref type="bibr" target="#b267">Doddington, 2002)</ref> on the validation and test sets. <ref type="bibr">5</ref> Based on a few preliminary experiments, the learning rate is set to 0.001, embedding size 50, LSTM cell size 128, and batch size 20. Reranking penalty for decoding is 100. <ref type="bibr">6</ref> Training is terminated early if the top 10 so far achieved validation BLEU scores do not change for 100 passes. <ref type="bibr">7</ref> We use the same settings as with the seq2seq generator. <ref type="bibr">8</ref> The validation set is given 10 times more importance.  <ref type="table" target="#tab_10">Table 1</ref>: Results on the BAGEL data set NIST, BLEU, and semantic errors in a sample of the output.</p><p>* <ref type="bibr">Mairesse et al. (2010)</ref> use manual alignments in their work, so their result is not directly comparable to ours. The zero semantic error is implied by the manual alignments and the architecture of their system.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Results</head><p>The results of our experiments and a comparison to previous works on this dataset are shown in Table 1. We include BLEU and NIST scores and the number of semantic errors (incorrect, missing, and repeated information), which we assessed manually on a sample of 42 output sentences (outputs of two randomly selected cross-validation runs). The outputs of direct string generation show that the models learn to produce fluent sentences in the domain style; 9 incoherent sentences are rare, but semantic errors are very frequent in the greedy search. Most errors involve confusion of semantically close items, e.g., Italian instead of French or riverside area instead of city centre (see Table 2); items occurring more frequently are preferred regardless of their relevance. The beam search brings a BLEU improvement but keeps most semantic errors in place. The reranker is able to reduce the number of semantic errors while increasing automatic scores considerably. Using a larger beam increases the effect of the reranker as expected, resulting in slightly improved outputs.</p><p>Models generating deep syntax trees are also able to learn the domain style, and they have virtually no problems producing valid trees. <ref type="bibr">10</ref> The surface realizer works almost flawlessly on this lim- <ref type="bibr">9</ref> The average sentence length is around 13 tokens. <ref type="bibr">10</ref> The generated sequences are longer, but have a very rigid structure, i.e., less uncertainty per generation step. The average output length is around 36 tokens in the generated sequence or 9 tree nodes; surface realizer outputs have a similar length as the sentences produced in direct string generation.</p><p>ited domain <ref type="bibr">(Dušek and Jurčíček, 2015)</ref>, leaving the seq2seq generator as the major error source. The syntax-generating models tend to make different kinds of errors than the string-based models: Some outputs are valid trees but not entirely syntactically fluent; missing, incorrect, or repeated information is more frequent than a confusion of semantically similar items (see <ref type="table" target="#tab_5">Table 2</ref>). Semantic error rates of greedy and beam-search decoding are lower than for string-based models, partly because confusion of two similar items counts as two errors. The beam search brings an increase in BLEU but also in the number of semantic errors. The reranker is able to reduce the number of errors and improve automatic scores slightly. A larger beam leads to a small BLEU decrease even though the sentences contain less errors; here, NIST reflects the situation more accurately.</p><p>A comparison of the two approaches goes in favor of the joint setup: Without the reranker, models generating trees produce less semantic errors and gain higher BLEU/NIST scores. However, with the reranker, the string-based model is able to reduce the number of semantic errors while producing outputs significantly better in terms of BLEU/NIST. <ref type="bibr">11</ref> In addition, the joint setup does not need an external surface realizer. The best results of both setups surpass the best results on this dataset using training data without manual alignments <ref type="bibr">(Dušek and Jurčíček, 2015)</ref> in both automatic metrics 12 and the number of semantic errors.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Related Work</head><p>While most recent NLG systems attempt to learn generation from data, the choice of a particular approach -pipeline or joint -is often arbitrary and depends on system architecture or particular generation domain. Works using the pipeline approach in SDS tend to focus on sentence planning, improving a handcrafted generator <ref type="bibr">(Walker et al., 2001;</ref><ref type="bibr">Stent et al., 2004;</ref><ref type="bibr">Paiva and Evans, 2005)</ref> or using perceptron-guided A* search <ref type="bibr">(Dušek and Jurčíček, 2015)</ref>. Generators taking the joint approach employ various methods, e.g., factored language models <ref type="bibr">(Mairesse et al., 2010)</ref>, inverted parsing <ref type="bibr">(Wong and Mooney, 2007;</ref><ref type="bibr">Konstas and Lapata, 2013)</ref>, or a pipeline of discriminative classifiers <ref type="bibr" target="#b22">(Angeli et al., 2010)</ref>. Unlike most previous Input DA inform <ref type="bibr">(name=X-name, type=placetoeat, eattype=restaurant, area=citycentre, near=X-near,</ref> food="Chinese takeaway", food=Japanese) Reference X is a Chinese takeaway and Japanese restaurant in the city centre near X. Greedy with trees X is a restaurant offering chinese takeaway in the centre of town near X.</p><p>[Japanese] + Beam search X is a restaurant and japanese food and chinese takeaway. + Reranker X is a restaurant serving japanese food in the centre of the city that offers chinese takeaway. Greedy into strings X is a restaurant offering italian and indian takeaway in the city centre area near X. [Japanese, Chinese] + Beam search X is a restaurant that serves fusion chinese takeaway in the riverside area near X. [Japanese, citycentre] + Reranker X is a japanese restaurant in the city centre near X providing chinese food.</p><p>[takeaway] Input DA inform(name=X-name, type=placetoeat, eattype=restaurant, area=riverside, food=French) Reference X is a French restaurant on the riverside. Greedy with trees X is a restaurant providing french and continental and by the river. + Beam search X is a restaurant that serves french takeaway.</p><p>[riverside] + Reranker X is a french restaurant in the riverside area. Greedy into strings X is a restaurant in the riverside that serves italian food. <ref type="bibr">[French]</ref> + Beam search X is a restaurant in the riverside that serves italian food.</p><p>[French] + Reranker X is a restaurant in the riverside area that serves french food. Input DA inform(name=X-name, type=placetoeat, eattype=restaurant, near=X-near, food=Continental, food=French) Reference X is a French and Continental restaurant near X. Greedy with trees X is a french restaurant that serves french food and near X.</p><p>[Continental] + Beam search X is a french restaurant that serves french food and near X.</p><p>[Continental] + Reranker X is a restaurant serving french and continental food near X. Greedy into strings X is a french and continental style restaurant near X. + Beam search X is a french and continental style restaurant near X. + Reranker X is a restaurant providing french and continental food, near X. <ref type="table" target="#tab_5">Table 2</ref>: Example outputs of different generator setups (beam size 100 is used). Errors are marked in color (missing, superfluous, repeated information, disfluency).</p><p>NLG systems, our generator is trainable from unaligned pairs of MR and sentences alone. Recent RNN-based generators are most similar to our work. <ref type="bibr">Wen et al. (2015a)</ref> combined two RNN with a convolutional network reranker; <ref type="bibr">Wen et al. (2015b)</ref> later replaced basic sigmoid cells with an LSTM. <ref type="bibr">Mei et al. (2015)</ref> present the only seq2seq-based NLG system known to us. We extend the previous works by generating deep syntax trees as well as strings and directly comparing pipeline and joint generation. In addition, we experiment with an order-of-magnitude smaller dataset than other RNN-based systems.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">Conclusions and Future Work</head><p>We have presented a direct comparison of two-step generation via deep syntax trees with a direct generation into strings, both using the same NLG system based on the seq2seq approach. While both approaches offer decent performance, their outputs are quite different. The results show the direct approach as more favorable, with significantly higher n-gram based scores and a similar number of semantic errors in the output.</p><p>We also showed that our generator can learn to produce meaningful utterances using a much smaller amount of training data than what is typically used for RNN-based approaches. The resulting models had virtually no problems with producing fluent, coherent sentences or with generating valid structure of bracketed deep syntax trees. Our generator was able to surpass the best BLEU/NIST scores on the same dataset previously achieved by a perceptron-based generator of <ref type="bibr">Dušek and Jurčíček (2015)</ref> while reducing the amount of irrelevant information on the output.</p><p>Our generator is released on GitHub at the following URL:</p><p>https://github.com/UFAL-DSG/tgen</p><p>We intend to apply it to other datasets for a broader comparison, and we plan further improvements, such as enhancing the reranker or including a bidirectional encoder <ref type="bibr" target="#b80">(Bahdanau et al., 2015;</ref><ref type="bibr">Mei et al., 2015;</ref> and sequence level training <ref type="bibr">(Ranzato et al., 2015</ref> </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Meaning is not uniform, neither across space, nor across time. Across space, different languages tend to exhibit different polysemous associations for corresponding terms <ref type="bibr">(Eger et al., 2015;</ref><ref type="bibr">Kulkarni et al., 2015b)</ref>. Across time, several wellknown examples of meaning change in English have been documented. For example, the word gay's meaning has shifted, during the 1970s, from an adjectival meaning of cheerful at the beginning of the 20 th century to its present meaning of homosexual <ref type="bibr">(Kulkarni et al., 2015a)</ref>. Similarly, technological progress has led to semantic broadening of terms such as transmission, mouse, or apple.</p><p>In this work, we consider two graph models of semantic change. Our first model is a dynamic model in that the underlying paradigm is a (time-)series of graphs. Each node in the series of graphs corresponds to one word, associated with which is a semantic embedding vector. We then ask how the embedding vectors in one time period (graph) can be predicted from the embedding vectors of neighbor words in previous time periods. In particular, we postulate that there is a linear functional relationship that couples a word's today's meaning with its neighbor's meanings in the past. When estimating the coefficients of this model, we find that the linear form appears indeed very plausible. This functional form then allows us to address further questions, such as negative relationships between words -which indicate semantic differentiation over time -as well as projections into the future. We call our second graph model time-indexed self-similarity graphs. In these graphs, each node corresponds to a time point and the link between two time points indicates the semantic similarity of a specific word across the two time points under consideration. The analysis of these graphs reveals that most words obey a law of linear semantic 'decay': semantic self-similarity decreases linearly over time.</p><p>In our work, we capture semantics by means of word embeddings derived from context-predicting neural network architectures, which have become the state-of-the-art in distributional semantics modeling . Our approach and results are partly independent of this representation, however, in that we take a structuralist approach: we derive new, 'second-order embeddings' by modeling the meaning of words by means of their semantic similarity relations to all other words in the vocabulary <ref type="bibr">(de Saussure, 1916;</ref><ref type="bibr">Rieger, 2003)</ref>. Thus, future research may in principle substitute the deep-learning architectures for semantics considered here by any other method capable of producing semantic similarity values between lexical units.</p><p>This work is structured as follows. In §2, we discuss related work. In §3.1 and 3.2, respectively, we formally introduce the two graph models outlined. In §4, we detail our experiments and in §5, we conclude.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Related work</head><p>Broadly speaking, one can distinguish two recent NLP approaches to meaning change analysis. On the one hand, coarse-grained trend analyses compare the semantics of a word in one time period with the meaning of the word in the preceding time period <ref type="bibr">(Jatowt and Duh, 2014;</ref><ref type="bibr">Kulkarni et al., 2015a)</ref>. Such coarse-grained models, by themselves, do not specify in which respects a word has changed (e.g., semantic broadening or narrowing), but just aim at capturing whether meaning change has occurred. In contrast, more fine-grained analyses typically senselabel word occurrences in corpora and then investigate changes in the corresponding meaning distributions <ref type="bibr">(Rohrdantz et al., 2011;</ref><ref type="bibr">Mitra et al., 2014;</ref><ref type="bibr">Plitz et al., 2015;</ref>. Sense-labeling may be achieved by clustering of the context vectors of words <ref type="bibr" target="#b424">(Huang et al., 2012;</ref><ref type="bibr">Neelakantan et al., 2014)</ref> or by applying LDA-based techniques where word contexts take the roles of documents and word senses take the roles of topics <ref type="bibr">(Rohrdantz et al., 2011;</ref><ref type="bibr">Lau et al., 2012)</ref>. Finally, there are studies that test particular meaning change hypotheses such as whether similar words tend to diverge in meaning over time (according to the 'law of differentiation') <ref type="bibr">(Xu and Kemp, 2015)</ref> and papers that intend to detect corresponding terms across time (words with similar meanings/roles in two time periods but potentially different lexical forms) .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Graph models</head><p>Let V = {w 1 , . . . , w |V | } be the common vocabulary (intersection) of all words in all time periods t ∈ T . Here, T is a set of time indices. Denote an embedding of a word w i at time period t as w i (t) ∈ R d . Since embeddings w i (s), w i (t) for two different time periods s, t are generally not comparable, as they may lie in different coordinate systems, we consider the vectorsw i (t) = sim(w i (t), w 1 (t)), . . . , sim(w i (t), w |V | (t)) , (1) each of which lies in R |V | and where sim is a similarity function such as the cosine. We note that our structuralist definition ofw i (t) is not unproblematic, since the vectors w 1 (t), . . . , w |V | (t) tend to be different across t, by our very postulate, so that there is non-identity of these 'reference points' over time. However, as we may assume that the meanings of at least a few words are stable over time, we strongly expect the vectorsw i (t) to be suitable for our task of analysis of meaning changes. 1 For the remainder of this work, for convenience, we do not distinguish, in terms of notation, between w i (t) andw i (t).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">A linear model of semantic change</head><p>We postulate, and subsequently test, the following model of meaning dynamics which describes meaning change over time for words w i :</p><formula xml:id="formula_10">w i (t) = p n=1 w j ∈V ∩N (w i ) α n w j w j (t − n) (2)</formula><p>where α n w j ∈ R, for n = 1, . . . , p, are coefficients of meaning vectors w j (t − n) and p ≥ 1 is the order of the model. The set N (w i ) ⊆ V denotes a set of 'neighbors' of word w i . <ref type="bibr">2</ref> This model says that the meaning of a word w i at some time t is determined by reference to the meanings of its 'neighbors' in previous time periods, and that the underlying functional relationship is linear.</p><p>We remark that the model described by Eq. (2) is a time-series model, and, in particular, a vector-autoregressive (VAR) model with special 1 An alternative to our second-order embeddings is to project vectors from different time periods in a common space , which requires to find corresponding terms across time. Further, one could also consider a 'core' vocabulary of semantically stable words, e.g., in the spirit of <ref type="bibr">Swadesh (1952)</ref>, instead of using all vocabulary words as reference. <ref type="bibr">2</ref> We also constrain the vectors wi(t), for all wi ∈ V , to contain non-zero entries only for words in N (wi).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>2</head><p>53 structure. The model may also be seen in the socio-economic context of so-called "opinion dynamic models" <ref type="bibr">(Golub and Jackson, 2010;</ref><ref type="bibr">Acemoglu and Ozdaglar, 2011;</ref><ref type="bibr">Eger, 2016)</ref>. There it is assumed that agents are situated in network structures and continuously update their opinions/beliefs/actions according to their ties with other agents. Model (2) substitutes multi-dimensional embedding vectors for onedimensional opinions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Time-indexed self-similarity graphs</head><p>We track meaning change by considering a fully connected graph G(w) for each word w in V . The nodes of G(w) are the time indices T , and there is an undirected link between any two s, t ∈ T whose weight is given by sim(w(s), w(t)). We call the graphs G(w) time-indexed self-similarity (TISS) graphs because they indicate the (semantic) similarity of a given word with itself across different time periods. Particular interest may lie in weak links in these graphs as they indicate low similarity between two different time periods, i.e., semantic change across time.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Experiments</head><p>Data As corpus for English, we use the Corpus of Historical American (COHA). <ref type="bibr" target="#b471">3</ref> This covers texts from the time period 1810 to 2000. We extract two slices: the years 1900-2000 and 1810-2000. For both slices, each time period t is one decade, e.g., T = {1810, 1820, 1830, . . .}. <ref type="bibr">4</ref> For each slice, we only keep words associated to the word classes nouns, adjectives, and verbs. For computational and estimation purposes, we also only consider words that occur at least 100 times in each time period. To induce word embeddings w ∈ R d for each word w ∈ V , we use word2vec  with default parametrizations. We do so for each time period t ∈ T independently. We then use these embeddings to derive the new embeddings as in Eq. (1). Throughout, we use cosine similarity as sim measure. For German, we consider a proprietary dataset of the German newspaper SZ 5 for which T = {1994, 1995, . . . , 2003}.</p><p>We lemmatize and POS tag the data and likewise only consider nouns, verbs and adjectives, making the same frequency constraints as in English. Finally, we use the PL (Migne, 1855) as data set for Latin. Here, T = {300, 400, . . . , 1300}. We use the same preprocessing, frequency, and word class constraints as for English and German.</p><p>Throughout, our datasets are well-balanced in terms of size. For example, the English COHA datasets contain about 24M-30M tokens for each decade from 1900 to 2000, where the decades 1990 and 2000 contain slighly more data than the earlier decades. The pre-1900 decades contain 18-24M tokens, with only the decades 1810 and 1820 containing very little data (1M and 7M tokens, respectively). The corpora are also balanced by genre.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">TISS graphs</head><p>We start with investigating the TISS graphs. Let D t 0 represent how semantically similar a word is across two time periods, on average, when the distance between time periods is t 0 :  The values D t 0 as a function of t 0 are averages over all words. Thus, it might be possible that the average word's meaning decays linearly in time, while the semantic behavior, over time, of a large fraction of words follows different trends. To investigate this, we consider the distribution of</p><formula xml:id="formula_11">D t 0 = 1 C w∈V |s−t|=t 0 sim(w(s), w(t)), where C = |V | · |{(s, t) | |s − t| = t 0 }| is a normalizer.</formula><formula xml:id="formula_12">D t 0 (w) = 1 C ′ |s−t|=t 0</formula><p>sim(w(s), w(t)) over fixed words w. Here C ′ = |{(s, t) | |s − t| = t 0 }|. We consider the regression models</p><formula xml:id="formula_13">D t 0 (w) = α · t 0 + const.</formula><p>for each word w independently and assess the distribution of coefficients α as well as the goodnessof-fit values. <ref type="figure" target="#fig_8">Figure 2</ref> shows -exemplarily for the English 1900-2000 COHA data -that the coefficients α are negative for almost all words. In fact, the distribution is left-skewed with a mean of around −0.4%. Moreover, the linear model is always a good to very good fit of the data in that R 2 values are centered around 85% and rarely fall below 75%. We find similar patterns for all other datasets considered here. This shows that not only the average word's meaning decays linearly, but almost all words' (whose frequency mass exceeds a particular threshold) semantics behaves this way.</p><p>Next, we use our TISS graphs for the task of finding words that have undergone meaning change. To this end, we sort the graphs G(w) by the ratios R G(w) = maxlink minlink , where maxlink denotes maximal weight of a link in graph G(w) and minlink is the minimal weight of a link in graph G(w). We note that weak links may indicate semantic change, but the stated ratio requires that 'weakness' is seen relative to the strongest semantic links in the TISS graphs. <ref type="table" target="#tab_5">Table 2</ref>  selected words that have highest values R G(w) . <ref type="bibr">6</ref> We omit a fine-grained semantic change analysis, bush (1), web (2), alan (3), implement (4) jeff (5), gay (6), program (7), film (8), focus (9), terrific (16), axis (36) In brackets are the ranks of words, i.e., bush has the highest value R G(w) , web the 2nd highest, etc.</p><p>which could be conducted via the methods outlined in §2, but notice a few cases. 'Terrific' has a large semantic discrepancy between the 1900s and the 1970s, when the word probably (had) changed from a negative to a more positive meaning. The largest discrepancy for 'web' is between the 1940s and the 2000s, when it probably came to be massively used in the context of the Internet. The high R G(w) value for w = 'axis' derives from comparing its use in the 1900s with its use in the 1940s, when it probably came to be used in the context of Nazi Germany and its allies. We notice that the presented method can account for gradual, accumulating change, which is not possible for models that compare two succeeding time points such as the model of <ref type="bibr">Kulkarni et al. (2015a)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Meaning dynamics network models</head><p>Finally, we estimate meaning dynamics models as in Eq. (2), i.e., we estimate the coefficients α n w j from our data sources. We let the neighbors N (w) of a word w as in Eq. (2) be the union (w.r.t. t) over sets N t (w; n) denoting the n ≥ 1 semantically most similar words (estimated by cosine similarity on the original word2vec vectors) of word w in time period t ∈ T . 7 In <ref type="table" target="#tab_6">Table 3</ref>, we indicate two measures: adjusted R 2 , which indicates the goodness-of-fit of a model, and prediction error. By prediction error, we measure the average Euclidean distance between the true semantic vector of a word in the final time period t N vs. the predicted semantic vector, via the linear model in Eq. (2), estimated on the data excluding the final period. The indicated prediction error is the average over all words. We note the following: R 2 values are high (typically above 95%), indicating that the linear semantic change model we have suggested fits the data well. Moreover, R 2 values slightly increase between order p = 1 and p = 2; however, for prediction error this trend is reversed. <ref type="bibr">8</ref> We also include a strong baseline that claims that word meanings do not change in the final period t N but are the same as in t N −1 . We note that the order p = 1 model consistently improves upon this baseline, by as much as 18%, depending upon parameter settings.</p><p>Negative relationships Another very interest- <ref type="bibr">7</ref> We exclude word w from Nt(w; n). We found that including w did not improve performance results. <ref type="bibr">8</ref> We experimented with orders p ≥ 3, but found them to be inadequate. Typically, coefficients for lagged-3 variables are either zero or model predictions are way off, possibly indicating multi-collinearity.  <ref type="table" target="#tab_6">Table 3</ref>: English data, 1900-2000. R 2 and prediction error in %.</p><p>ing aspect of the model in Eq. (2) is that it allows for detecting words w j whose embeddings have negative coefficients α w j for a target word w i (we consider p = 1 in the remainder). Such negative coefficients may be seen as instantiations of the 'law of differentiation': the two words' meanings move, over time, in opposite directions in semantic space. We find significantly negative relationships between the following words, among others: summit ↔ foot, boy ↔ woman, vow ↔ belief, negro ↔ black. Instead of a detailed analysis, we mention that the Wikipedia entry for the last pair indicates that the meanings of 'negro' and 'black' switched roles between the early and late 20 th century. While 'negro' was once the "neutral" term for the colored population in the US, it acquired negative connotations after the 1960s; and vice versa for 'black'.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Concluding remarks</head><p>We suggested two novel models of semantic change. First, TISS graphs allow for detecting gradual, non-consecutive meaning change. They enable to detect statistical trends of a possibly general nature. Second, our time-series models allow for investigating negative trends in meaning change ('law of differentiation') as well as forecasting into the future, which we leave for future work. Both models hint at a linear behavior of semantic change, which deserves further investigation. We note that this linearity concerns the core vocabulary of languages (in our case, words that occurred at least 100 times in each time period), and, in the case of TISS graphs, is an average result; particular words may have drastic, non-linear meaning changes across time (e.g., proper names referring to entirely different entities). However, our analysis also finds that most core words' meanings decay linearly in time. This problem has inspired much recent work in low-resource speech recognition <ref type="bibr" target="#b164">(Lee et al., 2015;</ref><ref type="bibr">Lee and Glass, 2012;</ref><ref type="bibr">Jansen and Church, 2011;</ref><ref type="bibr">Varadarajan et al., 2008)</ref>, with impressive results. Nonetheless, many of these researchers conclude that their systems learn too many phonetic categories, a problem they attribute to the presence of contextual variants (allophones) of the different sounds. For instance, the <ref type="bibr">[a]</ref> in dog is likely longer than the <ref type="bibr">[a]</ref> in dock (Ladefoged and <ref type="bibr">Johnson, 2010)</ref>, but this difference is not phonologically meaningful in English-it cannot differentiate any pair of words on its own. Many unsupervised systems are claimed to erroneously learn these kinds of differences as categorical ones.</p><p>Here, we attempt to model the problem in a more controlled setting by extending work in cognitive modeling of language acquisition. We present a system which jointly acquires vowel categories and lexical items from a mixed symbolic/acoustic representation of the input. As is traditional in cognitive models of vowel acquisition, it uses a singlepoint formant representation of the vowel acoustics, and is tested on a simulated corpus in which vowel acoustics are unaffected by context. We find that, under these circumstances, vowel categories and lexical items can be learned jointly with relatively little decrease in accuracy from learning either alone. Thus, our results support the hypothesis that the more realistic problem is hard because of contextual variability. As a secondary point, we show that the results reflect problems with local minima in the popular framework of hierarchical Bayesian modeling.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Related work</head><p>This work aims to induce both a set of phonetic vowel categories and a lexical representation from unlabeled data. It extends the closely related model of <ref type="bibr">Feldman et al. (2013a)</ref>, which performs the same task, but with known word boundaries; this requirement is a significant limitation on the model's cognitive plausibility. Our model infers a latent word segmentation. Another extension, <ref type="bibr">Frank et al. (2014)</ref>, uses semantic information to disambiguate words, but still with known word boundaries.</p><p>A few models learn a lexicon while categorizing all sounds, instead of just vowels. <ref type="bibr" target="#b164">Lee et al. (2015)</ref> and <ref type="bibr">Lee and Glass (2012)</ref> use hierarchical Bayesian models to induce word and subword units. These models are mathematically very similar to our own, differing primarily using more complex acoustic representations and inducing categories for all sounds instead of just vowels. <ref type="bibr">Jansen and Church (2011)</ref> learns whole-word Markov models, then clusters their states into phone-like units using a spectral algorithm. Their system still learns multiple allophonic categories for most sounds.</p><p>In the segmentation literature, several previous systems learn lexical items from variable input <ref type="bibr">(Elsner et al., 2013;</ref><ref type="bibr">Daland and Pierrehumbert, 2011;</ref><ref type="bibr">Rytting et al., 2010;</ref><ref type="bibr">Neubig et al., 2010;</ref><ref type="bibr">Fleck, 2008)</ref>. However, these models use pre-processed representations of the acoustics (phonetic transcription or posterior probabilities from a phone recognizer) rather than inducing an acoustic category structure directly. <ref type="bibr">Elsner et al. (2013)</ref> and <ref type="bibr">Neubig et al. (2010)</ref> use Bayesian models and sampling schemes similar to those presented here.</p><p>Acquisition models like <ref type="bibr">Elsner et al. (2013)</ref>, <ref type="bibr">Rytting et al. (2010)</ref> and <ref type="bibr">Fleck (2008)</ref> are designed to handle phonological variability. In particular, they are designed to cope with words which have multiple transcribed pronunciations <ref type="bibr">([wan]</ref> and <ref type="bibr">[want]</ref> for "want"); this kind of alternation can insert or delete whole segments, or change a vowel sound from one perceptual category to another. Such variability is common in spoken English <ref type="bibr">(Pitt et al., 2005)</ref> and presents a challenge for speech recognition <ref type="bibr">(McAllaster et al., 1998)</ref>.</p><p>In contrast, the system presented here models phonetic variability within a single category. It uses an untranscribed, continuous-valued representation for vowel sounds, so that different tokens within a single category may differ from one another. But it does so within an idealized dataset which lacks phonological variants. Moreover, although the phonetic input to the system is variable, the variation is not predictable; tokens within the category differ at random, independently from their environment.</p><p>Several other models also learn phonetic categories from continuous input, either from real or idealized datasets, without learning a lexicon. <ref type="bibr">Varadarajan et al. (2008)</ref> learn subword units by incrementally splitting an HMM model of the data to maximize likelihood. <ref type="bibr">Badino et al. (2014)</ref> perform k-means clustering on the acoustic representation learned by an autoencoder. Cognitive models using formant values as input are common, many using mixture of Gaussians <ref type="bibr">(Vallabha et al., 2007;</ref><ref type="bibr">de Boer and Kuhl, 2003)</ref>. Because they lack a lexicon, these models have particular difficulty distinguishing meaningful from allophonic variability.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Dataset and model</head><p>Our dataset replicates the previous idealized setting for vowel category induction in cognitive modeling, but in a corpus of unsegmented utterances rather than a wordlist. We adapt a standard word segmentation corpus of child-directed speech <ref type="bibr">(Brent, 1999)</ref>, which consists of 8000 utterances from <ref type="bibr">Bernstein-Ratner (1987)</ref>, orthographically transcribed and then phonetically transcribed using a pronunciation dictionary.</p><p>We add simulated acoustics (without contextual variation) to each vowel in the Brent corpus. Following previous cognitive models of category induction <ref type="bibr">(Feldman et al., 2013b)</ref>, we use the vowel dataset given by <ref type="bibr">Hillenbrand et al. (1995)</ref>, which gives formants for English vowels read in the context h d. We estimate a multivariate Gaussian distribution for each vowel, and, whenever a monophthongal vowel occurs in the Brent corpus, we replace it with a pair of formants (f 1 , f 2 ) drawn from the appropriate Gaussian. The ARPABET diphthongs "oy, aw, ay, em, en", and all the consonants, retain their discrete values. The first three words of the dataset, orthographically "you want to", are rendered: y[380.53 1251.69] w[811.88 1431.96]n t[532.91 1094.14].</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Model</head><p>Our model merges the <ref type="bibr">Feldman et al. (2013a)</ref> vowel category learner with the <ref type="bibr">Elsner et al. (2013)</ref> noisychannel framework for word segmentation, which is in turn based on the segmentation model of <ref type="bibr" target="#b16">Goldwater et al. (2009)</ref>. In generative terms, it defines a sequential process for sampling a dataset. The observations will be surface strings S, which are divided into (latent) words X i=1:n . We denote the j-th character of word i as S ij . When S ij is a vowel, the observed value is a real-valued formant pair (f 1 , f 2 ); when it is a consonant, it is observed directly.</p><p>1. Draw a distribution over vowel categories, π v ∼ DP (α v ) 2. Sample parameters for each category,</p><formula xml:id="formula_14">µ v , Σ v ∼ N IW (µ 0 , Λ, ν) 3. Draw a distribution over word strings, G 0 ∼ DP (α 0 , CV (π v , p c , p stop ) 4. Draw bigram transition distributions, G x ∼ DP (α 1 , G 0 )</formula><p>5. Sample word sequences, X i ∼ G X i−1 6. Realize each vowel token in the surface string,</p><formula xml:id="formula_15">S ij ∼ N ormal(µ X ij , Σ X ij )</formula><p>The initial prior over word forms, CV (π v , p c , p stop ) is the following: sample a word length ≥ 1 from Geom(p stop ); for each character in the word, choose to sample a consonant with probability p c or a vowel otherwise; sample all consonants uniformally, and all vowels according to the (possibly-infinite) probability vector π v . 1 In practice, we integrate out π v , yielding a Chinese restaurant process in which the distribution over vowels in a new word depend on those used in already-seen words. Vowels which occur in many word types are more likely to recur <ref type="bibr">(Goldwater et al., 2006;</ref><ref type="bibr" target="#b590">Teh et al., 2006)</ref>.</p><p>The hyperparameters for the model are α 0 and α 1 (which control the size of the unigram and bigram vocabularies), α v (which weakly affects the number of vowel categories), µ 0 , n, Λ and ν (which affect the average location and dispersion of vowel categories in formant space), and p c and p stop (which weakly affect the length and composition of words). We set α 0 and α 1 to their optimal values for word segmentation (3000 and 100 <ref type="bibr" target="#b16">(Goldwater et al., 2009)</ref>) and α v to .001. In practice, no value of α v we tried would produce a useful number of vowels and so we fix the maximum number of vowels (non-probabilistically) to n v ; we explore a variety of values of this parameter below. The mean vector for the vowel category parameters is set to [500, 1500] and the inverse precision matrix to 500I, biasing vowel categories to be near the center of the vowel space and have variances on the order of hundreds of hertz. We set the prior degrees of freedom ν to 2.001. Since ν can be interpreted as a pseudocount determining the prior strength, this means the prior influence is relatively weak for reasonably-sized vowel categories. We set p c = .5 and p stop = .5; based on Goldwater et al. <ref type="formula" target="#formula_1">(2009)</ref>, we do not expect these parameters to be influential.</p><p>These hyperparameter values were mostly taken from previous work. The vowel inverse precision and degrees of freedom differ from those in <ref type="bibr">Feldman et al. (2013a)</ref>, since our approach requires us to sample from the prior, but the uninformative prior used there was too poor a fit for the data. We chose a variance with units on the order of the overall data variance, but did not tune it.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Inference</head><p>We conduct inference by Gibbs sampling, including three sampling moves: block sampling of the analyses of a single utterance, table label relabeling of a lexical item <ref type="bibr" target="#b16">(Johnson and Goldwater, 2009)</ref> and resampling of the vowel category parameters µ v and Σ v . We run 1000 iterations of utterance resampling, with table relabeling every 10 iterations. <ref type="bibr">2</ref> Following previous work, we integrate out the mixing weight distributions G 0 , G 1 and π v , resulting in Chinese restaurant process distributions for unigrams, bigrams and vowel categories in the lexicon <ref type="bibr" target="#b590">(Teh et al., 2006)</ref>. Unlike <ref type="bibr">Feldman et al. (2013a)</ref> and many other variants of the Infinite Mixture of Gaussians (Rasmussen, 1999), we do not integrate out µ v and Σ v , since this would create long-distance dependencies between different tokens of the same vowel category within an utterance and thus complicate the implementation of a whole-utterance block sampling scheme.</p><p>To block sample the analyses of a single utterance, we use beam sampling <ref type="bibr">(Van Gael et al., 2008;</ref><ref type="bibr">Huggins and Wood, 2014)</ref>, an auxiliary-variable sampling scheme in which we encode the model as an (infeasibly large) finite-state transducer, then sample cutoff variables which restrict our algorithm to a finite subset of the transducer and sample a trajectory within it. We then use a MetropolisHastings acceptance test to correct for the discrepancy between our finite-state encoding and the actual model probability caused by repetitions of a lexical item within the same utterance.</p><p>Specifically, for each vowel s ij , we sample a cutoff c ij ∼ U [0, P (s ij |X ij )]. This cutoff indicates the least probable category assignment we will permit for the surface symbol s ij . This cutoff constrains us to consider only a finite number of vowels at each point; if there are not enough, we can instantiate unseen vowels by sampling their µ and Σ from the prior. We then construct the lattice of possible word segmentations in which s ij is allowed to correspond to any vowel in any lexical entry, as long as all the consonants match up and the vowel assignment density P (s ij |x ij ) is greater than the cutoff. We then propose a new trajectory by sampling from this lattice. See Mochihashi et al. <ref type="bibr">2</ref> Annealing is applied linearly, with inverse temperature scaling from .1 to 1 for 800 iterations, then linearly from 1.0 to 2.0 to encourage a MAP solution. The Gaussian densities for acoustic token emissions are annealed to inverse temperature .3, to keep them comparable to the LM probabilities <ref type="bibr">(Bahl et al., 1980</ref>  <ref type="bibr" target="#b16">(Johnson and Goldwater, 2009</ref>) which changes the word type for a single table in the unigram Chinese restaurant process by changing one of the vowels. This recategorizes a large number of tokens which share the same type (though not necessarily all, since there may be multiple unigram tables for the same word type). The implementation is tricky because of the bigram dependencies between adjacent words, some of which may be tokens of the same lexical item. Nonetheless, this move is necessary because token-level sampling has insufficient mobility to change the representation of a whole word type: if the sampler has incorrectly assigned many tokens to the non-word hAv, moving any single token to the correct haev will raise the transducer probability but also catastrophically lower the lexical probability by creating a singleton lexical item.</p><p>Finally, because µ v and Σ v are explicitly represented rather than integrated out, their values must be resampled given the set of formant values associated with each vowel cluster. The use of a conjugate (Normal-Inverse Wishart) prior makes this simple, applying equations 250-254 in Murphy (2007).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Results</head><p>Despite using multiple block moves, mobility is a severe issue for the sampler; the inference procedure fails to merge together redundant vowel categories even when doing so would raise the posterior probability significantly. We demonstrate this by running the sampler with various numbers of vowel categories n v . Posterior probabilities peak around the true value of 12, but models with extra categories always use the entire set.</p><p>With n v set to 11 or 12 categories, quantitative performance is relatively good, although segmentation is not as good as the <ref type="bibr" target="#b16">Goldwater et al. (2009)</ref> segmenter without any acoustics. In fact, the system slightly outperforms the <ref type="bibr">Feldman et al. (2013a)</ref> lexical-distributional model with gold-standard segmentation. Results are shown in <ref type="table" target="#tab_10">Table 1</ref>.</p><p>Word tokens are correctly segmented (both boundaries correct) with an F-score of 67% <ref type="bibr">3 (versus 74% in (Goldwater et al., 2009)</ref>. Individual boundaries are detected with an F-score of 82% <ref type="bibr" target="#b471">3</ref> The joint model scores are averaged over two sampler runs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>System</head><p>Seg P R F Vow P R <ref type="table" target="#tab_2">F  Goldwater  76  72 74  ---Feldman  -----76  joint, nv=12  64  69 67  87  80 83  joint, nv=11  65  70 67  85  84 85   Table 1</ref>: Segmentation and vowel clustering scores.</p><p>versus 87%. We also evaluate the lexical items, checking whether words are correctly grouped as well as segmented (for example, whether tokens of "is" and "as" are separated). <ref type="bibr">Feldman et al. (2013a)</ref> evaluates the lexicon by computing a pairwise Fscore on tokens (positive class: clustered together). Under this metric, their highest lexicon score for English words is 93%. We compute this metric on the subset of words for which the segmentation system performs correctly (it is not clear how to count "misses" and "false alarms" for tokens which were mis-segmented). On this subset, this metric scores our system with n v = 12 at 91%, which indicates that we correctly identify most of the correctly segmented items. We evaluate our phonetic clustering by computing the same pairwise F-score on pairs of vowel tokens. Our score is 83%; the Feldman et al. (2013a) model scores 76%. We conjecture that the improvement results from the use of bigram context information to disambiguate between homophones. Confusion between vowels (attached as supplemental material) is mostly reasonable. We find crossclusters for ah,ao, ey,ih, and uh,uw. The model's successful learning of the vowel categories demonstrates that the high performance of cognitive models in this domain is not due solely to their access to gold-standard word boundaries (see also ). We believe that the idealized acoustic values (sampled from stationary Gaussians reflecting laboratory production) are critical in allowing these models to outperform those which use natural speech.</p><p>Though solving the two tasks together is harder than tackling either alone, these results nonetheless demonstrate comparable performance to other models which have to cope with variability while segmenting. <ref type="bibr">Fleck (2008)</ref> reports only 44% segmentation scores on transcribed English text including phonological variability; the noisy channel model of <ref type="bibr">Elsner et al. (2013)</ref> yields a segmentation token score of 67%. <ref type="bibr">4</ref> Besides generic task difficulty, we attribute the low scores to the model's inability to mix, which prevents it from merging similar vowel classes. Because table relabeling does not merge tables in the CRP hierarchy, even if it replaces an uncommon word with a more common one, the configurational probability does not change. Thus the model's sparsity preference cannot encourage such moves. The prior on vowel categories, DP (p v ), does encourage changes which reduce the number of lexical types using a rare vowel, but relabeling a table can rearrange at most a single sample from this prior distribution and is easily outweighed by the likelihood.</p><p>A hand analysis of one sampler run in which /I/ was split into two categories showed clear mixing problems. Many common words, such as "it" and "this", appeared as duplicate lexical entries (e.g.</p><p>[I 1 t] and [I 2 t]). These presumably captured some chance variation within the category, but not an actual linguistic feature.</p><p>We suspect that this mobility problem is also a likely issue with models like <ref type="bibr">Lee and Glass (2012)</ref> which use deep Bayesian hierarchies and relatively local inference moves. Since the problem occurs even in this idealized setting, we expect it to exacerbate the problems caused by contextual variability in more realistic experiments.</p><p>Some errors did result from the joint nature of the task itself. We looked for reanalyses involving both a mis-segmentation and a vowel category mistake. For instance, the model is capable of misanalyzing the word "milk" as "me" followed by the phonotactically implausible sequence "lk". Mistakes like these, in which the misanalysis creates a word, are relatively rare as a proportion of the total. The most common words created are "say", "and", "shoe", "it" and "a". More commonly, misanalyses of this type segment out single vowels or nonwords like [luk], <ref type="bibr">[eN], and [mO]</ref>. Some such errors could be corrected by incorporating phonotactics into the model <ref type="bibr" target="#b16">(Johnson and Goldwater, 2009)</ref>. In general, the error patterns are neither particularly interpretable nor cognitively very plausible. This stands in contrast to the effects on word boundary detection found in a model of phonological variation <ref type="bibr">(Elsner et al., 2013)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Conclusion</head><p>The main result of our work is that joint word segmentation and vowel clustering is possible, with relatively high effectiveness, by merging models known to be successful in each setting independently. The finding that success of this kind is possible in an idealized setting reinforces an argument made in previous work: that much of the difficulty in category acquisition is due to contextual variation.</p><p>Both phonological and phonetic variability probably contribute to the difficulty of the real task. Phonological processes such as reduction create variant versions of words, splitting real lexical items and creating misleading minimal pairs. Phonetic processes like coarticulation and compensatory lengthening create predictible variation within a category, encouraging the model to split the category into allophones. In future work, we hope to quantify the contributions of these sources of error and work to address them explicitly within the same model. <ref type="bibr">Micha Elsner, Sharon Goldwater, Naomi Feldman, and Frank Wood. 2013</ref> Event detection aims to extract event triggers (most often a single verb or noun) and classify them into specific types precisely. It is a crucial and quite challenging sub-task of event extraction, because the same event might appear in the form of various trigger expressions and an expression might represent different event types in different contexts. <ref type="figure" target="#fig_3">Figure 1</ref> shows two examples. In S1, "release" is a verb concept and a trigger for "Transfer-Money" event, while in S2, "release " is a noun concept and a trigger for "Release-Parole" event.</p><p>Most of previous methods <ref type="bibr">(Ji et al., 2008;</ref><ref type="bibr">Liao et al., 2010;</ref><ref type="bibr">Hong et al., 2011;</ref><ref type="bibr">Li et al., 2015b)</ref>  fication problem and designed a lot of lexical and syntactic features. Although such approaches perform reasonably well, features are often derived from language-specific resources and the output of pre-existing natural language processing toolkits (e,g., name tagger and dependency parser), which makes these methods difficult to be applied to different languages. Sequence and chunk are two types of meaningful language-independent structures for event detection. For example, in S2, when predicting the type of a trigger candidate " release", the forward sequence information such as "court" can help the classifier label "release" as a trigger of a "Release-Parole" event. However, for feature engineering methods, it is hard to establish a relation between "court" and "release", because there is no direct dependency path between them. In addition, considering S1, "European Union" and "20 million euros" are two chunks, which indicate that this sentence is related to an organization and financial activities. These cluese are very helpful to infer "release" as a trigger of a "Transfer-Money" event. However, chunkers and parsers are only available for a few highresource languages and their performance varies a lot.  Recently, deep learning techniques have been widely used in modeling complex structures and proven effective for many NLP tasks, such as machine translation , relation extraction <ref type="bibr">(Zeng et al., 2014)</ref> and sentiment analysis <ref type="bibr">(Tang et al., 2015a)</ref>. Bi-directional long short-term memory (Bi-LSTM) model <ref type="bibr">(Schuster et al., 1997</ref>) is a two-way recurrent neural network (RNN) <ref type="bibr">(Mikolov et al., 2010)</ref> which can capture both the preceding and following context information of each word. Convolutional neural network (CNN) <ref type="bibr">(LeCun et al., 1995</ref>) is another effective model for extracting semantic representations and capturing salient features in a flat structure , such as chunks. In this work, we develop a hybrid neural network incorporating two types of neural networks: Bi-LSTM and CNN, to model both sequence and chunk information from specific contexts. Taking advantage of word semantic representation, our model can get rid of hand-crafted features and thus be easily adapted to multiple languages.</p><p>We evaluate our system on the event detection task for various languages for which ground-truth event detection annotations are available. In English event detection task, our approach achieved 73.4% F-score with average 3.0% absolute improvement compared to state-of-the-art. For Chinese and Spanish, the experiment results are also competitive. We demonstrate that our combined model outperforms traditional feature-based methods with respect to generalization performance across languages due to: (i) its capacity to model semantic representations of each word by capturing both sequence and chunk information. (ii) the use of word embeddings to induce a more general representation for trigger candidates.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Our Approach</head><p>In this section, we introduce a hybrid neural networks, which combines Bi-directional LSTM (Bi-LSTM) and convolutional neural networks to learn a continuous representation for each word in a sentence. This representation is used to predict whether the word is an event trigger or not. Specifically, we first use a Bi-LSTM to encode semantics of each word with its preceding and following information. Then, we add a convolutional neural network to capture structure information from local contexts.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Bi-LSTM</head><p>In this section we describe a Bidirectional LSTM model for event detection. Bi-LSTM is a type of bidirectional recurrent neural networks (RNN), which can simultaneously model word representation with its preceding and following information. Word representations can be naturally considered as features to detect triggers and their event types. As show in , we take all the words of the whole sentence as the input and each token is transformed by looking up word embeddings. Specifically, we use the SkipGram model to pre-train the word embeddings to represent each word .</p><p>We present the details of Bi-LSTM for event trigger extraction in <ref type="figure" target="#fig_8">Figure 2</ref>. We can see that Bi-LSTM is composed of two LSTM neural networks, a forward LSTM F to model the preced-   <ref type="figure" target="#fig_6">Figure 3</ref>: CNN structure.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Max-Pooling</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C3</head><p>ing contexts, and a backward LSTM B to model the following contexts respectively. The input of LSTM F is the preceding contexts along with the word as trigger candidate, and the input of LSTM B is the following contexts plus the word as trigger candidate. We run LSTM F from the beginning to the end of a sentence, and run LSTM B from the end to the beginning of a sentence. Afterwards, we concatenate the output F v of LSTM F and B v of LSTM B as the output of Bi-LSTM. One could also try averaging or summing the last hidden vectors of LSTM F and LSTM B as alternatives.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Convolution Neural Network</head><p>As the convolutional neural network (CNN) is good at capturing salient features from a sequence of objects , we design a CNN to capture some local chunks. This approach has been used for event detection in previous studies <ref type="bibr">(Nguyen and Grishman, 2015;</ref>. Specifically, we use multiple convolutional filters with different widths to produce local context representation. The reason is that they are capable of capturing local semantics of n-grams of various granularities, which are proven powerful for event detection. In our work, multiple convolutional filters with widths of 2 and 3 encode the semantics of bigrams and trigrams in a sentence. This local information can also help our model fix some errors due to lexical ambiguity.</p><p>An illustration of CNN with three convolutional filters is given in <ref type="figure" target="#fig_6">Figure 3</ref>. Let us denote a sentence consisting of n words as {w 1 , w 2 , ...w i , ...w n }, and each word w i is mapped to its embedding representation e i ∈ R d . In addition, we add a position feature (PF), which is defined as the relative distance between the current word and the trigger candidate. A convolutional filter is a list of linear layers with shared parameters. We feed the output of a convolutional filter to a MaxPooling layer and obtain an output vector with fixed length.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Output</head><p>At the end, we concatenate the bidirectional sequence features: F and B, which are learned from the Bi-LSTM, and local context features: C 2 and C 3 , which are the output of CNN with convolutional filters with width of 2 and 3, as a single vector O = [F, B, C 2 , C 3 ]. Then, we exploit a softmax approach to identify trigger candidates and classify each trigger candidate as a specific event type.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.4">Training</head><p>In our model, the loss function is the cross-entropy error of event trigger identification and trigger classification. We initialize all parameters to form a uniform distribution U (−0.01, 0.01). We set the widths of convolutional filters as 2 and 3. The number of feature maps is 300 and the dimension of the PF is 5. <ref type="table" target="#tab_10">Table 1</ref> illustrates the setting parameters used for three languages in our experiments <ref type="bibr" target="#b656">(Zeiler, 2012)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Experiments</head><p>In this section, we will describe the detailed experimental settings and discuss the results. We evaluate the proposed approach on various languages (English, Chinese and Spanish) with Precision (P), Recall (R) and F-measure <ref type="bibr">(F)</ref>. <ref type="table" target="#tab_10">Table 1</ref> shows the detailed description of the data sets used in our experiments. We abbreviate our model as HNN (Hybrid Neural Networks).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Baseline Methods</head><p>We compare our approach with the following baseline methods.</p><p>(1) MaxEnt, a basesline feature-based method, which trains a Maximum Entropy classifier with some lexical and syntactic features <ref type="bibr">(Ji et al., 2008)</ref>.</p><p>(2) Cross-Event (Liao et al., 2010), using document-level information to improve the performance of ACE event extraction.</p><p>(3) Cross-Entity <ref type="bibr">(Hong et al., 2011)</ref>, extracting events using cross-entity inference.</p><p>(4) Joint Model <ref type="bibr">(Li and Ji, 2014)</ref>, a joint structured perception approach, incorporating multilevel linguistic features to extract event triggers and arguments at the same time so that local predictions can be mutually improved.   (5) Pattern Recognition (Miao and Grishman, 2015), using a pattern expansion technique to extract event triggers.</p><p>(6) Convolutional Neural Network , which exploits a dynamic multi-pooling convolutional neural network for event trigger detection. <ref type="table" target="#tab_5">Table 2</ref> shows the overall performance of all methods on the ACE2005 English corpus. We can see that our approach significantly outperforms all previous methods. The better performance of HNN can be further explained by the following reasons: (1) Compared with feature based methods, such as MaxEnt, Cross-Event, Cross-Entity, and Joint Model, neural network based methods (including CNN, Bi-LSTM, HNN) performs better because they can make better use of word semantic information and avoid the errors propagated from NLP tools which may hinder the performance for event detection. (2) Moreover, Bi-LSTM can capture both preceding and following sequence information, which is much richer than dependency path. For example, in S2, the semantic of "court" can be delivered to release by a forward sequence in our approach. It is an important clue which can help to predict "release" as a trigger for "ReleaseParole". For explicit feature based methods, they can not establish a relation between "court" and "release", because they belong to different clauses, and there is no direct dependency path between them. While in our approach, the semantics of "court" can be delivered to release by a forward sequence. (3) Cross-entity system achieves higher recall because it uses not only sentence-level information but also document-level information. It utilizes event concordance to predict a local trigger's event type based on cross-sentence inference. For example, an "attack" event is more likely to occur with "killed" or "die" event rather than "marry" event. However, this method heavily relies on lexical and syntactic features, thus the precision is lower than neural network based methods. (4) RNN and LSTM perform slightly worse than Bi-LSTM. An obvious reason is that RNN and LSTM only consider the preceding sequence information of the trigger, which may miss some important following clues. Considering S1 again, when extracting the trigger "releases", both models will miss the following sequence "20 million euros to Iraq". This may seriously hinder the performance of RNN and LSTM for event detection.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Comparison On English</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Comparison on Chinese</head><p>For Chinese, we follow previous work  and employ Language Technology Platform <ref type="bibr">(Liu et al., 2011)</ref> to do word segmentation. <ref type="table" target="#tab_6">Table 3</ref> shows the comparison results between our model and the state-of-the-art methods <ref type="bibr" target="#b370">(Li et al., 2013;</ref>. MaxEnt ) is a pipeline model, which employs humandesigned lexical and syntactic features. Rich-C is developed by , which also incorporates Chinese-specific features to improve Chinese event detection. We can see that our method outperforms methods based on human designed features for event trigger identification and achieves comparable F-score for event classification.   </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">Spanish Extraction</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Related Work</head><p>Event detection is a fundamental problem in information extraction and natural language processing , which aims at detecting the event trigger of a sentence <ref type="bibr">(Ji et al., 2008)</ref>. The majority of existing methods regard this problem as a classification task, and use machine learning methods with hand-crafted features, such as lexical features (e.g., full word, pos tag), syntactic features (e.g., dependency features) and external knowledge features (WordNet). There also exists some studies leveraging richer evidences like cross-document <ref type="bibr">(Ji et al., 2008)</ref>, cross-entity <ref type="bibr">(Hong et al., 2011)</ref> and joint inference <ref type="bibr">(Li and Ji, 2014)</ref>. Despite the effectiveness of feature-based methods, we argue that manually designing feature templates is typically labor intensive. Besides, feature engineering requires expert knowledge and rich external resources, which is not always available for some low-resource languages. Furthermore, a desirable approach should have the ability to automatically learn informative representations from data, so that it could be easily adapted to different languages. Recently, neural network emerges as a powerful way to learn text representation automatically from data and has obtained promising performances in a variety of NLP tasks.</p><p>For event detection, two recent studies <ref type="bibr">(Nguyen and Grishman, 2015;</ref> explore neural network to learn continuous word representation and regard it as the feature to infer whether a word is a trigger or not. <ref type="bibr" target="#b293">Nguyen (2015)</ref> presented a convolutional neural network with entity type information and word position information as extra features. However, their system limits the context to a fixed window size which leads the loss of word semantic representation for long sentences.</p><p>We introduce a hybrid neural network to learn continuous word representation. Compared with feature-based approaches, the method here does not require feature engineering and could be directly applied to different languages. Compared with previous neural models, we keep the advantage of convolutional neural network <ref type="bibr">(Nguyen and Grishman, 2015)</ref> in capturing local contexts. Besides, we also incorporate a Bi-directional LSTM to model the preceding and following information of a word as it has been commonly accepted that LSTM is good at capturing long-term dependencies in a sequence <ref type="bibr">(Tang et al., 2015b;</ref><ref type="bibr">Li et al., 2015a)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Conclusions</head><p>In this work, We introduce a hybrid neural network model, which incorporates both bidirectional LSTMs and convolutional neural networks to capture sequence and structure semantic information from specific contexts, for event detection. Compared with traditional event detection methods, our approach does not rely on any linguistic resources, thus can be easily applied to any languages. We conduct experiments on various languages ( English, Chinese and Spanish. Empirical results show our approach achieved state-of-theart performance in English and competitive results in Chinese. We also find that bi-directional LSTM is powerful for trigger extraction in capturing preceding and following contexts in long distance. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>References</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Many natural language processing systems make use of syntactic representations of sentences. These representations are produced by parsers, which often produce incorrect analyses. Many of the mistakes are in coordination structures, and structures involving non-constituent coordination, such as Argument Cluster Coordination, Right Node-Raising and Gapping <ref type="bibr">(Dowty, 1988)</ref>, are especially hard. Coordination is a common syntactic phenomena and work has been done to improve coordination structures predication in the general case <ref type="bibr">(Hogan, 2007;</ref><ref type="bibr">Hara et al., 2009;</ref><ref type="bibr">Shimbo and Hara, 2007;</ref><ref type="bibr">Okuma et al., 2009)</ref>. In this work we focus on one particular coordination structure: Argument Cluster Coordination (ACC). While ACC are not common in the Penn TreeBank <ref type="bibr" target="#b65">(Marcus et al., 1993)</ref>, they commonly appear in other corpora. For example, in a dataset of questions from the Regents 4th grade science exam (the Aristo Challenge), 14% of the sentences include ACC.</p><p>ACC is characterized by non-constituent sequences that are parallel in structure. For instance, in "I bought John a microphone on Monday and Richie a guitar on Saturday", the conjunction is between "John a microphone on Monday" and "Richie a guitar on Saturday" which are both nonconstituents and include parallel arguments: the NPs "John" and "Richie"; the NPs "a microphone" and "a guitar"; and the PPs "on Monday" and "on Saturday".</p><p>Previous NLP research on the Argument Clusters Coordination <ref type="bibr">(Mouret, 2006)</ref> as well as the Penn TreeBank annotation guidelines <ref type="bibr" target="#b65">(Marcus et al., 1993;</ref><ref type="bibr">Bies et al., 1995)</ref> focused mainly on providing representation schemes capable of expressing the linguistic nuances that may appear in such coordinations. The resulting representations are relatively complex, and are not easily learnable by current day parsers, including parsers that refine the grammar by learning latent annotations <ref type="bibr">(Petrov et al., 2006)</ref>, which are thought to be more agnostic to the annotations scheme of the trees. In this work, we suggest an alternative, simpler representation scheme which is capable of representing most of the Argument Cluster coordination cases in the Penn Treebank, and is better suited for training a parser. We show that by changing the annotation of 125 trees, we get a parser which is substantially better at handling ACC structures, and is also marginally better at parsing general sentences. The main VP includes two conjoined VPs. The first VP includes the verb was and two indexed arguments: "only 65%" (1) and "in 1987" (2). The second VP does not include a verb, but only two arguments, that are co-indexed with the parallel argument at the first conjoined VP. ACC structures in the PTB may include modifiers that are annotated under the main VP, and the conjoined VPs may includes arguments that are not part of the cluster. These are annotated with no index, i.e. "insurance costs" in <ref type="bibr">[1a]</ref>.</p><p>ACC structures are not common in the PTB. The training set includes only 141 ACC structures of which are conjoined by and or or. Some of them are complex but most (78%) have the following pattern (NT is used to denote non-terminals): These structures can be characterized as follows: (1) the first token of the first conjoined VP is a verb; (2) the indexed arguments are direct children of the conjoined VPs; (3) the number of the indexed arguments is the same for each conjoined VP.</p><p>Almost all of these cases (98%) are symmetric: each of the conjoined VPs has the same types of indexed arguments. Non-symmetric clusters (e.g. "He made [these gestures] 1 N P [to the red group] 2 P P and [for us] 2 P P [nothing] 1 N P ") exist but are less common.</p><p>We argue that while the PTB representation for ACC gives a clear structure and covers all the ACC forms, it is not a good representation for learning PCFG parsers from. The arguments in the clusters are linked via co-indexation, breaking the context-free assumptions that PCFG parsers rely on. PCFG parsers ignore the indexes, essentially losing all the information about the ACC construction. Moreover, ignoring the indexes result in "weird" CFG rules such as VP → NP PP. Not only that the RHS of these rules do not include a verbal component, it is also a very common structure for NPs. This makes the parser very likely to either mis-analyze the argument cluster as a nounphrase, or to analyze some NPs as (supposedly ACC) VPs. The parallel nature of the construction is also lost. To improve the parser performance for ACC structures prediction, we suggest an alternative constituency representation for ACC phrases which is easier to learn.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Alternative Representation for ACC</head><p>Our proposed representation for ACC respects the context-free nature of the parser. In order to avoid incorrect syntactic derivations and derivations that allows conjoining of clusters with other phrases, as well as to express the symmetry that occur in many ACC phrases, we change the PTB representation for ACC as follows: (1) we move the verb and non-indexed elements out of the first argument cluster to under the main VP; (2) each argument cluster is treated as a phrase, with new non-terminal symbols specific to argument clusters; (3) the conjunction of clusters also receives a dedicated phrase level. For example see comparison between the original and new representations: The main verb driven as well as the particle up and the non-indexed argument insurance costs are moved to the external VP. The two argument clusters (formerly VPs) receive dedicated phrase labels ACC X , where X reflects the syntactic types of the indexed elements (e.g. ACC N P −P P for the first cluster in [1b] above). The most common cases are ACC N P −P P which appears in 41.6% of the clusters, ACC ADJP −P P with 21.2% of the clusters and ACC P P −P P with 5.3% of the clusters.</p><p>Finally, we introduce a new phrase type (ACCP H X ) for the coordination of the two clusters. Here X denotes the main element in the clusters, determined heuristically by taking the first of the following types that appear in any of the clusters: NP, PP, ADJP, SBAR. Cases where the clusters contains an ADVP element are usually special (e.g. the following structure is missing "people" in the second cluster: ((NP 8000 people) (in Spain)) and ((NP 2000) (ADVP abroad))). For such cases, we add "ADVP" to the ACCP H level label. Table 1 lists the ACCP H level labels and their number of the appearances in the 125 modified trees. <ref type="bibr">1</ref> The representation is capable of representing common cases of ACC where the cluster elements are siblings. We similarly handle also some of the more complex cases, in which an extra layer appears between an indexed argument and the conjoined VP to host an empty element, such as in the following case with an extra S layer above single-B-3: 1 Parsers that apply latent annotations to the grammar, such as the Berkeley Parser <ref type="bibr">(Petrov et al., 2006)</ref> we use in our experiments, can potentially learn some of our proposed refinements on their own. However, as we show in the experiments section, the performance of the Berkeley Parser on ACC structures significantly improve when applying our transformations prior to training.</p><formula xml:id="formula_16">Label # Label # ACCP H N P</formula><p>69 ACCP H N P −ADV P 6 ACCP H P P 36 ACCP H P P −ADV P 11 ACCP H ADJP 2 ACCP H SBAR−ADV P 1 in each of the following two years". Our changes are local and appear in small number of trees (0.003% of the PTB train set). We also ignore more complex cases of ACC. Yet, training the parser with the modified trees significantly improves the parser results on ACC structures.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Experiments</head><p>We converted 125 trees with ACC structures in the training sets (sections 2-21) of the PTB to the new representation, and trained the Berkeley parser <ref type="bibr">(Petrov et al., 2006</ref>) with its default settings.</p><p>As the PTB test and dev sets have only 12 ACC structures that are coordinated by and or or, we evaluate the parser on Regents, a dataset in which ACC structures are prevalent (details below). As Regents does not include syntactic structures, we focus on the ACC phenomena and evaluate the parsers' ability to correctly identify the spans of the clusters and the arguments in them.</p><p>To verify that the new representation does not harm general parsing performance, we also eval-   <ref type="table" target="#tab_6">Table 3</ref>: The parser Recall score in recovering ACC conjunct spans on the Regents dataset. ACC P T B : the set is annotated with the verb inside the first cluster. ACC OU R : the set is annotated following our approach.</p><p>uate the parer on the traditional development and test sets (sections 22 and 23). As can be seen in <ref type="table" target="#tab_5">Table 2</ref>, the parser results are slightly better when trained with the modified trees. 2</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Regents data-set</head><p>Regents -a dataset of questions from the Regents 4th grade science exam (the Aristo Challenge), <ref type="bibr" target="#b471">3</ref> includes 281 sentences with coordination phrases, where 54 of them include Argument Cluster coordination. We manually annotated the sentences by marking the conjuncts spans for the constituent coordination phrases, e.g.:</p><p>Wendy (ran 19 miles) and (walked 9 miles)</p><p>as well as the spans of each component of the argument-cluster coordinations, including the inner span of each argument: The bracketing in this set follow our proposed ACC bracketing, and we refer to it as ACC OU R . We also created a version in which the bracketing follow the PTB scheme, with the verb included in span of the first cluster, e.g.: We refer to this dataset as ACC P T B .</p><formula xml:id="formula_17">Mary ([paid] [$</formula><p>We evaluate the parsers' ability to correctly recover the components of the coordination structures by computing the percentage of gold annotated phrases where the number of predicted conjunct is correct and all conjuncts spans (round brackets) are predicted correctly (Recall). For example, consider the following gold annotated phrase:</p><p>A restaurant served (9 pizzas during lunch) and (6 during dinner) today A prediction of ("9 pizzas during lunch", "6 during dinner today") is considered as incorrect because the second conjunct boundaries are not matched to the gold annotation.</p><p>We compare the Recall score that the parser achieves when it is trained on the modified trees to the score when the parser is trained on the PTB trees.</p><p>When evaluated on all coordination cases in the Regents dataset (both ACC and other cases of constituent coordination), the parser trained on the modified trees was successful in recovering 54.3% of the spans, compared to only 47% when trained on the original PTB trees.</p><p>We now focus on specifically on the ACC cases <ref type="table" target="#tab_6">(Table 3)</ref>. When evaluating the PTB-trained parser on ACC P T B , it correctly recovers only 13% of the ACC boundaries. Somewhat surprisingly, the PTB-trained parser performs better when evaluated against ACC OU R , correctly recovering 24.1% of the structures. This highlights how unnatural the original ACC representation is for the parser: it predicts the alternative representation more often than it predicts the one it was trained on. When the parser is trained on the modified trees, results on ACC OU R jump to 64.8%, correctly recovering ×2.7 more structures.</p><p>The previous results were on recovering the spans of the coordinated elements (the round brackets in the examples above). When measuring the Recall in recovering any of the arguments themselves (the elements surrounded by square brackets), the parser trained on the modified trees recovers 72.46% of the arguments in clusters, compared to only 58.29% recovery by the PTB-trained parser. We also measure in what percentage of the cases in which both the cluster boundaries (round brackets) were recovered correctly, all the internal structure (square brackets) was recovered correctly as well. The score is 80% when the parser trained on the modified trees com-pared to 61.5% when it is trained on the PTB-trees.</p><p>Overall, the parser trained on the modified trees significantly outperforms the one trained on the original trees in all the evaluation scenarios.</p><p>Another interesting evaluation is the ability of the parser that is trained on the modified trees to determine whether a coordination is of Argument Clusters type (that is, whether the predicted coordination spans are marked with the ACCPH label). <ref type="bibr">4</ref> The results are a Recall of 57.4% and Precision of 83.78%. When we further require that both the head be marked as ACCPH and the internal structure be correct, the results are 48.14% Recall and 70.27% Precision.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Conclusions</head><p>By focusing on the details of a single and relatively rare syntactic construction, argument clusters coordination, we have been able to significantly improve parsing results for this construction, while also slightly improving general parsing results. More broadly, while most current research efforts in natural language processing and in syntactic parsing in particular is devoted to the design of general-purpose, data-agnostic techniques, such methods work on the common phenomena while often neglecting the very long tail of important constructions. This work shows that there are gains to be had also from focusing on the details of particular linguistic phenomena, and changing the data such that it is easier for a "data agnostic" system to learn. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Equivalence to the source text is the defining characteristic of translation. One of the fundamental aspects of translation quality is, therefore, its semantic adequacy, which reflects to what extent the meaning of the original text is preserved in the translation. In the field of Machine Translation (MT), on the other hand, it has recently become common practice to perform quality assessment using a human reference translation instead of the source text. Reference-based evaluation is an attractive practical solution since it does not require bilingual speakers. However, we believe this approach has a strong conceptual flaw: the assumption that the task of translation has a single correct solution. In reality, except for very short sentences or very specific technical domains, the same source sentence may be correctly translated in many different ways. Depending on a broad textual and real-world context, the translation can differ from the source text at any linguistic level -lexical, syntactic, semantic or even discourse -and still be considered perfectly correct. Therefore, using a single translation as a proxy for the original text may be unreliable.</p><p>In the monolingual, reference-based evaluation scenario, human judges are expected to recognize acceptable variations between translation options and assign a high score to a good MT, even if it happens to be different from a particular human reference provided. In this paper we argue that, contrary to this expectation, annotators are strongly biased by the reference. They inadvertently favor machine translations (MTs) that make similar choices to the ones present in the reference translation. To test this hypothesis, we perform an experiment where the same set of MT outputs is manually assessed using different reference translations and analyze the discrepancies between the resulting quality scores.</p><p>The results confirm that annotators are indeed heavily influenced by the particular human translation that was used for evaluation. We discuss the implications of this finding on the reliability of current practices in manual quality assessment. Our general recommendation is that, in order to avoid reference bias, the assessment should be performed by comparing the MT output to the original text, rather than to a reference.</p><p>The rest of this paper is organized as follows. In Section 2 we present related work. In Section 3 we describe our experimental settings. In Section 4 we focus on the effect of reference bias on MT evaluation. In Section 5 we examine the impact of the fatigue factor on the results of our experiments.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Related Work</head><p>It has become widely acceptable in the MT community to use human translation instead of (or along with) the source segment for MT evaluation. In most major evaluation campaigns (ARPA <ref type="bibr">(White et al., 1994)</ref>, 2008 NIST Metrics for Machine Translation Challenge <ref type="bibr">(Przybocki et al., 2008)</ref>, and annual Workshops on Statistical Ma-chine Translation <ref type="bibr" target="#b725">Bojar et al., 2015)</ref>), manual assessment is expected to consider both MT fluency and adequacy, with a human (reference) translation commonly used as a proxy for the source text to allow for adequacy judgement by monolingual judges.</p><p>The reference bias problem has been extensively discussed in the context of automatic MT evaluation. Evaluation systems based on stringlevel comparison, such as the well known BLEU metric <ref type="bibr" target="#b284">(Papineni et al., 2002)</ref> heavily penalize potentially acceptable variations between MT and human reference. A variety of methods have been proposed to address this issue, from using multiple references <ref type="bibr">(Dreyer and Marcu, 2012)</ref> to referencefree evaluation <ref type="bibr">(Specia et al., 2010)</ref>.</p><p>Research in manual evaluation has focused on overcoming annotator bias, i.e. the preferences and expectations of individual annotators with respect to translation quality that lead to low levels of inter-annotator agreement <ref type="bibr" target="#b731">(Cohn and Specia, 2013;</ref><ref type="bibr">Denkowski and Lavie, 2010;</ref><ref type="bibr">Graham et al., 2013;</ref><ref type="bibr" target="#b274">Guzmán et al., 2015)</ref>. The problem of reference bias, however, has not been examined in previous work. By contrast to automatic MT evaluation, monolingual quality assessment is considered unproblematic, since human annotators are supposed to recognize meaning-preserving variations between the MT output and a given human reference. However, as will be shown in what follows, manual evaluation is also strongly affected by biases due to specific reference translations.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Settings</head><p>To show that monolingual quality assessment depends on the human translation used as goldstandard, we devised an evaluation task where annotators were asked to assess the same set of MT outputs using different references. As control groups, we have annotators assessing MT using the same reference, and using the source segments.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Dataset</head><p>MT data with multiple references is rare. We used MTC-P4 Chinese-English dataset, produced by Linguistic Data Consortium (LDC2006T04). The dataset contains 919 source sentences from news domain, 4 reference translations and MT outputs generated by 10 translation systems. Human translations were produced by four teams of professional translators and included editor's proofreading. All teams used the same translation guidelines, which emphasize faithfulness to the source sentence as one of the main requirements.</p><p>We note that even in such a scenario, human translations differ from each other. We measured the average similarity between the four references in the dataset using the Meteor evaluation metric <ref type="bibr">(Denkowski and Lavie, 2014)</ref>. Meteor scores range between 0 and 1 and reflect the proportion of similar words occurring in similar order. This metric is normally used to compare the MT output with a human reference, but it can also be applied to measure similarity between any two translations. We computed Meteor for all possible combinations between the four available references and took the average score. Even though Meteor covers certain amount of acceptable linguistic variation by allowing for synonym and paraphrase matching, the resulting score is only 0.33, which shows that, not surprisingly, human translations vary substantially.</p><p>To make the annotation process feasible given the resources available, we selected a subset of 100 source sentences for the experiment. To ensure variable levels of similarity between the MT and each of the references, we computed sentencelevel Meteor scores for the MT outputs using each of the references and selected the sentences with the highest standard deviation between the scores.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Method</head><p>We developed a simple online interface to collect human judgments. Our evaluation task was based on the adequacy criterion. Specifically, judges were asked to estimate how much of the meaning of the human translation was expressed in the MT output (see <ref type="figure" target="#fig_3">Figure 1)</ref>. The responses were interpreted on a five-point scale, with the labels in Figure 1 corresponding to numbers from 1 ("None") to 5 ("All").</p><p>For the main task, judgments were collected using English native speakers who volunteered to participate. They were either professional translators or researchers with a degree in Computational Linguistics, English or Translation Studies. 20 annotators participated in this monolingual task. Each of them evaluated the same set of 100 MT outputs. Our estimates showed that the task could be completed in approximately one hour. The annotators were divided into four groups, corresponding to the four available refer- Having multiple annotators in each group allowed us to minimize the effect of individual annotators' biases, preferences and expectations.</p><p>As a control group, five annotators (native speakers of English, fluent in Chinese or bilingual speakers) performed a bilingual evaluation task for the same MT outputs. In the bilingual task, annotators were presented with an MT output and its corresponding source sentence and asked how much of the meaning of the source sentence was expressed in the MT.</p><p>In total, we collected 2,500 judgments. Both the data and the tool for collecting human judgments are available at https://github. com/mfomicheva/tradopad.git.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Reference Bias</head><p>The goal of the experiment is to show that depending on the reference translation used for evaluation, the quality of the same MT output will be perceived differently. However, we are aware that MT evaluation is a subjective task. Certain discrepancies between evaluation scores produced by different raters are expected simply because of their backgrounds, individual perceptions and expectations regarding translation quality.</p><p>To show that some differences are related to reference bias and not to the bias introduced by individual annotators, we compare the agreement between annotators evaluating with the same and with different references. First, we randomly select from the data 20 pairs of annotators who used the same reference translations and 20 pairs of annotators who used different reference translations. The agreement is then computed for each pair. Next, we calculate the average agreement for the same-reference and different-reference groups. We repeat the experiment 100 times and report the corresponding averages and confidence intervals. <ref type="table" target="#tab_10">Table 1</ref> shows the results in terms of standard <ref type="bibr">(Cohen, 1960)</ref> and linearly weighted <ref type="bibr">(Cohen, 1968)</ref> Kappa coefficient (k). <ref type="bibr">1</ref> We also report oneoff version of weighted k, which discards the disagreements unless they are larger than one category. As shown in <ref type="table" target="#tab_10">Table 1</ref>, the agreement is consistently lower for annotators using different references. In other words, the same MT outputs systematically receive different scores when differ-ent human translations are used for their evaluation. Here and in what follows, the differences between the results for the same-reference annotator group and different-reference annotator group were found to be statistically significant with pvalue &lt; 0.01.</p><p>The agreement between annotators using the source sentences is slightly lower than in the monolingual, same-reference scenario, but it is higher than in the case of the different-reference group. This may be an indication that referencebased evaluation is an easier task for annotators, perhaps because in this case they are not required to shift between languages. Nevertheless, the fact that given a different reference, the same MT outputs receive different scores, undermines the reliability of this type of evaluation.  <ref type="table" target="#tab_5">Table 2</ref>: Average human scores for the groups of annotators using different references and BLEU scores calculated with the corresponding references. Human scores range from 1 to 5, while BLEU scores range from 0 to 1.</p><p>In <ref type="table" target="#tab_5">Table 2</ref> we computed average evaluation scores for each group of annotators. Average scores vary considerably across groups of annotators. This shows that MT quality is perceived differently depending on the human translation used as gold-standard. For the sake of comparison, we also present the scores from the widely used automatic evaluation metric BLEU. Not surprisingly, BLEU scores are also strongly affected by the reference bias. Below we give an example of linguistic variation in professional human translations and its effect on reference-based MT evaluation.</p><p>Src: 不过这一切都由不得你 2 MT: But all this is beyond the control of you. R1: But all this is beyond your control. R2: However, you cannot choose yourself. R3: However, not everything is up to you to decide.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>R4: But you can't choose that.</head><p>Although all the references carry the same message, the linguistic means used by the translators are very different. Most of these references are high-level paraphrases of what we would consider a close version of the source sentence. Annotators are expected to recognize meaning-preserving variation between the MT and any of the references. However, the average score for this sentence was 3.4 in case of Reference 1, and 2.0, 2.0 and 2.8 in case of the other three references, respectively, which illustrates the bias introduced by the reference translation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Time Effect</head><p>It is well known that the reliability and consistency of human annotation tasks is affected by fatigue <ref type="bibr">(Llorà et al., 2005)</ref>. In this section we examine how this factor may gave influenced the evaluation on the impact of reference bias and thus the reliability of our experiment.</p><p>We measured inter-annotator agreement for the same-reference and different-reference annotators at different stages of the evaluation process. We divided the dataset in five sets of sentences based on the chronological order in which they were annotated <ref type="bibr">(0-20, 20-40, ..., 80-100)</ref>. For each slice of the data we repeated the procedure reported in Section 4. <ref type="figure" target="#fig_8">Figure 2</ref> shows the results.</p><p>First, we note that the agreement is always higher in the case of same-reference annotators. Second, in the intermediate stages of the task we observe the highest inter-annotator agreement (sentences 20-40) and the smallest difference between the same-reference and different-reference annotators (sentences 40-60). This seems to indicate that the effect of reference bias is minimal half-way through the evaluation process. In other words, when the annotators are already acquainted with the task but not yet tired, they are able to better recognize meaning-preserving variation between different translation options.</p><p>To further investigate how fatigue affects the evaluation process, we tested the variability of human scores in different (chronological) slices of the data. We again divided the data in five sets of sentences and calculated standard deviation between the scores in each set. We repeated this procedure for each annotator and averaged the results. As can be seen in <ref type="figure" target="#fig_6">Figure 3</ref> </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Conclusions</head><p>In this work we examined the effect of reference bias on monolingual MT evaluation. We compared the agreement between the annotators who used the same human reference translation and those who used different reference translations. We were able to show that in addition to the inevitable bias introduced by different annotators, monolingual evaluation is systematically affected by the reference provided. Annotators consistently assign different scores to the same MT outputs when a different human translation is used as goldstandard. The MTs that are correct but happen to be different from a particular human translation are inadvertently penalized during evaluation.</p><p>We also analyzed the relation between reference bias and annotation at different times throughout the process. The results suggest that annotators are less influenced by specific translation choices present in the reference in the intermediate stages of the evaluation process, when they have already familiarized themselves with the task but are not yet fatigued by it. To reduce the fatigue effect, the task may be done in smaller batches over time. Regarding the lack of experience, annotators should receive previous training.</p><p>Quality assessment is instrumental in the development and deployment of MT systems. If evaluation is to be objective and informative, its purpose must be clearly defined. The same sentence can be translated in many different ways. Using a human reference as a proxy for the source sentence, we evaluate the similarity of the MT to a particular reference, which does not necessarily reflect how well the contents of the original is expressed in the MT or how suitable it is for a given purpose. Therefore, monolingual evaluation undermines the reliability of quality assessment. We recommend that unless the evaluation is aimed for a very specific translation task, where the number of possible translations is indeed limited, the assessment should be performed by comparing MT to the original text. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Class-based language modeling has a long history of being used to improve the quality of speech recognition systems <ref type="bibr">Knesser and Ney, 1993)</ref>. Recent work on class-based models has exploited named entity recognition (NER) approaches to label language model training data with class labels <ref type="bibr">(Levit et al., 2014;</ref><ref type="bibr">Vasserman et al., 2015)</ref>, providing a means to assign words and phrases to classes based on their context. These contextually assigned classes have been shown to improve speech recognition significantly over grammar-based, deterministic class assignments. In this work, we address the problem of labeling training data in order to build a class sequence tagger. We borrow from the successes of previous cross-lingual projection experiments for labeling tasks <ref type="bibr">Burkett et al., 2010;</ref><ref type="bibr">Padó and Lapata, 2009</ref>). We focus on numeric classes (e.g., address numbers, dates, currencies, times, etc.) as the sequence-based labeling approach has been shown to be effective for identifying them. Given a model trained from human-labeled data in one language (we refer to this as the highresource language), we label translations of sentences from another language (referred to as the low-resource language). We show that we can project the numeric entity boundaries and labels across the aligned translations with a phrase-based translation model. Furthermore, we show that if we train a class labeling model on the projected low-resource language and then use that to build a class-based speech recognition system, we achieve between 70% and 85% of the error reduction as we would have achieved with human-labeled examples in the low-resource language.</p><p>We present empirical results projecting numeric entity labels from English to Russian, Indonesian, and Italian. We present full speech recognition results for using human annotated data (the ideal performance) and projected data with various sizes of training data.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Related work</head><p>There is an increasingly large body of work based on exploiting alignments between translations of sentences in multiple languages <ref type="bibr">Burkett et al., 2010;</ref>. In this work we employ the simple approach of projecting annotations across alignments of translated sentences. Our cross-lingual approach is closely related to other NER projection approaches <ref type="bibr">(Huang et al.,</ref>  2003; <ref type="bibr">Moore, 2003)</ref>; however, we have focused on a limited class of entities which may explain why the simple approach works reasonably well.</p><p>Our projection approach is most closely related to that presented in  and <ref type="bibr">(Padó and Lapata, 2009)</ref>. In each of these, labels over sequences of words are projected across alignments directly from one language to the other. While we follow a similar approach, our goal is not necessarily to get the exact projection, but to get a projection which allows us to learn contextual cues for the classes we are labeling. Additionally, we focus on the case where we are generating the translated data rather that identifying existing parallel data. Similar to , we filter out poor alignments (details are described in Section 3.2).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Methodology</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Training class taggers for language modeling</head><p>We use a statistical sequence tagger to identify and replace class instances in raw text with their label. For example, the tokens 10 thousand dollars in the raw training text may be replaced with a placeholder class symbol. The decision is contextdependent: the tagger is able to resolve ambiguities among possible labels, or even leave the text unchanged. Next, this modified text is used to train a standard n-gram language model. Fi- nally, all placeholders become non-terminals in the language model and are expanded either statically or dynamically with stochastic finite-state class grammars (see <ref type="figure" target="#fig_8">Figure 2</ref> for an example). Decorator tokens inside the grammars are used to mark class instances in the word lattice so that they can be converted (after recognition) to the desired written forms using deterministic spoken-towritten text-normalization rules.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Cross-lingual Projection Techniques</head><p>The starting point for cross-lingual projection is to train a statistical sentence tagger of high quality in a high-resource language, i.e., a language where both a lot of training data and human annotators are readily available. We use English in our experiments.</p><p>To obtain annotated sentences in a low-resource language, we translate unlabeled sentences into the high-resource language. We use an in-house phrase-based statistical machine translation system <ref type="bibr" target="#b91">(Koehn et al., 2003)</ref> which is trained with parallel texts extracted from web pages; described in detail in Section 4.1 of <ref type="bibr">(Nakagawa, 2015)</ref>. The translation system we use provides token-by-token alignments as part of the output. This is achieved by keeping alignments along with phrase-pairs during the phrase extraction stage of training the alignment system.</p><p>The high quality sentence tagger is applied to the translated sentences. Then, using the alignments between the translated sentences, we map class tags back to the low-resource language. See <ref type="figure" target="#fig_3">Figure 1</ref> for examples of actual mappings produced by this procedure.</p><p>With this approach, we can produce arbitrarily large in-domain annotated training sets for the low-resource language. These annotated sentences are then used to train a class tagger for the low-resource language. The main question is whether the resulting class tagger is of sufficient quality for our down-stream objective.</p><p>For the goal of training a class-based language model in a low-resource language, one may consider a different approach than the one just described: instead of training a tagger in the lowresource language, each sentence in the language model training data could be translated to the highresource language, tagged using the statistical tagger, and projected back to the low-resource language. The primary reason for not pursuing this approach is the size of the language model training data (tens of billions of sentences). Translating a corpus this large is prohibitive. As the highresource language tagger is trained on approximately 150K tokens, we believe that we have covered a large number of the predictive cues for the set of classes.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Alignment details</head><p>When projecting the class labels back from a translated sentence to the original sentence, various subtle issues arise. We describe these and our solutions for each in this section.</p><p>To tag a token in the low-resource language, we see which tokens in the high-resource language are aligned to it in the translation, and look at their class tags. If all of these tokens have the same class tag, we assign the same tag to the lowresource language token. Otherwise, we use the following rules:</p><p>• If some tokens have no class tag but others have some class tag, we still assign the class tag to the original token.</p><p>• If multiple tokens with different class tags map to the original token, we consider the tagging ambiguous. In such a case, we simply skip the sentence and do not use it for training the low-resource tagger. We can afford to do so because there is no shortage of unlabeled training sentences.</p><p>In a number of cases, we ignore sentence pairs which may have contained alignments allowing us to project labels, but also contained noise (e.g., spurious many-to-one alignments). We rejected poor alignments 2%, 31% and 14% of the time for Indonesian, Russian and Italian respectively. Date and time expressions were often affected by these noisy alignments.</p><p>4 Empirical evaluation</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Data</head><p>We trained an English conditional random field (CRF)  tagger to be used in all experiments in order to provide labels for the sentences produced by translation. To train this tagger we obtained a data set of 24,503 manually labeled sentences (150K tokens) sampled from a corpus of British English language model training material. Each token is labeled with one of 17 possible tags. About 95% of the tokens are labeled with a 'none' tag, meaning that the token is not in any of the pre-determined non-lexical classes.</p><p>Separately, we obtained similar training sets to create Italian, Indonesian and Russian taggers. The models trained from these labeled data sets were used only to create baseline systems for comparison with the cross-lingual systems.</p><p>To provide input into our cross-lingual projection procedure, we also sampled datasets of unlabeled sentences of varying sizes for each evaluation language, using the same sampling procedure as used for the human-labeled sets.</p><p>Note that these tagger training sets have inconsistent sizes across languages (see <ref type="table" target="#tab_5">Table 2</ref>) due to the nature of the sampling procedure: Each training source is searched for sentences matching an extensive list of patterns of numeric entities. Sentences from each training source are collected up to a source-specific maximum number (which may not always be reached). We also apply a flattening step to increase diversity of the sample.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">CRF model</head><p>Our CRF tagger model was trained online using a variant of the MIRA algorithm <ref type="bibr">(Crammer and Singer, 2003)</ref>. Our feature set includes isolated features (for word identity w i , word type d i , and word cluster c i ) as well as features for neighboring</p><formula xml:id="formula_18">words w i−2 , w i−1 , w i+1 , w i+2 , w i+3 , neighbor- ing clusters c i−2 , c i−1 , c i+1 , c i+2 , c i+3 , pair fea- tures (w i , d i−1 ), (w i , d i+1 ), (d i , d i−1 ), (d i , d i+1 )</formula><p>, and domain-specific features (indicators for tokens within a given numeric range, or tokens that end in a certain number of zero digits). We also include class bias features, which capture the class prior distribution found in the training set.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Metrics</head><p>We use two manually transcribed test sets to evaluate the performance of our approach in the con- We report word-error-rate (WER) on each test set for each model evaluated, including two baseline systems (one built without classes at all and another that has classes identified by a tagger trained on human-labeled data). We also report a labeled-bracket F1 score to show the performance of the tagger independent of the speechrecognition task. For each language, the test set used for labeled-bracket F1 is a human-labeled corpus of approximately 2K sentences that were held out from the human-labeled corpora for the baseline systems.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4">Results</head><p>The results in <ref type="table" target="#tab_5">Table 2</ref> show that all class-based systems outperform the baseline in WER on the NUMERIC test set, while performance on the VOICE-SEARCH test set was mostly flat. The flat performance on VOICE-SEARCH is expected: as seen in <ref type="table" target="#tab_10">Table 1</ref> this test set has a very low proportion of words that are numeric in form. We provide results on this test set in order to confirm that our approach does not harm general voice-search queries. As for performance on the NUMERIC test set, larger cross-lingual data sets led to better performance for Russian and Italian, but caused a slight regression for Indonesian. The translation system we use for these experiments has been optimized for a general-purpose web search  <ref type="table" target="#tab_5">Table 2</ref>: NUM refers to the NUMERIC entities test set and VS refers to the VOICE-SEARCH test set. All NUM WER results are statistically significant (p &lt; 0.1%) using a paired random permutation significance test.</p><p>translation task rather than for an academic task. When evaluated on a test set matched to the translation task, performance for Russian-to-English was considerably worse than for Indonesian-toEnglish or Italian-to-English. For Indonesian (ID), the human-labeled system achieved a 4.5% relative WER reduction on NUMERIC, while the best cross-lingual system achieved a 3.5% relative reduction.</p><p>For Russian (RU), the human-labeled system improved more, achieving an 11.8% relative reduction on NUMERIC, while the best cross-lingual system achieved an 8.7% relative reduction.</p><p>Finally, for Italian (IT), the human-labeled system gave an impressive 17.4% relative reduction on NUMERIC, while the best cross-lingual system achieved a 14.8% relative reduction on the same test set.</p><p>Across the three languages, the cross-lingual systems achieved relative error reductions on the NUMERIC test set that were between 70% and 85% of the reduction achieved when using only human-labeled data for training the class tagger.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.5">Error Analysis</head><p>We noticed that the Russian cross-lingual-derived training set was of lower quality than those of the other languages, as seen in the labeled-bracket F1 metric in <ref type="table" target="#tab_5">Table 2</ref>. Looking more closely, we noticed that the per-class F1 scores tended to be lower for labels used for dates and times. This observation also concides with the observation that the alignment procedure frequently ran into ambiguity issues when aligning month, day and year tokens between Russian and English, thus significantly reducing the coverage of these labels in the induced cross-lingual training set.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Conclusion</head><p>We presented a cross-lingual projection technique for training class-based language models. We extend a previously successful sequence-modelingbased class labeling approach for identifying contextually-dependent class assignments by projecting labels from a high-resource language to a low-resources language. This allows us to build class-based language models in low-resource languages with no annotated data. Our empirical results show that we are able to achieve between 70% and 85% of the error reduction that we would have obtained had we used human-labeled data.</p><p>While cross-lingual projection for sequencelabeling techniques are well known in the community, our approach exploits the fact that we are generating training data from the projection rather than using the projected result directly. Furthermore, noise in the class-labeling system does not cripple the language model as it learns a distribution over labels (including no label).</p><p>In future work, we will experiment with alternative projection approaches including projecting the training data and translating from the high-resource language to the low-resource language. We also plan to experiment with different projection approaches to address the ambiguity issues we observed when aligning time and date expressions.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Abstract</head><p>Retrieving semantic similar short texts is a crucial issue to many applications, e.g., web search, ads matching, questionanswer system, and so forth. Most of the traditional methods concentrate on how to improve the precision of the similarity measurement, while current real applications need to efficiently explore the top similar short texts semantically related to the query one. We address the efficiency issue in this paper by investigating the similarity strategies and incorporating them into the FAST framework (efficient FrAmework for semantic similar Short Texts retrieval). We conduct comprehensive performance evaluation on real-life data which shows that our proposed method outperforms the state-ofthe-art techniques.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>In this paper, we investigate the fast approach of short texts retrieval, which is important to many applications, e.g., web search, ads matching, question-answer system, etc. <ref type="bibr" target="#b232">(Yu et al., 2016;</ref><ref type="bibr" target="#b457">Hua et al., 2015;</ref><ref type="bibr" target="#b402">Yang et al., 2015;</ref><ref type="bibr">Wang et al., 2010;</ref><ref type="bibr" target="#b147">Wei et al., 2008;</ref><ref type="bibr">Cui et al., 2005;</ref><ref type="bibr">Metzler et al., 2007;</ref><ref type="bibr">Ceccarelli et al., 2011;</ref><ref type="bibr">Radlinski et al., 2008)</ref>. The setting of the problem is that users always ask for those most semantically related to their queries from a huge text collection. A common solution is applying the state-of-the-art short texts similarity measurement techniques <ref type="bibr">(Islam and Inkpen, 2008;</ref><ref type="bibr" target="#b153">Li et al., 2006;</ref><ref type="bibr">Mihalcea et al., 2006;</ref><ref type="bibr">Sahami and Heilman, 2006;</ref><ref type="bibr">Tsatsaronis et al., 2010;</ref><ref type="bibr">Mohler et al., 2011;</ref>, and then return the top-k ones * Corresponding author.</p><p>by sorting them with regard to the similarity score. After surveying the previous approaches, we find that almost all the methods concentrate on how to improve the precision, i.e., effectiveness issue. In addition, the data collections which they conducted are rather small. However, the scale of the problem has dramatically increased and the current short texts similarity measurement techniques could not handle when the data collection size becomes enormous. In this paper, we aim to address the efficiency issue in the literature while keeping their high precision. Moreover, we focus on the top-k issue because users commonly do not care about the individual similarity score but only the sorted results. Furthermore, most of the previous studies <ref type="bibr">(Islam and Inkpen, 2008;</ref><ref type="bibr" target="#b153">Li et al., 2006;</ref><ref type="bibr">Tsatsaronis et al., 2010;</ref> need to set predefined threshold to filter out those dissimilar texts which is rather difficult to determine by users. Different from long texts, short texts cannot always observe the syntax of a written language and usually do not possess sufficient information to support statistical based text processing techniques, e.g., TF-IDF. This indicates that the traditional NLP techniques for long texts may not be always appropriate to apply to short texts. The related works on short texts similarity measurement can be classified into the following major categories, i.e., (1) inner resource based strategy <ref type="bibr" target="#b153">(Li et al., 2006;</ref><ref type="bibr">Islam and Inkpen, 2008)</ref>; (2) outer resource based strategy <ref type="bibr">(Tsatsaronis et al., 2010;</ref><ref type="bibr">Mihalcea et al., 2006;</ref><ref type="bibr">Islam and Inkpen, 2008;</ref>; and (3) hybrid based strategy <ref type="bibr">(Islam and Inkpen, 2008;</ref><ref type="bibr" target="#b153">Li et al., 2006;</ref>.</p><p>Naively testing the candidate short texts for topk similar short texts retrieval is inefficient when directly using these strategies. To tackle the efficiency problem, we propose an efficient strategy to evaluate as few candidates as possible. Moreover, our fast algorithm aims to output the results progressively, i.e., the top-1 should be obtained instantly. This scheme meets the demand of the real world applications, especially for big data environment. We list our contribution of this paper as follows: we propose a fast approach to tackle the efficiency problem for retrieving top-k semantic similar short texts; we present the optimized techniques and improve the efficiency which minimizes the candidate number to be evaluated in our framework. The results of four different settings demonstrate that the efficiency of our fast approach outperforms the state-of-the-art methods while keeping effectiveness.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Preliminaries</head><p>Formally, for a given query short text q, retrieving a set of k short texts T s in a data collection D s which are most semantically similar to q, i.e., ∀t ∈ T s and ∀r ∈ (D s − T s ) will yield sim(q, t) ≥ sim(q, r). To obtain the similarity score sim(q, t) between two short texts, we can apply the current state-of-the-art strategies <ref type="bibr">(Tsatsaronis et al., 2010;</ref><ref type="bibr">Mihalcea et al., 2006;</ref><ref type="bibr">Islam and Inkpen, 2008;</ref>. In this paper, we judiciously select some similarity metrics which are assembled into a general framework to tackle the efficiency problem. Most of the existing strategies of evaluating the similarity between short texts are based on word similarity, because of the intuitive idea that short text is composed of words. As a result, we introduce the representative word similarity in the next section.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Selected Representative Similarity Measurement Strategies</head><p>There are a number of semantic similarity strategies having been developed in the previous decades which are useful in some specific applications of NLP tasks. Recently, outer resources are indispensable for short texts similarity measurement <ref type="bibr">(Tsatsaronis et al., 2010;</ref><ref type="bibr">Mihalcea et al., 2006;</ref><ref type="bibr">Islam and Inkpen, 2008;</ref><ref type="bibr" target="#b457">Hua et al., 2015)</ref>. After extensively investigating a number of similarity measurement strategies, we judiciously explore two representative word similarity measurement strategies which obtain the best performance compared with human judges.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Knowledge based Strategy</head><p>Knowledge based strategy determines whether two words are semantically similar by measuring their shortest path in the predefined taxonomy. The path between them can be calculated by applying word thesauri, e.g., WordNet. In this paper, we take one representative metric which has been proposed in <ref type="bibr">(Leacock and Chodorow, 1998</ref>). Let's take two words w i ,w j as an example, the similarity is as follows:</p><formula xml:id="formula_19">Sim k (w i , w j ) = −ln path s (w i , w j )</formula><p>2 * D where path s (w i , w j ) is the shortest path between two word concepts by using related strategy, e.g., node-counting strategy. D is the maximum depth of such taxonomy (D is with different size in either noun taxonomy or verb taxonomy).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Corpus based Strategy</head><p>Different from knowledge based strategy, corpus based strategy cannot form a new entity which means we can only apply statistical information to determine the similarity between two words. There are a few corpus based similarity measurement strategies, e.g., PMI, LSA, HAL, and so forth. In this paper, we select a representative strategy which applies Wiki encyclopedia to map Wiki texts into appropriate topics. Each Wiki topic is represented as an attribute vector. The words in the vector occur in the corresponding articles. Entries of these vectors are assigned weight which quantifies the association between words and each Wiki topic after applying vector based scheme, e.g., TF-IDF. The similarity can be evaluated by aggregating each word distributing on these topics. In addition, a short text is a vector based on topics with weight of each topic T i formulated as:</p><formula xml:id="formula_20">∑ w i ∈Ts v i · d j ,</formula><p>where v i is TF-IDF weight of w i and d j which quantifies the degree of association of word w i with Wiki topic T j . Here, the Wiki topic could be concepts or topics generated by other techniques, e.g., LDA, LSA, etc.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Semantic Similarity Measurement between Two Short Texts</head><p>Semantic similarity between two short texts can be measured by combining the words similarity in a general framework. Therefore, the method of combining the words similarities into a framework may affect the efficiency and effectiveness of the similarity score. In this paper, we integrate differ-ent similarity strategies linearly and this method has been proved that it has high precision by comparing with human judges <ref type="bibr" target="#b153">(Li et al., 2006;</ref><ref type="bibr">Islam and Inkpen, 2008)</ref>. The scheme measures each word pair of short texts and then constructs a similarity score matrix. Finally, the similarity score between two short texts is recursively executed by aggregating the representative words.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">A Fast Approach for Semantic Similar Short Texts Retrieval</head><p>We propose a fast approach for retrieving the topk semantic similar short texts to a given query q in this section. The key idea of this scheme is to access a rather small size of candidates in the whole data collection. The scheme is conducted by building appropriate indices in offline procedure, i.e., preprocessing procedure. We illustrate the whole framework in <ref type="figure" target="#fig_3">Figure 1</ref>. The figure tells us, to efficiently retrieve top-k similar short texts, our proposed strategy only accesses as small as possible part of candidates which are filled in grey color.  <ref type="figure" target="#fig_3">Figure 1</ref>: The framework of proposed fast approach</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Efficiently Aggregate Similarity Metrics</head><p>In this section, we present an efficient assembling strategy to hasten the process of retrieving top-k similar short texts <ref type="bibr">(Fagin et al., 2001)</ref>. A concrete example to illustrate our proposal is presented in <ref type="figure" target="#fig_3">Figure 1</ref>. For example, let the query short text is: "Delicious lunch in Japan". After preprocessing (stemming and removing the stopwords), the query is: delicious lunch Japan. From <ref type="figure" target="#fig_3">Figure 1</ref>, we can see that there is a hierarchical structure in our framework. Suppose that if we want to retrieve top-1 short text from the whole data, the ranked list (i.e., order list) of knowledge based similarity and corpus based similarity are needed respectively. From the analysis on the property of threshold algorithm, the top-1 short text comes from these two ranked lists instantly. However, we cannot know such ranking directly because these two lists are texts layer but each list has its sub layer, i.e., word layer. In this paper, we apply two kinds of similarity metrics. Therefore, there are two assembling tasks, i.e., (1)assembling knowledge based and corpus based similarities; and (2)assembling words to texts. The words are query words and each query word corresponds to a list which can be found in <ref type="figure" target="#fig_3">Figure 1</ref>. <ref type="figure" target="#fig_3">Figure 1</ref> also tells us for each word, it has the corresponding list in which all the words have been ranked based on the relatedness with such word. Since each word may occur in several short texts, the proposed method here should take the ID of each short text into consideration (e.g., word "delicious" occurs T2, etc.). We apply threshold algorithm to obtain the top short texts based on each query word. Therefore, the top-1 result comes from these two ranked lists based on threshold algorithm. In this example, T2 is finally outputted as the top-1 value.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Ranking list on Similarity Strategies</head><p>From the description in Section 3.1, we can see that the ranked list is crucial for using threshold algorithm to retrieve top-k short texts. In this section, we introduce the optimized method on each similarity metric.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Ranking on Knowledge based strategy</head><p>Since WordNet is a representative knowledge base, we apply the Leacock and Chodorow strategy as a WordNet evaluator which optimized as an efficient technique <ref type="bibr">(Yang and Kitsuregawa, 2011)</ref>.</p><p>Lemma 1 (Ordering in WordNet) Let q be the query. Let P and S be two candidates that exist in the same taxonomy of q, that is, T P and T q . The shortest path between q and</p><formula xml:id="formula_21">P (or S) is L P in T P (or L S in T S ). The maximum depth of T P is D P (or D S of T S )</formula><p>. P is more similar to Q compared with S. Thus, we have</p><formula xml:id="formula_22">D P L P &gt; D S L S .</formula><p>The lemma tells us that the similarity ordering between candidates in WordNet depends on the integration of the shortest path and the maximum depth of the taxonomy. We access the related synonyms set between two taxonomies successively based on the value of D L and obtain the top-k results in a progressive manner.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Ranking on Corpus based Strategy</head><p>We measure the similarity between short texts by aggregating each word distribution on topics. A short text is a valued vector based on topics, where the weight of each topic T i calculated as:</p><formula xml:id="formula_23">∑ w i ∈Ts v i · k j ,</formula><p>where v i is TF-IDF weight of w i and k j which quantifies the strength of association of word w i with Wiki topic T j . Different from the traditional approaches, we first calculate all the similarity scores between each word in Wiki and that between topics in the data collection to obtain a set of lists during preprocessing. The topic could be generated either by ESA or by LDA. After that, we build a weighted inverted list where each list presents a word with sorted corresponding short texts according to the similarity score. Therefore, for a given query text q, each word in q corresponds to a list of short texts. As that, we apply the threshold algorithm retrieve the top-k results by using this manner. This manner accesses a small size of components of the data without necessity to evaluate every candidate short text.</p><p>After obtaining all the ranking lists, we can apply the threshold algorithm aforementioned to efficiently retrieve the top-k semantic similar short texts either by equal weight scheme or weight tuning strategy.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Experimental Evaluation</head><p>In this section, we conduct on three different datasets to evaluate the performance of our approach. To evaluate the effectiveness, we test the dataset which was used in <ref type="bibr" target="#b153">(Li et al., 2006)</ref>. For efficiency evaluation, we apply the BNC and MSC datasets which are extracted from British National Corpus and Microsoft Research Paraphrase Corpus respectively. The baseline strategy is implemented according to the state-of-the-art (linear assembling strategy as <ref type="bibr">(Islam and Inkpen, 2008)</ref>). In our proposed strategy, we take four different settings: (1) FAST E is the one that we apply the ESA topic strategy; (2) FAST L employs the LDA topic strategy in corpus based similarity with equal weight; and (3) FAST Ew and FAST Lw are implemented based on the former two ones, respectively, with the tuned combinational weights.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Efficiency Evaluation</head><p>We evaluate the efficiency by using two real-life datasets which have been denoted as BNC and MSC. To test the effect of size of data collection, we select different size of these two datasets. Firstly, we conducted experiments on the fixed size of data collection by using 4 settings of our proposed approach. The results show that comparing with the baseline strategy, FAST E , FAST L , FAST Ew and FAST Lw have promotion at 75.34%, 74.68%, 75.31% and 74.59% respectively. The four settings have similar results which indicates that the weight is not the crucial factor in our proposed strategy. <ref type="table">Table.</ref> 1 tells us the number of candidates accessed. Our evaluation has been conducted on different data collection size to test the scalability of our proposed strategy. Since the baseline strategy should access all the short texts in each size of data collection, which means in 1k size of BNC data collection, the baseline strategy access all these 1k candidates. However, our proposed strategies under different settings only access small size candidates to obtain the results. From the table, we can see that, our proposed strategy can largely reduce the number of candidates accessed in both data collections. In addition, the number of candidates accessed has increases not quickly which indicate our proposed approach scales well. Therefore, the proposed strategy is efficient than the baseline strategy.  We also evaluate the effect of k which is an important factor for evaluating the efficiency of an algorithm. The experiments conducted on a fixed size of data collection which show that the top-1 value has been outputted instantly by apply our proposed strategy while baseline strategy should access all candidates. For the query time of FAST E setting costs only 19.12s while baseline strategy costs 897.5s for obtaining the top-1 value. FAST L , FAST Es and FAST Lw cost 20.13s, 21.21s and 20.32s respectively which confirms that combinational weight is not an important factor in our proposed strategy.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Effectiveness Evaluation</head><p>We illustrate the results of the correlation coefficient with human ratings in <ref type="table">Table.</ref> 2. Note here, the baseline strategy is composed by knowledge based strategy and corpus based strategy (ESA method) with equal weight. From the table we can see that, the FAST E has the same precision as the baseline because our proposed strategy only changes the order of the evaluated short texts but not the similarity strategy. FAST L has better precision than FAST E because we select the best LDA topic size to form Wiki topic. FAST Ew and FAST Lw have dynamically changed the combinational weights and therefore, the performance of them has been improved.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Conclusion</head><p>In this paper, we propose a fast approach to tackle the efficiency problem of retrieving top-k similar short texts which has not been extensively studied before. We select two representative similarity metrics, i.e., knowledge based and corpus based similarity. Efficient strategies are introduced to test as few candidates as possible in the querying process. Four different settings have been proposed to improve the effectiveness. The comprehensive experiments demonstrate the efficiency of the proposed techniques while keeping the high precision. In the future, we will investigate new methods to tackle efficiency issue and take effect semantic similarity strategies to obtain high performance. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Empty categories, which are used in Penn Treebank style annotations to represent complex syntactic phenomena like constituent movement and discontinuous constituents, provide important information for understanding the semantic structure of sentences. Previous studies attempt empty element recovery by casting it as linear tagging <ref type="bibr">(Dienes and Dubey, 2003)</ref>, PCFG parsing <ref type="bibr">(Schmid, 2006;</ref><ref type="bibr" target="#b3">Cai et al., 2011)</ref> or post-processing of syntactic parsing <ref type="bibr">(Johnson, 2002;</ref><ref type="bibr">Gabbard et al., 2006)</ref>. To the best of our knowledge, the results reported by <ref type="bibr" target="#b3">(Cai et al., 2011)</ref> are the best yet reported, so we pursue a method that uses syntactic parsing to jointly solve the empty element recovery problem. Our proposal uses the spinal Tree Adjoining Grammar (TAG) formalism of <ref type="bibr" target="#b4">(Carreras et al., 2008)</ref>. The spinal TAG has a set of elementary trees, called spines, each consisting of a lexical anchor with a series of unary projections. Figure 1 displays (a) a head-annotated constituent tree and (b) spines extracted from the tree. This paper presents a transition-based algorithm together with several operations to combine spines for constructing full parse trees with empty elements. Compared with the PCFG parsing approaches, one advantage of our method is its flexible feature representations, which allow the incorporation of constituency-, dependency-and spine-based features. Of particular interest, the motivation for our spinal TAG-based approach comes from the . . (a) .  intuition that features extracted from spines can be expected to be useful for empty element recovery in the same way as constituency-based vertical higher-order conjunctive features are used in recent post-processing methods <ref type="bibr">(Xiang et al., 2013;</ref><ref type="bibr">Takeno et al., 2015)</ref>. Experiments on English and Japanese datasets empirically show that our system outperforms existing alternatives.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Spinal Tree Adjoining Grammars</head><p>We define here the spinal TAG G = (N, PT, T, LS) where N is a set of nonterminal symbols, PT is a set of pre-terminal symbols (or part-of-speech tags), T is a set of terminal symbols (or words), and LS is a set of lexical spines. Each spine, s, has the form n 0 → n 1 → · · · → n k−1 → n k (k ∈ N) which satisfies the conditions:</p><p>• n 0 ∈ T and n 1 ∈ PT ,</p><formula xml:id="formula_24">• ∀i ∈ [2, k], n i ∈ N.</formula><p>The height of spine s is ht(s) = k + 1 and for some position i ∈ [0, k], the label at i is s(i) = n i . <ref type="table">Tak</ref>  We use @# to illustrate node position on a spine, explicitly. After a regular adjunction, the resulting tree has an additional node level which has a copy of its original node at position @x, while a sister adjunction simply inserts a spine into some node of another spine. If adjunction left (or right) inserts spine s 1 into some node at @x on spine s 2 , we call s 2 the head spine of s 1 and s 1 the left (or right) child spine of s 2 1 . This paper denotes sister adjunction left and right as s 1 ▷ ⃝ x s 2 , s 2 ◁ ⃝ x s 1 , regular adjunction left and right as s 1 ▶ ⃝ x s 2 , s 2 ◀ ⃝ x s 1 , respectively.</p><p>3 Arc-Standard Shift-Reduce Spinal TAG Parsing</p><p>There are three algorithms for spinal TAG parsing, (1) Eisner-Satta CKY <ref type="bibr" target="#b4">(Carreras et al., 2008)</ref>, <ref type="formula" target="#formula_1">(2)</ref> arc-eager shift-reduce <ref type="bibr" target="#b1">(Ballesteros and Carreras, 2015)</ref> and <ref type="formula" target="#formula_6">(3)</ref> arc-standard shift-reduce <ref type="bibr">(Hayashi et al., 2016)</ref> algorithms. This paper uses the arc-standard shift-reduce algorithm since it provides a more simple implementation. A transition system for spinal TAG parsing is the tuple S = (C, T, I,C t ), where C is a set of configurations, T is a set of transitions, which are partial functions t : C ⇀ C, I is a total initialization function mapping each input string to a unique configuration, and C t ⊆ C is a set of terminal configurations. A configuration is the tuple (α, β , A) where α is a stack of stack elements, β is a buffer of elements from an input, and A is a set of parser operations. A stack element s is a pair (s, j) where s is a spine and j is a node index of s. We refer to s and j of s as s.s and s. j, respectively. Let x = ⟨w 1 /t 1 , . . . , w n /t n ⟩ (∀i ∈ [1, n], w i ∈ T and t i ∈ PT ) be a pos-tagged input sentence. The arc-standard transition system by <ref type="bibr">Hayashi et al. (2016)</ref> can be defined as follows: its initialization function is <ref type="bibr">)</ref>, and it has the following transitions:</p><formula xml:id="formula_25">I(x) = ([], [w 1 /t 1 , . . . , w n /t n ], / 0), its set of terminal configurations is C t = ([], [], A</formula><p>1. for each s ∈ LS with s(0) = w i and s(1) = t i , a shift transition of the form (α,</p><formula xml:id="formula_26">w i /t i |β , A) ⊢ (α|s 1 , β , A) where s 1 = (s, 2) 2 ;</formula><p>2-3. for each j with s 1 . j ≤ j &lt; ht(s 1 .s), a sister adjunction left transition of the form</p><formula xml:id="formula_27">(σ |s 2 |s 1 , β , A) ⊢ (σ |s ′ 1 , β , A ∪ {s 2 .s ▷ ⃝ j s 1 .s})</formula><p>and a regular adjunction left transition of the form</p><formula xml:id="formula_28">(σ |s 2 |s 1 , β , A) ⊢ (σ |s ′ 1 , β , A ∪ {s 2 .s ▶ ⃝ j s 1 .s})</formula><p>where s ′ 1 = (s 1 .s, j); 4-5. for each j with s 2 . j ≤ j &lt; ht(s 2 .s), a sister adjunction right transition of the form</p><formula xml:id="formula_29">(σ |s 2 |s 1 , β , A) ⊢ (σ |s ′ 1 , β , A ∪ {s 2 .s ◁ ⃝ j s 1 .s})</formula><p>and a regular adjunction right transition of the form  To reduce search errors, <ref type="bibr">Hayashi et al. (2016)</ref> employed beam search with Dynamic Programming of <ref type="bibr">(Huang and Sagae, 2010)</ref>. For experiments, we also use this technique and discriminative modeling of <ref type="bibr">(Hayashi et al., 2016)</ref>.</p><formula xml:id="formula_30">(σ |s 2 |s 1 , β , A) ⊢ (σ |s ′ 1 , β , A ∪ {s 2 .s ◀ ⃝ j s 1 .s})</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Empty Element Recovery</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Spinal TAG with Empty Elements</head><p>In this paper, we redefine the spinal TAG as G = (N, PT, T, LS, *e*, ET, ES), where *e* is a special word, ET is a set of empty categories, and ES is a set of empty spines. An empty spine s = n 0 → n 1 → · · · → n k−1 → n k (k ∈ N) has the same form as lexical spines, but n 0 = *e* and n 1 ∈ ET . The height and label definitions are also the same as those of lexical spines. For example, the rightmost spine s = *e* → *T* → ADVP in <ref type="figure" target="#fig_3">Figure 1 (b)</ref> is an empty spine with ht(s) = 3 and s(1) = *T*. This paper extends empty spines to allow the use of phrasal constituents that consist of only empty elements, as a single spine. A phrasal empty spine is a tuple (t, h), where t is a sequence of (phrasal) empty spines specifying some sister adjunctions between these spines and h is a head spine in t. The phrasal empty spine in <ref type="figure" target="#fig_6">Figure 3</ref> consists of two empty spines *e* → 0 and *e* → *T* → S → SBAR, where a sister adjunction left is performed at the SBAR node of the latter spine, which is a head spine in the phrase. To apply parser operations to a phrasal empty spine, we use its head spine rather than itself. This paper defines the height and label of a phrasal empty spine as those of its head spine.</p><p>To recover empty elements, this paper introduces two additional operations, insert and combine, both of which have left and right types. <ref type="bibr">Figures 2 (c) and (d)</ref> show insert left and combine right operations. These operations are similar to sister adjunctions in that the former simply inserts some phrasal empty spine into some node of another spine and the latter also inserts a spine into some node of a phrasal empty spine.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">New Transitions</head><p>To handle empty spines in parsing process, we add the following five transitions to the arc-standard transition system of <ref type="bibr">(Hayashi et al., 2016):</ref> 7-8. for each s ∈ ES and each j with s 1 . j ≤ j &lt; ht(s 1 .s), an insert left transition of the form</p><formula xml:id="formula_31">(σ |s 1 , β , A) ⊢ (σ |s ′ 1 , β , A ∪ {s ▷ ⃝ j s 1 .s})</formula><p>and an insert right transition of the form</p><formula xml:id="formula_32">(σ |s 1 , β , A) ⊢ (σ |s ′ 1 , β , A ∪ {s 1 .s ◁ ⃝ j s})</formula><p>where s ′ 1 = (s 1 .s, j);</p><p>9-10. for each s ∈ ES and each j with 2 ≤ j &lt; ht(s), a combine left transition of the form</p><formula xml:id="formula_33">(σ |s 1 , β , A) ⊢ (σ |s ′ 1 , β , A ∪ {s 1 .s ▷ ⃝ j s})</formula><p>and a combine right transition of the form</p><formula xml:id="formula_34">(σ |s 1 , β , A) ⊢ (σ |s ′ 1 , β , A ∪ {s ◁ ⃝ j s 1 .s})</formula><p>where s ′ 1 = (s, j);</p><p>11. an idle transition of the form (σ |s 1 , β , A) ⊢ (σ |s 1 , β , A);</p><p>Like unary and idle rules in shift-reduce CFG parsing <ref type="bibr" target="#b169">(Zhu et al., 2013)</ref>, our current system prohibits &gt; b consecutive actions consisting of only insert, combine and idle operations. Given an input sentence with length n, after performing n shift, n − 1 adjunction, b · (2n − 1) {insert, combine or idle} actions, the system triggers the finish action and terminates. For training, we make oracle derivations using the stack-shortest strategy.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Related Work</head><p>To realize empty element recovery, other lexicalized TAG formalisms <ref type="bibr" target="#b5">(Chen and Shanker, 2004;</ref><ref type="bibr">Shen et al., 2008)</ref> attach some or all empty elements directly to surface word lexicons. Our framework, however, uses spinal TAG parser operations as they provide more efficient parsing and more compact sets of lexicons. It is remarkable that this paper is the first study to present a shiftreduce spinal TAG parsing algorithm to recover empty elements. Recent work has shown that empty element recovery can be effectively solved in conjunction   with parsing <ref type="bibr">(Schmid, 2006;</ref><ref type="bibr" target="#b3">Cai et al., 2011)</ref>. Schmid (2006) annotated a constituent tree with slash features to recover a direct path from a filler node to its trace. <ref type="bibr" target="#b3">Cai et al. (2011)</ref>   perceptron algorithm <ref type="bibr" target="#b424">(Huang et al., 2012)</ref>. For training and testing, we set beam size to 16 and max count b, introduced in Section 4.2, to 2. For comparison with other systems in our environment, we also implemented two systems:</p><p>• Lattice is a method by <ref type="bibr" target="#b3">Cai et al. (2011)</ref>. We also used blatt 5 , which is an extension of the Berkeley parser, to parse word lattices in which the special word *e* is encoded as described in <ref type="bibr" target="#b3">(Cai et al., 2011)</ref>.</p><p>• Tagger decides whether some empty category is inserted at the front of a word or not, with regularized logistic regression. To simplify point-wise linear tagging, we combined empty categories, those that appeared in the same position of a sentence, into a single category: thus the original 10 empty types increased to 63. <ref type="table" target="#tab_10">Table 1</ref> shows final results on Section 23. To evaluate the accuracy of empty element recovery, we calculated precision, recall and F1 scores for (1) Labeled Empty Bracket (X/t,i,i), (2) Labeled Empty Element (t,i,i), and (3) All Brackets, where X ∈ NT , t ∈ ET and i is a position of the empty element, using eevalb 6 . The results clearly show that our proposed method significantly outperforms the other systems. Table 2 shows the main reason for the improvement achieved by our method. The *ICH*, *RNR* and *EXP* empty types are used to show the relation between non-adjacent constituents, caused by syntactic phenomena like Extraposition and Conjunction. Our method captures such complex relations better with the help of the syntactic feature richness. <ref type="table" target="#tab_10">Table 1</ref> reports the scores for non-empty brackets to examine whether the joint method improves the standard PARSEVAL scores. While the Lattice <ref type="bibr">Johnson (X/t,i,i)</ref>  method was less accurate than the vanilla Berkeley parser, the performance of our method could be maintained with little loss in parsing accuracy. <ref type="figure" target="#fig_15">Figure 4</ref> shows the parse time in seconds for each test sentence and that our empty element recovery parser works in reasonable time.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.2">Experiments on the Japanese Keyaki Treebank</head><p>Finally, to show that our method works well on other languages, we conduct experiments on the Japanese Keyaki Treebank <ref type="bibr" target="#b2">(Butler et al., 2012)</ref>. For this data, we modified blatt to keep function labels And, in order to consider segmentation errors, we also modified eevalb to calculate not word but character span in a sentence. We follow the experiments in <ref type="bibr">(Takeno et al., 2015)</ref> and show the results in <ref type="table" target="#tab_6">Table 3</ref>. Our method significantly outperforms the state-of-the-art post-processing method in Japanese.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">Conclusion and Future Work</head><p>Using spinal parsing for the joint recovery of empty elements achieves state-of-the-art performance in standard English and Japanese datasets. We plan to extend our work to recover trace-filler and frame semantic structures using the PropBank data. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>According to the Conceptual Metaphor theory <ref type="bibr">(Lakoff and Johnson, 1980)</ref>, metaphoricity is a property of concepts in a particular context of use, not of specific words. The notion of a concept is a fluid one, however. While write and wrote would likely constitute instances of the same concept according to any definition, it is less clear whether eat and gobble would. Furthermore, the Conceptual Metaphor theory typically operates with whole semantic domains that certainly generalize beyond narrowly-conceived concepts; thus, save and waste share a very general semantic feature of applying to finite resources -it is this meaning element that accounts for the observation that they tend to be used metaphorically in similar contexts.</p><p>In this paper, we investigate which kinds of generalizations are the most effective for capturing regularities of metaphor usage.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Related Work</head><p>Most previous supervised approaches to verb metaphor classification evaluated their systems on selected examples or in small-scale experiments <ref type="bibr">(Tsvetkov et al., 2014;</ref><ref type="bibr">Heintz et al., 2013;</ref><ref type="bibr">Turney et al., 2011;</ref><ref type="bibr">Birke and Sarkar, 2007;</ref><ref type="bibr">Gedigan et al., 2006)</ref>, rather than using naturally occurring continuous text, as done here. Beigman <ref type="bibr" target="#b626">Klebanov et al. (2014) and</ref><ref type="bibr">Beigman Klebanov et al. (2015)</ref> are the exceptions, used as a baseline in the current paper.</p><p>Features that have been used so far in supervised metaphor classification address concreteness and abstractness, topic models, orthographic unigrams, sensorial features, semantic classifications using WordNet, among others <ref type="bibr">(Beigman Klebanov et al., 2015;</ref><ref type="bibr">Tekiroglu et al., 2015;</ref><ref type="bibr">Tsvetkov et al., 2014;</ref><ref type="bibr">Dunn, 2014;</ref><ref type="bibr">Heintz et al., 2013;</ref><ref type="bibr">Turney et al., 2011)</ref>. Of the feature sets presented in this paper, all but WordNet features are novel.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Semantic Classifications</head><p>In the following subsections, we describe the different types of semantic classifications;  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Grammar-based</head><p>The most minimal level of semantic generalization is that of putting together verbs that share the same lemma (lemma unigrams, UL). We use NLTK <ref type="bibr">(Bird et al., 2009)</ref> for identifying verb lemmas. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Corpus-based</head><p>We also experimented with automaticallygenerated verb clusters as semantic classes. We clustered VerbNet verbs using a spectral clustering algorithm and lexico-syntactic features. We selected the verbs that occur more than 150 times in the British National Corpus, 1,610 in total, and clustered them into 150 clusters (Corpus).</p><p>We used verb subcategorization frames (SCF) and the verb's nominal arguments as features for clustering, as they have proved successful in previous verb classification experiments <ref type="bibr">(Shutova et al., 2010)</ref>. We extracted our features from the Gigaword corpus <ref type="bibr" target="#b62">(Graff et al., 2003)</ref> using the SCF classification system of <ref type="bibr">Preiss et al. (2007)</ref> to identify verb SCFs and the RASP parser <ref type="bibr">(Briscoe et al., 2006)</ref> to extract the verb's nominal arguments.</p><p>Spectral clustering partitions the data relying on a similarity matrix that records similarities between all pairs of data points. We use JensenShannon divergence (d JS ) to measure similarity between feature vectors for two verbs, v i and v j , and construct a similarity matrix S ij :</p><formula xml:id="formula_35">S ij = exp(−d JS (v i , v j ))<label>(1)</label></formula><p>The matrix S encodes a similarity graph G over our verbs. The clustering problem can then be defined as identifying the optimal partition, or cut, of the graph into clusters. We use the multiway normalized cut (MNCut) algorithm of <ref type="bibr">Meila and Shi (2001)</ref> for this purpose. The algorithm transforms S into a stochastic matrix P containing transition probabilities between the vertices in the graph as P = D −1 S, where the degree matrix D is a diagonal matrix with D ii = N j=1 S ij . It then computes the K leading eigenvectors of P , where K is the desired number of clusters. The graph is partitioned by finding approximately equal elements in the eigenvectors using a simpler clustering algorithm, such as k-means. Meila and <ref type="bibr">Shi (2001)</ref> have shown that the partition I derived in this way minimizes the MNCut criterion:</p><formula xml:id="formula_36">MNCut(I) = K k=1 [1 − P (I k → I k |I k )],<label>(2)</label></formula><p>which is the sum of transition probabilities across different clusters. Since k-means starts from a random cluster assignment, we ran the algorithm multiple times and used the partition that minimizes the cluster distortion, that is, distances to cluster centroid. We tried expanding the coverage of VerbNet verbs and the number of clusters using grid search on the training data, with coverage grid ={2,500; 3,000; 4,000} and #clusters grid = {200; 250; 300; 350; 400}, but obtained no improvement in performance over our original setting.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Experiment setup</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Data</head><p>We use the VU Amsterdam Metaphor Corpus <ref type="bibr">(Steen et al., 2010)</ref>. <ref type="bibr">1</ref> The corpus contains annotations of all tokens in running text as metaphor or non metaphor, according to a protocol similar to MIP <ref type="bibr">(Pragglejaz, 2007)</ref>. The data come from the BNC, across 4 genres: news (N), academic writing (A), fiction <ref type="bibr">(F)</ref>, and conversation (C). We address each genre separately. We consider all verbs apart from have, be, and do.</p><p>We use the same training and testing partitions as Beigman <ref type="bibr">Klebanov et al. (2015)</ref>.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Machine Learning Methods</head><p>Our setting is that of supervised machine learning for binary classification. We experimented with a number of classifiers using VU-News training data, including those used in relevant prior work: Logistic Regression <ref type="bibr">(Beigman Klebanov et al., 2015</ref><ref type="bibr">), Random Forest (Tsvetkov et al., 2014</ref>, Linear Support Vector Classifier. We found that Logistic Regression was better for unigram features, Random Forest was better for features using WordNet and VerbNet classifications, whereas the corpus-based features yielded similar performance across classifiers. We therefore ran all evaluations with both Logistic Regression and Random Forest classifiers. We use the skll and scikit-learn toolkits <ref type="bibr" target="#b616">(Blanchard et al., 2013;</ref>. During training, each class is weighted in inverse proportion to its frequency. The optimization function is F1 (metaphor).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Results</head><p>We first consider the performance of each type of semantic classification separately as well as various combinations using cross-validation on the training set. <ref type="table" target="#tab_6">Table 3</ref> shows the results with the classifier that yields the best performance for the given feature set.  <ref type="table" target="#tab_6">Table 3</ref>: Performance (F1) of each of the feature sets, xval on training data. U = unigram baseline.</p><p>Of all types of semantic classification, only the grammatical one (lemma unigrams, UL) shows an overall improvement over the unigram baseline with no detriment for any of the genres.VNRaw and WordNet show improved performance for Academic but lower performance on Fiction than the unigram baseline. Other versions of VerbNet-based semantic classifications are generally worse than VN-Raw, with some exceptions for the Conversation genre. Distributional clusters (Corpus) generally perform worse than the resource-based classifications, even when the resource is restricted to the exact same set of verbs as that covered in the Corpus clusters (compare Corpus to VN-RawToCorpus).</p><p>The distributional features are, however, about as effective as WordNet features when combined with the lemma unigrams (UL); the combinations improve the performance over UL alone for every genre. We also note that the better performance for these combinations is generally attained by the Logistic Regression classifier. We experimented with additional combinations of feature sets, but observed no further improvements.</p><p>To assess the consistency of metaphoricity behavior of semantic classes across genres, we calculated correlations between the weights assigned by the UL+WN model to the 15 WordNet features. All pairwise correlations between News, Academic, and Fiction were strong (r &gt; 0.7), while Conversation had low to negative correlation with other genres. The low correlations with Conversation was largely due to a highly discrepant behavior of verbs of weather 3 -these are consistently used metaphorically in all genres apart from Conversation. This discrepancy, however, is not so much due to genre-specific differences in behavior of the same verbs as to the difference in the identity of the weather verbs that occur in the data from the different genres. While burn, pour, reflect, fall are common in the other genres, the most common weather verb in Conversation is rain, and none of its occurrences is metaphoric; its single occurrence in the other genres is likewise not metaphoric. More than a difference across genres, this case underscores the complementarity of lemma-based and semantic class-based information -it is possible for weather verbs to tend towards metaphoricity as a class, yet some verbs might not share the tendency -verb-specific information can help correct the class-based pattern.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Blind Test Benchmark</head><p>To compare the results against state-of-art, we show the performance of Beigman <ref type="bibr">Klebanov et al. (2015)</ref> system (SOA'15) on the test data (see <ref type="table" target="#tab_5">Table 2</ref> for the sizes of the test sets per genre). Their system uses Logistic Regression classifier and a set of features that includes orthographic unigrams, part of speech tags, concreteness, and difference in concreteness between the verb and its direct object. Against this benchmark, we evaluate the performance of the best combination identified during the cross-validation runs, namely, UL+WN feature set using Logistic Regression classifier. We also show the performance of the resource-lean model, UL+Corpus. The top three rows of <ref type="table" target="#tab_42">Table 4</ref> show the results. The UL+WN model outperforms the state of art for every genre; the improvement is statistically significant ( p&lt;0.05). <ref type="bibr">4</ref> The improvement of UL+Corpus over SOA'15 is not significant.</p><p>Following the observation of the similarity between weights of semantic class features across genres, we also trained the three systems on all the available training data across all genres (all data in the Train column in <ref type="table" target="#tab_5">Table 2)</ref>, and tested on test data for the specific genre. This resulted in performance improvements for all systems in all genres, including Conversation (see the bottom 3 rows in <ref type="table" target="#tab_42">Table 4</ref>).  <ref type="table" target="#tab_42">Table 4</ref>: Benchmark performance, F1 score.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Conclusion</head><p>The goal of this paper was to investigate the effectiveness of semantic generalizations/classifications for metaphoricity classification of verbs. We found that generalization from orthographic unigrams to lemmas is effective. Further, lemma unigrams and semantic class features based on WordNet combine effectively, producing a significant improvement over the state of the art. We observed that semantic class features were weighted largely consistently across genres; adding training data from other genres is helpful. Finally, we found that a resource-lean model where lemma unigram features were combined with clusters generated automatically using a large corpus yielded a competitive performance. This latter result is encouraging, as the knowledge-lean system is relatively easy to adapt to a new domain or language. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Abstract</head><p>Over the past decade, e-Commerce has rapidly grown enabling customers to purchase products with the click of a button. But to be able to do so, one has to understand the semantics of a user query and identify that in digital lifestyle tv, digital lifestyle is a brand and tv is a product.</p><p>In this paper, we develop a series of structured prediction algorithms for semantic tagging of shopping queries with the product, brand, model and product family types. We model wide variety of features and show an alternative way to capture knowledge base information using embeddings. We conduct an extensive study over 37, 000 manually annotated queries and report performance of 90.92 F 1 independent of the query length.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Recent study shows that yearly e-Commerce sales in the U.S. top 100 Billion <ref type="bibr">(Fulgoni, 2014)</ref>. This leads to substantially increased interest in building semantic taggers that can accurately recognize product, brand, model and product family types in shopping queries to better understand and match the needs of online shoppers. Despite the necessity for semantic understanding, yet most widely used approaches for product retrieval categorize the query and the offer <ref type="bibr">(Kozareva, 2015)</ref> into a shopping taxonomy and use the predicted category as a proxy for retrieving the relevant products. Unfortunately, such procedure falls short and leads to inaccurate product retrieval. Recent efforts <ref type="bibr">(Manshadi and Li, 2009;</ref><ref type="bibr">Li, 2010)</ref> focused on building CRF taggers that recognize basic entity types in shopping query such as brands, types and models. <ref type="bibr">(Li, 2010)</ref> conducted a study over 4000 shopping queries and showed promising results when huge knowledge bases are present. <ref type="bibr">(Paşca and Van Durme, 2008;</ref><ref type="bibr">Kozareva et al., 2008;</ref><ref type="bibr">Kozareva and Hovy, 2010)</ref> focused on using Hearst patterns <ref type="bibr">(Hearst, 1992)</ref> to learn semantic lexicons. While such methods are promising, they cannot be used to recognize all product entities in a query. In parallel to the semantic query understanding task, there have been semantic tagging efforts on the product offer side. (Putthividhya and Hu, 2011) recognize brand, size and color entities in eBay product offers, while <ref type="bibr">(Kannan et al., 2011)</ref> recognized similar fields in Bing product catalogs.</p><p>Despite these efforts, to date there are three important questions, which have not been answered, but we address in our work. (1) What is an alternative method when product knowledge bases are not present? (2) Is the performance of the semantic taggers agnostic to the query length? (3) Can we minimize manual feature engineering for shopping query log tagging using neural networks?</p><p>The main contributions of the paper are:</p><p>• Building semantic tagging framework for shopping queries.</p><p>• Leveraging missing knowledge base entries through word embeddings learned on large amount of unlabeled query logs.</p><p>• Annotating 37, 000 shopping queries with product, brand, model and product family entity types.</p><p>• Conducting a comparative and efficiency study of multiple structured prediction algorithms and settings.</p><p>• Showing that long short-term memory networks reaches the best performance of 90.92 F 1 and is agnostic to query length.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Problem Formulation and Modeling</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Task Definition</head><p>We define our task as given a shopping query identify and classify all segments that are product, brand, product family and model, where: -Product is generic term(s) for goods not specific to a particular manufacturer (e.g. shirts).</p><p>-Brand is the actual name of the product manufacturer (e.g. Calvin Klein).</p><p>-Product Family is a brand-specific grouping of products sharing the same product (e.g. Samsung Galaxy).</p><p>-Model is used by manufacturer to distinguish variations (e.g. for the brand Lexus has IS product family, which has model 200t and 300 F Sport).</p><p>For modeling, we denote with T = {⊥, t 1 , t 2 , . . . , t K } the whole label space, where ⊥ indicates a word that is not a part of an entity and t i stands for an entity category. The tagging models have to recognize the following types product, brand, model, product family and ⊥ (other) using the BIO schema <ref type="bibr">(Tjong Kim Sang, 2002)</ref>.</p><p>We denote as x = (x 1 , x 2 , . . . , x M ) a shopping query of length M . The objective is to find the best configurationŷ such that:</p><formula xml:id="formula_37">y = arg max y p(y|x),</formula><p>where y=(y 1 , y 2 , ..., y N ) (N ≤ M ) are the shopping query segments labeled with their corresponding entity category. Each segment y i corresponds to a triple b i , e i , t i indicating the start index b i and end index e i of the sequence followed by the entity category t i ∈ T . When t i = ⊥, the segment contains only one word.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Structured Prediction Models</head><p>To tackle the shopping tagging problem of query logs, we use Conditional Random Fields , CRF) 1 , learning to search <ref type="bibr">(Daumé III et al., 2009, SEARN)</ref> 2 , structured perceptron <ref type="bibr">(Collins, 2002, STRUCTPERCEPTRON)</ref> and a long short-term memory networks extended by CRF layer <ref type="bibr">(Hochreiter and Schmidhuber, 1997;</ref><ref type="bibr">Graves, 2012, LSTM-CRF)</ref>. CRF: is a popular algorithms for sequence tagging tasks ). The objective is 1 taku910.github.io/crfpp/ 2 github.com/JohnLangford/vowpal_wabbit to find the label sequence y = (y 1 , ..., y M ) that maximizes</p><formula xml:id="formula_38">p(y|x) = 1 Z λ (x) exp{λ · f (y, x)},</formula><p>where Z λ (x) is the normalization factor, λ is the weight vector and f (y, x) is the extracted feature vector for the observed sequence x. SEARN is a powerful structured prediction algorithm, which formulates the sequence labeling problem as a search process. The objective is to find the label sequence y = (y 1 , ..., y M ) that maximizes</p><formula xml:id="formula_39">p(y|x) ∝ M m=1 I [C(x,y 1 ,...,y m−1 )=ŷm] ,</formula><p>where C(•) is a cost sensitive multiclass classifier andŷ are the ground-truth labels. STRUCTPERCEPTRON is an extension of the standard perceptron. In our setting we model a segment-based search algorithm, where each unit is a segment of x (e.g., b i , e i ), rather than a single word (e.g., x i ). The objective is to find the label sequence y = (y 1 , ..., y M ) that maximizes</p><formula xml:id="formula_40">p(y|x) ∝ w · f (x, y),</formula><p>where f (x, y) represents the feature vector for instance x along with the configuration y and w is updated as w ← w + f (x,ŷ) − f (x, y). LSTM-CRF The above algorithms heavily rely on manually-crafted features to perform sequence tagging. We decided to alleviate that by using long short-term memory networks with a CRF layer. Our model is similar to R-CRF <ref type="bibr">(Mesnil et al., 2015)</ref>, but for the hidden recurrent layer we use LSTM <ref type="bibr">(Hochreiter and Schmidhuber, 1997;</ref><ref type="bibr">Graves, 2012</ref>). We denote with h i the hidden vector produced by the LSTM cell at i-th token. Then the conditional probability of y given a query x becomes:</p><formula xml:id="formula_41">p(y|x) = 1 Z(h) exp{ i (W h y i h i + W t y i ,y i−1 )},</formula><p>where W h y i is the weight vector corresponding to label y i , and W t y i ,y i−1 is the transition score corresponding to y i and y i−1 . During training, the values of W h , W t , the LSTM layer and the input word embeddings are updated through the standard back-propagation with AdaGrad algorithm. We also concatenate pre-trained word embedding and randomly initialized embedding (50-d) for the knowledge-base types of each token and use this information in the input layer. In our experiments, we set the learning rate to 0.05 and take each query as a mini-batch and run 5 epochs to finish training.  <ref type="table" target="#tab_10">Table 1</ref>: Results from feature study.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Features</head><p>Lexical (LEX): are widely used N -gram features. We use unigrams of the current w 0 , previous w −1 and next w +1 words, and bigrams w −1 w 0 and w 0 w +1 . Orthographic (ORTO): are binary mutually nonexclusive features that check if w 0 , w −1 and w +1 contain all-digits, any-digit, start-with-digit-endin-letter and start-with-letter-end-in-digit. They are designed to capture model names like hero3 and m560. Positional (PSTNL): are discrete features modeling the position of the words in the query. They capture the way people tend to write products and brands in the query. Part-of-Speech (POS): capture nouns and proper names to better recognize products and brands. We use Stanford tagger <ref type="bibr">(Toutanova et al., 2003)</ref>. Knowledgebase (KB): are powerful semantic features <ref type="bibr">(Tjong Kim Sang, 2002;</ref><ref type="bibr" target="#b6">Carreras et al., 2002;</ref><ref type="bibr">Passos et al., 2014)</ref>. We automatically collected and manually validated 200K brands, products, models and product families items extracted from Macy's and Amazon websites. WordEmbeddings (WE): While external knowledge bases are great resource, they are expensive to create and time-consuming to maintain. We use word embeddings   <ref type="bibr" target="#b471">3</ref> as a cheap low-maintenance alternative for knowledge base construction. We train the embeddings over 2.5M unlabeled shopping queries. For each token in the query, we use as features the 200 dimensional embeddings of the top 5 most similar terms returned by cosine similarity.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Experiments and Results</head><p>Data Set To the best of our knowledge, there is no publicly available shopping query data annotated with product, brand, model, product family and other categories. To conduct our experiments, we collect 2.5M shopping queries through click 3 https://code.google.com/p/word2vec/ logs <ref type="bibr" target="#b63">(Hua et al., 2013)</ref>. We randomly sampled 37, 000 unique queries from the head, torso and tail of a commercial web search engine and asked two independent annotators to tag the data. We measured the Kappa agreement of the editors and found .92 agreement, which is sufficient to warrant the goodness of the annotations.</p><p>We randomly split the data into 80% for training and 20% for testing.  We tune all parameters on the training set using 5-fold cross validation and report performance on the test set. All results are calculated with the CONLL evaluation script 4 .</p><p>Performance w.r.t. Features <ref type="table" target="#tab_10">Table 1</ref> shows the performance of the different models and feature combinations. We use the individual features as a baseline. The obtained results show that these are insufficient to solve such a complex task. We compared the performance of the KB and WE features when combined with (LEX+ORTO+PSTNL) information. As we can see, both KB and WE reach comparable performance. This study shows that training embeddings on large in-domain data of shopping queries is a reliable and cheap source for knowledge base construction, when such information is not present. In our study the best performance is reached when all features are combined. Among all machine learning classifiers for which we manually designed features, structured perception reaches the best performance of 88.13 F 1 score. In addition to the feature combination and model comparison, we also study in <ref type="figure" target="#fig_3">Figure 1</ref> the training time of each model in log scale against its F 1 score. SEARN is the fastest algorithm to train,   Performance w.r.t. Entity Category <ref type="table" target="#tab_6">Table 3</ref> shows the performance of the algorithms with the manually designed features against the automatically induced ones with LSTM-CRF. We show the performance of each individual product entity category. Compared to all models and settings, LSTM-CRF reaches the best performance of 90.92 F 1 score. The most challenging entity types are product family and model, due to their "wild" and irregular nature.</p><formula xml:id="formula_42">Category CRF SEARN STRUCTPERCEPTRON LSTM-CRF P (%) R (%) F1 P (%) R (%) F1 P (%) R (%) F1 P (%) R (%) F1</formula><p>Performance w.r.t. Query Length Finally, we also study the performance of our approach with respect to the different query length. <ref type="figure" target="#fig_8">Figure 2</ref> shows the F 1 score of the two best performing algorithms LSTM-CRF and STRUCTPERCEPTRON against the different query length in the test set. Around 83% of the queries have length between 2 to 5 words, the rest are either very short or very long ones. As it can be seen in <ref type="figure" target="#fig_8">Figure 2</ref>, independent of the query length, our models reach the same performance for short and long queries. This shows that the models are robust and agnostic to the query length. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Conclusions and Future Work</head><p>In this work, we have defined the task of product entity recognition in shopping queries. We have studied the performance of multiple structured prediction algorithms to automatically recognize product, brand, model and product family entities. Our comprehensive experimental study and analysis showed that combining lexical, positional, orthographic, POS, knowledge base and word embedding features leads to the best performance. We showed that word embeddings trained on large amount of unlabeled queries could substitute knowledge bases when they are missing for specialized domains. Among all manually designed feature classifiers STRUCTPERCEPTRON reached the best performance. While among all algorithms LSTM-CRF achieved the highest performance of 90.92 F1 score. Our analysis showed that our models reach robust performance independent of the query length. In the future we plan to tackle attribute identification to better understand queries like "diamond shape emerald ring", where diamond shape is a cut and emerald is a gemstone type. Such fine-grained information could further enrich online shopping experience. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Abstract</head><p>Recent work in learning vector-space embeddings for multi-relational data has focused on combining relational information derived from knowledge bases with distributional information derived from large text corpora. We propose a simple approach that leverages the descriptions of entities or phrases available in lexical resources, in conjunction with distributional semantics, in order to derive a better initialization for training relational models. Applying this initialization to the TransE model results in significant new stateof-the-art performances on the WordNet dataset, decreasing the mean rank from the previous best of 212 to 51. It also results in faster convergence of the entity representations. We find that there is a tradeoff between improving the mean rank and the hits@10 with this approach. This illustrates that much remains to be understood regarding performance improvements in relational models.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>A surprising result of work on vector-space word embeddings is that word representations that are learned from a large training corpus display semantic regularities in the form of linear vector translations. For example,  show that using their induced word vector representations, king − man + woman ≈ queen. Such a structure is appealing because it provides an interpretation to the distributional vector space through lexical-semantic analogical inferences.</p><p>Concurrent to that work, <ref type="bibr" target="#b446">Bordes et al. (2013)</ref>  A natural next step is to attempt to integrate the two approaches in order to develop a representation that is informed by both unstructured text and a structured knowledge base <ref type="bibr" target="#b691">Xu et al., 2014;</ref><ref type="bibr">Fried and Duh, 2015;</ref><ref type="bibr" target="#b402">Yang et al., 2015)</ref>. However, existing work makes a crucial assumption-that reliable distributional vectors are available for all of the entities in the hierarchy being modeled. Unfortunately, this assumption does not hold in practice; when moving to a new domain with a new knowledge base, for example, there will likely be many entities or phrases for which there is no distributional information in the training corpus. This important problem is illustrated in <ref type="table" target="#tab_10">Table 1</ref>, where most of the entities from WordNet and Freebase are seen to be missing from the distributional vectors derived using Word2Vec and GloVe trained on the Google News corpus. Even when the entities are found, they may not have occurred enough times in the training corpus for their vector representation to be reliable. What is needed is a method to derive entity representations that works well for both common and rare entities.</p><p>Fortunately, knowledge bases typically contain a short description or definition for each of the entities or phrases they contain. For example, in a medical dataset with many technical words, the Wikipedia pages, dictionary definitions, or medical descriptions via a site such as medilexicon.com could be leveraged as lexical resources. Similarly, when building language models for social media, resources such as urbandicionary.com could be used for information about slang words. For the WordNet and Freebase datasets, we use entity descriptions which are readily available (see <ref type="table" target="#tab_5">Table 2</ref>).</p><p>In this paper, we propose a simple and efficient procedure to convert these short descriptions into a vector space representation, with the help of existing word embedding models. These vectors are then used as the input to further training with the TransE model, in order to incorporate structural information. Our method provides a better initialization for the TransE model, not just for the entities that do not appear in the data, but in fact for all entities. This is demonstrated by achieving stateof-the-art mean rank on an entity ranking task on two very different data sets: WordNet synsets with lexical semantic relations <ref type="bibr" target="#b249">(Miller, 1995)</ref>, and Freebase named entities with general semantic relations <ref type="bibr">(Bollacker et al., 2008)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Related Work</head><p>Dictionary definitions were the core component of early methods in word sense disambiguation (WSD), such as the Lesk algorithm (1986).  build on the use of synset glosses for WSD by leveraging lexical resources. Our work goes further to tie these glosses together with relational semantics, a connection that has not been drawn in the literature before. The integration of lexical resources into distributional semantics has been studied in other lexical semantic tasks,   <ref type="bibr">Kambhatla, 2004)</ref>, and calculating the semantic distance between concepts <ref type="bibr">(Mohammad, 2008;</ref><ref type="bibr">Marton et al., 2009)</ref>. We aim to combine lexical resources and other semantic knowledge, but we do so in the context of neural network-based word embeddings, rather than in specific lexical semantic tasks. <ref type="bibr">Bordes et al. (2011)</ref> propose the Structured Embeddings (SE) model, which embeds entities into vectors and relations into matrices. The relation connection between two entities is modeled by the projection of their embeddings into a different vector space. <ref type="bibr">Rothe and Schütze (2015)</ref> use Wordnet as a lexical resource to learn embeddings for synsets and lexemes. Perhaps most related to our work are previous relational models that initialize their embeddings via distributional semantics calculated from a larger corpus.  propose the Neural Tensor Network (NTN), and <ref type="bibr" target="#b402">Yang et al. (2015)</ref> the Bilinear model using this technique. Other approaches modify the objective function or change the structure of the model in order to integrate distributional and relational information <ref type="bibr">Fried and Duh, 2015;</ref><ref type="bibr" target="#b466">Toutanova and Chen, 2015)</ref>.  retrofit word vectors after they are trained according to distributional criteria. We propose a method that does not necessitate post-processing of the embeddings, and can be applied orthogonally to the previously mentioned improvements.</p><p>3 Architecture of the Approach</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">The TransE Model</head><p>The Translating Embedding (TransE) model <ref type="bibr" target="#b446">(Bordes et al., 2013)</ref> has become one of the most popu-lar multi-relational models due to its relative simplicity, scalability to large datasets, and (until recently) state-of-the-art results. It assumes a simple additive interaction between vector representations of entities and relations. More precisely, assume a given relationship triplet (h, l, t) is valid; then, the embedding of the object t should be very close to the embedding of the subject h plus some vector in R k that depends on the relation l 3 .</p><p>For each positive triplet (h, l, t) ∈ S, a negative triplet (h , l, t ) ∈ S is constructed by randomly sampling an entity from E to replace either the subject h or the object t of the relationship. The training objective of TransE is to minimize the dissimilarity measure d(h + l, t) of a positive triplet while ensuring that d(h + l, t ) for the corrupted triplet remains large. This is accomplished by minimizing the hinge loss over the training set:</p><formula xml:id="formula_43">L = (h,l,t)∈S (h ,l,t )∈S [γ+d(h+l, t)−d(h +l, t )] +</formula><p>where γ is the hinge loss margin and [x] + represents the positive portion of x. There is an additional constraint that the L 2 -norm of entity embeddings (but not relation embeddings) must be 1, which prevents the training process to trivially minimize L by artificially increasing the norms of entity embeddings.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Initializing Representations with Entity Descriptions</head><p>We propose to leverage some external lexical resource to improve the quality of the entity vector representations. In general, this could consist of product descriptions in a product database, or information from a web resource. For the WordNet and Freebase datasets, we use entity descriptions which are readily available. Although there are many ways to incorporate this, we propose a simple method whereby the entity descriptions are used to initialize the entity representations of the model, which we show to have empirical benefits. In particular, we first decompose the description of a given entity into a sequence of word vectors, and combine them into a single embedding by averaging. We then reduce the dimensionality using principle component analysis (PCA), which we found experimentally to reduce overfitting. We obtain these word vectors using distributed representations computed using word2vec  and GloVe . Approximating compositionality by averaging vector representations is simple, yet has some theoretical justification <ref type="bibr">(Tian et al., 2015)</ref> and can work well in practice <ref type="bibr" target="#b125">(Wieting et al., 2015)</ref>.</p><p>Additional decisions need to be made concerning which parts of the entity description to include. In particular, if an entity description or word definition is longer than several sentences, using the entire description could cause a 'dilution' of the desired embedding, as not all sentences will be equally pertinent. We solve this by only considering the first sentence of any entity description, which is often the most relevant one. This is necessary for Freebase, where the description length can be several paragraphs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Experiments</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Training and Testing Setup</head><p>We perform experiments on the WordNet (WN) <ref type="bibr" target="#b249">(Miller, 1995)</ref> and Freebase (FB15k) <ref type="bibr">(Bollacker et al., 2008)</ref> datasets used by the original TransE model. TransE hyperparameters include the learning rate λ for stochastic gradient descent, the margin γ for the hinge loss, the dimension of the embeddings k, and the dissimilarity metric d. For the TransE model with random initialization, we use the optimal hyperparameters from <ref type="bibr" target="#b446">(Bordes et al., 2013)</ref>: for WN, λ = 0.01, γ = 2, k = 20, and d = L 1 -norm; for FB15k, λ = 0.01, γ = 0.5, k = 50, and d = L 2 -norm. The values of k were further tested to ensure that k = 20 and k = 50 were optimal. For the TransE model with strategic initialization, we used different embedding dimensions. The distributional vectors used in the entity descriptions are of dimension 1000 for the word2vec vectors with Freebase vocabulary, and dimension 300 in all other cases. Dimensionality reduction with PCA was then applied to reduce this to k = 30 for WN, and k = 55 for FB15k, which were empirically found to be optimal. PCA was necessary in this case as pre-trained vectors from word2vec and GloVe are not available for all dimension values.</p><p>We use the same train/test/validation split and evaluation procedure as <ref type="bibr" target="#b446">(Bordes et al., 2013)</ref>: for each test triplet (h, l, t), we remove entity h and t in turn, and rank each entity in the dictionary   by similarity according to the model. We evaluate using the original and most common metrics for relational models: i) the mean of the predicted ranks, and ii) hits@10, which represents the percentage of correct entities found in the top 10 list; however, other metrics are possible, such as mean reciprocal rank (MRR). We evaluate in both the filtered setting, where other correct responses are removed from the lists ranked by the model, and the raw setting, where no changes are made. We compare against the TransE model with random initialization, and the SE model <ref type="bibr">(Bordes et al., 2011)</ref>. We also compare against the state-ofthe-art TransD model <ref type="bibr">(Ji et al., 2015)</ref>. This model uses two vectors to represent each entity and relation; one to represent the meaning of the entity, and one to construct a mapping matrix dynamically. This allows for the representation of more diverse entities. <ref type="table" target="#tab_6">Table 3</ref> summarizes the experimental results, compared to baseline and state-of-the-art relational models. We see that the mean rank is greatly improved for the TransE model with strategic initialization over random initialization. More surprisingly, all of our models achieve state-of-the-art performance for both raw and filtered data, compared to the recently developed TransD model. These results are highly significant with p &lt; 10 −3 according to the Mann-Whitney U test. Thus, even though our method is simple and straightforward to apply, it can still beat all attempts at more complicated structural modifications to the TransE model on this dataset. Further, the fact that our optimal embedding dimensions are larger (30 and 55 vs. 20 and 50) suggests that our initialization approach helps avoid overfitting.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Results and Analysis</head><p>For Freebase, our models slightly outperform the TransE model with random initialization, with p-values of 0.173 and 0.410 for initialization with descriptions (including stopwords) using GloVe and word2vec, respectively. We also see improvements over the case of direct initialization with word2vec. Further, we set a new state-of-the-art for mean rank on the raw data, though the improvement is marginal.  Finally, we see in <ref type="figure" target="#fig_3">Figure 1</ref> that the TransE model converges more quickly during training when initialized with our approach, compared to random initialization. This is particularly true on WordNet.</p><p>Mean rank and hits@10 discrepancy It is interesting to note the relationship between the mean rank and hits@10. By changing our model, we are able to increase one at the expense of the other. For example, using word2vec without stopwords gives similar hits@10 to TransD with better mean rank, while using GloVe further improves the mean rank at a cost to hits@10. The exact nature of this tradeoff isn't clear, and is an interesting avenue for future work.</p><p>However, there are potential reasons for the results discrepancy betweeen mean rank and hits@10. We conjecture that our model helps avoid 'disasters' where some correct entities are ranked very low. For TransE with random initialization, these disasters cause a large decrease in mean rank, which is significantly improved by our model. On the other hand, reducing the number of correct entities that are poorly ranked may not significantly affect the hits@10, since this only considers entities near the top of the ranking.</p><p>Note also that using hits@10 to evaluate relational models is not ideal; a model can rank reasonable alternative entities highly, but be penalized because the target entity is not in the top 10. For example, given "rabbit IS-A", both "animal" and "mammal" fit as target entities. This is alleviated by filtering, but is not completely eliminated due to the sparsity of relations in the dataset (which is the reason we require the link prediction task). Thus, we believe the mean rank is a more accurate measure of the performance of a model, particularly on raw data.</p><p>Dataset differences It is also interesting to note the discrepancy between the results on the WordNet and Freebase datasets. Although using the entity descriptions leads to a significantly lower mean rank for the WordNet dataset, it only results in a faster convergence rate for Freebase. However, the relations presented in these two datasets are significantly different: WordNet relations are quite general and are meant to provide links between concepts, while the Freebase relations are very specific, and denote relationships between named entities. This is shown in <ref type="table" target="#tab_42">Table 4</ref>. It seems that incorporating the definition of these named entities does not improve the ability of the algorithm to answer very specific relation questions. This would be the case if the optimization landscape for the TransE model had fewer local minima for Freebase than for WordNet, thus rendering it less sensitive to the initial condition. It is also possible that the TransE model is simply not powerful enough to achieve a filtered mean rank lower than 90, no matter the initialization strategy.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Conclusion and Future Work</head><p>We have shown that leveraging external lexical resources, along with distributional semantics, can lead to both a significantly improved optimum and a faster rate of convergence when applied with the TransE model for relational data. We established new state-of-the-art results on WordNet, and obtain small improvements to the state-of-the-art on raw relational data for Freebase. Our method is quite simple and could be applied in a straightforward manner to other models that take entity vector representations as input. Further research is needed to investigate whether performance on other NLP tasks can be improved by leveraging available lexical resources in a similar manner.</p><p>More complex methods initialization methods could easily be devised, e.g. by using inverse document frequency (idf) weighted averaging, or by applying the work of  on paragraph vectors. Alternatively, distributional semantics could be used as a regularizer, similar to <ref type="bibr">(Labutov and Lipson, 2013)</ref>, with learned embeddings being penalized for how far they stray from the pre-trained GloVe embeddings. However, even with intuitive and straightforward methodology, leveraging lexical resources can have a significant impact on the results of models for multi-relational data. <ref type="bibr">Daniel Fried and Kevin Duh. 2015</ref> </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Semantic role labeling (SRL) aims to identify predicate-argument structures of a sentence. The following example shows the arguments labeled with the roles A0 (typically the agent of an action) and A1 (typically the patient of an action), as well as the predicate in bold.</p><p>[Little Willy A0 ] broke [a window A1 ].</p><p>As manual annotations are expensive and timeconsuming, supervised approaches <ref type="bibr">(Gildea and Jurafsky, 2002;</ref><ref type="bibr">Xue and Palmer, 2004;</ref><ref type="bibr">Pradhan et al., 2005;</ref><ref type="bibr">Punyakanok et al., 2008;</ref><ref type="bibr">Das et al., 2010;</ref><ref type="bibr">Das et al., 2014)</ref> to this problem are held back by limited coverage of available gold annotations <ref type="bibr">(Palmer and Sporleder, 2010)</ref>. SRL performance decreases remarkably when applied to out-of-domain data <ref type="bibr">(Pradhan et al., 2008)</ref>.</p><p>Unsupervised SRL offer a promising alternative <ref type="bibr">(Lang and Lapata, 2011;</ref><ref type="bibr">Titov and Klementiev, 2012;</ref><ref type="bibr">Garg and Henderson, 2012;</ref><ref type="bibr">Lang and Lapata, 2014;</ref><ref type="bibr">Titov and Khoddam, 2015)</ref>. It is commonly formalized as a clustering problem, where each cluster represents an induced semantic role. Such clustering is usually performed through manually defined semantic and syntactic features defined over argument instances. However, the representation based on these features are usually sparse and difficult to generalize.</p><p>Inspired by the recent success of distributed word representations , we introduce two unsupervised models that learn embeddings of arguments, predicates, and syntactic dependency relations between them. The embeddings are learned by predicting each argument from its context, which includes the predicate and other arguments in the same sentence. Driven by the importance of syntactic dependency relations in SRL, we explicitly model dependencies as multiplicative factors in neural networks, yielding more succinct models than existing representation learning methods employing dependencies <ref type="bibr">Woodsend and Lapata, 2015)</ref>. The learned argument embeddings are then clustered and are evaluated by the clusters' agreement with ground truth labels.</p><p>On unsupervised SRL, our models outperform the state of the art by <ref type="bibr">Woodsend and Lapata (2015)</ref> on gold parses and Titov and Khoddam (2015) on automatic parses. Qualitative results suggest our model is effective in biasing argument embeddings toward a specific dependency relation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Related Work</head><p>There has been growing interest in using neural networks and representation learning for supervised and unsupervised SRL <ref type="bibr">Hermann et al., 2014;</ref><ref type="bibr">Zhou and Xu, 2015</ref>;   who use dependency relations in learning word embeddings. In comparison, our models separate the representation of dependency relations and arguments, thereby allow the same word in different relations to share weights in order to reduce model parameters and data sparsity.</p><formula xml:id="formula_44">u t-k (a) SYMDEP E t-k × u t+k … … u p v t E t+k × D t × u t-k (b) ASYMDEP E t-k × u t+k … … u p v t E t+k × D t × A</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Approach</head><p>Most unsupervised approaches to SRL perform the following two steps: (1) identifying the arguments of the predicate and (2) assigning arguments to unlabeled roles, such as argument clusters.</p><p>Step (1) can be usually tackled with heuristic rules <ref type="bibr">(Lang and Lapata, 2014)</ref>. In this paper, we focus on tackling step (2) by creating clusters of arguments that belongs to the same semantic role. As we assume PropBank-style roles <ref type="bibr">(Kingsbury and Palmer, 2002)</ref>, our models allocate a separate set of role clusters for each predicate and assign its arguments to the clusters. We evaluate the results by the overlapping between the induced clusters and PropBank-style gold labels.</p><p>The example below suggests that SRL requires more than just lexical embeddings.</p><p>[A car A1 ] is hit by [another car A0 ].</p><p>The A0 and A1 roles are very similar lexically, but their dependency relations to the predicate differ. To allow the same lexical embedding to shift according to different relations to the predicate, we propose the following models.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Models</head><p>Following the framework of CBOW <ref type="bibr" target="#b375">(Mikolov et al., 2013)</ref>, our models predict an argument by its context, which includes surrounding arguments and the predicate.</p><p>Let v t be the embedding of the t th argument in a sentence, and u t the embedding of the argument when it is part of the context. Let u p be the embedding of the predicate. u c = {u t−k , . . . , u t−1 , u t+1 , . . . , u t+k } are the vectors surrounding the t th argument with a window of size k. 1 The prediction of the t th argument is:</p><formula xml:id="formula_45">p(v t |u p , u c ) ∝ exp(f(v t ) g(u p , u c ))<label>(1)</label></formula><p>where f(·) and g(·) are two transformation functions of the target argument embedding and context vectors respectively. We further associate a dependency relation with each argument (explained in more details in §4.1). Let matrix D t encode the biasing effect of the dependency relation between the t th argument and its predicate, and E t be the corresponding dependency matrix for the t th argument if it is used as a context. We define a ⊗ operator:</p><formula xml:id="formula_46">v t ⊗ D t tanh (D t v t ) u t ⊗ E t tanh (E t u t ) ,<label>(2)</label></formula><p>where tanh(·) is the element-wise tanh function. Eq. 2 composes an argument and its dependency with a multiplicative nonlinear operation. The multiplicative formulation encourages the decoupling of dependencies and arguments, which is useful in learning representations tightly focused on lexical and relational semantics, respectively. Symmetric-Dependency. In our first model, we apply the dependency multiplication to all arguments. We have</p><formula xml:id="formula_47">f 1 (v t ) = v t ⊗ D t (3) g 1 (u p , u c ) = u p ⊗ E p + u i ∈u c u i ⊗ E i (4)</formula><p>This model is named Symmetric-Dependency (SYMDEP) for the symmetric use of ⊗. Since the predicate does not have an dependency with itself, we let E p = I. Generally, ∀i, E i = I. Asymmetric-Dependency. An alternative model is to concentrate the dependency relations' effects by shifting the dependency of the predicted argument from f (·) to g(·), thereby move all ⊗ operations to construct context vector:</p><formula xml:id="formula_48">g 2 (u p , u c ) = (u p ⊗E p + u i ∈u c u i ⊗E i )⊗D t (5) f 2 (v t ) = v t<label>(6)</label></formula><p>This model is named Asymmetric-Dependency or ASYMDEP. <ref type="figure" target="#fig_3">Figure 1</ref> shows the two models side by side. Note that Eq. 5 actually defines a feedforward neural network structure g 2 (u p , u c ) for predicting arguments. Consider the prediction function defined in Eq. 1, these two models will be equivalent if we eliminate all nonlinearities introduced by tanh(·).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Clustering Arguments</head><p>In the final step of semantic role induction, we perform agglomerative clustering on the learned embeddings of arguments. We first create a number of seed clusters based on syntactic positions <ref type="bibr">(Lang and Lapata, 2014)</ref>, which are hierarchically merged. Similar to Lang and Lapata (2011), we define the similarity between clusters as the cosine similarity (CosSim) between the centroids with a penalty for clustering two arguments from the same sentence into the same role. Consider two clusters C and C with the centroids x and y respectively, their similarity is:</p><formula xml:id="formula_49">S(C, C ) = CosSim(x, y) − α · pen(C, C ) (7)</formula><p>where α is heuristically set to 1.</p><p>To compute the penalty, let V (C, C ) be the set of arguments a i ∈ C such that a i appears in the same sentence with another argument a j ∈ C . We have</p><formula xml:id="formula_50">pen(C, C ) = |V (C, C )| + |V (C , C)| |C| + |C |<label>(8)</label></formula><p>where | · | is set cardinality. When this penalty is large, the clusters C and C will appear dissimilar, so it becomes difficult to merge them into the same cluster, preventing a i and a j from appearing in the same cluster.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Experiments</head><p>We evaluate our models in unsupervised SRL and compare the effectiveness our approach in modeling dependency relations with the previous work.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Setup</head><p>Our models are trained on 24 million tokens and 1 million sentences from the North American News Text corpus <ref type="bibr">(Graff, 1995)</ref>. We use MATE <ref type="bibr">(Björkelund et al., 2009</ref>) to parse the dependency tree and identify predicates and arguments. Embeddings of head words are the only feature we use in clustering. Dependency matrices are restricted to contain only diagonal terms. The vocabulary sizes for arguments and predicates are 10K and 5K respectively. We hand-picked the dimension of embeddings to be 50 for all models. We take the first dependency relation on the path from an argument's head word to the predicate as its dependency label, considering the dependency's direction. For example, the label for the first car in <ref type="figure" target="#fig_3">Figure 1</ref>(c) is SBJ −1 . We use negative sampling  to approximate softmax in the objective function. For SYMDEP, we sample both the predicted argument and dependency. For ASYMDEP, we sample only the argument. Models are trained using AdaGrad <ref type="bibr" target="#b269">(Duchi et al., 2011)</ref> with L2 regularization. All embeddings are randomly initialized. 2 Baselines. We compare against several baselines using representation learning: CBOW and SkipGram , GloVe , L&amp;G  and <ref type="bibr">Arg2vec (Woodsend and Lapata, 2015)</ref>. Similar to ours, L&amp;G and Arg2vec both encode dependency relations in the embeddings. We train all models on the same dataset as ours using publicly avail-able code <ref type="bibr" target="#b471">3</ref> , and then apply the same clustering algorithm. Introduced by <ref type="bibr">Lang and Lapata (2014)</ref>, SYNTF is a strong baseline that clusters arguments based on purely syntactic cues: voice of the verb, relative position to the predicate, syntactic relations, and realizing prepositions. The window size for Arg2vec and our models are set to 1, while all other embeddings are set to 2. We also employ two state-of-the-art methods from Titov and Klementiev (2012) (T&amp;K12) and Titov and Khoddam (2015) (T&amp;K15).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">SRL Results</head><p>Following common practices (Lang and Lapata, 2014), we measure the overlap of induced semantic roles and their gold labels on the CoNLL 2008 training data <ref type="bibr">(Surdeanu et al., 2008)</ref>. We report purity (PU), collocation (CO), and their harmonic mean (F1) evaluated on gold arguments in two settings of gold parses and automatic parses from the MaltParser <ref type="bibr" target="#b187">(Nivre et al., 2007)</ref>. <ref type="table" target="#tab_10">Table 1</ref> shows the results. <ref type="bibr">4</ref> SYMDEP and ASYMDEP outperform all representation learning baselines for SRL. T&amp;K12 outperforms our models on gold parsing because they use a strong generative clustering method, which shared parameters across verbs in the clustering step. In addition, T&amp;K15 incorporates featurerich latent structure learning. Nevertheless, our models perform better with automatic parses, indicating the robustness of our models under noise in automatic parsing. Future work involves more sophisticated clutering techniques <ref type="bibr">(Titov and Klementiev, 2012)</ref> as well as incorporating featurerich models <ref type="bibr">(Titov and Khoddam, 2015)</ref> to improve performance further. <ref type="table" target="#tab_10">Table 1</ref> shows that including dependency relations (L&amp;G, Arg2vec, SYMDEP, and ASYMDEP) improves performance. Additionally, our models achieve the best performance among those, showing the strength of modeling dependencies as multiplicative factors. Arg2vec learns word embedings from the context features which are concatenation of syntactic features (dependency reations and POS tags) and word embedings. L&amp;G treats each word-dependency pair as a separate to- <ref type="bibr" target="#b471">3</ref> Except that Arg2vec is reimplemented since there is no public code online. <ref type="bibr">4</ref> The numbers reported for Arg2vec with gold parsing (80.7) is different from Woodsend and Lapata <ref type="formula" target="#formula_0">(2015)</ref>  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Word Similarity Results</head><p>As a further evaluation of the learned embeddings, we test if similarities between word embeddings agree with human annotation from SimLex999 . <ref type="table" target="#tab_6">Table 3</ref> shows that SYMDEP outperforms Arg2vec on both nouns and verbs, suggesting multiplicative dependency relations are indeed effective. However, ASYMDEP performs better than SYMDEP on noun similarity but much worse on verb similarity. We explore this further in an ablation study.    <ref type="table" target="#tab_6">Table 3</ref>. By keeping D i dependency independent, performance on verbs is significantly improved with the cost of noun performance.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Conclusions</head><p>We present a new unsupervised semantic role labeling approach that learns embeddings of arguments by predicting each argument from its context and considering dependency relation as a multiplicative factor. Two proposed neural networks outperform current state-of-the-art embeddings on unsupervised SRL and the SimLex999 word similarity task. As an effective model for dependency relations, our multiplicative argument-dependency factor models encourage the decoupling of argument and dependency representations. Disentangling linguistic factors in similar manners may be worth investigating in similar tasks such as frame semantic parsing and event detection. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Abstract</head><p>In order to capture rich language phenomena, neural machine translation models have to use a large vocabulary size, which requires high computing time and large memory usage. In this paper, we alleviate this issue by introducing a sentence-level or batch-level vocabulary, which is only a very small sub-set of the full output vocabulary. For each sentence or batch, we only predict the target words in its sentencelevel or batch-level vocabulary. Thus, we reduce both the computing time and the memory usage. Our method simply takes into account the translation options of each word or phrase in the source sentence, and picks a very small target vocabulary for each sentence based on a wordto-word translation model or a bilingual phrase library learned from a traditional machine translation model. Experimental results on the large-scale English-toFrench task show that our method achieves better translation performance by 1 BLEU point over the large vocabulary neural machine translation system of .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Neural machine translation (NMT)  has gained popularity in recent two years. But it can only handle a small vocabulary size due to the computational complexity. In order to capture rich language phenomena and have a better word coverage, neural machine translation models have to use a large vocabulary.  alleviated the large vocabulary issue by proposing an approach that partitions the training corpus and defines a subset of the full target vocabulary for each partition. Thus, they only use a subset vocabulary for each partition in the training procedure without increasing computational complexity. However, there are still some drawbacks of 's method. First, the importance sampling is simply based on the sequence of training sentences, which is not linguistically motivated, thus, translation ambiguity may not be captured in the training. Second, the target vocabulary for each training batch is fixed in the whole training procedure. Third, the target vocabulary size for each batch during training still needs to be as large as 30k, so the computing time is still high.</p><p>In this paper, we alleviate the above issues by introducing a sentence-level vocabulary, which is very small compared with the full target vocabulary. In order to capture the translation ambiguity, we generate those sentence-level vocabularies by utilizing word-to-word and phrase-tophrase translation models which are learned from a traditional phrase-based machine translation system (SMT). Another motivation of this work is to combine the merits of both traditional SMT and NMT, since training an NMT system usually takes several weeks, while the word alignment and rule extraction for SMT are much faster (can be done in one day). Thus, for each training sentence, we build a separate target vocabulary which is the union of following three parts:</p><p>• target vocabularies of word and phrase translations that can be applied to the current sentence. (to capture the translation ambiguity) • top 2k most frequent target words. (to cover the unaligned target words) • target words in the reference of the current sentence. (to make the reference reachable) As we use mini-batch in the training procedure, we merge the target vocabularies of all the sentences in each batch, and update only those related parameters for each batch. In addition, we also shuffle the training sentences at the beginning of each epoch, so the target vocabulary for a specific sentence varies in each epoch. In the beam search for the development or test set, we apply the similar procedure for each source sentence, except the third bullet (as we do not have the reference) and mini-batch parts. Experimental results on large-scale English-to-French task (Section 5) show that our method achieves significant improvements over the large vocabulary neural machine translation system.</p><formula xml:id="formula_51">↵ t1 ↵ tl s t 1 s t … o t H t = l X i=1 (↵ ti · h i ) l X i=1 (↵ ti · ! h i ) x 1 x l h 1 h l ! h l ! h 1 … … … x 2 ! h 2 h 2 ↵ t2 y ⇤ t 1 V o</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Neural Machine Translation</head><p>As shown in <ref type="figure" target="#fig_3">Figure 1</ref>, neural machine translation  is an encoder-decoder network. The encoder employs a bi-directional recurrent neural network to encode the source sentence x = (x 1 , ..., x l ), where l is the sentence length, into a sequence of hidden states h = (h 1 , ..., h l ), each h i is a concatenation of a left-to-right − → h i and a right-to-left ← − h i ,</p><formula xml:id="formula_52">h i = ← − h i − → h i = ← − f (x i , ← − h i+1 ) − → f (x i , − → h i−1 ) ,</formula><p>where ← − f and − → f are two gated recurrent units (GRU).</p><p>Given h, the decoder predicts the target translation by maximizing the conditional log-probability of the correct translation y * = (y * 1 , ...y * m ), where m is the length of target sentence. At each time t, the probability of each word y t from a target vocabulary V y is:</p><formula xml:id="formula_53">p(y t |h, y * t−1 ..y * 1 ) ∝ exp(g(s t , y * t−1 , H t )), (1)</formula><p>where g is a multi layer feed-forward neural network, which takes the embedding of the previous word y * t−1 , the hidden state s t , and the context state H t as input. The output layer of g is a target vocabulary V o , y t ∈ V o in the training procedure. V o is originally defined as the full target vocabulary V y . We apply the softmax function over the output layer, and get the probability of p(y t |h, y * t−1 ..y * 1 ). In Section 3, we differentiate V o from V y by adding a separate and sentence-dependent V o for each source sentence. In this way, we enable to maintain a large V y , and use a small V o for each sentence.</p><p>The s t is computed as:</p><formula xml:id="formula_54">s t = q(s t−1 , y * t−1 , c t )<label>(2)</label></formula><formula xml:id="formula_55">c t = l i=1 (α ti · ← − h i ) l i=1 (α ti · − → h i ) ,<label>(3)</label></formula><p>where q is a GRU, c t is a weighted sum of h, the weights, α, are computed with a feed-forward neural network r:</p><formula xml:id="formula_56">α ti = exp{r(s t−1 , h i , y * t−1 )} l k=1 exp{r(s t−1 , h k , y * t−1 )}<label>(4)</label></formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Target Vocabulary</head><p>The output of function g is the probability distribution over the target vocabulary V o . As V o is defined as V y in , the softmax function over V o requires to compute all the scores for all words in V o , and results in a high computing complexity. Thus,  only uses top 30k most frequent words for both V o and V y , and replaces all other words as unknown words (UNK).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Target Vocabulary Manipulation</head><p>In this section, we aim to use a large vocabulary of V y (e.g. 500k, to have a better word coverage), and, at the same, to reduce the size of V o as small as possible (in order to reduce the computing time). Our basic idea is to maintain a separate and small vocabulary V o for each sentence so that we only need to compute the probability distribution of g over a small vocabulary for each sentence. Thus, we introduce a sentence-level vocabulary V x to be our V o , which depends on the sentence x. In the following part, we show how we generate the sentence-dependent V x . The first objective of our method aims to capture the real translation ambiguity for each word, and the target vocabulary of a sentence V o = V x is supposed to cover as many as those possible translation candidates. Take the English to Chinese translation for example, the target vocabulary for the English word bank should contain yínháng (a financial institution) and héàn (sloping land) in Chinese.</p><p>So we first use a word-to-word translation dictionary to generate some target vocaularies for x. Given a dictionary D(x) = [y 1 , y 2 , ...], where x is a source word, [y 1 , y 2 , ...] is a sorted list of candidate translations, we generate a target vocabulary V D</p><p>x for a sentence x = (x 1 , ..., x l ) by merging all the candidates of all words x in x.</p><formula xml:id="formula_57">V D x = l i=1 D(x i )</formula><p>As the word-to-word translation dictionary only focuses on the source words, it can not cover the target unaligned functional or content words, where the traditional phrases are designed for this purpose. Thus, in addition to the word dictionary, given a word aligned training corpus, we also extract phrases P (x 1 ...x i ) = [y 1 , ..., y j ], where x 1 ...x i is a consecutive source words, and [y 1 , ..., y j ] is a list of target words 1 . For each sentence x, we collect all the phrases that can be applied to sentence x, e.g. x 1 ...x i is a sub-sequence of sentence x.</p><formula xml:id="formula_58">V P x = ∀x i ...x j ∈subseq(x) P (x i ...x j ),</formula><p>where subseq(x) is all the possible sub-sequence of x with a length limit.</p><p>In order to cover target un-aligned functional words, we need top n most common target words.</p><formula xml:id="formula_59">V T x = T (n).</formula><p>Training: in our training procedure, our optimization objective is to maximize the loglikelihood over the whole training set. In order to make the reference reachable, besides V D x , V P x and V T x , we also need to include the target words in the reference y,</p><formula xml:id="formula_60">V R x = ∀y i ∈y y i , 1</formula><p>Here we change the definition of a phrase in traditional SMT, where the [y1, ...yj] should also be a consecutive target words. But our task in this paper is to get the target vocabulary, so we only care about the target word set, not the order. where x and y are a translation pair. So for each sentence x, we have a target vocabulary V x :</p><formula xml:id="formula_61">V x = V D x ∪ V P x ∪ V T x ∪ V R x</formula><p>Then, we start our mini-batch training by randomly shuffling the training sentences before each epoch. For simplicity, we use the union of all V x in a batch,</p><formula xml:id="formula_62">V o = V b = V x 1 ∪ V x 2 ∪ ...V x b ,</formula><p>where b is the batch size. This merge gives an advantage that V b changes dynamically in each epoch, which leads to a better coverage of parameters.</p><p>Decoding: different from the training, the target vocabulary for a sentence x is</p><formula xml:id="formula_63">V o = V x = V D x ∪ V P x ∪ V T x ,</formula><p>and we do not use mini-batch in decoding.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Related Work</head><p>To address the large vocabulary issue in NMT,  propose a method to use different but small sub vocabularies for different partitions of the training corpus. They first partition the training set. Then, for each partition, they create a sub vocabulary V p , and only predict and apply softmax over the vocabularies in V p in training procedure. When the training moves to the next partition, they change the sub vocabulary set accordingly.</p><p>Noise-contrastive estimation <ref type="bibr">(Gutmann and Hyvarinen, 2010;</ref><ref type="bibr">Mnih and Teh, 2012;</ref><ref type="bibr" target="#b375">Mikolov et al., 2013;</ref><ref type="bibr">Mnih and Kavukcuoglu, 2013)</ref> and hierarchical classes <ref type="bibr">(Mnih and Hinton, 2009</ref>) are introduced to stochastically approximate the target word probability. But, as suggested by , those methods are only designed to reduce the computational complexity in training, not for decoding.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Experiments</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Data Preparation</head><p>We run our experiments on English to French (EnFr) task. The training corpus consists of approximately 12 million sentences, which is identical to the set of  and . Our development set is the concatenation of news-test-2012 and news-test-2013, which The average reference coverage ratios (in word-level) on the training and development sets. We use fixed top 10 candidates for each phrase when generating V P x , and top 2k most common words for V T</p><formula xml:id="formula_64">set V P x V D x V P x ∪ V D x V P x ∪ V D x ∪ V T x 10</formula><p>x . Then we check various top n (10, 20, and 50) candidates for the word-to-word dictionary for V D x . has 6003 sentences in total. Our test set has 3003 sentences from WMT news-test 2014. We evaluate the translation quality using the case-sensitive BLEU-4 metric <ref type="bibr" target="#b284">(Papineni et al., 2002)</ref> with the multi-bleu.perl script.</p><p>Same as , our full vocabulary size is 500k, we use AdaDelta <ref type="bibr" target="#b656">(Zeiler, 2012)</ref>, and mini-batch size is 80. Given the training set, we first run the 'fast align' <ref type="bibr" target="#b13">(Dyer et al., 2013)</ref> in one direction, and use the translation table as our word-to-word dictionary. Then we run the reverse direction and apply 'grow-diag-final-and' heuristics to get the alignment. The phrase table is extracted with a standard algorithm in Moses .</p><p>In the decoding procedure, our method is very similar to the 'candidate list' of , except that we also use bilingual phrases and we only include top 2k most frequent target words. Following , we dump the alignments for each sentence, and replace UNKs with the word-to-word dictionary or the source word.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Results</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2.1">Reference Reachability</head><p>The reference coverage or reachability ratio is very important when we limit the target vocabulary for each source sentence, since we do not have the reference in the decoding time, and we do not want to narrow the search space into a bad space. Table 1 shows the average reference coverage ratios (in word-level) on the training and development sets. For each source sentence x, V * x here is a set of target word indexes (the vocabulary size is 500k, others are mapped to UNK). The average reference vocabulary size V R x for each sentence is 23.7 on the training set (22.6 on the dev. set). The word-to-word dictionary V D x has a better coverage than phrases V P x , and when we combine the three sets we can get better coverage ratios. Those statistics suggest that we can not use each of them alone due to the low reference coverage ratios. The last three columns show three combinations, system train dev. sentence mini-batch sentence  30k 30k 30k Ours 2080 6153 2067 all of which have higher than 90% coverage ratios.</p><p>As there are many combinations, training an NMT system is time consuming, and we also want to keep the output vocabulary size small (the setting in the last column in <ref type="table" target="#tab_10">Table 1</ref> results in an average 11k vocabulary size for mini-batch 80), thus, in the following part, we only run one combination (top 10 candidates for both V P x and V D x , and top 2k for V T x ), where the full sentence coverage ratio is 20.7% on the development set.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2.2">Average Size of V o</head><p>With the setting shown in bold column in Table 1, we list average vocabulary size of  and ours in <ref type="table" target="#tab_5">Table 2</ref>.  fix the vocabulary size to 30k for each sentence and mini-batch, while our approach reduces the vocabulary size to 2080 for each sentence, and 6153 for each mini-batch. Especially in the decoding time, our vocabulary size for each sentence is about 14.5 times smaller than 30k.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2.3">Translation Results</head><p>The red solid line in <ref type="figure" target="#fig_8">Figure 2</ref> shows the learning curve of our method on the development set, which picks at epoch 7 with a BLEU score of 30.72. We also fix word embeddings at epoch 5, and continue several more epochs. The corresponding blue dashed line suggests that there is no significant difference between them.</p><p>We also run two more experiments:  <ref type="table" target="#tab_2">202  324  605  1089 2067 10029   Table 3</ref>: Given a trained NMT model, we decode the development set with various top n most common target words. For En-Fr task, the results suggest that we can reduce the n to 50 without losing much in terms of BLEU score. The average size of V o is reduced to as small as 202, which is significant lower than 2067 (the default setting we use in our training).  single system dev. test Moses from  N/A 33.30</p><formula xml:id="formula_65">V D x ∪ V T x and V P x ∪V T x separately (always have V R x in train- ing).</formula><formula xml:id="formula_66">V o = V P x ∪ V D x ∪ V T x</formula><p>Jean <ref type="formula" target="#formula_0">(2015)</ref>   <ref type="bibr">Durrani et al. (2014)</ref> N/A 37.03 <ref type="table" target="#tab_42">Table 4</ref>: Single system results on En-Fr task. <ref type="table" target="#tab_42">Table 4</ref> shows the single system results on EnFr task. The standard Moses in  on the test set is 33.3. Our target vocabulary manipulation achieves a BLEU score of 34.45 on the test set, and 35.11 after the UNK replacement. Our approach improves the translation quality by 1.0 BLEU point on the test set over the method of . But our single system is still about 2 points behind of the best phrase-based system <ref type="bibr">(Durrani et al., 2014)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2.4">Decoding with Different Top n Most Common Target Words</head><p>Another interesting question is what is the performance if we vary the size top n most common target words in V T x . As the training for NMT is time consuming, we vary the size n only in the decoding time. <ref type="table" target="#tab_6">Table 3</ref> shows the BLEU scores on the development set. When we reduce the n from 2000 to 50, we only loss 0.1 points, and the average size of sentence level V o is reduced to 202, which is significant smaller than 2067 (shown in <ref type="table" target="#tab_5">Table 2</ref>). But we should notice that we train our NMT model in the condition of the bold column in <ref type="table" target="#tab_5">Table 2</ref>, and only test different n in our decoding procedure only. Thus there is a mismatch between the training and testing when n is not 2000.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2.5">Speed</head><p>In terms of speed, as we have different code bases 2 between  and us, it is hard to conduct an apple to apple comparison. So, for simplicity, we run another experiment with our code base, and increase V b size to 30k for each batch (the same size in ). Results show that increasing the V b to 30k slows down the training speed by 1.5 times.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Conclusion</head><p>In this paper, we address the large vocabulary issue in neural machine translation by proposing to use a sentence-level target vocabulary V o , which is much smaller than the full target vocabulary V y . The small size of V o reduces the computing time of the softmax function in each predict step, while the large vocabulary of V y enable us to model rich language phenomena. The sentence-level vocabulary V o is generated with the traditional word-to-word and phrase-to-phrase translation libraries. In this way, we decrease the size of output vocabulary V o under 3k for each sentence, and we speedup and improve the large-vocabulary NMT system. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Recognizing entailment and contradiction between two sentences (called a premise and a hypothesis) is known as natural language inference (NLI) in MacCartney (2009). Provided with a premise sentence, the task is to judge whether the hypothesis can be inferred (entailment), or the hypothesis cannot be true (contradiction). Several examples are illustrated in <ref type="table" target="#tab_10">Table 1</ref>. NLI is in the core of natural language understanding and has wide applications in NLP, e.g., question answering <ref type="bibr">(Harabagiu and Hickl, 2006)</ref> and automatic summarization <ref type="bibr">(Lacatusu et al., 2006;</ref><ref type="bibr">Yan et al., 2011a;</ref><ref type="bibr">Yan et al., 2011b)</ref>. Moreover, NLI is also related to other tasks of sentence pair modeling, including paraphrase detection <ref type="bibr" target="#b180">(Hu et al., 2014)</ref>, relation recognition of discourse units <ref type="bibr" target="#b360">(Liu et al., 2016)</ref>, etc.</p><p>Traditional approaches to NLI mainly fall into two groups: feature-rich models and formal reasoning methods. Feature-based approaches typically leverage machine learning models, but require intensive human engineering to represent lexical and syntactic information in two sentences * Equal contribution.</p><p>† Corresponding authors.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Premise</head><p>Two men on bicycles competing in a race. People are riding bikes. E Hypothesis Men are riding bicycles on the streets. C A few people are catching fish. N <ref type="table" target="#tab_10">Table 1</ref>: Examples of relations between a premise and a hypothesis: Entailment, Contradiction, and Neutral (irrelevant).</p><p>( <ref type="bibr">MacCartney et al., 2006;</ref><ref type="bibr">Harabagiu et al., 2006)</ref>. Formal reasoning, on the other hand, converts a sentence into a formal logical representation and uses interpreters to search for a proof. However, such approaches are limited in terms of scope and accuracy <ref type="bibr" target="#b10">(Bos and Markert, 2005)</ref>. The renewed prosperity of neural networks has made significant achievements in various NLP applications, including individual sentence modeling <ref type="bibr">(Kalchbrenner et al., 2014;</ref><ref type="bibr">Mou et al., 2015)</ref> as well as sentence matching <ref type="bibr" target="#b180">(Hu et al., 2014;</ref><ref type="bibr" target="#b488">Yin and Schütze, 2015)</ref>. A typical neural architecture to model sentence pairs is the "Siamese" structure <ref type="bibr">(Bromley et al., 1993)</ref>, which involves an underlying sentence model and a matching layer to determine the relationship between two sentences. Prevailing sentence models include convolutional networks <ref type="bibr">(Kalchbrenner et al., 2014)</ref> and recurrent/recursive networks <ref type="bibr">(Socher et al., 2011b)</ref>. Although they have achieved high performance, they may either fail to fully make use of the syntactical information in sentences or be difficult to train due to the long propagation path. Recently, we propose a novel tree-based convolutional neural network (TBCNN) to alleviate the aforementioned problems and have achieved higher performance in two sentence classification tasks <ref type="bibr">(Mou et al., 2015)</ref>. However, it is less clear whether TBCNN can be harnessed to model sentence pairs for implicit logical inference, as is in the NLI task.</p><p>In this paper, we propose the TBCNN-pair neural model to recognize entailment and contradiction between two sentences. We lever-age our newly proposed TBCNN model to capture structural information in sentences, which is important to NLI. For example, the phrase "riding bicycles on the streets" in <ref type="table" target="#tab_10">Table 1</ref> can be well recognized by TBCNN via the dependency relations dobj(riding,bicycles) and prep on(riding,street). As we can see, TBCNN is more robust than sequential convolution in terms of word order distortion, which may be introduced by determinators, modifiers, etc. A pooling layer then aggregates information along the tree, serving as a way of semantic compositonality. Finally, two sentences' information is combined by several heuristic matching layers, including concatenation, element-wise product and difference; they are effective in capturing relationships between two sentences, but remain low complexity.</p><p>To sum up, the main contributions of this paper are two-fold: (1) We are the first to introduce tree-based convolution to sentence pair modeling tasks like NLI; (2) Leveraging additional heuristics further improves the accuracy while remaining low complexity, outperforming existing sentence encoding-based approaches to a large extent, including feature-rich methods and long short term memory (LSTM)-based recurrent networks. 1</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Related Work</head><p>Entailment recognition can be viewed as a task of sentence pair modeling. Most neural networks in this field involve a sentence-level model, followed by one or a few matching layers. They are sometimes called "Siamese" architectures <ref type="bibr">(Bromley et al., 1993)</ref>. <ref type="bibr" target="#b180">Hu et al. (2014)</ref> and <ref type="bibr" target="#b488">Yin and Schütze (2015)</ref> apply convolutional neural networks (CNNs) as the individual sentence model, where a set of feature detectors over successive words are designed to extract local features. <ref type="bibr">Wan et al. (2015)</ref> build sentence pair models upon recurrent neural networks (RNNs) to iteratively integrate information along a sentence. <ref type="bibr">Socher et al. (2011a)</ref> dynamically construct tree structures (analogous to parse trees) by recursive autoencoders to detect paraphrase between two sentences. As shown, inherent structural information in sentences is oftentimes important to natural language understanding.</p><p>The simplest approach to match two sentences, perhaps, is to concatenate their vector representations <ref type="bibr">Hu et al., 2014, Arc-I)</ref>.</p><p>Concatenation is also applied in our previous work of matching the subject and object in relation classification <ref type="bibr">Xu et al., 2016)</ref>.  apply additional heuristics, namely Euclidean distance, cosine measure, and elementwise absolute difference. The above methods operate on a fixed-size vector representation of a sentence, categorized as sentence encoding-based approaches. Thus the matching complexity is O(1), i.e., independent of the sentence length. Word-byword similarity matrices are introduced to enhance interaction. To obtain the similarity matrix, <ref type="bibr" target="#b180">Hu et al. (2014)</ref> (Arc-II) concatenate two words' vectors (after convolution), <ref type="bibr">Socher et al. (2011a)</ref> compute Euclidean distance, and Wan et al. <ref type="formula" target="#formula_0">(2015)</ref> apply tensor product. In this way, the complexity is of O(n 2 ), where n is the length of a sentence; hence similarity matrices are difficult to scale and less efficient for large datasets. Recently, <ref type="bibr">Rocktäschel et al. (2016)</ref> introduce several context-aware methods for sentence matching. They report that RNNs over a single chain of two sentences are more informative than separate RNNs; a static attention over the first sentence is also useful when modeling the second one. Such context-awareness interweaves the sentence modeling and matching steps. In some scenarios like sentence pair re-ranking <ref type="bibr">(Yan et al., 2016)</ref>, it is not feasible to pre-calculate the vector representations of sentences, so the matching complexity is of O(n). <ref type="bibr">Rocktäschel et al. (2016)</ref> further develop a word-by-word attention mechanism and obtain a higher accuracy with a complexity order of O(n 2 ).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Our Approach</head><p>We follow the "Siamese" architecture (like most work in Section 2) and adopt a two-step strategy to classify the relation between two sentences. Concretely, our model comprises two parts:</p><p>• A tree-based convolutional neural network models each individual sentence ( <ref type="figure" target="#fig_3">Figure 1a</ref>). Notice that, the two sentences, premise and hypothesis, share a same TBCNN model (with same parameters), because this part aims to capture general semantics of sentences.</p><p>• A matching layer combines two sentences' information by heuristics <ref type="figure" target="#fig_3">(Figure 1b)</ref>. After individual sentence models, we design a sentence matching layer to aggregate information. We use simple heuristics, including concate- nation, element-wise product and difference, which are effective and efficient. Finally, we add a softmax layer for output. The training objective is cross-entropy loss, and we adopt mini-batch stochastic gradient descent, computed by back-propagation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Tree-Based Convolution</head><p>The tree-based convolutoinal neural network (TBCNN) is first proposed in our previous work <ref type="bibr">(Mou et al., 2016)</ref> 2 to classify program source code; later, we further propose TBCNN variants to model sentences <ref type="bibr">(Mou et al., 2015)</ref>. This subsection details the tree-based convolution process.</p><p>The basic idea of TBCNN is to design a set of subtree feature detectors sliding over the parse tree of a sentence; either a constituency tree or a dependency tree applies. In this paper, we prefer the dependency tree-based convolution for its efficiency and compact expressiveness.</p><p>Concretely, a sentence is first converted to a dependency parse tree. <ref type="bibr" target="#b471">3</ref> Each node in the dependency tree corresponds to a word in the sentence; an edge a→b indicates a is governed by b. Edges are labeled with grammatical relations (e.g., nsubj) between the parent node and its children <ref type="bibr">(de Marneffe et al., 2006)</ref>. Words are represented by pretrained vector representations, also known as word embeddings  Now, we consider a set of two-layer subtree feature detectors sliding over the dependency tree. At a position where the parent node is p with child nodes c 1 , · · · , c n , the output of the feature detector, y, is</p><formula xml:id="formula_67">y = f W p p + n i=1 W r[c i ] c i + b</formula><p>Let us assume word embeddings (p and c i ) are of n e dimensions; that the convolutional layer y is n c -dimensional. W ∈ R nc×ne is the weight matrix; b ∈ R nc is the bias vector. r[c i ] denotes the dependency relation between p and c i . f is the non-linear activation function, and we apply ReLU in our experiments.</p><p>After tree-based convolution, we obtain a set of feature maps, which are one-one corresponding to original words in the sentence. Therefore, they may vary in size and length. A dynamic pooling layer is applied to aggregate information along different parts of the tree, serving as a way of semantic compositionality <ref type="bibr" target="#b180">(Hu et al., 2014)</ref>. We use the max pooling operation, which takes the maximum value in each dimension.</p><p>Then we add a fully-connected hidden layer to further mix the information in a sentence. The obtained vector representation of a sentence is denoted as h (also called a sentence embedding). Notice that the same tree-based convolution applies to both the premise and hypothesis.</p><p>Tree-based convolution along with pooling enables structural features to reach the output layer with short propagation paths, as opposed to the recursive network <ref type="bibr">(Socher et al., 2011b)</ref>, which is also structure-sensitive but may suffer from the problem of long propagation path. By contrast, TBCNN is effective and efficient in learning such structural information <ref type="bibr">(Mou et al., 2015)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Matching Heuristics</head><p>In this part, we introduce how vector representations of individual sentences are combined to capture the relation between the premise and hypothesis. As the dataset is large, we prefer O(1) matching operations because of efficiency concerns. Concretely, we have three matching heuristics:</p><p>• Concatenation of the two sentence vectors, • Element-wise product, and • Element-wise difference. The first heuristic follows the most standard procedure of the "Siamese" architectures, while the latter two are certain measures of "similarity" or "closeness." These matching layers are further concatenated <ref type="figure" target="#fig_3">(Figure 1b)</ref>, given by</p><formula xml:id="formula_68">m = [h 1 ; h 2 ; h 1 − h 2 ; h 1 • h 2 ]</formula><p>where h 1 ∈ R nc and h 2 ∈ R nc are the sentence vectors of the premise and hypothesis, respectively; "•" denotes element-wise product; semicolons refer to column vector concatenation. m ∈ R 4nc is the output of the matching layer.</p><p>We would like to point out that, with subsequent linear transformation, element-wise difference is a special case of concatenation. </p><formula xml:id="formula_69">(h 1 − h 2 ) = [W 0 −W 0 ][h 1 h 2 ] .</formula><p>(W 0 is the weights corresponding to element-wise difference.) Thus, our third heuristic can be absorbed into the first one in terms of model capacity. However, as will be shown in the experiment, explicitly specifying this heuristic significantly improves the performance, indicating that optimization differs, despite the same model capacity. Moreover, word embedding studies show that linear offset of vectors can capture relationships between two words , but it has not been exploited in sentence-pair relation recognition. Although element-wise distance is used to detect paraphrase in , it mainly reflects "similarity" information. Our study verifies that vector offset is useful in capturing generic sentence relationships, akin to the word analogy task.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Evaluation</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Dataset</head><p>To evaluate our TBCNN-pair model, we used the newly published Stanford Natural Language Inference (SNLI) dataset <ref type="bibr">(Bowman et al., 2015)</ref>. <ref type="bibr">4</ref> The dataset is constructed by crowdsourced efforts, each sentence written by humans. Moreover, the SNLI dataset is magnitudes of larger than previous resources, and hence is particularly suitable for comparing neural models. The target labels comprise three classes: Entailment, Contradiction, and Neutral (two irrelevant sentences).</p><p>We applied the standard train/validation/test split, contraining 550k, 10k, and 10k samples, respectively.    additional dataset statistics, especially those relevant to dependency parse trees. 5</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Hyperparameter Settings</head><p>All our neural layers, including embeddings, were set to 300 dimensions. The model is mostly robust when the dimension is large, e.g., several hundred <ref type="bibr">(Collobert and Weston, 2008)</ref>. Word embeddings were pretrained ourselves by word2vec on the English Wikipedia corpus and fined tuned during training as a part of model parameters. We applied 2 penalty of 3×10 −4 ; dropout was chosen by validation with a granularity of 0.1 <ref type="figure" target="#fig_8">(Figure 2)</ref>. We see that a large dropout rate (≥ 0.3) hurts the performance (and also makes training slow) for such a large dataset as opposed to small datasets in other tasks <ref type="bibr" target="#b287">(Peng et al., 2015)</ref>. Initial learning rate was set to 1, and a power decay was applied. We used stochastic gradient descent with a batch size of 50. <ref type="table" target="#tab_6">Table 3</ref> compares our model with previous results.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Performance</head><p>As seen, the TBCNN sentence pair model, followed by simple concatenation alone, outperforms existing sentence encoding-based approaches (without pretraining), including a feature-rich method using 6 groups of humanengineered features, long short term memory   <ref type="bibr">Bowman et al., 2015;</ref><ref type="bibr">v Vendrov et al., 2015;</ref><ref type="bibr">r Rocktäschel et al., 2015)</ref>. "cat" refers to concatenation; "-" and "•" denote element-wise difference and product, resp.  (LSTM)-based RNNs, and traditional CNNs. This verifies the rationale for using tree-based convolution as the sentence-level neural model for NLI. <ref type="table" target="#tab_42">Table 4</ref> compares different heuristics of matching. We first analyze each heuristic separately: using element-wise product alone is significantly worse than concatenation or element-wise difference; the latter two are comparable to each other.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Model</head><p>Combining different matching heuristics improves the result: the TBCNN-pair model with concatenation, element-wise product and difference yields the highest performance of 82.1%. As analyzed in Section 3.2, the element-wise difference matching layer does not add to model complexity and can be absorbed as a special case into simple concatenation. However, explicitly using such heuristic yields an accuracy boost of 1-2%. Further applying element-wise product improves the accuracy by another 0.5%.</p><p>The full TBCNN-pair model outperforms all existing sentence encoding-based approaches, including a 1024d gated recurrent unit (GRU)-based RNN with "skip-thought" pretraining <ref type="bibr">(Vendrov et al., 2015)</ref>. The results obtained by our model are also comparable to several attention-based LSTMs, which are more computationally intensive than ours in terms of complexity order.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4">Complexity Concerns</head><p>For most sentence models including TBCNN, the overall complexity is at least O(n). However, an efficient matching approach is still important, especially to retrieval-and-reranking systems <ref type="bibr">(Yan et al., 2016;</ref><ref type="bibr" target="#b232">Li et al., 2016)</ref>. For example, in a retrieval-based question-answering or conversation system, we can largely reduce response time by performing sentence matching based on precomputed candidates' embeddings. By contrast, context-aware matching approaches as described in Section 2 involve processing each candidate given a new user-issued query, which is timeconsuming in terms of most industrial products.</p><p>In our experiments, the matching part <ref type="figure" target="#fig_3">(Figure 1b</ref>) counts 1.71% of the total time during prediction (single-CPU, C++ implementation), showing the potential applications of our approach in efficient retrieval of semantically related sentences.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Conclusion</head><p>In this paper, we proposed the TBCNN-pair model for natural language inference. Our model relies on the tree-based convolutional neural network (TBCNN) to capture sentence-level semantics; then two sentences' information is combined by several heuristics including concatenation, element-wise product and difference. Experimental results on a large dataset show a high performance of our TBCNN-pair model while remaining a low complexity order. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Abstract</head><p>In this paper we improve over the hierarchical Pitman-Yor processes language model in a cross-domain setting by adding skipgrams as features. We find that adding skipgram features reduces the perplexity. This reduction is substantial when models are trained on a generic corpus and tested on domain-specific corpora. We also find that within-domain testing and crossdomain testing require different backoff strategies. We observe a 30-40% reduction in perplexity in a cross-domain language modelling task, and up to 6% reduction in a within-domain experiment, for both English and Flemish-Dutch.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Since the seminal paper on hierarchical Bayesian language models based on Pitman-Yor processes <ref type="bibr" target="#b590">(Teh, 2006)</ref>, Bayesian language modelling has regained an interest. Although Bayesian language models are not new <ref type="bibr">(MacKay and Peto, 1995)</ref>, previously proposed models were reported to be inferior compared to other smoothing methods. Teh's work was the first to report on improvements over interpolated Kneser-Ney smoothing <ref type="bibr" target="#b590">(Teh, 2006)</ref>.</p><p>To overcome the traditional problems of overestimating the probabilities of rare occurrences and underestimating the probabilities of unseen events, a range of smoothing algorithms have been proposed in the literature <ref type="bibr">(Goodman, 2001)</ref>. Most methods take a heuristic-frequentist approach combining n-gram probabilities for various values of n, using back-off schemes or interpolation. <ref type="bibr" target="#b590">Teh (2006)</ref> showed that MacKay and Peto's (1995) research on parametric Bayesian language models with a Dirichlet prior could be extended to give better results, but also that one of the best smoothing methods, interpolated <ref type="bibr">Kneser-Ney (Kneser and Ney, 1995)</ref>, can be derived as an approximation of the Hierarchical Pitman-Yor process language model (HPYLM).</p><p>The success of the Bayesian approach to language modelling is due to the use of statistical distributions such as the Dirichlet distribution, and distributions over distributions, such as the Dirichlet process and its two-parameter generalisation, the Pitman-Yor process. Both are widely studied in the statistics and probability theory communities. Interestingly, language modelling has acquired the status of a "fruit fly" problem in these communities, to benchmark the performance of statistical models. In this paper we approach language modelling from a computational linguistics point of view, and consider the statistical methods to be the tool with the future goal of improving language models for extrinsic tasks such as speech recognition.</p><p>We derive our model from <ref type="bibr" target="#b590">Teh (2006)</ref>, and propose an extension with skipgrams. A frequentist approach to language modelling with skipgrams is described by <ref type="bibr">Pickhardt et al. (2014)</ref>, who introduce an approach using skip-n-grams which are interpolated using modified Kneser-Ney smoothing. In this paper we show that a Bayesian skip-ngram approach outperforms a frequentist skip-ngram model.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Method</head><p>Traditionally, the most widely used pattern in language modelling is the n-gram, which represents a pattern of n contiguous words, of which we call the first (n − 1) words the history or context, and the nth word the focus word. The motivation for using n-grams can be traced back to the distributional hypothesis of Harris <ref type="bibr">Sahlgren, 2008)</ref>. Although n-grams are small patterns without any explicit linguistic annotation, they are surprisingly effective in many tasks, such as language modelling in machine translation, automatic speech recognition, and information retrieval.</p><p>One of the main limitations of n-grams is their contiguity, because this limits the expressive power to relations between neighboring words. Many patterns in language span a range that is longer than the typical length of n; we call these relations long-distance relations. Other patterns may be within the range of n, but are still noncontiguous; they skip over positions. Both types of relations may be modelled with (syntactic) dependencies, and modelling these explicitly requires a method to derive a parser, e.g. a dependency parser, from linguistically annotated data.</p><p>To be able to model long-distance and other non-contiguous relations between words without resorting to explicitly computing syntactic dependencies, we use skipgrams. Skipgrams are a generalisation of n-grams. They consist of n tokens, but now each token may represent a skip of at least one word, where a skip can match any word. Let {m} be a skip of length m, then the {1} house can match "the big house", or "the yellow house", etc. We do not allow skips to be at the beginning or end of the skipgram, so for n &gt; 2 skipgrams are a generalisation of n-grams <ref type="bibr">(Goodman, 2001;</ref><ref type="bibr">Shazeer et al., 2015;</ref><ref type="bibr">Pickhardt et al., 2014)</ref>.</p><p>Pitman-Yor Processes (PYP) belong to the family of non-parametric Bayesian models. Let W be a fixed and finite vocabulary of V words. For each word w ∈ W let G(w) be the probability of w, and G = [G(w)] w∈W be the vector of word probabilities. Since word frequencies generally follow a power-law distribution, we use a Pitman-Yor process, which is a distribution over partitions with power-law distributions. In the context of a language model this means that for a space P (u), with c(u·) elements (tokens), we want to partition P (u) in V subsets such that the partition is a good approximation of the underlying data, in which c(uw) is the size of subset w of P (u). We assume that the training data is an sample of the underlying data, and for this reason we seek to find an approximation, rather than using the partitions precisely as found in the training data.</p><p>Since we also assume that a power-law distribution on the words in the underlying data, we place a PYP prior on G:</p><formula xml:id="formula_70">G ∼ PY(d, θ, G 0 ), with discount parameter 0 ≤ d &lt; 1, a strength parameter θ &gt; −d and a mean vector G 0 = [G 0 (w)] w∈W . G 0 (w)</formula><p>is the a-priori probability of word w, which we set uniformly: G 0 (w) = 1/V for all w ∈ W . In general, there is no known analytic form for the density of PY(d, θ, G 0 ) when the vocabulary is finite. However, we are interested in the distribution over word sequences induced by the PYP, which has a tractable form, and is sufficient for the purpose of language modelling.</p><p>Let G and G 0 be distributions over W , and x 1 , x 2 , . . . be a sequence of words drawn i.i.d. from G. The PYP is then described in terms of a generative procedure that takes x 1 , x 2 , . . . to produce a separate sequence of i.i.d. draws y 1 , y 2 , . . . from the mean distribution G 0 as follows. The first word x 1 is assigned the value of the first draw y 1 from G 0 . Let t be the current number of draws from G 0 , c k the number of words assigned the value of draw y k and c · = t k=1 c k the number of draws from G 0 . For each subsequent word x c·+1 , we either assign it the value of a previous draw y k , with probability</p><formula xml:id="formula_71">c k −d</formula><p>θ+c· , or assign it the value of a new draw from G 0 with probability θ+dt θ+c· . For an n-gram language model we use a hierarchical extension of the PYP. The hierarchical extension describes the probabilities over the current word given various contexts consisting of up to n − 1 words. Given a context u, let G u (w) be the probability of the current word taking on value w. A PYP is used as the prior for</p><formula xml:id="formula_72">G u = [G u (w)] w∈W : G u ∼ PY(d |u| , θ |u| , G π(u) ),</formula><p>where π(u) is the suffix of u consisting of all but the first word, and |u| being the length of u. The priors are recursively placed with parameters θ |π(u)| , d |π(u)| and mean vector G π(π(u)) , until we get to G ∅ :</p><formula xml:id="formula_73">G ∅ ∼ PY(d 0 , θ 0 , G 0 ),</formula><p>with G 0 being the uniformly distributed global mean vector for the empty context ∅.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Backoff Strategies</head><p>In this paper we investigate three backoff strategies: ngram, limited, and full. ngram is the traditional n-gram backoff method as described by <ref type="bibr" target="#b590">Teh (2006)</ref>; limited and full are extensions that also incorporate skipgram probabilities. The full backoff strategy is similar to ngram in that it always backs off recursively to the word probabilities, while limited halts as soon as a probability is known for a pattern. The backoff strategies can be formalised as follows. For all strategies, we have that p(w|u) = G 0 (w) if u = ∅. For ngram, the other case is defined as:</p><formula xml:id="formula_74">p(w|u) = c uw· − d |u| t uw· θ |u| + c u·· + θ |u| + d |u| t u·· θ |u| + c u·· p(w|π(u))</formula><p>with c uw· being the number of uw tokens, and c u·· the number of patterns starting with context u. Similarly, t uwk is 1 if draw the kth from G u was w, 0 otherwise. t uw· then denotes if there is a pattern uw, and t u·· is the number of types following context u. Now let σ n be the operator that adds a skip to a pattern u on the nth position if there is not already a skip. Then σ(u) = [σ n (u)] |u| n=2 is the set of patterns with one skip more than the number of skips currently in u. The number of generated patterns is ς = |σ(u)|. We also introduce the indicator function S, which for the full backoff strategy always returns its argument: S uw (y) = y. The full backoff strategy is defined as follows, with u x = σ x (u), and discount frequency δ u = 1:</p><formula xml:id="formula_75">p(w|u) = ς m=1 1 ς + 1 c umw· − δ um d |um| t umw· δ um θ |um| + c um·· + S umw θ |um| + d |um| t um·· δ um θ |um| + c um·· p(w|π(u m )) + 1 ς + 1 c uw· − δ u d |u| t uw· δ u θ |u| + c u·· + S uw θ |u| + d |u| t u·· δ u θ |u| + c u·· p(w|π(u))</formula><p>The limited backoff strategy is an extension of the full backoff strategy that stops the recursion if a test pattern uw has already occurred in the training data. This means that the count is not zero, and hence at training time a probability has been assigned to that pattern. S is the indicator function which tells if a pattern has been seen during training: S uw (·) = 0 if count(uw) &gt; 0, 1 otherwise; and δ u = V − w∈W S uw (·). Setting S uw (·) = 0 stops the recursion.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Data</head><p>In this section we give an overview of the data sets we use for the English and Flemish-Dutch experiments.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">English Data</head><p>For the experiments on English we use four corpora: two large generic mixed-domain corpora and two smaller domain-specific corpora. We train on the largest of the two mixed-domain corpora, and test on all four corpora.</p><p>The first generic corpus is the Google 1 billion words shuffled web corpus of 769 million tokens <ref type="bibr">(Chelba et al., 2013)</ref>. For training we use sets 1 through 100, out of the 101 available training sets; for testing we use all available 50 test sets (8M tokens). The second generic corpus, used as test data, is a Wikipedia snapshot (368M tokens) of November 2013 as used and provided by <ref type="bibr">Pickhardt et al. (2014)</ref>. The first domain-specific corpus is from JRC-Acquis v3.0 <ref type="bibr">(Steinberger et al., 2006)</ref>, which contains legislative text of the European Union (8M tokens). The second domain-specific corpus consists of documents from the European Medicines Agency, EMEA <ref type="bibr">(Tiedemann, 2009)</ref>. We shuffled all sentences, and selected 20% of them as the test set (3M tokens).</p><p>Since the HPYLM uses a substantial amount of memory, even with histogram-based sampling, we cannot model the complete 1bw data set without thresholding the patterns in the model. We used a high occurrence threshold of 100 on the unigrams, yielding 99,553 types that occur above this threshold. We use all n-grams and skipgrams that occurred at least twice, consisting of the included unigrams as focus words, with UNKs occupying the positions of words not in the vocabulary. Note that because these settings are different from models competing on this benchmark, the results in this paper cannot be compared to those results.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Flemish-Dutch Data</head><p>For the experiments on Flemish-Dutch data, we use the Mediargus corpus as training material. It contains 5 years of newspaper texts from 12 Flemish newspapers and magazines, totaling 1.3 billion words.</p><p>For testing we use the Flemish part of the Spoken Dutch Corpus (CGN) (Oostdijk, 2000) (3.2M words), divided over 15 components, ranging from spontaneous speech to books read aloud. CGN also contains two components which are news articles and news, which from a domain perspective are similar to the training data of Mediargus. We report on each component separately.</p><p>Similarly to the 1bw models, we used a threshold on the word types, such that we have a similar size of vocabulary (100k types), which we produced with a threshold of 250. We used the same occurrence threshold of 2 on the n-and skipgrams.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Experimental Setup</head><p>We train 4-gram language model on the two training corpora, the Google 1 billion word benchmark and the Mediargus corpus. We do not perform any preprocessing on the data except tokenisation. The models are trained with a HPYLM. We do not use sentence beginning and end markers. The results for the ngram backoff strategy are obtained by training without skipgrams; for limited and full we added skipgram features during training.</p><p>At the core of our experimental framework we use cpyp, 1 which is an existing library for nonparametric Bayesian modelling with PY priors with histogram-based sampling <ref type="bibr">(Blunsom et al., 2009)</ref>. This library has an example application to showcase its performance with n-gram based language modelling. Limitations of the library, such as not natively supporting skipgrams, and the lack of other functionality such as thresholding and discarding of certain patterns, led us to extend the library with Colibri Core, 2 a pattern modelling library. Colibri Core resolves the limitations, and together the libraries are a complete language model that handles skipgrams: cococpyp. <ref type="bibr" target="#b471">3</ref> Each model is run for 50 iterations (without an explicit burn-in phase), with hyperparameters θ = 1.0 and γ = 0.8. The hyperparameters are resampled every 30 iterations with slice sampling <ref type="bibr">(Walker, 2007</ref>   Components range from spontaneous (a) to nonspontaneous (o), with components j (news reports) and k (news) being in-domain for the training corpus, and the other components being out-ofdomain. ↓% is the relative reduction in perplexity for the column to its left.</p><p>that were unseen in the training data are ignored in computing the perplexity on test data.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Results</head><p>The results are reported in terms of perplexity, in <ref type="table" target="#tab_10">Table 1</ref> for English, and in <ref type="table" target="#tab_5">Table 2</ref> for FlemishDutch. We computed baseline perplexity scores with SRILM (Stolcke, 2002) for 1bw. We used an interpolated modified Kneser-Ney language model, with Good-Turing discounting to mimic our thresholding options. Although the models are not comparable, this is arguably the closest approximation in SRILM of our HPYLM. For 1bw the baseline is 147; for jrc, emea, and wp, 1391, 1430, and 1403 respectively. In some cases the baseline is better compared to the ngram backoff strategy. With adding skipgrams we always outperform the baseline, especially on the out-ofdomain test sets. We find that with large data sets adding skipgrams lowers the perplexity, for both languages, in both within-and cross-domain experiments. For English, we observe absolute perplexity reductions up to 680 (a relative reduction of 39%) in a cross-domain setting, and absolute perplexity reductions of 10 (relative reduction of 6%) in a within-domain setting. For Flemish-Dutch we observe similar results with absolute reductions up to 560 (relative reduction of 36%) and 31 (relative reduction 11%), respectively.</p><p>If we consider the three backoff strategies individually, we can see the following effects on both English and Flemish-Dutch data. In a withindomain experiment limited backoff is the best strategy. In a cross-domain setting, the full backoff strategy yields the lowest perplexity and largest perplexity reductions. In the first case, stopping the backoff when there is a pattern probability for the word and its context yields a more certain probability than when the probability is diffused by more uncertain backoff probabilities.</p><p>Upon inspection of the model sizes, we observe that the skipgram model contains almost five times as many parameters as the n-gram model. This difference is explained by the addition of skipgrams of length 3 and 4, and the bigrams and unigrams derived from these skipgrams. Each 4-gram can be deconstructed into three skipgrams of length 4, and one of these skipgrams yields a skipgram of length 3. Tests with ngram backoff on skipgram models show that the performance is worse compared to ngram backoff in pure n-gram models because of the extra bigrams and unigrams (ngram ignores the skipgrams). Yet, the experimental results also indicate that with sufficient data, skipgram models outperform n-gram models. Because the difference in parameters is only noticeable in terms of memory, and it hardly impacts the run-time, this makes the skipgram model the favourable model.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">Conclusions</head><p>In this paper we showed that by adding skipgrams, a straightforward but powerful generalisation of ngram word patterns, we can reduce the perplexity of a Bayesian language model, especially in a cross-domain language modelling task. By changing the backoff strategy we can also improve on a within-domain task. We found this effect in two languages.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>References</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Motivation</head><p>Language is complex, and the process of reading and understanding language is difficult for many groups of people. The goal of text simplification is to rewrite text in order to make it easier to understand, for example, by children <ref type="bibr">(De Belder and Moens, 2010)</ref>, language learners <ref type="bibr">(Petersen and Ostendorf, 2007)</ref>, people with disabilities <ref type="bibr">(Rello et al., 2013;</ref><ref type="bibr">Evans et al., 2014)</ref>, and even by machines <ref type="bibr">(Siddharthan et al., 2004)</ref>. Automatic text simplification <ref type="bibr">(Napoles and Dredze, 2010;</ref><ref type="bibr">Wubben et al., 2012;</ref><ref type="bibr">Xu et al., 2016)</ref> has the potential to dramatically increase access to information by making written documents available at all reading levels.</p><p>Full text simplification involves many steps, including grammatical restructuring and summarization <ref type="bibr">(Feng, 2008)</ref>. One of the most basic subtasks is lexical simplification (Specia et al., 2012)-replacing complicated words and phrases with simpler paraphrases. While there is active research in the area of lexical simplification <ref type="bibr">(Coster and Kauchak, 2011a;</ref><ref type="bibr">Glavaš andŠtajner, 2015;</ref><ref type="bibr">Paetzold, 2015)</ref>, existing models have been byand-large limited to single words. Often, howmedical practitioner → doctor legislative texts → laws hypertension → high blood pressure prevalent → very common significant quantity → a lot impact negatively → be bad ever, it is preferable, or even necessary to paraphrase a single complex word with multiple simpler words, or to paraphrase multiple words with a single word. For example, it is difficult to imagine a simple, single-word paraphrase of hypertension, but the three-word phrase high blood pressure is a very good simplification <ref type="table" target="#tab_10">(Table 1)</ref>. Such phrasal simplifications are overlooked by current lexical simplification models, and thus are often unavailable to the end-to-end text simplification systems that require them. Recent research in data-driven paraphrasing has produced enormous resources containing millions of meaning-equivalent phrases <ref type="bibr">(Ganitkevitch et al., 2013)</ref>. Such resources capture a wide range of language variation, including the types of lexical and phrasal simplifications just described. In this work, we apply state-of-the-art machine learned models for lexical simplification in order to identify phrase pairs from the Paraphrase Database (PPDB) applicable to the task of text simplification. We introduce Simple PPDB, 1 a subset of the Paraphrase Database containing 4.5 million simplifying paraphrase rules. The large scale of Simple PPDB will support research into increasingly advanced methods for text simplification.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Identifying Simplification Rules</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Paraphrase Rules</head><p>The Paraphrase Database (PPDB) is currently the largest available collection of paraphrases. Each paraphrase rule in the database has an automatically-assigned quality score between 1 and 5 <ref type="bibr">(Pavlick et al., 2015)</ref>. In this work, we use the PPDB-TLDR 2 dataset, which contains 14 million high-scoring lexical and phrasal paraphrases, and is intended to give a generally good tradeoff between precision and recall. To preprocess the data, we lemmatize all of the phrases, and remove rules which differ only by morphology, punctuation, or stop words, or which involve phrases longer than 3 words. The resulting list contains 7.5 million paraphrase rules covering 625K unique lemmatized words and phrases.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Lexical Simplification Model</head><p>Our goal is to build a model which can accurately identify paraphrase rules that both 1) simplify the input phrase and 2) preserve its meaning. That is, we want to avoid a model which favors "simple" words (e.g. the, and) even when they capture none of the meaning of the input phrase. We therefore train our model to make a three-way distinction between rules which simplify the input, rules which make the input less simple, and rules which generate bad paraphrases.</p><p>Data. We collect our training data in two phases. First, we sample 1,000 phrases from the vocabulary of the PPDB. We limit ourselves to words which also appear at least once in the Newsela corpus for text simplifcation , in order to ensure that we focus our model on the types of words for which the final resource is most likely to be applied. For each of these 1,000 words/phrases, we sample up to 10 candidate paraphrases from PPDB, stratified evenly across paraphrase quality scores. We ask workers on Amazon Mechanical Turk to rate each of the chosen paraphrase rules on a scale from 1 to 5 to indicate how well the paraphrase preserves the meaning of the original phrase. We use the same annotation design used in <ref type="bibr">Pavlick et al. (2015)</ref>. We have 5 workers judge each pair, omitting workers who do not provide correct answers on the embedded gold-standard pairs which we draw from WordNet. For 62% of the paraphrase rules we had scored, the average human rating falls below 3, indicating that the meaning of the paraphrase differs substantially from that of the input. We assign all of these rules to the "bad paraphrase" class.</p><p>We take the remaining 3,758 meaningpreserving paraphrase rules (scored ≥3 in the above annotation task) and feed them into a second annotation task, in which we identify rules that simplify the input. We use the same annotation interface as in <ref type="bibr">Pavlick and Nenkova (2015)</ref>, which asks workers to choose which of the two phrases is simpler, or to indicate that there is no difference in complexity. We collect 7 judgements per pair and take the majority label, discarding pairs for which the majority opinion was that there was no difference. We include each rule in our training data twice, once as an instance of a "simplifying" rule, and once in the reverse direction as an instance of a "complicating" rule.</p><p>In the end, our training dataset contains 11,829 pairs, with the majority class being "bad paraphrase" (47%), and the remaining split evenly between "simplifying" and "complicating" paraphrase rules (26% each).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Features.</head><p>We use a variety of features that have been shown in prior work to give good signal about phrases' relative complexity. The features we include are as follows: phrase length in words and in characters, frequency according to the Google NGram corpus <ref type="bibr">(Brants and Franz, 2006)</ref>, number of syllables, the relative frequency of usage in Simple Wikipedia compared to normal Wikipedia <ref type="bibr">(Pavlick and Nenkova, 2015)</ref>, character unigrams and bigrams, POS tags, and the averaged Word2Vec word embeddings for the words in the phrase . For each phrase pair e 1 , e 2 , for each feature f , we include f (e 1 ), f (e 2 ) and f (e 1 ) − f (e 2 ). <ref type="bibr" target="#b471">3</ref> We also include the cosine similarity of the averaged word embeddings and the PPDB paraphrase quality score as features.</p><p>We train a multi-class logistic regression model 4 to predict if the application of a paraphrase rule will result in 1) simpler output, 2) more complex output, or 3) non-sense output.</p><p>Performance.  <ref type="table" target="#tab_5">Table 2</ref>: Accuracy on 10-fold cross-validation, and precision for identifying simplifying rules. Folds are constructed so that train and test vocabularies are disjoint.</p><p>5 points higher than the strongest baseline, a supervised model which uses only word embeddings as features.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Simple PPDB</head><p>We run the trained model described above over all 7.5 million paraphrase rules. From the predictions, we construct Simple PPDB: a list of 4.5 million simplifying paraphrase rules. A rule in Simple PPDB is represented as a triple, consisting of a syntactic category, and input phrase, and a simplified output phrase. Each rule is associated with both a paraphrase quality score from 1 to 5 (taken from PPDB 2.0), and simplification confidence score from 0 to 1.0 (our classifier's confidence in the prediction that the rule belongs to the "simplifying" class). Note that ranking via the confidence scores of a classification model has not, to our knowledge, been explored in previous work on lexical simplification. The remainder of this paper evaluates the quality of the simplification ranking. For an evaluation of the paraphrase quality ranking, see <ref type="bibr">Pavlick et al. (2015)</ref>. <ref type="table" target="#tab_6">Table 3</ref> shows examples of some of the top ranked paraphrases according to Simple PPDB's simplification score for several input phrases.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Evaluation</head><p>To evaluate Simple PPDB, we apply it in a setting intended to emulate the way it is likely to be used in practice. We use the Newsela Simplification Dataset , a corpus of manually simplified news articles. This corpus is currently the cleanest available simplification dataset and is likely to be used to train and/or evaluate the simplification systems that we envision benefitting most from Simple PPDB. We draw a sample of 100 unique word types ("targets") from the corpus for which Simple PPDB has at least one candidate simplification. For each target, we take Simple PPDB's full list of simplification rules which are of high quality according to the PPDB 2.0 paraphrase score 5 and which match the syntactic category of the target. On average, Simple PPDB proposes 8.8 such candidate simplifications per target.</p><p>Comparison to existing methods. Our baselines include three existing methods for generating lists of candidates that were proposed in prior work. The methods we test for generating lists of candidate paraphrases for a given target are: the WordNetGenerator, which pulls synonyms from WordNet <ref type="bibr">(Devlin and Tait, 1998;</ref><ref type="bibr">Carroll et al., 1999)</ref>, the KauchakGenerator, which generates candidates based on automatic alignments between Simple Wikipedia and normal Wikipedia (Coster and Kauchak, 2011a), and the GlavasGenerator, which generates candidates from nearby phrases in vector space (Glavaš anď Stajner, 2015) (we use the pre-trained Word2Vec VSM ).</p><p>For each generated list, we follow Horn et al. <ref type="formula" target="#formula_0">(2014)</ref>'s supervised SVM Rank approach to rank the candidates for simplicity. We reimplement the main features of their model: namely, word frequencies according to the Google NGrams corpus <ref type="bibr">(Brants and Franz, 2006)</ref> and the Simple Wikipedia corpus, and the alignment probabilities according to automatic word alignments between Wikipedia and Simple Wikipedia sentences <ref type="bibr">(Coster and Kauchak, 2011b)</ref>. We omit the language modeling features since our evaluation does not consider the context in which the substitution is to be applied.</p><p>All of these methods (the three generation methods and the ranker) are implemented as part of the LEXenstein toolkit <ref type="bibr">(Paetzold and Specia, 2015)</ref>. We use the LEXenstein implementations for the results reported here, using off-the-shelf configurations and treating each method as a black box.</p><p>Setup. We use each of the generate-and-rank methods to produce a ranked list of simplification candidates for each of the 100 targets drawn from the Newsela corpus. When a generation method fails to produce any candidates for a given target, we simply ignore that target for that particular method. This is to avoid giving Simple PPDB keenly omit employment opportunity remedied most strongly leave out a new job set right deeply delete it opportunity be fixed strongly be removed business opportunity be corrected eagerly forget about it the job to be resolved very be ignored labour be solved <ref type="table" target="#tab_6">Table 3</ref>: Examples of top-ranked simplifications proposed by Simple PPDB for several input words. Often, the best simplification for a single word is a multiword phrase, or vice-versa. These many-to-one mappings are overlooked when systems use only length or frequency as a proxy for simplicity.</p><p>an unfair advantage, since, by construction, PPDB will have full coverage of our list of 100 targets. In the end, the GlavasGenerator is evaluated over 95, the WordNetGenerator over 82, and the KauchakGenerator over 48. The results in <ref type="table" target="#tab_42">Table 4</ref> do not change significantly if we restrict all systems to the 48 targets which the KauchakGenerator is capable of handling. Since the GlavasGenerator is capable of producing an arbitrary number of candidates for each target, we limit the length of each of its candidate lists to be equal to the number of candidates produced by Simple PPDB for that same target.</p><p>Human judgments. For each of the proposed rules from all four systems, we collect human judgements on Amazon Mechanical Turk, using the same annotation interface as before. That is, we ask 7 workers to view each pair and indicate which of the two phrases is simpler, or to indicate that there is no difference. We take the majority label to be the true label for each rule. Workers show moderate agreement on the 3-way task (κ = 0.4 ± 0.03), with 14% of pairs receiving unanimous agreement and 37% receiving the same label from 6 out of 7 annotators. We note that the κ metric is likely a lower bound, as it punishes low agreement on pairs for which there is little difference in complexity, and thus the "correct" answer is not clear (e.g. for the pair matter, subject , 3 annotators say that matter is simpler, 2 say that subject is simpler, and 2 say there is no difference).</p><p>Results.  <ref type="table" target="#tab_42">Table 4</ref>: Precision of relative simplification rankings of three existing lexical simplification methods compared to the Simple PPDB resource in terms of Average Precision and P@1 (both range from 0 to 1 and higher is better). All of the existing methods were evaluated using the implementations as provided in the LEXenstein toolkit.</p><p>likely due to a combination of the additional features applied in Simple PPDB's model (e.g. word embeddings) and the difference in training data (Simple PPDB's model was trained on 11K paraphrase pairs with trinary labels, while the Horn et al. (2014) model was trained on 500 words, each with a ranked list of paraphrases).  Bold words were rated by humans to be simpler than the target word. Note that these candidates are judged on simplicity, not on their goodness as paraphrases.</p><p>In addition, Simple PPDB offers the largest coverage <ref type="table" target="#tab_23">(Table 6</ref>). It has a total vocabulary of 624K unique words and phrases, and provides the largest number of potential simplifications for  each target-for the 100 targets drawn from the Newsela corpus, PPDB provided an average of 8.8 candidates per target. The next best generator, the WordNet-based system, produces only 6.7 candidates per target on average, and has a total vocabulary of only 155K words.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Conclusion</head><p>We have described Simple PPDB, a subset of the Paraphrase Database adapted for the task of text simplification. Simple PPDB is built by applying state-of-the-art machine learned models for lexical simplification to the largest available resource of lexical and phrasal paraphrases, resulting in a web-scale resource capable of supporting research in data-driven methods for text simplification. We have shown that Simple PPDB offers substantially increased coverage of both words and multiword phrases, while maintaining high quality compared to existing methods for lexical simplification. Simple PPDB, along with the human judgements collected as part of its creation, is freely available with the publication of this paper. 6</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgments</head><p>This research was supported by a Facebook Fellowship, and by gifts from the Alfred P. Sloan Foundation, Google, and Facebook. This material is based in part on research sponsored by the NSF grant under IIS-1249516 and DARPA under number FA8750-13-2-0017 (the DEFT program). The U.S. Government is authorized to reproduce and distribute reprints for Governmental purposes. The views and conclusions contained in this publication are those of the authors and should not be interpreted as representing official policies or endorsements of DARPA and the U.S. Government. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Abstract</head><p>Named entity recognition, and other information extraction tasks, frequently use linguistic features such as part of speech tags or chunkings. For languages where word boundaries are not readily identified in text, word segmentation is a key first step to generating features for an NER system. While using word boundary tags as features are helpful, the signals that aid in identifying these boundaries may provide richer information for an NER system. New state-of-the-art word segmentation systems use neural models to learn representations for predicting word boundaries. We show that these same representations, jointly trained with an NER system, yield significant improvements in NER for Chinese social media. In our experiments, jointly training NER and word segmentation with an LSTM-CRF model yields nearly 5% absolute improvement over previously published results.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Entity mention detection, and more specifically named entity recognition (NER) <ref type="bibr">(Collins and Singer, 1999;</ref><ref type="bibr">McCallum and Li, 2003;</ref><ref type="bibr">Nadeau and Sekine, 2007;</ref><ref type="bibr">Jin and Chen, 2008;</ref><ref type="bibr">He et al., 2012)</ref>, has become a popular task for social media analysis <ref type="bibr">(Finin et al., 2010;</ref><ref type="bibr">Liu et al., 2011;</ref><ref type="bibr" target="#b71">Ritter et al., 2011;</ref><ref type="bibr">Fromreide et al., 2014;</ref><ref type="bibr">Liu et al., 2012a)</ref>. Many downstream applications that use social media, such as relation extraction <ref type="bibr">(Bunescu and Mooney, 2005)</ref> and entity linking <ref type="bibr">(Dredze et al., 2010;</ref><ref type="bibr">Ratinov et al., 2011)</ref>, rely on first identifying mentions of entities. Not surprisingly, accuracy of NER systems in social media trails state-of-the-art systems for news text and other formal domains. While this gap is shrinking in English <ref type="bibr" target="#b71">(Ritter et al., 2011;</ref><ref type="bibr">Cherry and Guo, 2015)</ref>, it remains large in other languages, such as Chinese <ref type="bibr">(Peng and Dredze, 2015;</ref><ref type="bibr">Fu et al., 2015)</ref>.</p><p>One reason for this gap is the lack of robust up-stream NLP systems that provide useful features for NER, such as part-of-speech tagging or chunking. <ref type="bibr" target="#b71">Ritter et al. (2011)</ref> annotated Twitter data for these systems to improve a Twitter NER tagger, however, these systems do not exist for social media in most languages. Another approach has been that of <ref type="bibr">Cherry and Guo (2015)</ref> and Peng and Dredze <ref type="formula" target="#formula_0">(2015)</ref>, who relied on training unsupervised lexical embeddings in place of these upstream systems and achieved state-of-the-art results for English and Chinese social media, respectively. The same approach was also found helpful for NER in the news domain <ref type="bibr">(Collobert and Weston, 2008;</ref><ref type="bibr">Passos et al., 2014)</ref> In Asian languages like Chinese, Japanese and Korean, word segmentation is a critical first step for many tasks <ref type="bibr">(Gao et al., 2005;</ref><ref type="bibr" target="#b695">Zhang et al., 2006;</ref><ref type="bibr">Mao et al., 2008)</ref>. <ref type="bibr">Peng and Dredze (2015)</ref> showed the value of word segmentation to Chinese NER in social media by using character positional embeddings, which encoded word segmentation information.</p><p>In this paper, we investigate better ways to incorporate word boundary information into an NER system for Chinese social media. We combine the state-of-the-art Chinese word segmentation system  with the best Chinese social media NER model <ref type="bibr">(Peng and Dredze, 2015)</ref>. Since both systems used learned representations, we propose an integrated model that allows for joint training learned representations, providing more information to the NER system about hidden representations learned from word segmentation, as compared to features based on segmentation output. Our integrated model achieves nearly  <ref type="table">Table   c</ref> Input For CWS</p><formula xml:id="formula_76">C (1) …… C (n-1) C (n)</formula><p>Figure 1: The joint model for Chinese word segmentation and NER. The left hand side is an LSTM module for word segmentation, and the right hand side is a traditional feature-based CRF model for NER. Note that the linear chain CRF for NER has both access to the feature extractor specifically for NER and the representations produced by the LSTM module for word segmentation. The CRF in this version is a log-bilinear CRF, where it treats the embeddings and hidden vectors inputs as variables and modifies them according to the objective function. As a result, it enables propagating the gradients back into the LSTM to adjust the parameters. Therefore, the word segmentation and NER training share all the parameters of the LSTM module. This facilitates the joint training. a 5% absolute improvement over the previous best results on both NER and nominal mentions for Chinese social media.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Model</head><p>We propose a model that integrates the best Chinese word segmentation system  using an LSTM neural model that learns representations, with the best NER model for Chinese social media <ref type="bibr">(Peng and Dredze, 2015)</ref>, that supports training neural representations by a log-bilinear CRF. We begin with a brief review of each system.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">LSTM for Word Segmentation</head><p>Chen et al. <ref type="formula" target="#formula_0">(2015)</ref> proposed a single layer, left to right LSTM for Chinese word segmentation. An LSTM is a recurrent neural network (RNN) which uses a series of gates (input, forget and output gate) to control how memory is propagated in the hidden states of the model. For the Chinese word segmentation task, each Chinese character is initialized as a d dimensional vector, which the LSTM will modify during its training. For each input character, the model learns a hidden vector h. These vectors are then used with a biased-linear transformation to predict the output labels, which in this case are Begin, Inside, End, and Singleton. A prediction for position t is given as:</p><formula xml:id="formula_77">y (t) = W o h (t) + b o (1)</formula><p>where W o is a matrix for the transformation parameters, b o is a vector for the bias parameters, and h (t) is the hidden vector at position t. To model the tag dependencies, they introduced the transition score A ij to measure the probability of jumping from tag i ∈ T to tag j ∈ T .</p><p>We used the same model as  trained on the same data (segmented Chinese news article). However, we employed a different training objective.  employed a max-margin objective, however, while they found this objective yielded better results, we observed that maximum-likelihood yielded better segmentation results in our experiments 1 . Additionally, we sought to integrate their model with a logbilinear CRF, which uses a maximum-likelihood training objective. For consistency, we trained the LSTM with a maximum-likelihood training objective as well. The maximum-likelihood CRF objective function for predicting segmentations is:</p><formula xml:id="formula_78">L s (y s ; x s , Θ) = 1 K k log 1 Z(x s ) k + i T s (y k i−1 , y k i ) + s(y k i ; x k s , Λ s ) (2)</formula><p>Example pairs (y s , x s ) are word segmented sentences, k indexes examples, and i indexes positions in examples. T s (y k i−1 , y k i ) are standard transition probabilities learned by the CRF 2 . The LSTM parameters Λ s are used to produce s(y k i ; x k s , Λ s ), the emission probability of the label at position i for input sentence k, which is obtained by taking a soft-max over (1). We use a first-order Markov model.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Log-bilinear CRF for NER</head><p>Peng and Dredze <ref type="formula" target="#formula_0">(2015)</ref> proposed a log-bilinear model for Chinese social media NER. They used standard NER features along with additional features based on lexical embeddings. By fine-tuning these embeddings, and jointly training them with a word2vec  objective, the resulting model is log-bilinear.</p><p>Typical lexical embeddings provide a single embedding vector for each word type. However, Chinese text is not word segmented, making the mapping between input to embedding vector unclear. Peng and Dredze (2015) explored several types of representations for Chinese, including pre-segmenting the input to obtain words, using character embeddings, and a combined approach that learned embeddings for characters based on their position in the word. This final representation yielded the largest improvements.</p><p>We use the same idea but augmented it with LSTM learned representations, and we enable interaction between the CRF and the LSTM parameters. More details are described in ( §2.3).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Using Segmentation Representations to Improve NER</head><p>The improvements provided by character position embeddings demonstrated by <ref type="bibr">Peng and Dredze (2015)</ref> indicated that word segmentation information can be helpful for NER. Embeddings aside, a simple way to include this information in an NER system would be to add features to the CRF using the predicted segmentation labels as features. However, these features alone may overlook useful information from the segmentation model. Previous work showed that jointly learning different stages of the NLP pipeline helped for Chinese <ref type="bibr">(Liu et al., 2012b;</ref><ref type="bibr" target="#b697">Zheng et al., 2013)</ref>. We thus seek approaches for deeper interaction between word segmentation and NER models. The LSTM word segmentor learns two different types of representations: 1) embeddings for each character and 2) hidden vectors for predicting segmentation tags. Compressing these rich representations down to a small feature set imposes a bottleneck on using richer word segmentation related information for NER. We thus experiment with including both of these information sources directly into the NER model.</p><p>Since the log-bilinear CRF already supports joint training of lexical embeddings, we can also incorporate the LSTM output hidden vectors as dynamic features using a joint objective function.</p><p>First, we augment the CRF with the LSTM parameters as follows:</p><formula xml:id="formula_79">L n (y n ; x n , Θ) = 1 K k log 1 Z(x n ) k + j Λ j F j (y k n , x k n , e w , h w ) ,<label>(3)</label></formula><p>where k indexes instances, j positions, and</p><formula xml:id="formula_80">Fj(y k , x k , ew, hw) = n i=1 fj(y k i−1 , y k i , x k , ew, hw, i)</formula><p>represents the feature functions. These features now depend on the embeddings learned by the LSTM (e w ) and the LSTM's output hidden vectors (h w ). Note that by including h w alone we create dependence on all LSTM parameters on which the hidden states depend (i.e. the weight matrices). We experiment with including input embeddings and output hidden vectors independently, as well as both parameters together. An illustration of the integrated model is shown in <ref type="figure" target="#fig_3">Figure 1</ref>.</p><p>Joint Training In our integrated model, the LSTM parameters are used for both predicting word segmentations and NER. Therefore, we consider a joint training scheme. We maximize a (weighted) joint objective:</p><formula xml:id="formula_81">L joint (Θ) = λL s (y s ; x s , Θ) + L n (y n ; x n , Θ)<label>(4)</label></formula><p>where λ trades off between better segmentations or better NER, and Θ includes all parameters used in both models. Since we are interested in improving NER we consider settings with λ &lt; 1. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Parameter Estimation</head><p>We train all of our models using stochastic gradient descent (SGD.) We train for up to 30 epochs, stopping when NER results converged on dev data. We use a separate learning rate for each part of the joint objective, with a schedule that decays the learning rate by half if dev results do not improve after 5 consecutive epochs. Dropout is introduced in the input layer of LSTM following . We optimize two hyper-parameters using held out dev data: the joint coefficient λ in the interval [0.5, 1] and the dropout rate in the interval [0, 0.5]. All other hyper-parameters were set to the values given by  for the LSTM and Peng and Dredze <ref type="formula" target="#formula_0">(2015)</ref> for the CRF.</p><p>We train the joint model using an alternating optimization strategy. Since the segmentation dataset is significantly larger than the NER dataset, we subsample the former at each iteration to be the same size as the NER training data, with different subsamples in each iteration. We found subsampling critical and it significantly reduced training time and allowed us to better explore the hyperparameter space.</p><p>We initialized LSTM input embeddings with pre-trained character-positional embeddings trained on 112,971,734 Weibo messages to initialize the input embeddings for LSTM. We used word2vec  with the same parameter settings as Peng and Dredze <ref type="formula" target="#formula_0">(2015)</ref> to pre-train the embeddings.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Experiments and Analysis</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Datasets</head><p>We use the same training, development and test splits as  for word segmentation and Peng and Dredze <ref type="formula" target="#formula_0">(2015)</ref> for NER.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Word Segmentation</head><p>The segmentation data is taken from the SIGHAN 2005 shared task. We used the PKU portion, which includes 43,963 word sentences as training and 4,278 sentences as test. We did not apply any special preprocessing.</p><p>NER This dataset contains 1,890 Sina Weibo messages annotated with four entity types (person, organization, location and geo-political entity), including named and nominal mentions. We note that the word segmentation dataset is significantly larger than the NER data, which motivates our subsampling during training ( §3). <ref type="table" target="#tab_10">Table 1</ref> shows results for NER in terms of precision, recall and F1 for named (left) and nominal (right) mentions on both dev and test sets. The hyper-parameters are tuned on dev data and then applied on test. We now explain the results.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Results and Analysis</head><p>We begin by establishing a CRF baseline (#1) and show that adding segmentation features helps (#2). However, adding those features to the full model (with embeddings) in Peng and Dredze (2015) (#3) did not improve results (#4). This is probably because the character-positional embeddings already carry segmentation information. Replacing the character-positional embeddings with character embeddings (#5) gets worse results than (#3), but benefits from adding segmentation features (#6). This demonstrates both that word segmentation helps and that character-positional embeddings effectively convey word boundary information.</p><p>We now consider our model of jointly training the character embeddings (#9), the LSTM hidden vectors (#10) and both (#11). They all improve over the best published results (#3). Jointly training the LSTM hidden vectors (#10) does better than jointly training the embeddings (#9), probably because they carry richer word boundary information. Using both representations achieves the single best result (#11): 4.3% improvement on named and 5.3% on nominal mentions F1 scores.</p><p>Finally, we examine how much of the gain is from joint training versus from pre-trained segmentation representations. We first train an LSTM for word segmentation, then use the trained embeddings and hidden vectors as inputs to the logbilinear CRF model for NER, and fine tune these representations. This (#7) improved test F1 by 2%, about half of the overall improvements from joint training.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Discussion</head><p>Huang et al. <ref type="formula" target="#formula_0">(2015)</ref> first proposed recurrent neural networks stacked with a CRF for sequential tagging tasks, as was applied to POS, chunking and NER tasks. More recent efforts have been made to add character level modeling and explore different types of RNNs <ref type="bibr">(Lample et al., 2016;</ref><ref type="bibr">Ma and Hovy, 2016;</ref><ref type="bibr">Yang et al., 2016)</ref>. These methods have achieved state-of-the-art results for NER on English news and several other Indo-European languages. However, this work has not considered languages that require word segmentation, nor do they consider social media.</p><p>We can view our method as multi-task learning <ref type="bibr">(Caruana, 1997;</ref><ref type="bibr">Ando and Zhang, 2005;</ref><ref type="bibr">Collobert and Weston, 2008)</ref>, where we are using the same learned representations (embeddings and hidden vectors) for two tasks: segmentation and NER, which use different prediction and decoding layers. Result #8 shows the effect of excluding the additional NER features and just sharing a jointly trained LSTM 3 . While this does not perform as well as adding the additional NER features (#11), it is impressive that this simple architecture achieved similar F1 as the best results in Peng and Dredze (2015). While we may expect both NER and word segmentation results to improve, we found the segmentation performances of the best joint model tuned for NER lose to the stand alone word segmentation model (F1 of 90.7% v.s. 93.3%). This lies in the fact that tuning λ means choosing between the two tasks; no single setting achieved improvements for both, which suggests further work is needed on better model structures Second, our segmentation data is from the news domain, whereas the NER data is from social media. While it is well known that segmentation systems trained on news do worse on social media <ref type="bibr">(Duan et al., 2012)</ref>, we still show large improvements in applying our model to these different domains. It may be that we are able to obtain better results in the case of domain mismatch because we integrate the representations of the LSTM model directly into our CRF, as opposed to only using the predictions of the LSTM segmentation model. We plan to consider expanding our model to explicitly include domain adaptation mechanisms <ref type="bibr">(Yang and Eisenstein, 2015</ref> </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Multiword expressions (MWEs) are notoriously challenging for NLP, due to their many potential levels of idiosyncrasy, from lexical to semantic and pragmatic to statistical <ref type="bibr">(Sag et al., 2002;</ref><ref type="bibr">Ramisch, 2015)</ref>. One widely known problem is the semantic interpretation of noun compounds, which in English are noun phrases composed by a sequence of nouns. These MWEs often lack a structure from which to identify implicit semantic relations unambiguously. For instance, there is no indication that a brick wall is a wall made of bricks, while a cheese knife is not a knife made of cheese, but rather a knife for cutting cheese <ref type="bibr">(Girju et al., 2005)</ref>.</p><p>Noun compounds are often idiomatic or noncompositional. That is, the meaning of the whole does not come directly from the meaning of the parts. For instance, a black Friday is not any Friday that is somehow black, but is the day following Thanksgiving Day in the United States. Moreover, the contribution of the semantics of each element for the meaning of the compound may vary considerably (e.g. police car vs. crocodile tears). Any NLP application that intends to deal with phrasal semantics adequately must be able to distinguish fairly compositional from fully idiomatic compounds. For example, automatically translating dead end literally into French (?fin morte) or Portuguese (?fim morto) would drastically alter the meaning of the original expression. In this paper we introduce a resource with human judgments about the semantics of compounds and their individual elements.</p><p>Eliciting quantitative judgments about compositionality from non-linguists may be too abstract, even with accompanying guidelines and training. We propose a more constrained way of obtaining these judgments, with the participation of non-experts through crowdsourcing. We first focus the participants' attention on compound interpretation in context, by requesting paraphrases in example sentences. Then, we inquire about the degree to which the meaning of a given compound arises from each of its elements. The assumption is that if the interpretation of the compound comes from both nouns (e.g. access road), then it is fully compositional, whereas if it is unrelated to both nouns (e.g. nut case), then it is fully idiomatic. This indirect annotation does not require expert knowledge and provides reliable and stable data. This paper presents a multilingual resource that models compounds compositionality, including both numerical scores and free paraphrases. Data is currently available for 180 compounds in 3 different languages: English, French and Portuguese. Such resources are extremely valuable, as they enable the development and evaluation of techniques for automatic compositionality prediction and lexical substitution. This paper is structured as follows: §2 discusses related work; §3 discusses the target compounds, the annotation schema and interface; §4 presents the results and §5 the conclusions and future work.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Related Work</head><p>There are many proposals in the literature to represent the semantics of nominal compounds. Lauer <ref type="bibr">(1995)</ref> argues that prepositions (such as from, for, in) provide information about the role of each noun in a compound (e.g. olive oil is oil from olives). These prepositions are explicitly part of some nominal compounds in Romance languages (e.g. huile d'olive in French and azeite de oliva in Portuguese). <ref type="bibr">Girju et al. (2005)</ref> present and compare several inventories of semantic relations between nouns, from fine-grained to coarse senses. These relations include syntactic and semantic classes such as subject, instrument and location. Free paraphrases have also been used to model noun compound semantics. <ref type="bibr">Nakov (2008)</ref> suggests using unsupervised generation of paraphrases combined with web search engines to classify nominal compounds. This was further extended in SemEval 2013, in a task where free paraphrases were ranked according to their relevance for explicitly describing the underlying semantic relations in the compounds <ref type="bibr">(Hendrickx et al., 2013)</ref>. For instance, for the MWE flu virus, paraphrases involving the verbs cause, spread and create (virus that causes/spreads/creates flu) were in the top of the rank. Some authors model the meaning of compounds using numerical compositionality scores: low values mean completely idiomatic compounds while high values represent compositional ones. Separate scores can be provided for the amount of meaning provided by each individual word. For instance, olive oil could be 80% related to olives and 100% related to oil, whereas dead end is 5% dead and 90% an end. Some datasets that employ a numerical representation for different types of MWE are:</p><p>• Baldwin and Villavicencio <ref type="formula" target="#formula_1">(2002)</ref>  <ref type="formula" target="#formula_0">(2015)</ref>: individual binary judgments for non-compositionality and conventionality for 1,042 English noun compounds, annotated by 4 experts. One possible source of divergence among annotators is that some datasets do not take polysemy into account. Authors ask annotators to think about the most common sense of an MWE without providing context. Some of these datasets address this issue by providing example sentences to attenuate this problem. We also employ this strategy in our questionnaires. The most similar datasets to ours are the ones presented by Reddy et al. <ref type="formula" target="#formula_0">(2011)</ref> and <ref type="bibr">Hendrickx et al. (2013)</ref>. Our dataset combines the methodology from both of these, extending it to French and Portuguese.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Dataset Construction</head><p>Although noun-noun compounds are rare in some languages mainly due to syntactic reasons, these languages present alternatives to this type of configuration. In French (FR) and Brazilian Portuguese (PT), the equivalents of English (EN) compounds of the form N 1 N 2 are usually:</p><p>1. N 2 PREP N 1 , connecting the nouns through a preposition and optional determiner; e.g. lung cancer (EN) → cancer du poumon (FR), câncer de pulmão (PT). 2. N 2 ADJ 1 , using a denominal adjective which is derived from N 1 ; e.g. cell death (EN) → mort cellulaire (FR), morte celular (PT). We describe the construction of datasets for English, French and Brazilian Portuguese. Given the two syntactic forms above, we focus on N 2 ADJ 1 for French and Portuguese, as its simpler structure resembles more closely the English noun-noun compound structure, and also because we have some ADJ 1 N 2 compounds in English as well (e.g. sacred cow). We collectively call our target constructions nominal compounds, as they have nouns as head of the phrase.</p><p>For each language, data collection involves the following steps: (1) compound selection; (2) sentence selection; and <ref type="formula" target="#formula_6">(3)</ref> questionnaire design.</p><p>Compound selection The initial set of idiomatic and partially compositional candidates was constructed by introspection, independently for each language, since these may be harder to find in corpora because of lower frequency. This list of compounds was complemented by selecting entries from lists of frequent adjective+noun and noun+noun pairs. These were automatically extracted through POS-sequence queries using the mwetoolkit (Ramisch, 2015) from ukWaC <ref type="bibr">(Baroni et al., 2009</ref>), frWaC and brWaC <ref type="bibr">(Boos et al., 2014)</ref>. We removed all compounds in which the complement is not an adjective in Portuguese/French (e.g. PT noun-noun abelha rainha), those in which the head is not necessarily a noun (e.g. FR aller simple, as aller is also a verb) and those in which the literal sense is very common in the corpus (e.g. EN low blow). For each language, we attempted to select a balanced set of 60 idiomatic, 60 partially compositional and 60 fully compositional compounds by rough manual preannotation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>1</head><p>Sentence selection For each compound, we selected 3 sentences from a WaC corpus where the compound is used with the same meaning. These sentences are used during the data collection process (described later) as disambiguating context for the annotators. We sort them by sentence length, in order to favor shorter sentences, and manually select 3 examples that satisfy these criteria:</p><p>• The occurrence of the compound must have the same meaning in all sentences.</p><p>• A sentence must contain enough context to enable mental disambiguation of the compound.</p><p>• Inter-sentence variability can be used to provide more information to the reader. Questionnaire design We collect data for each compound through a separate HIT (Human Intelligence Task). Each HIT page contains a list of instructions followed by the questionnaire associated with that compound. In the instructions, we briefly describe the task and require that the users fill in an external identification form, following <ref type="bibr">Reddy et al. (2011)</ref>. This form provides us with demographics about the annotators, ensuring that they are native speakers of the target language. At the end of the form, they are also given extra example questions with annotated answers for training. After filling in the identification form, users can start working on the task. This section of the HIT is structured in 5 subtasks: 1. Read the compound itself. 2. Read 3 sentences containing the compound. 3. Provide 2 to 3 synonym expressions for the target compound seen in the sentences. 4. Using a Likert scale from 0 to 5, judge how much of the meaning of the compound comes from word 1 (mod) and word 2 (head) separately, as shown in <ref type="figure" target="#fig_3">Figure 1</ref>. 5. Using a Likert scale from 0 to 5, judge how much of the meaning of the compound (comp) comes from its components. We have been consciously careful about requiring answers in an even-numbered scale (0-5 makes for 6 reply categories), as otherwise, undecided annotators would be biased towards the middle score. As an additional help for the annotators, when the mouse hovers over a reply to a multiple-choice question, we present a guiding tooltip, as in <ref type="figure" target="#fig_3">Figure 1</ref>. We avoid incomplete HITs by making Subtasks 3-5 mandatory.</p><p>The order of subtasks has also been taken into account. During a pilot test, we found that presenting the multiple-choice questions (Subtasks 4-5) before asking for synonyms (Subtask 3) yielded lower agreement, as users were often less self-consistent in the multiplechoice questions (e.g. replying "non-compositional" for Subtask 4 but "compositional" for Subtask 5), even if they carefully selected their synonyms in response to Subtask 3. Asking for synonyms prior to the multiplechoice questions helps the user focus on the target meaning for the compound and also have more examples (the synonyms) when considering the semantic contribution of each element of the compound.</p><p>For EN and FR, annotators were recruited and paid via Amazon Mechanical Turk. The quality of FR results was manually controlled by only accepting HITs with reasonable paraphrases. During a pilot, we noticed the lack of qualified PT native speakers on the platform. For PT only, judgments were provided by volunteers through a standalone web interface that simulated the HIT page.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Results</head><p>For each compound, we have collected judgments from around 15 HITs. The average of these scores, for EN 2 , FR and PT, are shown in <ref type="figure" target="#fig_8">Figure 2</ref>. The compositionality judgments for the compounds confirm that they are balanced with respect to idiomaticity. Moreover, there seems to be a greater agreement between the score for the compound and that of its head (or modifier) for the two extremes (totally idiomatic and fully compositional). For PT and FR, in particular, the compound score seems to be a lower bound to each member word's score.</p><p>We also looked at the distribution of each of the scores around the mean in terms of the standard deviation (σ). Ideally, if all the annotators agreed on compositionality, σ should be low. We calculated for each language the number of compounds, heads and modifiers with standard deviations greater than 1.5 <ref type="table" target="#tab_10">(Table  1)</ref>  Out of all human judges, 3 of them annotated a large subset of 119 compounds in PT. For this subset, we report inter-annotator agreement. Pairwise weighted κ values range from .28 to .58 depending on the question (head, mod or comp) and on the annotator pair. Multi-rater α agreement <ref type="bibr" target="#b11">(Artstein and Poesio, 2008)</ref> values are α = .52 for head, α = .36 for mod and α = .42 for comp scores. We have also calculated the α score of an expert annotator with himself, performing the same task a few weeks later. The score ranges from  0.59 for modifiers and compounds to 0.69 for heads. This seems to confirm the hypothesis that modifiers are harder to annotate than heads. <ref type="table" target="#tab_5">Table 2</ref> presents the most controversial compounds, along with the ones that had highest agreement (lowest σ). The most consensual compounds are mostly 100% compositional and sometimes 100% idiomatic. Low σ values are consistent among the three questions, indicating that some compounds are simply easier to judge than others.</p><p>There are multiple reasons for divergences in the judgment scores. For some MWEs, our sentences were not enough for disambiguation; e.g. one of the fish story sentences talked about a whale and prompted literal interpretations of fish for some judges). Other differences have been caused by the interpretation of uncommon words; e.g. the PT noun olhado does not appear by itself very often; some judges seem to have interpreted it as an adjective and thus concluded that mau-olhado (evil eye, lit. bad-glance) has a fully non-compositional head. Finally, some differences have been caused by whether speakers had incorporated a new meaning into their lexicon; e.g. EN speakers agreed on the level of head and head+modifier compositionality for dirty word, but disagreed when judging the modifier: it is fully idiomatic for some, while just containing an uncommon sense of dirty for others.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Conclusions and Future Work</head><p>We presented a multilingual dataset of nominal compounds containing human judgments about compositionality. It contains 180 compounds for each of the 3 target languages: English, French and Portuguese. Annotations are collected through crowdsourcing. Since the task is performed by native speakers who may not have a background in linguistics, it needs to be appropriately constrained not to require expert knowledge. The resulting resource can be used for applications and tasks involving some degree of semantic processing, such as lexical substitution and text simplification. For the cases where the numerical judgments alone are not enough for a given task, our dataset also provides sets of paraphrases, which serve as a symbolic counterpart to those scores. The complete resource will be made freely available. <ref type="bibr" target="#b471">3</ref> As future work, we plan to validate these scores through compositionality prediction (Yaz-    <ref type="bibr">Salehi et al., 2015)</ref> and by incorporating the scores and paraphrases into a machine translation system. We also envisage extending the dataset for each of the languages and for additional languages. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>While a considerable amount of linguistic research has been carried out on sign languages to date, work in automatic sign language processing is still in its infancy. Automatic sign language processing comprises applications such as sign language recognition, sign language synthesis, and sign language translation <ref type="bibr">(Sáfár and Glauert, 2012)</ref>. For all of these applications, drawing on the expertise of native signers, sign language linguists and sign language interpreters is crucial. These different types of sign language experts may exhibit varying degrees of computer literacy. In the past, their contribution to the development of systems that automatically translate into sign language has been restricted mostly to the provision of transcribed and/or annotated sign language data. In this paper, we report on the development and evaluation of a platform that allows sign language experts with modest computational skills to play a more active role in sign language machine translation. The platform enables these users to independently develop and run applications translating speech into synthesized sign language through a web interface. Synthesized sign language is presented by means of a signing avatar. To the best of our knowledge, our platform is the first to facilitate low-threshold speech-to-sign translation, opening up various possible use cases, e.g. that of communicating with a Deaf customer in a public service setting like a hospital, train station or bank. 1 By pursuing a rule-based translation approach, the platform also offers new possibilities for empirical investigation of sign language linguistics: the linguist can concretely implement a fragment of a hypothesized sign language grammar, sign a range of generated utterances through the avatar, and obtain judgements from Deaf informants.</p><p>The remainder of this paper is structured as follows. Section 2 presents background and related work. Section 3 describes the architecture of the speech-to-sign platform. Section 4 reports on a preliminary evaluation of the usability of the platform and of translations produced by the platform. Section 5 offers a conclusion and an outlook on future research questions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Background and related work</head><p>There has been surprisingly little work to date on speech to sign language translation. The bestperforming system reported in the literature still appears to be TESSA <ref type="bibr">(Cox et al., 2002)</ref>, which translated English speech into British Sign Language (BSL) in a tightly constrained post office counter service domain, using coverage captured in 370 English phrasal patterns with associated BSL translations. The system was evaluated in a realistic setting in a British post office, with three post office clerks on the hearing side of the dialogues and six Deaf subjects playing the role of customers, and performed creditably. Another substantial project is the one described by <ref type="bibr">SanSegundo et al. (2008)</ref>, which translated Spanish speech into Spanish Sign Language; this, however, does not appear to have reached the stage of being able to achieve reasonable coverage even of a small domain, and the evaluation described in the paper is restricted to comprehensibility of signs from the manual alphabet. <ref type="bibr">2</ref> It is reasonable to ask why so little attention has been devoted to what many people would agree is an important and interesting problem, especially given the early success of TESSA. Our own experiences, and those of other researchers we have talked to, suggest that the critical problem is the high barrier to entry: in order to build a speechto-sign system, it is necessary to be able to combine components for speech recognition, translation and sign language animation. The first two technologies are now well-understood, and good platforms are readily available. Sign language animation is still, however, a niche subject, and the practical problems involved in obtaining usable sign language animation components are nontrivial. The fact that <ref type="bibr">San-Segundo et al. (2008)</ref> chose to develop their own animation component speaks eloquently about the difficulties involved.</p><p>There are three approaches to sign language animation: hand-crafted animation, motion capturing and synthesis from form notation <ref type="bibr">(Glauert, 2013)</ref>. Hand-crafted animation consists of manually modeling and posing an avatar character. This procedure typically yields high-quality results but is very labor-intensive. A signing avatar may also be animated based on information obtained from motion capturing, which involves recording a human's signing. Although sign language animations obtained through motion capturing also tend to be of good quality, the major drawback of this approach is the long calibration time and extensive postprocessing required.</p><p>Synthesis from form notation permits construction of a fully-fledged animation system that allows synthesis of any signed form that can be described through the associated notation. Avatar signing synthesized from form notation is the most flexible in that it is able to render dynamic content, e.g. display the sign language output of a machine translation system, present the contents of a sign language wiki or an e-learning application, visualize lexicon entries or present public transportation information <ref type="bibr">(Efthimiou et al., 2012;</ref><ref type="bibr">Kipp et al., 2011)</ref>. At the same time, this approach to sign language animation typically results in the lowest quality: controlling the appearance of all possible sign forms that may be produced from a given notation is virtually impossible.</p><p>The most comprehensive existing sign language animation system based on synthesis from form notation is undoubtedly JASigning <ref type="bibr">(Elliott et al., 2008;</ref><ref type="bibr">Jennings et al., 2010)</ref>, a distant descendant of the avatar system used in TESSA which was further developed over the course of the eS-IGN and DictaSign European Framework projects. JASigning performs synthesis from SiGML <ref type="bibr">(Elliott et al., 2000)</ref>, an XML-based representation of the physical form of signs based on the wellunderstood Hamburg Notation System for Sign Languages (HamNoSys) <ref type="bibr">(Prillwitz et al., 1989)</ref>. HamNoSys can be converted into SiGML in a straightforward fashion. Unfortunately, despite its many good and indeed unique properties, JASigning is a piece of research software that in practice has posed an insurmountable challenge to most linguists without a computer science background.</p><p>The basic purpose of the Lite Speech2Sign project can now be summarised in a sentence: we wished to package JASigning together with a state-of-the-art commercial speech recognition platform and a basic machine translation framework in a way that makes the combination easily usable by sign language linguists who are not software engineers. In the rest of the paper, we describe the result.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="163">3 The Lite Speech2Sign platform</head><p>The fact that the Lite Speech2Sign platform is intended primarily for use by sign language experts who may only have modest skills in computer science has dictated several key design decisions. In particular, 1) the formalism used is simple and minimal and 2) no software need be installed on the local machine: all processing (compilation, deployment, testing) is performed on a remote server accessed through the web interface.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Runtime functionality and formalism</head><p>At runtime, the basic processing flow is speech → source language text → "sign table" → SiGML → signed animation. Input speech, source language text and signed animation have their obvious meanings, and we have already introduced SiGML in the preceding section. At the input end of the pipeline, speech recognition is carried out using the Nuance Recognizer 10.2 platform, equipped with domain-specific language models compiled from the grammar. At the output end, SiGML is converted into signed animation form using the JASigning avatar system.</p><p>The "sign table", the level which joins all these pieces together, is an intermediate representation modelled on the diagrams typically used in theoretical sign language linguistics to represent signed utterances. A sign table is, concretely, a matrix whose rows represent the different parallel channels of signed language output (manual activities, gaze, head movements, mouth movements, etc). The only obligatory row is the one for manual activities, which consists of a sequence of "glosses", each gloss referring to one manual activity. There is one column for each gloss/manual activity in the signed utterance.</p><p>The usefulness of this representation is dependent on the appropriateness of the assumption that sign language is timed so that each non-manual activity can be assumed synchronous with some manual activity. This has been shown to be true for non-manual activities that serve linguistic functions. Non-manual activities that serve purely affective purposes, e.g., expressing anger or disgust, are known to start slightly earlier than the surrounding manual activities (Reilly and <ref type="bibr">Anderson, 2002;</ref><ref type="bibr">Wilbur, 2000)</ref>. A restriction imposed by the low-level SiGML representation is that nonmanual activities cannot be extended across several manual activities in a straightforward way;  however, workarounds have been introduced for this <ref type="bibr">(Ebling and Glauert, 2015)</ref>. Experience with SiGML has shown that it is capable of supporting signed animation of satisfactory quality <ref type="bibr">(Smith and Nolan, 2015)</ref>.</p><p>The core translation formalism is a version of Synchronous Context Free Grammar (SCFG; <ref type="bibr" target="#b12">(Aho and Ullman, 1969;</ref><ref type="bibr">Chiang, 2005)</ref>) adapted to the peculiarities of sign language translation. A complete toy application definition is shown in <ref type="figure" target="#fig_3">Figure 1</ref>. The top-level Utterance rule translates French expressions of the form Je m'appelle NAME ("I am called NAME ") to Swiss French Sign Language (LSF-CH) expressions of a form that can be glossed as MOI S_APPELER NAME together with accompanying non-manual components; for example, the manual activity MOI (signed by pointing at one's chest) is here performed together with a head nod, raised eyebrows, widened eyes, and a series of mouth movements approximating the shapes used to say "mwe". The two TrPhrase rules translate the names "Claude" and "Marie" into fingerspelled forms with accompanying mouthings.</p><p>The mapping between the sign table and SiGML levels is specified using three other types of declarations, defined in the resource lexica listed in the initial include lines. 1) Glosses are associated with strings of HamNoSys symbols; in this case, the resource lexicon used is lsf_ch.csv, a CSV spreadsheet whose columns are glosses and HNS strings for LSF-CH signs. 2) Symbols in the non-manual rows (Head, Gaze, etc) are mapped into the set of SiGML tags supported by the avatar, according to the declarations in the sign-language-independent resource file visicast.txt.</p><p>3) The Mouthing line is treated specially. Two types of mouthings are supported: "mouth pictures", approximate mouthings of phonemes, are written as SAMPA (Wells, 1997) strings (e.g. mwe is a SAMPA string). It is also possible to use the repertoire of "mouth gestures" (mouth movements not related to spoken language words, produced with teeth, jaw, lips, cheeks, or tongue) supported by the avatar, again using definitions taken from the visicast.txt resource file. For example, L23 denotes pursed lips <ref type="bibr">(Hanke, 2001)</ref>.</p><p>The Domain unit at the top defines the name of the translation app, the source language 3 and sign language channels, and the type of web client used to display it.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Compile-and deploy-time functionality</head><p>The compilation process takes application descriptions like the one above as input and transforms them first into SCFG grammars, then into GrXML grammars 4 , and finally into runnable Nuance recognition grammars. The compiler also produces tables of metadata listing associations between symbols and HamNoSys, SAMPA, and SiGML constants.</p><p>Two main challenges needed to be addressed when designing the compile-time functionality. The first was to make the process of developing, uploading, compiling, and deploying web-based speech applications simple to invoke, so that these operations could be performed without detailed understanding of the underlying technology. The second was to support development on a shared server; here, it is critical to ensure that a developer who uploads bad content is not able to break the system for other users.</p><p>At an abstract level, the architecture is as follows. Content is divided into separate "namespaces", with each developer controlling one or more namespaces; a namespace in turn contains one or more translation apps. At the source level, each namespace is a self-contained directory, and each app a self-contained subdirectory.</p><p>From the developer's point of view, the whole upload/compile/deploy cycle reduces to a simple progression across a dashboard with four tabs labeled "Select", "Compile", "Test", and "Release". The developer starts the upload/compile/deploy cycle by uploading one or more namespace directories over an FTP client and choosing one of them from the "Select" tab.</p><p>The platform contains three separate servers, respectively called compilation, staging, and deployment. After selecting the app on the first tab, the developer moves to the second one and presses the "Compile" button to invoke the compilation server. Successful compilation results in a Nuance grammar recognition module and a set of namespace-specific table entries; a separate Nuance recognition grammar is created for each namespace. As part of the compilation process, a set of files is also created which list undefined constants. These can be downloaded over the FTP connection and are structured so as to make it easy for the developer to fill in missing entries and add the new content to the resource files.</p><p>When the app has compiled, the developer proceeds to the third, "Staging" tab, and presses the "Test" button. This initiates a process which copies the compiled recognition grammar, table entries and metadata to appropriate places on the staging server and registers the grammar as available for use by the recognition engine, after which the developer can interactively test the application through the web interface. It is important that only copying actions are performed by the "Staging" server; experience shows that recompiling applications can often lead to problems if the compiler changes after an application is uploaded.</p><p>When the developer is satisfied with the application, they move to the fourth tab and press the "Release" button. This carries out a second set of copying operations which transfer the application to the deployment server.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Initial experiences with the platform</head><p>The Lite Speech2Sign platform is undergoing initial testing; during this process, we have constructed half a dozen toy apps for the translation directions French → LSF-CH and German → Swiss German Sign Language, and one moderately substantial app for French → LSF-CH. Grammars written so far all have a flat structure.</p><p>Our central claims regarding the platform are that it greatly simplifies the process of building a speech-to-sign application and allows rapid construction of apps which produce signed language of adequate quality. To give some substance to these statements, we tracked the construction of a small French → LSF-CH medical questionnaire app and performed a short evaluation. The app was built by a sign language expert whose main qualifications are in sign language interpretation. The expert began by discussing the corpus with Deaf native signers, to obtain video-recorded material on which to base development. They then implemented rules and HNS entries, uploaded, debugged, and deployed the content, and used the deployed system to perform the evaluation.</p><p>Rule-writing typically required on the order of ten to fifteen minutes per rule, using a method of repeatedly playing the recorded video and entering first the gloss line and then the accompanying non-manual lines. Uploading, debugging, and deployment of the app was completely straightforward and took approximately one hour. The most time-consuming part of the process was implementing HNS entries for signs missing from the current LSF-CH HNS lexicon. The time required per entry varied a great deal depending on the sign's complexity, but was typically on the order of half an hour to two hours. This part of the task will of course become less important as the HNS lexicon resource becomes more complete.</p><p>The evaluation was carried out with five Deaf subjects and based on recommendations for sign language animation evaluation studies by <ref type="bibr">Kacorri et al. (2015)</ref>. Each subject was first given a short demographic questionnaire. Subjects were then asked to watch seven outputs from the app and echo them back, either in signed or mouthed form, to check the comprensibility of the app's signed output. They then answered a second short questionnaire which asked for their overall impressions. The result was encouraging: although none of the subjects felt the signing was truly fluent and human-like (a frequent comment was "artificial"), they all considered it grammatically correct and perfectly comprehensible.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Conclusions and further directions</head><p>Although the Lite Speech2Sign platform is designed to appear very simple and most of its runtime processing is carried out by the third-party JASigning and Nuance components, it represents a non-trivial engineering effort. The value it adds is that it allows sign language linguists who may have only modest computational skills to build translation applications that produce synthesized signed language, using a tool whose basic functioning can be mastered in two or three weeks. By including speech recognition, these applications can potentially be useful in real situations. In a research context, the platform opens up new possibilities for investigation of the grammar of signed languages. If the linguist wishes to investigate the productivity of a hypothesized syntactic rule, they can quickly implement a grammar fragment and produce a set of related signed utterances, all signed uniformly using the avatar. Our initial experiences, as described in Section 4, suggest that rendering quality is sufficient to obtain useful signer judgements.</p><p>Full documentation for Lite Speech2Sign is available <ref type="bibr">(Rayner, 2016</ref> </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Abstract</head><p>In word alignment certain source words are only needed for fluency reasons and do not have a translation on the target side. Most word alignment models assume a target NULL word from which they generate these untranslatable source words. Hypothesising a target NULL word is not without problems, however. For example, because this NULL word has a position, it interferes with the distribution over alignment jumps. We present a word alignment model that accounts for untranslatable source words by generating them from preceding source words. It thereby removes the need for a target NULL word and only models alignments between word pairs that are actually observed in the data. Translation experiments on English paired with Czech, German, French and Japanese show that the model outperforms its traditional IBM counterparts in terms of BLEU score.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>When the IBM models <ref type="bibr">(Brown et al., 1993)</ref> were designed, some way of accounting for words that likely have no translation was needed. The modellers back then decided to introduce a NULL word on the target (generating) side 1 . All words on the source side without a proper target translation would then be generated by that NULL word.</p><p>While this solution is technically valid, it neglects that those untranslatable words are required for source fluency. Moreover, the NULL word, although hypothetical in nature, does have a position. It is well-known that this NULL posi-tion is problematic for distortion-based alignment models. Alignments to NULL demand a special treatment as they would otherwise induce very long jumps that one does not usually observe in distortion-based alignment models. Examples of this can be found in <ref type="bibr">Vogel et al. (1996)</ref>, who drop the NULL word entirely and thus force all source words to align lexically, and Och and Ney <ref type="formula" target="#formula_1">(2003)</ref>, who choose a fixed NULL probability.</p><p>In the present work, we introduce a family of IBM-style alignment models that can express dependencies between translated and untranslated source words. The models do not use NULL words and instead allow untranslatable source words to be generated from translated words in their context. This is achieved by modelling source word collocations. From a technical point of view the model can be seen as a mixture of an alignment and a language model.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">IBM models 1 and 2</head><p>Here, we quickly review the IBM alignment models 1 and 2 <ref type="bibr">(Brown et al., 1993)</ref>. We assume a random variable E over the English (target) vocabulary 2 , a variable F over the French (source) vocabulary and a variable A over alignment links <ref type="bibr" target="#b471">3</ref> . The IBM models assign probabilities to alignment configurations and source sentences given the target side. Under the assumption that all source words are conditionally independent given the alignment links, these probabilities factorise as</p><formula xml:id="formula_82">P (f m 1 , a m 1 |e l 0 ) = P (a m 1 ) m j=1 P (f j |e a j )<label>(1)</label></formula><p>where x k 1 is a vector of outcomes x 1 , . . . , x k and e a j denotes the English word that the French word in the j th position (f j ) is aligned to under a m 1 . In IBM model 1 P (a m 1 ) is uniform. In IBM model 2, all alignment links a j are assumed to be independent and follow a categorical distribution. Here, we choose to parametrise this categorical based on the distance between the two words to be aligned, as has been done by <ref type="bibr">Vogel et al. (1996)</ref> and <ref type="bibr" target="#b18">Liang et al. (2006)</ref>. Thus, in our IBM model 2</p><formula xml:id="formula_83">P (a m 1 ) = m j=1 P (a j ) = m j=1 P i − jl m<label>(2)</label></formula><p>where i is the position of the English word that a j links to and the values l and m stand for the target and source sentence lengths. Notice that there is a target position i = 0 for the NULL word. Alignment to this NULL position often causes unusually long alignment jumps.</p><p>3 Removing the NULL word</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Model description</head><p>Our model consists of an alignment model component (which is either IBM model 1 or 2 without NULL words) and a language model component. It also contains a random variable Z that indicates which component to use. If Z = 0 we use the alignment model, if Z = 1 we instead use the language model. We generate each z j conditional on f j−1 . By making the outcome z j depend on f j−1 , we allow the model to capture the tendency of individual source words to be part of a collocation, i.e. to be followed by a closely related word. A similar strategy has been employed for topic modelling by <ref type="bibr" target="#b14">Griffiths et al. (2007)</ref>. When generating the source side, the model does the following for each source word f j :</p><p>1. Depending on the previous source word f j−1 , draw z j .</p><p>2. If z j = 1, generate f j from f j−1 and choose a j according to P (a j ). Otherwise, if z j = 0, generate f j from the target side and choose a j according to the probability that it has under the relevant alignment model without a target NULL word.</p><p>Our model thus induces a joint probability distribution of the form <ref type="figure" target="#fig_3">Figure 1</ref>: A graphical representation of our model for S sentence pairs. We use V f /e to denote the source/target vocabulary sizes and D to denote the number of possible alignment link configurations. Furthermore, S m/l is the number of source/target words in the current sentence and f prv the source word preceding the one that we currently generate.</p><formula xml:id="formula_84">P (f m 1 , a m 1 , z m 1 |e l 1 ) (3) = P (a m 1 ) m j=1 P (z j |f j−1 )P (f j |e a j , f j−1 , z j ) f f prv a z θ f q e S l 1 θ e θ a α β γ s, r Sm Ve V f V f D S</formula><p>where it is crucial to note that there is no E 0 variable, standing for the NULL word, anymore. Therefore, jumps to a NULL position do not need to be modelled. Notice further that the formulation of our model is general enough to be readily extensible to an HMM alignment model <ref type="bibr">(Vogel et al., 1996)</ref>. Depending on the value of z j , F j is distributed either according to an alignment (4) or a language model 4 (5).</p><formula xml:id="formula_85">P (f j |e a j , f j−1 , z j = 0) = P (f j |e a j ) (4) P (f j |e a j , f j−1 , z j = 1) = P (f j |f j−1 )<label>(5)</label></formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">The full model</head><p>Our full model is a Bayesian model, meaning that we treat all model parameters as random variables that are drawn from prior distributions. A graphical depiction of the model can be found in <ref type="figure" target="#fig_3">Figure  1</ref>. We impose Dirichlet priors on the translation (θ e ), language model (θ f ) and distortion parameters (θ a ). This has been done before and improved the standard IBM models. In order to be able to bias the model against using the language model component (5) too often and instead make it prefer the alignment model component (4), we impose a Beta prior on the Bernoulli distributions over component choices.</p><p>In effect, the model will only explain a source word with the language model if there is a lot of evidence that this word cannot be translated from the target side. The full model can be summarised as follows:</p><formula xml:id="formula_86">F j |e, a j , z j = 0 ∼ Cat(θ e aj ) Θ e aj ∼ Dir(α) F j |f j−1 , z j = 1 ∼ Cat(θ f j−1 ) Θ f j−1 ∼ Dir(β) Z j |f j−1 ∼ Bernoulli(q) Q ∼ Beta(s, r) .</formula><p>For IBM model 1, A j is uniformly distributed whereas for model 2 we have</p><formula xml:id="formula_87">A ∼ Cat(θ a ) Θ a ∼ Dir(γ) .</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Inference</head><p>We use a Gibbs sampler to perform inference of the alignment and choice variables. Since our priors are conjugate to the model distributions, we integrate over the model parameters, giving us a collapsed sampler 5 . The sampler alternates between sampling alignment links A and component choices Z.</p><p>The predictive posterior probabilities for Z j = 0 and Z j = 1 are given in Equations <ref type="formula" target="#formula_48">(6)</ref> and <ref type="formula" target="#formula_102">(7)</ref> (up to proportionality). We use c(·) as a (conditional) count function that counts how often an outcome has been observed in a given context. We furthermore use V f to denote the French (source) vocabulary size. To ease notation, we also introduce the context set C −X j which contains the current values of all variables in our model except X j and the set H which simply contains all hyperparameters.</p><formula xml:id="formula_88">P Z j = 0|C −Z j , H ∝ (6) (c(z = 0|f j−1 ) + s) P (a j ) c(f j |e a j , z = 0) + α c(e a j |z = 0) + αV f P Z j = 1|C −Z j , H ∝ (7) (c(z = 1|f j−1 ) + r) c(f j |f j−1 , z = 1) + β c(z = 1|f j−1 ) + βV f</formula><p>When Z j = 0, the predictive probability for alignment link A j is proportional to Equation (8).</p><formula xml:id="formula_89">P a j |C −Z j ,−A j , Z j = 0, H ∝ (8) P (a j ) c(f j |e a j , z = 0) + α c(e a j |z = 0) + αV f 5</formula><p>Derivations of samplers similar to ours can be found in the appendices of <ref type="bibr">Mermer et al. (2013)</ref> and <ref type="bibr" target="#b14">Griffiths et al. (2007)</ref>. We omit the derivation here for space reasons.</p><p>When Z j = 1, it is simply proportional to P (a j ). In the case of IBM model 1, P (a j ) is a constant. For IBM model 2, we use</p><formula xml:id="formula_90">P (a j ) ∝ c i − jl m + γ .</formula><p>where l and m are the target and source sentence lengths. Notice that target positions start at 1 as we do not use a NULL word.</p><p>Notice that a naïve implementation of our sampler is unpractically slow. We therefore augment the sampler with an auxiliary variable <ref type="bibr">(Tanner and Wong, 1987)</ref> that uniformly chooses only one possible new assignment per sampled link. The sampling complexity, which would normally be linear in the size of the target sentence, thus becomes constant. In practice this speed up the sampler by several orders of magnitude, making our aligner as fast as Giza++. Unfortunately, this strategy also slightly impairs the mobility of our sampler.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">Decoding</head><p>Our samples contain assignments of the A and Z variables. If for a word f j we have z j = 1, we treat the word as not aligned. We then use maximum marginal decoding <ref type="bibr" target="#b16">(Johnson and Goldwater, 2009</ref>) over alignment links to generate final word alignments. This means that we align each source word to the target word it has been aligned to most often in the samples. If the word was unaligned in most samples, we leave it unaligned in the output alignment.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Experiments and results</head><p>We present translation experiments on English paired with German, French, Czech and Japanese, thereby covering four language families. We compare our model and the Bayesian IBM models 1 and 2 of <ref type="bibr">Mermer et al. (2013)</ref> against IBM model 2 as a baseline.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Experiments</head><p>Data We use the news commentary data from the WMT 2014 translation task 6 for German, French and Czech paired with English. We use newstest-2013 as development data and we use the newstest-2014 for testing. We use all available monolingual data from WMT 2014 for language modelling. All data are truecased and sentences   <ref type="formula" target="#formula_0">(1a)</ref> and bottom (1b) tables were obtained in the target-to-source direction and symmetrised, respectively. Differences are computed with respect to the directional IBM model 2 in its original parameterisation <ref type="bibr">(Brown et al., 1993)</ref>. The best Bayesian model in each column is boldfaced.</p><note type="other">Model En-De En-Fr En-Cs En-Ja De-En Fr-En Cs-En Ja-En</note><p>with more than 100 words discarded as is standardly done in SMT. The Japanese training data consist of 200.000 randomly extracted sentence pairs from the NTCIR-8 Patent Translation Task. The full data are used for language modelling. We use the NTCIR-7 dev sets for tuning and the NTCIR-9 test set for testing. 7</p><p>Training The maximum likelihood IBM model 2 is initialized with model 1 parameter estimates and trained for 5 EM iterations. Following Mermer and Saraçlar <ref type="formula" target="#formula_0">(2011)</ref>, we initialize the Gibbs samplers of all Bayesian models with the Viterbi alignment from IBM model 1. We run each sampler for 1000 iterations and take a sample after every 25 th iteration. We do not use burn-in. <ref type="bibr">8</ref> Hyperparameters All Bayesian models are trained with α = 0.0001 and β = 0.0001 to induce sparse lexical distributions. We also set s = 1 and r = 0.1 when IBM1 is the alignment component in our model. This has the effect of biasing the model towards using the align-7 The Japanese data was provided to us by a colleague with the pre-processing steps already performed, with sentences shortened to at most 40 words. Our algorithm can handle sentences of any length and there is actually no need to restrict the sentence lengths.</p><p>8 Burn-in is simply a heuristic that is not guaranteed to improve the samples in any way. See http://users. stat.umn.edu/˜geyer/mcmc/burn.html for further details. ment component. For the IBM2 version we even set r = 0.01 since IBM2 is a more trustworthy alignment model. For IBM2, we furthermore set γ = 1 to obtain a flat distortion prior.</p><p>Observe that experiments presented here use the same fixed hyperparameters for all language pairs. We tried to add another level to our model by imposing Gamma priors on the hyperparameters. The hyperparameters were then inferred using slice sampling after each Gibbs iteration. When run on the German-English and CzechEnglish data, this strategy increased the posterior probability of the states visited by our sampler but had no effect on BLEU. This may indicate that either the hand-chosen hyperparameters are adequate for the task or that the model generally performs well for a large range of hyperparameters.</p><p>Translation We train Moses systems  with 5-gram language models with modified Kneser-Ney-smoothing using KenLM <ref type="bibr" target="#b15">(Heafield et al., 2013)</ref> and orientation-based lexicalised reordering. We tune the systems with MERT (Och, 2003) on the dev sets. We report the BLEU score <ref type="bibr" target="#b284">(Papineni et al., 2002</ref>) for all models averaged over 5 MERT runs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Results</head><p>We report the translation results in <ref type="table" target="#tab_10">Tables (1a)</ref> and (1b). Results of the full Giza++ pipeline and fastAlign <ref type="bibr" target="#b13">(Dyer et al., 2013)</ref> are reported as a com-parison standard. All symmetrised results were obtained using the grow-diag-final-and heuristic.</p><p>Using IBM2 as an alignment component, our model mostly outperforms the standard IBM models and their Bayesian variants. Importantly, the improvement that our model 2 achieves over its model 1 variant is much larger than the difference between the corresponding models of <ref type="bibr">Mermer et al. (2013)</ref>. This indicates that our model makes better use of the distortion distribution that is not altered by NULL alignments. We also observe that our model gains relatively little from symmetrisation, likely because it is a very strong model already. It is interesting that although our model 2 does not use fertility parameters or dependencies between alignment links, it often approaches the performance of Giza which does use these features. Moreover, it also approaches the performance of fastAlign which does not use fertility nor dependencies between alignment links, but has a stronger inductive bias with respect to distortion.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Discussion and future work</head><p>We have presented an IBM-style word alignment model that does not need to hypothesise a NULL word as it explains untranslatable source words by grouping them with translated words. This also leads to a cleaner handling of distortion probabilities.</p><p>In our present work, we have only considered IBM models 1 and 2. As we have mentioned already, our model can easily be extended with the HMM alignment model. We are currently exploring this possibility. Our models also allow symmetrisation <ref type="bibr" target="#b18">(Liang et al., 2006)</ref> of all translation and distortion parameters where before the NULL distortion parameters had to be fixed. We therefore plan to extend them towards model-based instead of heuristic alignment symmetrisation.</p><p>A limitation of our model is that it is only capable of modelling left-to-right linear dependencies in the source language. In languages like German or English, however, where an adjective or determiner is selected by the following noun, this may not be appropriate to model selection biases amongst neighbouring words. An interesting extension to our model is thus to add more structure to it such that it will be able to capture more complex source side dependencies.</p><p>Another concern is the inference in our model. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Abstract</head><p>This work explores the use of unsupervised morph segmentation along with statistical language models for the task of vocabulary expansion. Unsupervised vocabulary expansion has large potential for improving vocabulary coverage and performance in different natural language processing tasks, especially in lessresourced settings on morphologically rich languages. We propose a combination of unsupervised morph segmentation and statistical language models and evaluate on languages from the Babel corpus. The method is shown to perform well for all the evaluated languages when compared to the previous work on the task.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Language modelling for different natural language processing tasks like speech recognition, machine translation or optical character recognition require large training corpora to achieve good language model estimates and high enough vocabulary coverage. Sometimes such resources are not readily available or easily acquirable. This is especially the case for the many less-resourced languages. In the case of morphologically rich languages, these issues are emphasized, as words appear in many forms, thus increasing the required vocabulary size and the data sparsity. Automatic speech recognition of spontaneous speech is a task with some special characteristics, as speech transcriptions are expensive to acquire. Taking all these factors into account, the importance of making the most out of the available resources becomes evident.</p><p>This work was done while the author was visiting the Saarland University Spoken Language Systems group Previous work on handling out-of-vocabulary (OOV) words in automatic speech recognition have included explicit OOV word modelling and confidence measures <ref type="bibr">(Hazen and Bazzi, 2001)</ref> and hybrid word-subword language modelling for OOV word detection <ref type="bibr">(Yazgan and Saraçlar, 2004)</ref>. Speech recognition by directly using optimized subword units has also <ref type="bibr">(Kneissler and Klakow, 2001</ref>) proven a good approach for speech recognition of a morphologically rich language.</p><p>In this work, we study unsupervised vocabulary expansion for conversational speech recognition of morphologically rich languages in a lessresourced setting. We expand the recognition vocabulary, and thus lower the OOV rate, by generating new word forms. Two recent works also target the unsupervised vocabulary expansion.</p><p>In <ref type="bibr">(Rasooli et al., 2014)</ref>, an unsupervised morphological segmentation was inferred from the training corpus using the Morfessor Categories-MAP (Creutz and Lagus, 2007) method. The prefix-stem-suffix structure estimated by the model was then represented as a finite-statetransducer for sampling new word forms. Different reranking schemes using a bigram language model and a letter trigraph language model were evaluated.</p><p>The Kaldi speech recognition package (Povey et al., 2011) includes an approach <ref type="bibr">(Trmal et al., 2014)</ref> for vocabulary expansion. In this approach, the provided syllable segmented pronunciation lexicon is used as the basis for the expansion. An n-gram model is trained over the syllable segmentation and syllabic words are generated from the model. Finally a phoneme-to-grapheme mapping is performed to obtain the grapheme form for the words.</p><p>In our approach, statistical language models are trained over a morph segmentation, which is learned unsupervisedly from the data. Words are sampled from the language models and ordered according to the probabilities given by the language models. We evaluate the method on seven morphologically rich languages from the Babel <ref type="bibr">(Harper, 2013)</ref> corpus and compare to the previously suggested approaches.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Suggested method</head><p>We present a combination of unsupervised morph segmentation and statistical language models for unsupervised vocabulary expansion. The suggested approach operates in four steps: unsupervised morph segmentation, statistical language model training, sampling of new word types and reranking of the sampled words. The phases are described in more detail in the corresponding subsections.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Unsupervised morph segmentation</head><p>Morfessor Baseline <ref type="bibr">(Creutz and Lagus, 2002</ref>) is a method for unsupervised morphological segmentation. The algorithm optimizes a two-part minimum description length code, finding a balance between the cost of encoding the training corpus and the lexicon, as in Formula 1.</p><formula xml:id="formula_91">arg min θ L(x, θ) = arg min L(x|θ) + L(θ) (1)</formula><p>The corpus encoding is based on a unigram model. A so-called α-term may be used for finetuning the corpus encoding cost. For the experiments in this work, a recent Python implementation Morfessor 2.0 (Smit et al., 2014) was used.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Statistical language models over morphs</head><p>As statistical language models, two state-of-theart models were selected. These language models were trained on a corpus, where one segmented word was treated as what would in normal language model training be a sentence. The training was done using log-weighted word frequencies, thus some words appearing multiple times in the training corpus. The rationale of the logweighting was to slightly emphasize the most common words. As a last step, the order of the training words was randomized.</p><p>The first model was a trigram model trained with the modified Kneser-Ney smoothing (Kneser and Ney, 1995) using three discounts per order. The discount parameters could normally be optimized on a held-out-set, but here leave-one-out estimates were used, as it is not clear what would in this case constitute a reasonable held-out set. The model was trained using the VariKN software package <ref type="bibr">(Siivola et al., 2007)</ref>.</p><p>It has recently been shown, that the recurrent neural network language models may efficiently be trained using the backpropagation algorithm <ref type="bibr">(Mikolov et al., 2010)</ref>, making it also an appealing choice for language modelling. As the second language model, a recurrent neural network language model was trained using the RNNLM toolkit. The words were treated as independent of the preceeding words in both the model training and the word sampling phases.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Sampling and reranking</head><p>The initial set of candidate words was obtained by sampling separately from both the n-gram model and the recurrent neural network language model. These word lists were then merged. It is very important to rerank the obtained word list, as the goal is to improve the OOV rate as much as possible with introducing as little incorrect words as possible to the vocabulary. As the final estimate on the word likelihood, the linear interpolation of these two model scores was used. The linear interpolation was applied morph-wise. The list of the sampled words was sorted in descending order with the linearly interpolated likelihood as the score.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Experiments</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Training corpus</head><p>The vocabulary expansion experiments were conducted on the Babel corpus <ref type="bibr">(DARPA, 2013)</ref>. The experiments were run on the following set of languages: Assamese, Bengali, Pashto, Tagalog, Tamil, Turkish and Zulu. The training corpora consist mainly of conversation transcriptions, but also additional scripted data is provided. Including the scripted training data in general helps to lower the OOV rate. The OOV reduction rate reachable by the vocabulary expansion then becomes, with some exceptions, slightly slower. Statistics of the datasets are in the <ref type="table" target="#tab_10">Table 1.</ref> As preprocessing, all special symbols were removed from the texts. Asterisk symbols are used to denote misspellings in cases where the real word was identifiable. Asterisk symbols were removed and the words included in the training corpus. Dash symbols in the beginning and end of a word are used to indicate hesitations. These words were removed from the training corpus.</p><p>Only proper names were written in uppercase in the transcriptions, so these words were kept intact.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Expansion model</head><p>As statistical language models, we evaluated a trigram language model, a recurrent neural network language model, and the linear interpolation of these models. 10 million new distinct word types were sampled from both the models separately. These lists were then merged and reranked as explained in the Section 2.3. The model parameters were optimized on selected languages and these parameters were used in all the experiments. For the recurrent neural network language model, the number of classes was set to 50 and the hidden layer size to 20. These values were reasonably close to optimum for all the languages.</p><p>The suitable α-value for the Morfessor Baseline segmentation was studied. With the default value of 1.0, the method seemed to suffer from a slight undersegmentation. To encourage the method to segment more, the α value was set to 0.8. This setting was equal or better for all the evaluated languages.</p><p>When evaluating the language models as standalone models, the trigram model provided better generation accuracy for 4 of the in total 7 languages and the recurrent neural network language model for 3 of the languages. Linear interpolation of the models was without exceptions the most accurate model. The linear interpolation weight was set to 0.5. <ref type="figure" target="#fig_3">Figure 1</ref> shows an example of the OOV rate development as a function of the extended vocabulary size for Turkish. The rapid improvement of the OOV rate for small extensions and the superi- </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Comparison to the previous work</head><p>We compared the approach to the previous results in ( <ref type="bibr">Rasooli et al., 2014)</ref>. They reported the results for a vocabulary expansion of 50k best words. Table 2 compares the type-based expansion results and <ref type="table" target="#tab_6">Table 3</ref> the token-based expansion results. Models for these comparisons were trained with the scripted data included.   We ran the Kaldi vocabulary expansion in the limited language pack setting as in <ref type="bibr">(Trmal et al., 2014)</ref>. In the default setting, around 1M distinct syllabic words are generated and converted by a phoneme-to-grapheme mapping to obtain the graphemic word form. <ref type="table" target="#tab_42">Table 4</ref> compares the typebased expansion results and <ref type="table" target="#tab_22">Table 5</ref> the tokenbased expansion results for a vocabulary expansion of similar size (in graphemic words). The scripted data was not used in training the models for these comparisons.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">OOV reduction and type to token ratio</head><p>The OOV reduction was evaluated as a function of the type/token ratio. This analysis may provide information about the properties of the evaluated languages. The token-based analysis is in the Figure 2 and the type-based analysis in the <ref type="figure" target="#fig_6">Figure 3</ref>. As the type/token ratio is dependent on the number of tokens, these values are computed on a matched number of tokens (65821) from the training corpus. The plots show that there are similarities, but also big differences between the languages. Most notable exceptions seem to be Tamil and Tagalog. For Tamil, the number of the most frequent words was lower with a slightly more even tail of less frequent words. For Tagalog, the average number of morphs per word as estimated by the Morfessor Baseline algorithm was 2.8, which was the highest value among all the languages. Still, the number of distinct word types in the training set was the lowest. These properties seem to play a role in the different vocabulary expansion characteristics. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Discussion</head><p>This work concerned the use of unsupervised morphological segmentation and statistical language models for the task of vocabulary expansion. Unsupervised vocabulary expansion has large potential for reducing OOV-rates and improving results in NLP tasks especially in less-resourced settings for morphologically rich languages.</p><p>The suggested method was evaluated on some of the morphologically rich languages of the Babel corpus in the limited language pack condition. The performance of the method was evaluated in terms of the improvement of the OOV-rate on the development set. The suggested combination of segmentation and interpolation of statistical language models provided to our understanding the best results on the task so far. Compared to <ref type="bibr">(Rasooli et al., 2014)</ref>, our approach differed in that the statistical language models were used directly in the word generation phase. As opposed to <ref type="bibr">(Trmal et al., 2014)</ref>, our approach operated purely on the grapheme level.</p><p>It is perhaps noteworthy, that the methods are not that different from what one would use in a normal language modelling scenario for automatic speech recognition. Morfessor Baseline (Creutz and Lagus, 2002) has been seen to give good results in morph-based speech recognition <ref type="bibr">(Creutz et al., 2007)</ref> when used along with standard n-gram models. If a larger training corpus is available, optimizing unigram likelihood more directly may be a good choice <ref type="bibr">(Varjokallio et al., 2013)</ref>.</p><p>Morph segmentations provided by the Morfessor Flatcat (Grönroos and Virpioja, 2014) -method were also evaluated for this work, but Morfessor Baseline was found to perform better. It is possible, that the tradeoff between the lexicon cost and the corpus encoding cost, as given by the Minimum Description Length -principle, is important for the modelling accuracy in this type of a less-resourced scenario. Morfessor Flatcat will in most cases segment more accurately according to the grammatical morph boundaries. This is likely a more valuable property for statistical machine translation than for the present task.</p><p>The linear interpolation of an n-gram model and a recurrent neural network language model provides at the moment state-of-the-art modelling accuracy in many statistical language modelling tasks. Some forms of class n-grams were also evaluated for this work. Sampling from a class ngram provided many complementary word forms, not easily generated by the other models. However, it became successively harder to improve the OOV reduction rates by a combination of three models.</p><p>This work concentrated only on methods for expanding the vocabulary. Naturally some language modelling methods are required to utilize these generated words in speech recognition or some other task. One possibility is to extend the unknown symbol and improve the obtained estimates via class n-gram models <ref type="bibr">(Trmal et al., 2014)</ref>. Morph-based language models may be utilized using a constrained vocabulary as suggested in <ref type="bibr">(Varjokallio and Kurimo, 2014)</ref>. In this case word-level pronunciation variants may be applied. Performing the vocabulary expansion may also provide insights into unlimited vocabulary speech recognition <ref type="bibr">(Kneissler and Klakow, 2001;</ref><ref type="bibr">Hirsimäki et al., 2006)</ref> with morph language models. Finding units with consistent grapheme-tophoneme mapping may, however, be challenging for some of the Babel languages.</p><p>Regarding the type of approaches considered in this work, it is possible that advances in either unsupervised morph segmentation or statistical language models could bring about further improvements in the expansion accuracy. Unsupervised learning of morphological paradigms is also a potential direction when seeking for improvements in the task.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Conclusion</head><p>Unsupervised vocabulary expansion has great potential for reducing out-of-vocabulary rates and improving results in different natural language processing tasks, including ASR. In this work, an approach comprising of unsupervised morph segmentation and statistical language models was suggested. The model was evaluated on the Babel languages and was shown to give large improvements compared to the previous work on the task. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Background</head><p>Mild cognitive impairment (MCI) is a heterogeneous set of symptoms that are essential in the early detection of Alzheimer's Disease (AD) <ref type="bibr">(Negash et al., 2007)</ref>. Symptoms such as language dysfunctions may occur even nine years before the actual diagnosis <ref type="bibr">(APA, 2000)</ref>. Thus, the language use of the patient may often indicate MCI well before the clinical diagnosis of dementia. MCI is known to influence the (spontaneous) speech of the patient via three main aspects. First, verbal fluency declines, which results in longer hesitations and a lower speech rate <ref type="bibr">(Roark et al., 2011)</ref>. Second, the lexical frequency of words and part-of-speech tags may also change significantly as the patient has problems with finding words <ref type="bibr">(Croot et al., 2000)</ref>. Third, the emotional responsiveness of the patient was also observed to change in many cases <ref type="bibr">(Lopez-de Ipiña et al., 2015)</ref>.</p><p>For many patients, MCI is never recognized as in the early stage of the disease it is not trivial even for experts to detect cognitive impairment: according to <ref type="bibr">Boise et al. (2004)</ref>, up to 50% of MCI patients are never diagnosed with MCI. Although there are well known tests such as the Mini Mental Test, they are usually not sensitive enough to reliably filter out MCI in its early stage. Tests on linguistic memory prove more efficient in detecting MCI, but they tend to yield a relatively high number of false positive diagnoses <ref type="bibr">(Roark et al., 2011)</ref>.</p><p>Although language abilities are impaired from an early stage of the disease, evaluating the language capacities of the patients has only received marginal attention when diagnosing AD <ref type="bibr">(Bayles, 1982)</ref>. However, if diagnosed early, a proper medical treatment may delay the occurrence of other (more severe) symptoms of dementia to the latest extent possible <ref type="bibr">(Kálmán et al., 2013)</ref>.</p><p>Here we seek to automatically identify Hungarian patients suffering from mild cognitive impairment based on their speech transcripts. Our system uses machine learning techniques and is based on several features like linguistic characteristics of spontaneous speech as well as features exploiting morphological and syntactic parsing.</p><p>Recently, several studies have reported results on identifying different types of dementia with NLP and speech recognition techniques. For instance, automatic speech recognition tools were employed in detecting aphasia <ref type="bibr">(Fraser et al., 2013b;</ref><ref type="bibr">Fraser et al., 2014;</ref><ref type="bibr">Fraser et al., 2013a)</ref> and mild cognitive impairment <ref type="bibr">(Lehr et al., 2012)</ref>, and Alzheimer's Disease <ref type="bibr">(Baldas et al., 2010;</ref><ref type="bibr">Satt et al., 2014)</ref>. <ref type="bibr">Jarrold et al. (2014)</ref> distinguished four types of dementia on the basis of spontaneous speech samples. Lexical analysis of spontaneous speech may also indicate different types of dementia <ref type="bibr">(Bucks et al., 2000;</ref><ref type="bibr">Holmes and Singh, 1996)</ref> and may be exploited in the automatic detection of patients suffering from dementia <ref type="bibr" target="#b681">(Thomas et al., 2005)</ref>. As for analyzing written language, changes in the writing style of people may also refer to <ref type="bibr">dementia (Garrard et al., 2005;</ref><ref type="bibr">Hirst and Wei Feng, 2012;</ref><ref type="bibr">Le et al., 2011)</ref>.</p><p>Concerning the automatic detection of MCI in Hungarian subjects, <ref type="bibr">Tóth et al. (2015)</ref> experimented with speech recognition techniques. However, to the best of our knowledge, this is the first attempt to identify MCI on the basis of written texts, i.e. speech transcripts for Hungarian.</p><p>In the long run, we would like to develop a system that can automatically detect linguistic symptoms of MCI in its early stage, so that the person can get medical treatment as early as possible. It should be noted, however, that our goal cannot be an official diagnosis as diagnosing patients requires medical experience. All we can do is implement a test supported by methods used in artificial intelligence, which indicates whether the patient is at risk and if so, s/he can turn to medical experts who will provide the clinical diagnosis.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Data</head><p>In our experiments 1 , two short animated films were presented to the patients at the memory ambulance of the University of Szeged. Patients were asked to talk about the first film then about their previous day, and lastly, about the second film. Their speech productions were recorded and transcribed by linguists, who explicitly marked speech phenomena like hesitations and pauses in the transcripts. These transcripts formed the basis of our experiments, i.e. we exploited only written information.</p><p>All of our 84 subjects were native speakers of Hungarian, a morphologically rich language. For each person, a clinical diagnosis was at our disposal, i.e. it was clinically proved whether the patient suffers from MCI or not. On the basis of these data, subjects were classified as either MCI patient or healthy control at the university memorial. Table 1 shows data on the subjects' gender and diagnosis while <ref type="table" target="#tab_5">Table 2</ref> shows the mean values for age and education (in terms of years attended at school).</p><p>Speech transcripts reflect several characteristics of spontaneous speech. On the one hand, they contain several forms of hesitations and silent pauses,  which are also marked in the transcripts, on the other hand, they abound in phenomena typical of spontaneous Hungarian speech such as phonological deletion (mer instead of the standard form mert "because" or ement instead of the standard form elment "(he) left") and lengthening (utánna instead of the standard form utána "then"). There are duplications (ez ezt "this this-ACC") and neologisms created by the speaker (feltkáva, which probably means főtt kávé "boiled coffee"). Fillers also deserve special attention when studying transcripts. Besides hesitations, we treated words and phrases referring to some kind of uncertainty together with indefinite pronouns as fillers such as ilyen "such", olyan "such", izé "thing, gadget",és aztán "and then", valamilyen "some kind of", valahogy "somehow", valamerre "somewhere" 2 . Thus, MCI patients often seem to substitute content words with fillers or indefinite pronouns, moreover, they also appear to use lots of paraphrases, which also indicate uncertainty just like egy ilyen bagolyszerűség a such owl-likeness "something similar to an owl" or az olyan délelőtt volt that such morning was "that happened some time in the morning".</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Experiments</head><p>In order to determine the status of the subjects, we experimented with machine learning tools. The task was regarded as binary classification, i.e. subjects were classified as either an MCI patient or a healthy control, on the basis of a feature set derived from their transcripts.</p><p>At first, transcripts were morphologically and syntactically analysed with magyarlanc, a linguistic preprocessing toolkit developed for Hungarian <ref type="bibr">(Zsibrita et al., 2013)</ref>. For classification, we exploited morphological, syntactic and semantic features extracted from the output of magyarlanc.</p><p>Each person was asked to recall three different stories. As MCI is strongly related to memory deficit, we believe that the order of the tasks might also influence performance, hence we opted for processing each transcript separately. Thus, for each person, features to be discussed below were calculated separately for the three transcripts and all of them were exploited in the system.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Feature set</head><p>In our experiments, we employed features of spontaneous speech and morphological and semantic features derived from the transcripts and their automatic linguistic analyses. When defining our features, we took into account the fact that the speech of MCI patients may contain more pauses and hesitations than that of healthy controls <ref type="bibr">(Tóth et al., 2015)</ref> and they are also supposed to have a restricted vocabulary due to cognitive deficit, which may affect the choice of words and the frequency of parts of speech <ref type="bibr">(Croot et al., 2000)</ref> and might even yield neologisms. We also made use of demographic features that were at our disposal.</p><p>Our feature set contained the following features: Spontaneous speech based features: number of filled and silent pauses; number and rate of hesitations compared to the number of tokens; number of pauses that follow an article and precede content words as this might reflect that MCI patients may have difficulties with finding the appropriate content words; number of lengthened sounds (which we considered as a special form of hesitation).</p><p>Morphological features: number of tokens and words; number and rate of distinct lemmas; number of punctuation marks; number and rate of nouns, verbs, adjectives, pronouns and conjunctions; number of first person singular verbs as it might also be indicative how often the patient reflects to him/herself; number and rate of unanalyzed words, i.e. those with an "unknown" POS tag, which might indicate neologisms created by the speaker on the spot.</p><p>Semantic features: number and rate of fillers and uncertain words compared to the number of all tokens; number and rate of words/phrases related to memory activity (e.g. nem emlékszem not remember-1SG "I can't remember") as they directly signal problems with memory and recall; number of negation words; number and rate of content words and function words; number of thematic words related to the content of the films, based on manually constructed lists.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Demographic features:</head><p>gender; age; education.</p><p>The mean values for each feature are reported in <ref type="table" target="#tab_6">Table 3</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Statistical analysis of features</head><p>In order to reveal which features can most effectively distinguish healthy controls from MCI patients, we carried out a statistical analysis of the data (t-tests for each feature and transcript). For most of the features, significant differences were found between the two groups -p-values are listed in <ref type="table" target="#tab_6">Table 3</ref>. The age of the patients also indicates significant differences: people who were at least 71 years old were more probable to suffer from MCI than those who were younger at the time of the experiment (p = 0.0124).</p><p>According to the data, each group of features has a significant effect in distinguishing controls and MCI patients. It is shown that it is mostly the second transcript (the one including the narratives about the subjects' previous days) where significant differences may be found among MCI patients and the control group. However, significant differences exist for the other two types of texts as well.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Machine learning experiments</head><p>To automatically identify MCI patients, we exploited machine learning techniques, i.e. support vector machines (SVM) <ref type="bibr">(Cortes and Vapnik, 1995)</ref> with the default settings of Weka <ref type="bibr" target="#b621">(Hall et al., 2009</ref>) and due to the small size of the dataset, we applied leave-one-out cross validation. As a baseline, majority labeling was used. For the evaluation, the accuracy, precision, recall and F-measure metrics were utilized.</p><p>In order to examine the effect of certain groups of features, we carried out an ablation study, i.e. we retrained the system without making use of one specific group of features. The results and differences are shown in   <ref type="table" target="#tab_42">Table 4</ref>: Results and differences. MCI: mild cognitive impairment, P: precision, R: recall, F: F-measure, %: accuracy.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Results and Discussion</head><p>Using all the features, our system managed to achieve an accuracy score of 69.1%, that is, 58 out of the 84 patients were correctly diagnosed. 12 patients were falsely diagnosed as healthy and 14 controls were falsely labeled as MCI patients. Our results outperformed the baseline (57.14% in terms of accuracy). The system got a high recall value for MCI patients (75.0) but a lower one for controls (61.1), which is encouraging in the light of the fact that our main goal is to identify the widest possible range of potential MCI patients, who can turn to clinical experts to find out what their clinical diagnosis is.</p><p>We also experimented with using only features that displayed statistically significant differences among controls and MCI patients (see <ref type="table" target="#tab_6">Table 3</ref>). Somewhat surprisingly, an accuracy of 75% could be achieved in this way, which indicates that some of our original features are superfluous and just confused the system, and this result needs further investigation.</p><p>An ablation study was also carried out to analyze the added value of each feature group. Speech-based, demographic and morphological features unequivocally contributed to performance. However, the effect of semantic features seems less obvious as they harm performance taken as a whole but some individual semantic features are useful for the system, as shown by the results achieved with just using significant features.</p><p>When investigating the errors made by our system, we found that MCI patients that spoke only a few short sentences were often classified as healthy controls. They had a lower number and rate of hesitations and pauses, moreover, their vocabulary contained fewer fillers and uncertain words, and these features resemble those typical of healthy controls. What is more, healthy subjects who talked more also hesitated more, which might be indicative of MCI. Furthermore, their use of pronouns and conjunctions was also more similar to those of MCI patients, hence the system falsely predicted a positive diagnosis for them.</p><p>Due to the specific characteristics of the data and the complexity of data collection -which requires clinical experiments -our dataset can be expanded only step by step. However, we found statistically significant differences among MCI patients and healthy controls concerning several linguistic and speech-based features even in our small dataset, which may be beneficial for our future experiments and might be also exploited by those who study spontaneous speech.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Conclusions</head><p>In this study, we introduced our system that automatically detects Hungarian patients suffering from mild cognitive impairment on the basis of their speech transcripts. The system is based on features derived from morphological and syntactic analysis as well as characteristics of spontaneous speech. Both statistical and machine learning results revealed that morphological and spontaneous speech-based features have an essential role in distinguishing MCI patients from healthy controls.</p><p>In the future, we would like to extend our dataset with new transcripts. Also, we intend to improve our machine learning system and investigate the role of semantic features. Lastly, we would like to integrate features from automatic speech recognition into our system so that tools from both speech technology and natural language processing can contribute to the automatic detection of mild cognitive impairment. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Abstract</head><p>Recent work has revealed the potential of using visual representations for bilingual lexicon learning (BLL). Such image-based BLL methods, however, still fall short of linguistic approaches. In this paper, we propose a simple yet effective multimodal approach that learns bilingual semantic representations that fuse linguistic and visual input. These new bilingual multi-modal embeddings display significant performance gains in the BLL task for three language pairs on two benchmarking test sets, outperforming linguistic-only BLL models using three different types of state-of-the-art bilingual word embeddings, as well as visual-only BLL models.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Bilingual lexicon learning (BLL) is the task of finding words that share a common meaning across different languages. It plays an important role in a variety of fundamental tasks in IR and NLP, e.g. cross-lingual information retrieval and statistical machine translation. The majority of current BLL models aim to learn lexicons from comparable data. These approaches work by (1) mapping language pairs to a shared crosslingual vector space (SCLVS) such that words are close when they have similar meanings; and (2) extracting close lexical items from the induced SCLVS. Bilingual word embedding (BWE) induced models currently hold the state-of-the-art on BLL <ref type="bibr">(Hermann and Blunsom, 2014;</ref><ref type="bibr" target="#b391">Gouws et al., 2015;</ref><ref type="bibr">Vulić and Moens, 2016)</ref>.</p><p>Although methods for learning SCLVSs are predominantly text-based, this space need not be linguistic in nature: Bergsma and van <ref type="bibr" target="#b363">Durme (2011)</ref> and <ref type="bibr">Kiela et al. (2015)</ref> used labeled images from the Web to learn bilingual lexicons based on visual features, with features derived from deep convolutional neural networks (CNNs) leading to the best results <ref type="bibr">(Kiela et al., 2015)</ref>. However, vision-based BLL does not yet perform at the same level as state-of-the-art linguistic models. Here, we unify the strengths of both approaches into one single multi-modal vision-language SCLVS.</p><p>It has been found in multi-modal semantics that linguistic and visual representations are often complementary in terms of the information they encode <ref type="bibr">(Deselaers and Ferrari, 2011;</ref><ref type="bibr">Bruni et al., 2014;</ref><ref type="bibr">Silberer and Lapata, 2014)</ref>. This is the first work to test the effectiveness of the multi-modal approach in a BLL setting. Our contributions are: We introduce bilingual multi-modal semantic spaces that merge linguistic and visual components to obtain semantically-enriched bilingual multi-modal word representations. These representations display significant improvements for three language pairs on two benchmarking BLL test sets in comparison to three different bilingual linguistic representations <ref type="bibr" target="#b391">Gouws et al., 2015;</ref><ref type="bibr">Vulić and Moens, 2016)</ref>, as well as over the uni-modal visual representations from <ref type="bibr">Kiela et al. (2015)</ref>.</p><p>We also propose a weighting technique based on image dispersion <ref type="bibr">(Kiela et al., 2014</ref>) that governs the influence of visual information in fused representations, and show that this technique leads to robust multi-modal models which do not require fine tuning of the fusion parameter.</p><p>tor:</p><formula xml:id="formula_92">w ling = [f ling 1 , . . . , f ling d l ]</formula><p>, where f ling k ∈ R is the value of the k-th cross-lingual feature for w. Similarity between w, v ∈ V S ∪ V T is computed through a similarity function (SF), sim ling (w, v) = SF (w ling , v ling ), e.g., cosine.</p><p>Type 1: M-EMB This type of BWE induction model assumes the following setup for learning the SCLVS <ref type="bibr">Dinu et al., 2015;</ref><ref type="bibr">Lazaridou et al., 2015a)</ref>: First, two monolingual spaces, R d S and R d T , are induced separately in each language using a standard monolingual embedding model. The bilingual signal is provided in the form of word translation pairs (x i , y i ), where x i ∈ V S , y i ∈ V T , and</p><formula xml:id="formula_93">x i ∈ R d S , y i ∈ R d T .</formula><p>Training is cast as a multivariate regression problem: it implies learning a function that maps the source language vectors to their corresponding target language vectors. A standard approach <ref type="bibr" target="#b375">(Mikolov et al., 2013;</ref><ref type="bibr">Dinu et al., 2015)</ref> is to assume a linear map W ∈ R d S ×d T , which is learned through an L 2 -regularized least-squares error objective. Any previously unseen source language word vector x u may be mapped into the target embedding space R d T as Wx u . After mapping all vectors x, x ∈ V S , the target space R d T serves as a SCLVS.</p><p>Type 2: G-EMB Another collection of BWE induction models optimizes two monolingual objectives jointly, with the cross-lingual objective acting as a cross-lingual regularizer during training <ref type="bibr" target="#b391">(Gouws et al., 2015;</ref><ref type="bibr">Soyer et al., 2015)</ref>. In a simplified formulation <ref type="bibr">(Luong et al., 2015)</ref>, the objective is: γ(Mono S + Mono T ) + δBi. The monolingual objectives Mono S and Mono T ensure that similar words in each language are assigned similar embeddings and aim to capture the semantic structure of each language, whereas the crosslingual objective Bi ensures that similar words across languages are assigned similar embeddings, and ties the two monolingual spaces together into a SCLVS. Parameters γ and δ govern the influence of the monolingual and bilingual components. <ref type="bibr">1</ref> The bilingual signal used as the cross-lingual regularizer during the joint training is obtained from sentence-aligned parallel data. We opt for the Bil-BOWA model from <ref type="bibr" target="#b391">Gouws et al. (2015)</ref> as the representative model to be included in the comparisons, due to its solid performance and robustness in the BLL task <ref type="bibr">(Luong et al., 2015)</ref>, its reduced complexity reflected in fast computations on massive datasets and its public availability. 2 Type 3: V-EMB The third set of models requires a different bilingual signal to induce a SCLVS: document alignments. Vulić and Moens (2016) created a collection of pseudo-bilingual documents by merging every pair of aligned documents in the data, in a way that preserves important local information -which words appeared next to which other words (in the same language), and which words appeared in the same region of the document (in different languages). This collection was then used to train word embeddings with monolingual skip-gram with negative sampling using word2vec. With pseudo-bilingual documents, the "context" of a word is redefined as a mixture of neighboring words (in the original language) and words that appeared in the same region of the document (in the foreign language). Bilingual contexts for each word in each pseudobilingual document steer the final model towards constructing a SCLVS.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Visual Representations</head><p>Only a few studies have tried to make use of the intuition that words in different languages denoting the same concepts are similarly grounded in the perceptual system (bicycles resemble each other irrespective of whether we call them bicyle, vélo, fiets or Fahrrad, see <ref type="figure" target="#fig_3">Fig. 1</ref>) <ref type="bibr">(Bergsma and van Durme, 2011;</ref><ref type="bibr">Kiela et al., 2015)</ref>. Although the idea is promising, such visual methods are still limited in comparison with linguistic ones, especially for more abstract concepts <ref type="bibr">(Kiela et al., 2015)</ref>. Recent findings in multi-modal semantics suggest that visual representations encode pieces of semantic information complementary to linguistic information derived from text <ref type="bibr">(Deselaers and Ferrari, 2011;</ref><ref type="bibr">Silberer and Lapata, 2014)</ref>.</p><p>We compute visual representations in a similar fashion to <ref type="bibr">Kiela et al. (2015)</ref>: For each word we retrieve n images from Google image search (see <ref type="figure" target="#fig_3">Fig. 1</ref>), and for each image we extract the presoftmax layer of an AlexNet <ref type="bibr">(Krizhevsky et al., 2012</ref>) that has been pre-trained on the ImageNet Each image is thus represented as a 4096-dimensional feature vector extracted from a convolutional neural network (CNN). We use two methods for computing visual similarity: (1) CNN-MAX produces a single visual vector by taking the pointwise maximum across the n image vector representations from the image set. The representation of each word w ∈ V S ∪ V T in a visual SCLVS is now a real-valued vector</p><formula xml:id="formula_94">w vis = [f vis 1 , . . . , f vis dv ]</formula><p>, where f vis k ∈ R denotes the score for the k-th visual cross-lingual feature for w within a d v -dimensional visual SCLVS (d v = 4096). As before, similarity between two words w, v ∈ V S ∪ V T is computed by applying a similarity function on their representations in the visual SCLVS: sim vis (w, v) = SF (w vis , v vis ), e.g. cosine. (2) CNN-AVGMAX: An alternative strategy, introduced by Bergsma and van Durme (2011), is to consider the similarities between individual images from the two sets and take the average of the maximum similarity scores as the final similarity sim vis (w, v).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Multi-Modal Representations</head><p>We experiment with two ways of fusing information stemming from the linguistic and visual modalities. Following recent work in multi-modal semantics <ref type="bibr">(Bruni et al., 2014;</ref><ref type="bibr">Kiela and Bottou, 2014)</ref>, we construct representations by concatenating the centered and L 2 -normalized linguistic and visual feature vectors:</p><formula xml:id="formula_95">wmm = α × w ling || (1 − α) × wvis<label>(1)</label></formula><p>where || denotes concatenation and α is a parameter governing the contributions of each unimodal representation. The final similarity may again be computed by applying an SF on the multimodal representations. We call this method EarlyFusion. Note that it is possible only with CNN-MAX. The alternative is not to build a full multimodal (MM) representation, but instead to combine the individual similarity scores from each uni-modal SCLVS. The similarity sim(w, v) between two words w and v is:</p><formula xml:id="formula_96">α × sim ling (w, v) + (1 − α) × simvis(w, v) = = α × SF (w ling , v ling ) + (1 − α) × SF (wvis, vvis)</formula><p>where α again controls for the importance of the uni-modal scores in the final combined scores. We call this method Late-Fusion 3 .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Experimental Setup</head><p>Task: Bilingual Lexicon Learning Given a source language word w s , the task is to find a target language word w t closest to w s in the SCLVS, and the resulting pair (w s , w t ) is a bilingual lexicon entry. Performance is measured using the BLL standard Top 1 accuracy (Acc 1 ) metric <ref type="bibr">(Gaussier et al., 2004;</ref><ref type="bibr" target="#b391">Gouws et al., 2015)</ref>.</p><p>Test Sets We work with three language pairs: English-Spanish/Dutch/Italian (EN-ES/NL/IT), and two benchmarking BLL test sets:</p><p>(1) BERGSMA500: consisting of a set of 500 ground truth noun pairs for the three language pairs, it is considered a benchmarking test set in prior work on BLL using vision (Bergsma and van Durme, 2011) 4 . Translation direction in our tests is  LinguaTools 6 . The 100K most frequent words were retained for all models. We followed related work <ref type="bibr">Lazaridou et al., 2015a)</ref> for learning the mapping W in M-EMB: starting from the BNC word frequency list <ref type="bibr">(Kilgarriff, 1997)</ref>, the 6, 318 most frequent EN words were translated to the three other languages using Google Translate. The lists were subsequently cleaned, removing all pairs that contain IT/ES/NL words occurring in the test sets and least frequent pairs, to build the final 3×5K training pairs. We trained two monolingual SGNS models, using SGD with a global learning rate of 0.025. For G-EMB, as in the original work <ref type="bibr" target="#b391">(Gouws et al., 2015)</ref>, the bilingual signal for the cross-lingual regularization was provided in the first 500K sentences from Europarl.v7 <ref type="bibr">(Tiedemann, 2012)</ref>. We used SGD with a global learning rate 0.15. For V-EMB, monolingual SGNS was trained on pseudo-bilingual documents using SGD with a global learning rate 0.025. All BWEs were trained with d = 300. 7 Other parameters are: 15 epochs, 15 negatives, subsampling rate 1e − 4. We report results with two α standard values: 0.5 and 0.7 (more weight assigned to the linguistic part). <ref type="table" target="#tab_10">Table 1</ref> summarizes Acc 1 scores, focusing on interesting comparisons across different dimen-6 http://linguatools.org/tools/corpora/ 7 Similar trends were observed with all models and d = 64, 500. We also vary the window size from 4 to 16 in steps of 4, and always report the best scoring linguistic embeddings. sions 8 . There is a marked difference in performance on BERGSMA500 and VULIC1000: visual-only BLL models on VULIC1000 perform two times worse than linguistic-only BLL models. This is easily explained by the increased abstractness of test words in VULIC1000 in comparison to BERGSMA500 9 , which highlights the need for a multi-modal approach.</p><formula xml:id="formula_97">EN → ES/IT /N L.<label>(2)</label></formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Results and Discussion</head><p>Multi-Modal vs. Uni-Modal The multi-modal models outperform both linguistic and visual models across all setups and combinations on BERGSMA500. On VULIC1000 multi-modal models again outperform their uni-modal components in both modalities. In the latter case, improvements are dependent on the amount of visual information included in the model, as governed by α. Since the dataset also contains highly abstract words, the inclusion of visual information may be detrimental to performance. These models outperform the uni-modal models across a wide variety of settings: they outperform the three linguistic-only BLL models that held best reported Acc 1 scores on the evaluation set (Vulić and <ref type="bibr">Moens, 2016)</ref>. The largest improvements are statistically significant according to McNemar's test, p &lt; 0.01. We find improvements on both test sets for all three BWE types.</p><p>The relative ranking of the visual metrics intro-duced in <ref type="bibr">Kiela et al. (2015)</ref> extends to the MM setting: Late-Fusion with CNN-AVGMAX is the most effective MM BLL model on average, but all other tested MM configurations also yield notable improvements.</p><p>Concreteness To measure concreteness, we use an unsupervised data-driven method, shown to closely mirror how concrete a concept is: image dispersion (ID) <ref type="bibr">(Kiela et al., 2014)</ref>. ID is defined as the average pairwise cosine distance between all the image representations/vectors {i 1 . . . i n } in the set of images for a given word w:</p><formula xml:id="formula_98">id(w) = 2 n(n − 1) j&lt;k≤n 1 − ij · i k |ij||i k |<label>(2)</label></formula><p>Intuitively, more concrete words display more coherent visual representations and consequently lower ID scores (see Footnote 9 again). The lowest improvements on VULIC1000 are reported for the IT-EN language pair, which is incidentally the most abstract test set.</p><p>There is some evidence that abstract concepts are also perceptually grounded (Lakoff and <ref type="bibr">Johnson, 1999)</ref>, albeit in a more complex way, since abstract concepts will relate more varied situations <ref type="bibr">(Barsalou and Wiemer-Hastings, 2005)</ref>. Consequently, uni-modal visual representations are not powerful enough to capture all the semantic intricacies of such abstract concepts, and the linguistic components are more beneficial in such cases. This explains an improved performance with α = 0.7, but also calls for a more intelligent decision mechanism on how much perceptual information to include in the multi-modal models. The decision should be closely related to the degree of a concept's concreteness, e.g., eq. (2).</p><p>Image Dispersion Weighting The intuition that the inclusion of visual information may lead to negative effects in MM modeling has been exploited by <ref type="bibr">Kiela et al. (2014)</ref> in their work on image-dispersion filtering: Although the filtering method displays some clear benefits, its shortcoming lies in the fact that it performs a binary decision which can potentially discard valuable perceptual information for less concrete concepts. Here, we introduce a weighting scheme where the perceptual information is weighted according to its ID value. Early-Fusion is now computed as:</p><formula xml:id="formula_99">wmm = α(id) × w ling || (1 − α(id)) × wvis</formula><p>Late-Fusion model becomes:</p><formula xml:id="formula_100">α(id) × SF (w ling , v ling ) + (1 − α(id)) × SF (wvis, vvis)</formula><p>α(id) denotes a weight that is proportional to the ID score of the source language word w: we opt for a simple approach and specify α(id) = id(w). Instead of having one global parameter α, the ID weighting adjusts the amount of information locally according to each concept's concreteness.</p><p>The results are summarised in <ref type="table" target="#tab_10">Table 1</ref>. All multi-modal models with ID-based weighting are outperforming their uni-modal components. The ID-weighted BLL models reach (near-)optimal BLL results across a variety of language-vision combinations without any fine-tuning.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Conclusion</head><p>We have presented a novel approach to bilingual lexicon learning (BLL) that combines linguistic and visual representations into new bilingual multi-modal (MM) models. Two simple yet effective ways to fuse the linguistic and visual information for BLL have been described. Such MM models outperform their linguistic and visual uni-modal component models on two standard benchmarking BLL test sets for three language pairs. Comparisons with three different state-of-the-art bilingual word embedding induction models demonstrate that the gains of MM modeling are generally applicable.</p><p>As future work, we plan to analyse the ability of multi-view representation learning algorithms to yield fused multi-modal representations in bilingual settings <ref type="bibr">(Lazaridou et al., 2015b;</ref><ref type="bibr">Rastogi et al., 2015;</ref>, as well as to apply multi-modal bilingual spaces in other tasks such as zero-short learning <ref type="bibr">(Frome et al., 2013)</ref> or cross-lingual MM information search and retrieval following paradigms from monolingual settings <ref type="bibr">(Pereira et al., 2014;</ref><ref type="bibr">Vulić and Moens, 2015)</ref>.</p><p>The inclusion of perceptual data, as this paper reveals, seems especially promising in bilingual settings <ref type="bibr">(Rajendran et al., 2016;</ref><ref type="bibr">Elliott et al., 2016)</ref>, since the perceptual information demonstrates the ability to transcend linguistic borders. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Abstract</head><p>In this paper we study how to identify persuasive posts in the online forum discussions, using data from Change My View sub-Reddit. Our analysis confirms that the users' voting score for a comment is highly correlated with its metadata information such as published time and author reputation. In this work, we propose and evaluate other features to rank comments for their persuasive scores, including textual information in the comments and social interaction related features. Our experiments show that the surface textual features do not perform well compared to the argumentation based features, and the social interaction based features are effective especially when more users participate in the discussion.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>With the popularity of online forums such as idebate 1 and convinceme 2 , researchers have been paying increasing attentions to analyzing persuasive content, including identification of arguing expressions in online debates <ref type="bibr">(Trabelsi and Zaıane, 2014)</ref>, recognition of stance in ideological online debates (Somasundaran and <ref type="bibr">Wiebe, 2010;</ref><ref type="bibr">Hasan and Ng, 2014;</ref><ref type="bibr">Ranade et al., 2013b)</ref>, and debate summarization <ref type="bibr">(Ranade et al., 2013a)</ref>. However, how to automatically determine if a text is persuasive is still an unsolved problem.</p><p>Text quality and popularity evaluation has been studied in different domains in the past few years <ref type="bibr">(Louis and Nenkova, 2013;</ref><ref type="bibr">Tan et al., 2014;</ref><ref type="bibr">Park et al., 2016;</ref><ref type="bibr">Guerini et al., 2015)</ref>. However, 1 http://idebate.org/ 2 http://convinceme.net quality evaluation of argumentative text in the online forum has some unique characterisitcs. First, persuasive text contains argument that is not common in other genres. Second, beside the text itself, the interplay between a comment and what it responds to is crucial. Third, the community reaction to the comment also needs to be taken into consideration.</p><p>In this paper, we propose several sets of features to capture the above mentioned characteristics for persuasive comment identification in the online forum. We constructed a dataset from a sub-forum of Reddit 3 , namely change my view (CMV) 4 . We first analyze the corpus and show the correlation between the human voting score for an argumentative comment and its entry order and author reputation. Then for the comment ranking task, we propose three sets of features including surface text features, social interaction based features and argumentation based features. Our experimental results show that the argumentation based features work the best in the early stage of the discussion and the effectiveness of social interaction features increases when the number of comments in the discussion grows.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Dataset and Task</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Data</head><p>On CMV, people initiate a discussion thread with a post expressing their thoughts toward a specific topic and other users reply with arguments from the opposite side in order to change the initiator's mind. The writing quality on CVM is quite good since the discussions are monitored by moderators. Besides commenting, users can vote on different replies to indicate which one is more persuasive than others. The total amount of upvotes  We use a corpus collected from CMV. <ref type="bibr">5</ref> The original corpus contains all the threads published between Jan. 2014 and Jan. 2015. We kept the threads with more than 100 comments to form our experimental dataset 6 . The basic statistics of the dataset can be seen in <ref type="table" target="#tab_10">Table 1</ref>. <ref type="figure" target="#fig_3">Figure 1a</ref> shows the distribution of the karma scores in the dataset. We can see that the karma score is highly skewed, similar to what is reported in <ref type="bibr">(Jaech et al., 2015)</ref>. 42% of comments obtain a karma score of exactly one (i.e., no votes beyond the author), and around 15% of comments have a score less than one. <ref type="figure" target="#fig_3">Figure 1b</ref> and 1c show the correlation of the karma score with two metadata features, author reputation 7 and entry order, respectively. We can see the karma score of a comment is highly related to its entry order. In general, the earlier a comment is posted, the higher karma score it obtains. The average score is less than one when it is posted after 30 comments. <ref type="figure" target="#fig_3">Figure 1c</ref> shows that authors of comments with higher karma scores tend to have higher reputation on average. <ref type="bibr">Tan et al. (2016)</ref> explored the task of mind change by focusing on delta awarded comments using their CMV data. However, the percentage of delta awarded comments is quite low, as shown in Table 1 (the percentage of comments obtained delta is as low as 0.5%). In addition, a persuasive comment is not necessarily delta awarded. It can be of high quality but does not change other people's mind. Our research thus uses the karma score of a comment, instead of delta, as the reference to represent the persuasiveness of the comment. Our analysis also shows that delta awarded comments generally have high karma scores (78.7% of DACs obtain a higher karma score than the median value in each delta awarded thread), indicating the karma score is correlated with the delta value.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Task</head><p>Using karma scores as ground truth, Jaech et al. <ref type="formula" target="#formula_0">(2015)</ref> proposed a comment ranking task on several sub-forums of Reddit. In order to reduce the impact of timing, they rank each set of 10 connective comments. However, their setting is not suitable for our task. First, at the later stage of the discussion, comments posted connectively in terms of time can belong to different sub-trees of the discussion, and thus can be viewed or reacted with great difference. Second, as shown in <ref type="figure" target="#fig_3">Figure 1b</ref>, comments entered in later stage obtain little attention from audience. This makes their karma scores less reliable as the ground-truth of persuasiveness.</p><p>To further control the factor of timing, we define the task as ranking the first-N comments in each thread. The final karma scores of these N comments are used to determine their reference rank for evaluation. We study two setups for this ranking task. First we use information until the time point when the thread contains only these N comments. Second we allow the system to access more comments than N . Our goal is to investigate if we can predict whether a comment is persuasive and how the community reacts to a comment in the future.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Methods</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Ranking Model</head><p>A pair-wise learning-to-rank model <ref type="bibr">(Ranking SVM (Joachims, 2002)</ref>) is used in our task. We first construct the training set including pairs of comments. In each pair, the first comment is more persuasive than the second one. Considering that two samples with similar karma scores might not be significantly different in terms of their persuasiveness, we propose to use a modified score to form training pairs in order to improve the learning efficacy. We group comments into 7 buckets based on their karma scores, <ref type="bibr">[-∞, 0]</ref> </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Social Interaction Features tree size</head><p>The tree size generated by c and rc. reply num</p><p>The number of replies obtained by c and rc. tree height</p><p>The height of the tree generated by by c and rc.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Is root reply</head><p>Is c a root reply of the post? Is leaf</p><p>Is c a leaf of the tree generated by rc? location</p><p>The position of c in the tree generated by rc.  as its modified score. We use all the formed pairs to train our ranker. In order to be consistent, we use the first-N comments in the training threads to construct the training samples to predict the rank for the first-N comments in a test thread.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Features</head><p>We propose several key features that we hypothesize are predictive of persuasive comments. The full feature list is given in <ref type="table" target="#tab_5">Table 2</ref>.</p><p>• Surface Text Features 8 : In order to capture the basic textual information, we use the comment length and content diversity represented as the number of words, POS tags, URLs, and punctuation marks. We also explored unigram features and named entity based features, but they did not improve system performance and are thus not included.</p><p>• Social Interaction Features: We hypothesize that if a comment attracts more social attention from the community, it is more likely to be persuasive, therefore we propose several social interaction features to capture the community reaction to a comment. Besides the reply tree generated by the comment, we also consider the reply tree generated by the root comment 9 for feature computing. The tree size is the number of comments in the reply tree. The position of c is its level in the reply tree (the level of root node is zero).</p><p>• Argumentation Related Features: We believe a comment's argumentation quality is a good indicator of its persuasiveness. In order to capture the argumentation related information, we propose two sub-groups of features based on the comment itself and the interplay between the comment and other comments in the discussion. a) Local features: we trained a binary classifier to classify sentences as argumentative and non-argumentative using features proposed in <ref type="bibr" target="#b628">(Stab and Gurevych, 2014</ref>  <ref type="table" target="#tab_6">Table 3</ref>: Performance of first-10 comments ranking (T+S+A: the combination of the three sets of features we proposed; all: the combination of two meta-data features and our features; bold: the best performance in each column; †: the approach is significantly better than both metadata baselines (p &lt;0.01); ‡: the approach is significantly better than LTR approaches using a single category of features (p &lt;0.01).).</p><p>tences predicted by the classifier as features. Besides, we include some features used in the classifier directly (i.e. number of connective words 10 and modal verbs). b) Interactive features: for these features, we consider the similarity of a comment and its parent comment, the original post, and all the previously published comments. We use cosine similarity computed based on the term frequency vector representation. Intuitively a comment needs to be relevant to the discussed topic and possibly have some original convincing opinions or arguments to receive a high karma score.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Experimental Results</head><p>We use 5-fold cross-validation in our experiments. Normalized discounted cumulative gain (NDCG) score <ref type="bibr">(Järvelin and Kekäläinen, 2000)</ref> is used as the evaluation metric for our First-N comments ranking task. In this study, N is10. <ref type="table" target="#tab_6">Table 3</ref> shows the results for first-10 comments ranking using information from only these 10 comments. As shown in <ref type="figure" target="#fig_3">Figure 1</ref>, metadata features, entry order and author's reputation are correlated with the karma score of a comment. We thus use these two values as baselines. We also include the performance of the random baseline for comparison 11 . For our ranking based models (LTR * ), we compare using the three sets of features described in Section. 3.2 (noted as text, social and arg respectively), individually or in combination. We report NDCG scores for position 1, 5 and 10 respectively. The followings are some findings.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Experiment I: Using N Comments for Ranking</head><p>• Both metadata based baselines generate significantly 12 better results compared to the random baseline. Baseline entry-order performs much better than author, suggesting that the entry order is more indicative for the karma score of a comment.</p><p>• The surface text features are least effective among the three sets of features, and the performance using them is even worse than the two metadata baselines. This might be because the general writing quality of the comments in CMV is high because of the policy of the forum. Therefore, the surface text features we used are not very discriminative for comment ranking. A further analysis of features in this category shows that length is the most effective feature.</p><p>• Argumentation based features have the best performance among the three categories. Its performance is significantly better than surface text features, consistent with our expectation that argumentation related features are useful for persuasiveness evaluation. Our additional experiments show that interactive features are more effective than local features. This might be because the argumentation features and models we use are not perfect. Future research is still needed to better represent argumentation information in the text.</p><p>• When combining two categories of features, the performance of the ranker increases consistently. The performance can be further improved by combining all the three categories of features we proposed (the improvement compared to using a single feature category is significant). The best results are achieved by LTR all , i.e., combining two metadata features and features we proposed. <ref type="bibr">11</ref> The performance of random baseline is high because of the tie of reference karma scores. <ref type="bibr">12</ref> Significance is computed by two tailed t-test. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Experiment II: Using Varying Numbers of Comments for Ranking</head><p>With the evolving discussion, there will be more comments joining the thread providing more information for social interaction based features. In order to show the impact of different features at different discussion stage, we conduct another experiment by ranking first-10 comments with varying numbers of comments in the test thread for feature computing. The result of the experiment is shown in <ref type="figure" target="#fig_8">Figure 2</ref>. The performance of LTR text and LTR arg remain the same since their feature values are not affected by the new coming comments. The performance of LTR social increases consistently when the number of comments grows, and it outperforms LTR arg when the number of comments is more than 20. LTR T +S+A has always the best performance, benefiting from the combination of different types of features.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Related Work</head><p>Our work is most related to two lines of work, including text quality evaluation and research on Reddit.com.</p><p>Text quality: Text quality and popularity evaluation has been studied in different domains in the past few years. Louis and Nenkova (2013) implemented features to capture aspects of great writing in science journalism domain. <ref type="bibr">Tan et al. (2014)</ref> looked into the effect of wording while predicting the popularity of social media content. <ref type="bibr">Park et al. (2016)</ref> developed an interactive system to assist human moderators to select high quality news. <ref type="bibr">Guerini et al. (2015)</ref> modeled a notion of euphony and explored the impact of sounds on different forms of persuasiveness. Their research focused on the phonetic aspect instead of language usage.</p><p>Reddit based research: Reddit has been used recently for research on social news analysis and recommendation (e.g., <ref type="bibr">(Buntain and Golbeck, 2014)</ref>). Researchers also analyzed the language use on Reddit. Jaech et al. <ref type="formula" target="#formula_0">(2015)</ref> studied how language use affects community reaction to comments in Reddit. <ref type="bibr">Tan et al. (2016)</ref> analyzed the interaction dynamics and persuasion strategies in CMV.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Conclusion</head><p>In this paper, we studied the impact of different sets of features on the identification of persuasive comments in the online forum. Our experiment results show that argumentation based features work the best in the early stage of the discussion, while the effectiveness of social interaction based features increases when the number of comments in the thread grows.</p><p>There are three major future directions for this research. First, the approach for argument modeling in this paper is lexical based, which limits the effectiveness of argumentation related features for our task. It is thus crucial to study more effective ways for argument modeling. Second, we will explore persuasion behavior of the argumentative comments and study the correlation between the strength of the argument and different persuasion behaviors. Third, we plan to automatically construct an argumentation corpus including pairs of arguments from two opposite sides of the topic from CMV, and use this for automatic disputing argument generation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>References</head><p>Cody Buntain and Jennifer Golbeck. 2014. Identifying social roles in reddit using network structure. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Abstract</head><p>We demonstrate the value of collecting semantic parse labels for knowledge base question answering. In particular, (1) unlike previous studies on small-scale datasets, we show that learning from labeled semantic parses significantly improves overall performance, resulting in absolute 5 point gain compared to learning from answers, (2) we show that with an appropriate user interface, one can obtain semantic parses with high accuracy and at a cost comparable or lower than obtaining just answers, and <ref type="formula" target="#formula_6">(3)</ref> we have created and shared the largest semantic-parse labeled dataset to date in order to advance research in question answering.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Semantic parsing is the mapping of text to a meaning representation. Early work on learning to build semantic parsers made use of datasets of questions and their associated semantic parses <ref type="bibr">(Zelle and Mooney, 1996;</ref><ref type="bibr">Zettlemoyer and Collins, 2005;</ref><ref type="bibr">Wong and Mooney, 2007)</ref>. Recent work on semantic parsing for knowledge base questionanswering (KBQA) has called into question the value of collecting such semantic parse labels, with most recent KBQA semantic parsing systems being trained using only question-answer pairs instead of question-parse pairs. In fact, there is evidence that using only question-answer pairs can yield improved performance as compared with approaches based on semantic parse labels <ref type="bibr" target="#b296">(Liang et al., 2013)</ref>. It is also widely believed that collecting semantic parse labels can be a "difficult, time consuming task" (Clarke et al., 2010) even for domain experts. Furthermore, recent focus has been more on the final task-specific performance of a system (i.e., did it get the right answer for a question) as opposed to agreement on intermediate representations <ref type="bibr" target="#b296">(Berant et al., 2013;</ref><ref type="bibr">Kwiatkowski et al., 2013)</ref>, which allows for KBQA datasets to be built with only the answers to each question.</p><p>In this work, we re-examine the value of semantic parse labeling and demonstrate that semantic parse labels can provide substantial value for knowledge base question-answering. We focus on the task of question-answering on Freebase, using the WEBQUESTIONS dataset <ref type="bibr" target="#b296">(Berant et al., 2013)</ref>.</p><p>Our first contribution is the construction of the largest semantic parse dataset for KB questionanswering to date. In order to evaluate the costs and benefits of gathering semantic parse labels, we created the WEBQUESTIONSSP dataset 1 , which contains semantic parses for the questions from WEBQUESTIONS that are answerable using Freebase. In particular, we provide SPARQL queries for 4,737 questions. The remaining 18.5% of the original WEBQUESTIONS questions are labeled as "not answerable". This is due to a number of factors including the use of a more stringent assessment of "answerable", namely that the question be answerable via SPARQL rather than by returning or extracting information from textual descriptions. Compared to the previous semantic parse dataset on Freebase, Free917 <ref type="bibr">(Cai and Yates, 2013)</ref>, our WEBQUESTIONSSP is not only substantially larger, but also provides the semantic parses in SPARQL with standard Freebase entity identifiers, which are directly executable on Freebase.</p><p>Our second contribution is a demonstration that semantic parses can be collected at low cost. We employ a staged labeling paradigm that enables efficient labeling of semantic parses and improves the accuracy, consistency and efficiency of ob-1 Available at http://aka.ms/WebQSP. 201 taining answers. In fact, in a simple comparison with using a web browser to extract answers from freebase.com, we show that we can collect semantic parse labels at a comparable or even faster rate than simply collecting answers.</p><p>Our third contribution is an empirical demonstration that we can leverage the semantic parse labels to increase the accuracy of a state-of-the-art question-answering system. We use a system that currently achieves state-of-the-art performance on KBQA and show that augmenting its training with semantic parse labels leads to an absolute 5-point increase in average F 1 .</p><p>Our work demonstrates that semantic parse labels can provide additional value over answer labels while, with the right labeling tools, being comparable in cost to collect. Besides accuracy gains, semantic parses also have further benefits in yielding answers that are more accurate and consistent, as well as being updatable if the knowledge base changes (for example, as facts are added or revised).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Collecting Semantic Parses</head><p>In order to verify the benefits of having labeled semantic parses, we completely re-annotated the WEBQUESTIONS dataset <ref type="bibr" target="#b296">(Berant et al., 2013)</ref> such that it contains both semantic parses and the derived answers. We chose to annotate the questions with the full semantic parses in SPARQL, based on the schema and data of the latest and last version of Freebase (2015-08-09).</p><p>Labeling interface Writing SPARQL queries for natural language questions using a text editor is obviously not an efficient way to provide semantic parses even for experts. Therefore, we designed a staged, dialog-like user interface (UI) to improve the labeling efficiency. Our UI breaks the potentially complicated structured-labeling task into separate, but inter-dependent sub-tasks. Given a question, the UI first presents entities detected in the questions using an entity linking system <ref type="bibr">(Yang and Chang, 2015)</ref>, and asks the user to pick an entity in the question as the topic entity that could lead to the answers. The user can also suggest a new entity if none of the candidates returned by the entity linking system is correct. Once the entity is selected, the system then requests the user to pick the Freebase predicate that represents the relationship between the answers and this topic entity. Finally, additional filters can be added to further constrain the answers. One key advantage of our UI design is that the annotator only needs to focus on one particular sub-task during each stage. All of the choices made by the labeler are used to automatically construct a coherent semantic parse. Note that the user can easily go back and forth to each of these three stages and change the previous choices, before pressing the final submit button.</p><p>Take the question "who voiced meg on family guy?" for example. The labeler will be presented with two entity choices: Meg Griffin and Family Guy, where the former links "meg" to the character's entity and the latter links to the TV show. Depending on the entity selected, legitimate Freebase predicates of the selected entity will be shown, along with the objects (either properties or entities). Suppose the labeler chooses Meg Griffin as the topic entity. He should then pick actor as the main relationship, meaning the answer should be the persons who have played this role. To accurately describe the question, the labeler should add additional filters like the TV series is Family Guy and the performance type is voice in the final stage 2 .</p><p>The design of our UI is inspired by recent work on semantic parsing that has been applied to the WEBQUESTIONS dataset <ref type="bibr">(Bast and Haussmann, 2015;</ref><ref type="bibr">Reddy et al., 2014;</ref><ref type="bibr">Berant and Liang, 2014;</ref><ref type="bibr">Yih et al., 2015)</ref>, as these approaches use a simpler and yet more restricted semantic representation than first-order logic expressions. Following the notion of query graph in <ref type="bibr">(Yih et al., 2015)</ref>, the semantic parse is anchored to one of the entities in the question as the topic entity and the core component is to represent the relation between the entity and the answer, referred as the inferential chain. Constraints, such as properties of the answer or additional conditions the relation needs to hold, are captured as well. <ref type="figure" target="#fig_3">Figure 1</ref> shows an example of these annotated semantic parse components and the corresponding SPARQL query. While it is clear that our UI does not cover complicated, highly compositional questions, most questions in WEBQUESTIONS can be covered 3 .</p><p>Labeling process In order to ensure the data quality, we recruit five annotators who are familiar with design of Freebase. Our goal is to provide  <ref type="figure" target="#fig_3">Figure 1</ref>: Example semantic parse of the question (a) "who voiced meg on family guy?" The three components in (b) record the labels collected through our dialog-like user interface, and can be mapped deterministically to either the corresponding query graph (c) or the SPARQL query (d).</p><p>correct semantic parses for each of the legitimate and unambiguous questions in WEBQUESTIONS. Our labeling instructions (included in the supplementary material) follow several key principles. For instance, the annotators should focus on giving the correct semantic parse of a question, based on the assumption that it will result in correct answers if the KB is complete and correct.</p><p>Among all the 5,810 questions in WEB-QUESTIONS, there are 1,073 questions that the annotators cannot provide the complete parses to find the answers, due to issues with the questions or Freebase. For example, some questions are ambiguous and without clear intent (e.g., "where did romans go?"). Others are questions that Freebase is not the appropriate information source (e.g., "where to watch tv online for free in canada?").</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Using Semantic Parses</head><p>In order to compare two training paradigms, learning from question-answer pairs and learning from semantic parses, we adopt the Staged Query Graph Generation (STAGG) algorithm <ref type="bibr">(Yih et al., 2015)</ref>, which achieves the highest published answer prediction accuracy on the WEBQUESTIONS dataset. STAGG formulates the output semantic parse in a query graph representation that mimics the design of a graph knowledge base. It searches over potential query graphs for a question, iteratively growing the query graph by sequentially adding a main topic entity, then adding an inferential chain and finally adding a set of constraints. During the search process, each candidate query graph is judged by a scoring function on how likely the graph is a correct parse, based on features indicating how each individual component matches the original question, as well as some properties of the whole query graph. Example features include the score output by the entity linking system, the match score of the inferential chain to the relation described in the question from a deep neural network model, number of nodes in the candidate query graph, and the number of matching words in constraints. For additional details see <ref type="bibr">(Yih et al., 2015)</ref>.</p><p>When question-answer pairs are available, we create a set of query graphs connecting entities in the question to the answers in the training set, as in <ref type="bibr">(Yih et al., 2015)</ref>. We score the quality of a query graph by using the F 1 score between the answer derived from the query graph and the answer in the training set. These scores are then used in a learning-to-rank approach to predict high-quality query graphs.</p><p>In the case that semantic parses are available, we change the score that we use for evaluating the quality of a query graph. In particular, we assign the query graph score to be zero whenever the query graph is not a subgraph consistent with the semantic parse label and to be the F 1 score described above otherwise. The hope is that by leveraging the semantic parse, we can significantly reduce the number of incorrect query graphs used during training. For instance, the predicate music.artist.track was incorrectly predicted as the inferential chain for the question "what are the songs that justin bieber write?", where a correct parse should use the relation music.composer.compositions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">The Value of Semantic Parses</head><p>In this section, we explore the costs of collecting semantic parse labels and the benefits of using them.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Benefits of Semantic Parses</head><p>Leveraging the new dataset, we study whether a semantic parser learned using full parses instead of just question-answer pairs can answer questions more accurately, using the knowledge base. Below, we describe our basic experimental setting and report the main results.</p><p>Experimental setting We followed the same training/testing splits as in the original WEB-QUESTIONS dataset, but only used questions with complete parses and answers for training and evaluation in our experiments. In the end, 3,098 questions are used for model training and 1,639 questions are used for evaluation 4 . Because there can be multiple answers to a question, precision, recall and F 1 are computed for each individual question. The average F 1 score is reported as the main evaluation metric. In addition, we also report the true accuracy -a question is considered answered correctly only when the predicted answers exactly match one of the answer sets.</p><p>Results <ref type="table" target="#tab_10">Table 1</ref> shows the results of two different models: learning from question-answer pairs vs. learning from semantic parses. With the labeled parses, the average F 1 score is 4.9-point higher (71.7% vs. 66.8%). The stricter metric, complete answer set accuracy, also reflects the same trend, where the accuracy of training with labeled parses is 5.1% higher than using only the answers (63.9% vs. 58.8%). While it is expected that training using the annotated parses could result in a better model, it is still interesting to see the performance gap, especially when the evaluation is on the correctness of the answers rather than the parses. We examined the output answers to the questions where the two models differ. Although the setting of using answers only often guesses the correct relations connecting the topic entity and answers, it can be confused by related, but incorrect relations as well. Similar phenomena also occur on constraints, which suggests that subtle differences in the meaning are difficult  to catch if the semantic parses are automatically generated using only the answers.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Costs of Semantic Parses</head><p>Our labeling process is very different from that of the original WEBQUESTIONS dataset, where the question is paired with answers found on the Freebase Website by Amazon MTurk workers. To compare these two annotation methods, we sampled 50 questions and had one expert label them using two schemes: finding answers using the Freebase Website and labeling the semantic parses using our UI. The time needed, as well as the correctness of the answers are summarized in <ref type="table" target="#tab_5">Table 2</ref>. Interestingly, in this study we found that it actually took less time to label these questions with semantic parses using our UI, than to label with only answers. There could be several possible explanations. First, as many questions in this dataset are actually "simple" and do not need complicated compositional structured semantic parses, our UI can help make the labeling process very efficient. By ranking the possible linked entities and likely relations, the annotators are able to pick the correct component labels fairly easily. In contrast, simple questions may have many legitimate answers. Enumerating all of the correct answers can take significantly longer than authoring a semantic parse that computes them.</p><p>When we compare the annotation quality between labeling semantic parses and answers, we find that the correctness 5 of the answers are about the same (92% vs 94%). In the original WEB-QUESTIONS dataset, only 66% of the answers are completely correct. This is largely due to the low accuracy (42.9%) of the 14 questions containing multiple answers. This indicates that to ensure data quality, more verification is needed when leveraging crowdsourcing.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Discussion</head><p>Unlike the work of <ref type="bibr" target="#b296">(Liang et al., 2013;</ref><ref type="bibr">Clarke et al., 2010)</ref>, we demonstrate that semantic parses can improve over state-of-the-art knowledge base question answering systems. There are a number of potential differences that are likely to contribute to this finding. Unlike previous work, we compare training with answers and training with semantic parses while making only minimal changes in a state-of-the-art training algorithm. This enables a more direct evaluation of the potential benefits of using semantic parses. Second, and perhaps the more significant difference, is that our evaluation is based on Freebase which is significantly larger than the knowledge bases used in the previous work. We suspect that the gains provided by semantic parse labels are due a significant reduction in the number of paths between candidate entities and answers when we limit to semantically valid paths. However, in domains where the number of potential paths between candidate entities and answers is small, the value of collecting semantic parse labels might also be small. Semantic parsing labels provide additional benefits. For example, collecting semantic parse labels relative to a knowledge base can ensure that the answers are more faithful to the knowledge base and better captures which questions are answerable by the knowledge base. Moreover, by creating semantic parses using a labeling system based on the target knowledge base, the correctness and completeness of answers can be improved. This is especially true for question that have large answer sets. Finally, semantic labels are more robust to changes in knowledge base facts because answers can be computed via execution of the semantic representation for the question. For instance, the answer to "Who does Chris Hemsworth have a baby with?" might change if the knowledge base is updated with new facts about children but the semantic parse would not need to change.</p><p>Notice that besides being used for the full semantic parsing task, our WEBQUESTIONSSP dataset is a good test bed for several important semantic tasks as well. For instance, the topic entity annotations are beneficial to training and testing entity linking systems. The core inferential chains alone are quality annotations for relation extraction and matching. Specific types of constraints are useful too. For example, the temporal semantic labels are valuable for identifying temporal expressions and their time spans. Because our dataset specifically focuses on questions, it complements existing datasets in these individual tasks, as they tend to target at normal corpora of regular sentences.</p><p>While our labeling interface design was aimed at supporting labeling experts, it would be valuable to enable crowdsourcing workers to provide semantic parse labels. One promising approach is to use a more dialog-driven interface using natural language (similar to ). Such UI design is also crucial for extending our work to handling more complicated questions. For instance, allowing users to traverse longer paths in a sequential manner will increase the expressiveness of the output parses, both in the core relation and constraints. Displaying a small knowledge graph centered at the selected entities and relations may help users explore alternative relations more effectively as well. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>References</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Relation classification is the task of finding semantic relations between pairs of nominals, which is useful for many NLP applications, such as information extraction <ref type="bibr">(Wu and Weld, 2010)</ref>, question answering <ref type="bibr" target="#b317">(Yao and Van Durme, 2014)</ref>. For instance, the following sentence contains an example of the Entity-Destination relation between the nominals Flowers and chapel. ⟨e 1 ⟩ Flowers ⟨/e 1 ⟩ are carried into the ⟨e 2 ⟩ chapel ⟨/e 2 ⟩. ⟨e 1 ⟩, ⟨/e 1 ⟩, ⟨e 2 ⟩, ⟨/e 2 ⟩ are four position indicators which specify the starting and ending of the nominals <ref type="bibr">(Hendrickx et al., 2009)</ref>.</p><p>Traditional relation classification methods that employ handcrafted features from lexical resources, are usually based on pattern matching, and have achieved high performance (Bunescu * Correspondence author: zhenyu.qi@ia.ac.cn <ref type="bibr">and Mooney, 2005;</ref><ref type="bibr">Mintz et al., 2009;</ref><ref type="bibr">Rink and Harabagiu, 2010)</ref>. One downside of these methods is that many traditional NLP systems are utilized to extract high-level features, such as part of speech tags, shortest dependency path and named entities, which consequently results in the increase of computational cost and additional propagation errors. Another downside is that designing features manually is time-consuming, and performing poor on generalization due to the low coverage of different training datasets.</p><p>Recently, deep learning methods provide an effective way of reducing the number of handcrafted features <ref type="bibr" target="#b424">(Socher et al., 2012;</ref><ref type="bibr">Zeng et al., 2014)</ref>. However, these approaches still use lexical resources such as WordNet <ref type="bibr" target="#b249">(Miller, 1995)</ref> or NLP systems like dependency parsers and NER to get high-level features.</p><p>This paper proposes a novel neural network Att-BLSTM for relation classification. Our model utilizes neural attention mechanism with Bidirectional Long Short-Term Memory Networks(BLSTM) to capture the most important semantic information in a sentence. This model doesn't utilize any features derived from lexical resources or NLP systems.</p><p>The contribution of this paper is using BLST-M with attention mechanism, which can automatically focus on the words that have decisive effect on classification, to capture the most important semantic information in a sentence, without using extra knowledge and NLP systems. We conduct experiments on the SemEval-2010 Task 8 dataset, and achieve an F 1-score of 84.0%, higher than most of the existing methods in the literature.</p><p>The remainder of the paper is structured as follows. In Section 2, we review related work about relation classification. Section 3 presents our Att-BLSTM model in detail. In Section 4, we describe details about the setup of experimental evaluation 207 and the experimental results. Finally, we have our conclusion in Section 5.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Related Work</head><p>Over the years, various methods have been proposed for relation classification. Most of them are based on pattern matching and apply extra NLP systems to derive lexical features. One related work is proposed by <ref type="bibr">Rink and Harabagiu (2010)</ref>, which utilizes many features derived from external corpora for a Support Vector Machine(SVM) classifier.</p><p>Recently, deep neural networks can learn underlying features automatically and have been used in the literature. Most representative progress was made by <ref type="bibr">Zeng et al. (2014)</ref>, who utilized convolutional neural networks(CNN) for relation classification. While CNN is not suitable for learning long-distance semantic information, so our approach builds on Recurrent Neural Network(RNN) <ref type="bibr">(Mikolov et al., 2010)</ref>.</p><p>One related work was proposed by <ref type="bibr" target="#b109">Zhang and Wang (2015)</ref>, which employed bidirectional RN-N to learn patterns of relations from raw text data. Although bidirectional RNN has access to both past and future context information, the range of context is limited due to the vanishing gradient problem. To overcome this problem, Long short-Term memory(LSTM) units are introduced by <ref type="bibr">Hochreiter and Schmidhuber (1997)</ref>.</p><p>Another related work is SDP-LSTM model proposed by <ref type="bibr" target="#b109">Yan et al. (2015)</ref>. This model leverages the shortest dependency path(SDP) between two nominals, then it picks up heterogeneous information along the SDP with LSTM units. While our method regards the raw text as a sequence.</p><p>Finally, our work is related to BLSTM model proposed by . This model utilizing NLP tools and lexical resources to get word, position, POS, NER, dependency parse and hypernym features, together with LSTM units, achieved a comparable result to the state-ofthe-art. However, comparing to the complicated features that employed by , our method regards the four position indicators ⟨e1⟩, ⟨/e1⟩, ⟨e2⟩, ⟨/e2⟩ as single words, and transforms all words to word vectors, forming a simple but competing model.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Model</head><p>In this section we propose Att-BLSTM model in detail. As shown in <ref type="figure" target="#fig_3">Figure 1</ref>, the model proposed in this paper contains five components:</p><p>(1) Input layer: input sentence to this model; (2) Embedding layer: map each word into a low dimension vector; (3) LSTM layer: utilize BLSTM to get high level features from step (2); (4) Attention layer: produce a weight vector, and merge word-level features from each time step into a sentence-level feature vector, by multiplying the weight vector;</p><p>(5) Output layer: the sentence-level feature vector is finally used for relation classification.</p><p>These components will be presented in detail in this section.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Word Embeddings</head><p>Given a sentence consisting of T words S = {x 1 , x 2 , . . . , x T }, every word x i is converted into a real-valued vector e i . For each word in S, we first look up the embedding matrix W wrd ∈ R d w |V | , where V is a fixed-sized vocabulary, and d w is the size of word embedding. The matrix W wrd is a parameter to be learned, and d w is a hyper-parameter to be chosen by user. We transform a word x i into its word embedding e i by using the matrix-vector product:</p><formula xml:id="formula_101">e i = W wrd v i<label>(1)</label></formula><p>where v i is a vector of size |V | which has value 1 at index e i and 0 in all other positions. Then the sentence is feed into the next layer as a real-valued vectors emb s = {e 1 , e 2 , . . . , e T } .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Bidirectional Network</head><p>LSTM units are firstly proposed by <ref type="bibr">Hochreiter and Schmidhuber (1997)</ref> to overcome gradient vanishing problem. The main idea is to introduce an adaptive gating mechanism, which decides the degree to which LSTM units keep the previous state and memorize the extracted features of the current data input. Then lots of LSTM variants have been proposed. We adopt a variant introduced by <ref type="bibr" target="#b645">Graves et al. (2013)</ref>, which adds weighted peephole connections from the Constant Error Carousel (CEC) to the gates of the same memory block. By directly employing the current cell state to generate the gate degrees, the peephole connections allow all gates to inspect into the cell (i.e.   <ref type="bibr" target="#b645">(Graves, 2013</ref> , all of those gates are set to generate some degrees, using current input x i , the state h i−1 that previous step generated , and current state of this cell c i−1 (peephole), for the decisions whether to take the inputs, forget the memory stored before, and output the state generated later. Just as these following equations demonstrate:</p><formula xml:id="formula_102">i t = σ(W xi x t + W hi h t−1 + W ci c t−1 + b i ) (2) f t = σ(W xf x t +W hf h t−1 +W cf c t−1 + b f ) (3) g t = tanh(W xc x t +W hc h t−1 +W cc c t−1 +b c ) (4) c t = i t g t + f t c t−1 (5) o t = σ(W xo x t + W ho h t−1 + W co c t + b o ) (6) h t = o t tanh(c t )<label>(7)</label></formula><p>Hence, current cell state c t will be generated by calculating the weighted sum using both previous cell state and current information generated by the cell <ref type="bibr" target="#b645">(Graves, 2013)</ref>.</p><p>For many sequence modelling tasks, it is beneficial to have access to future as well as past context. However, standard LSTM networks process sequences in temporal order, they ignore future context. Bidirectional LSTM networks extend the unidirectional LSTM networks by introducing a second layer, where the hidden to hidden connections flow in opposite temporal order. The model is therefore able to exploit information both from the past and the future.</p><p>In this paper, we use BLSTM. As also shown in <ref type="figure" target="#fig_3">Figure 1</ref>, the network contains two sub-networks for the left and right sequence context, which are forward and backward pass respectively. The output of the i th word is shown in the following equation:</p><formula xml:id="formula_103">h i = [ − → h i ⊕ ← − h i ]<label>(8)</label></formula><p>Here, we use element-wise sum to combine the forward and backward pass outputs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Attention</head><p>Attentive neural networks have recently demonstrated success in a wide range of tasks ranging from question answering, machine translations, speech recognition, to image captioning <ref type="bibr">(Hermann et al., 2015;</ref><ref type="bibr">Chorowski et al., 2015;</ref>. In this section, we propose the attention mechanism for relation classification tasks. Let H be a matrix consisting of output vectors[h 1 , h 2 , . . . , h T ] that the LSTM layer produced, where T is the sentence length. The representation r of the sentence is formed by a weighted sum of these output vectors:  <ref type="bibr" target="#b109">(Zhang and Wang, 2015)</ref> WV ) (dim=300) + PI 82.5 SDP-LSTM WV (pretrained by word2vec) (dim=200), syntactic parse 82.4 <ref type="bibr" target="#b109">(Yan et al., 2015)</ref> + POS + WordNet + grammar relation embeddings 83.7 BLSTM WV ) (dim=100) 82.7  + where</p><formula xml:id="formula_104">M = tanh(H) (9) α = sof tmax(w T M )<label>(10)</label></formula><formula xml:id="formula_105">r = Hα T<label>(11)</label></formula><formula xml:id="formula_106">H ∈ R d w ×T , d</formula><p>w is the dimension of the word vectors, w is a trained parameter vector and w T is a transpose. The dimension of w, α, r is d w , T, d w separately. We obtain the final sentence-pair representation used for classification from:</p><formula xml:id="formula_107">h * = tanh(r)<label>(12)</label></formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">Classifying</head><p>In this setting, we use a softmax classifier to predict labelŷ from a discrete set of classes Y for a sentence S. The classifier takes the hidden state h * as input:</p><formula xml:id="formula_108">p (y|S) = sof tmax ( W (S) h * + b (S) )<label>(13)</label></formula><formula xml:id="formula_109">y = arg max yp (y|S)<label>(14)</label></formula><p>The cost function is the negative log-likelihood of the true class labelsŷ:</p><formula xml:id="formula_110">J (θ) = − 1 m m ∑ i=1 t i log(y i ) + λ∥θ∥ 2 F<label>(15)</label></formula><p>where t ∈ ℜ m is the one-hot represented ground truth and y ∈ ℜ m is the estimated probability for each class by softmax (m is the number of target classes), and λ is an L2 regularization hyperparameter. In this paper, we combine dropout with L2 regularization to alleviate overfitting.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.5">Regularization</head><p>Dropout, proposed by <ref type="bibr" target="#b682">(Hinton et al., 2012)</ref>, prevents co-adaptation of hidden units by randomly omitting feature detectors from the network during forward propagation. We employ dropout on the embedding layer, LSTM layer and the penultimate layer. We additionally constrain L2-norms of the weight vectors by rescaling w to have ∥w∥ = s, whenever ∥w∥ &gt; s after a gradient descent step, as shown in equation 15. Training details are further introduced in Section 4.1.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Experiments 4.1 Dataset and Experimental Setup</head><p>Experiments are conducted on SemEval-2010 Task 8 dataset <ref type="bibr">(Hendrickx et al., 2009</ref>). This dataset contains 9 relationships (with two directions) and an undirected Other class. There are 10,717 annotated examples, including 8,000 sentences for training, and 2,717 for testing. We adopt the official evaluation metric to evaluate our systems, which is based on macro-averaged F1-score for the nine actual relations (excluding the Other relation) and takes the directionality into consideration.</p><p>In order to compare with the work by <ref type="bibr" target="#b109">Zhang and Wang (2015)</ref>, we use the same word vectors proposed by <ref type="bibr">Turian et al. (2010) (50-dimensional)</ref> to initialize the embedding layer. Additionally, to compare with the work by , we also use the 100-dimensional word vectors pretrained by .</p><p>Since there is no official development dataset, we randomly select 800 sentence for validation. The hyper-parameters for our model were tuned on the development set for each task. Our model was trained using AdaDelta (Zeiler, 2012) with a learning rate of 1.0 and a minibatch size 10. The model parameters were regularized with a perminibatch L2 regularization strength of 10 −5 . We evaluate the effect of dropout embedding layer, dropout LSTM layer and dropout the penultimate layer, the model has a better performance, when the dropout rate is set as 0.3, 0.3, 0.5 respectively. Other parameters in our model are initialized randomly.  <ref type="formula" target="#formula_0">(2014)</ref> treated a sentences as a sequential data and exploited the convolutional neural network to learn sentence-level features; they also used a special position vector to represent each word. Then the sentence-level and lexical features were concatenated into a single vector and fed into a softmax classifier for prediction. This model achieves an F 1 -score of 82.7%.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Experimental Results</head><p>RNN: <ref type="bibr" target="#b109">Zhang and Wang (2015)</ref> employed bidirectional RNN networks with two different dimension word vectors for relation classification. They achieved an F 1 -score of 82.8% using 300-dimensional word vectors pre-trained by <ref type="bibr" target="#b534">Mikolov et al. (2013)</ref>, and an F 1 -score of 80.0% using 50-dimensional word vectors pre-trained by . Our model with the same 50-dimensional word vectors achieves an F 1 -score of 82.5%, about 2.5 percent more than theirs. SDP-LSTM: <ref type="bibr" target="#b109">Yan et al. (2015)</ref> utilized four different channels to pick up heterogeneous along the SDP, and they achieved an F 1 -score of 83.7%. Comparing with their model, our model regarding the raw text as a sequence is simpler.</p><p>BLSTM:  employed many features derived from NLP tools and lexical resources with bidirectional LSTM networks to learn the sentence level features, and they achieved state-of-the-art performance on the SemEval-2010 Task 8 dataset. Our model with the same word vectors achieves a very similar result (84.0%), and our model is more simple.</p><p>Our proposed Att-BLSTM model yields an F 1 -score of 84.0%. It outperforms most of the existing competing approaches, without using lexical resources such as WordNet or NLP systems like dependency parser and NER to get high-level features.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Conclusion</head><p>In this paper, we propose a novel neural network model, named Att-BLSTM, for relation classification. This model does not rely on NLP tools or lexical resources to get, it uses raw text with position indicators as input. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Abstract</head><p>As a first step towards agents learning to communicate about their visual environment, we propose a system that, given visual representations of a referent (CAT) and a context (SOFA), identifies their discriminative attributes, i.e., properties that distinguish them (has_tail). Moreover, although supervision is only provided in terms of discriminativeness of attributes for pairs, the model learns to assign plausible attributes to specific objects (SOFA-has_cushion). Finally, we present a preliminary experiment confirming the referential success of the predicted discriminative attributes.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>There has recently been renewed interest in developing systems capable of genuine language understanding <ref type="bibr">(Hermann et al., 2015;</ref>. In this perspective, it is important to think of an appropriate general framework for teaching language to machines. Since we use language primarily for communication, a reasonable approach is to develop systems within a genuine communicative setup <ref type="bibr">(Steels, 2003;</ref><ref type="bibr" target="#b384">Mikolov et al., 2015)</ref>. Out long-term goal is thus to develop communities of computational agents that learn how to use language efficiently in order to achieve communicative success <ref type="bibr">(Vogel et al., 2013;</ref><ref type="bibr">Foerster et al., 2016)</ref>.</p><p>Within this general picture, one fundamental aspect of meaning where communication is indeed crucial is the act of reference <ref type="bibr">(Searle, 1969;</ref><ref type="bibr" target="#b20">Abbott, 2010)</ref>, the ability to successfully talk to others about things in the external world. A specific instantiation of reference studied in this paper is that of referring expression generation (Dale and is_round is_metal is_green made_of_wood <ref type="figure" target="#fig_3">Figure 1</ref>: Discriminative attributes predicted by our model. Can you identify the intended referent? See Section 6 for more information <ref type="bibr">Reiter, 1995;</ref><ref type="bibr">Mitchell et al., 2010;</ref><ref type="bibr">Kazemzadeh et al., 2014)</ref>. A necessary condition for achieving successful reference is that referring expressions (REs) accurately distinguish the intended referent from any other object in the context <ref type="bibr">(Dale and Haddock, 1991)</ref>. Along these lines, we present here a model that, given an intended referent and a context object, predicts the attributes that discriminate between the two. Some examples of the behaviour of the model are presented in <ref type="figure" target="#fig_3">Figure 1</ref>.</p><p>Importantly, and distinguishing our work from earlier literature on generating REs (Krahmer and Van Deemter, 2012): (i) the input objects are represented by natural images, so that the agent must learn to extract relevant attributes from realistic data; and (ii) no direct supervision on the attributes of a single object is provided: the training signal concerns their discriminativeness for object pairs (that is, during learning, the agent might be told that has_tail is discriminative for CAT, SOFA , but not that it is an attribute of cats). We use this "pragmatic" signal since it could later be replaced by a measure of success in actual communication between two agents (e.g., whether a second agent was able to pick the correct referent given a RE).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Discriminative Attribute Dataset</head><p>We generated the Discriminative Attribute Dataset, consisting of pairs of (intended) referents and contexts, with respect to which the referents should be identified by their distinctive attributes.  <ref type="bibr">(Silberer et al., 2013)</ref>, which contains per-concept (as opposed to perimage) attributes for 500 concrete concepts (CAT, SOFA, MILK) spanning across different categories (MAMMALS, FURNITURE), annotated with 636 general attributes. We disregarded ambiguous concepts (e.g., bat), thus reducing our working set of concepts C to 462 and the number of attributes V to 573, as we eliminated any attribute that did not occur with concepts in C. We extracted on average 100 images annotated with each of these concepts from ImageNet <ref type="bibr">(Deng et al., 2009</ref>). Finally, each image i of concept c was associated to a visual instance vector, by feeding the image to the VGG-19 ConvNet (Simonyan and Zisserman, 2014), as implemented in the MatConvNet toolkit <ref type="bibr">(Vedaldi and Lenc, 2015)</ref>, and extracting the second-to-last fully-connected (fc) layer as its 4096-dimensional visual representation v c i .</p><p>We split the target concepts into training, validation and test sets, containing 80%, 10% and 10% of the concepts in each category, respectively. This ensures that (i) the intersection between train and test concepts is empty, thus allowing us to test the generalization of the model across different objects, but (ii) there are instances of all categories in each set, so that it is possible to generalize across training and testing objects. Finally we build all possible combinations of concepts in the training split to form pairs of referents and contexts c r , c c and obtain their (binary) attribute vectors p cr and p cc from ViSA, resulting in 70K training pairs. From the latter, we derive, for each pair, a concept-level "discriminativeness" vector by computing the symmetric difference d cr,cc = (p cr − p cc ) ∪ (p cc − p cr ). The latter will contain 1s for discriminative attributes, 0s elsewhere. On average, each pair is associated with 20 discriminative attributes. The final training data are triples of the form c r , c c , d cr,cc (the model never observes the attribute vectors of specific concepts), to be associated with visual instances of the two concepts. <ref type="table" target="#tab_10">Table 1</ref> presents some examples.</p><p>Note that ViSA contain concept-level attributes, but images contain specific instances of concepts for which a general attribute might not hold. This introduces a small amount of noise. For example, is_green would in general be a discriminative attribute for apples and cats, but it is not for the second sample in <ref type="table" target="#tab_10">Table 1</ref>. Using datasets with perimage attribute annotations would solve this issue. However, those currently available only cover specific classes of concepts (e.g., only clothes, or animals, or scenes, etc.). Thus, taken separately, they are not general enough for our purposes, and we cannot merge them, since their concepts live in different attribute spaces.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Discriminative Attribute Network</head><p>The proposed Discriminative Attribute Network (DAN) learns to predict the discriminative attributes of referent object c r and context c c without direct supervision at the attribute level, but relying only on discriminativeness information (e.g., for the objects in the first row of <ref type="table" target="#tab_10">Table 1</ref>, the gold vector would contain 1 for has_tail, but 0 for both is_green and has_legs). Still, the model is implicitly encouraged to embed objects into a consistent attribute space, to generalize across the discriminativeness vectors of different training pairs, so it also effectively learns to annotate objects with visual attributes.</p><p>Figure 2 presents a schematic view of DAN, focusing on a single attribute. The model is presented with two concepts CAT, SOFA , and randomly samples a visual instance of each. The instance visual vectors v (i.e., ConvNet second-tolast fc layers) are mapped into attribute vectors of dimensionality |V | (cardinality of all available attributes), using weights M a ∈ R 4096×|V | shared between the two concepts. Intuitively, this layer should learn whether an attribute is active for a specific object, as this is crucial for determining whether the attribute is discriminative for an object pair. In Section 5, we present experimental evidence corroborating this hypothesis.</p><p>In order to capture the pairwise interactions between attribute vectors, the model proceeds by concatenating the two units associated with the same visual attribute v across the two objects (e.g., the units encoding information about has_tail) and pass them as input to the discriminative layer. The discriminative layer processes the two units by applying a linear transformation with weights M d ∈ R 2×h , followed by a sigmoid activation function, finally deriving a single value by another linear transformation with weights M D ∈ R h×1 . The outputd v encodes the predicted degree of discriminativeness of attribute v for the specific reference-context pair. The same process is applied to all attributes v ∈ V , to derive the estimated discriminativeness vectord, using the same shared weights M d and M D for each attribute.</p><p>To learn the parameters θ of the model (i.e. M a , M d and M D ), given training data c r , c c , d cr,cc , we minimize MSE between the gold vector d cr,cc and model-estimatedd cr,cc . We trained the model with rmsprop and with a batch size of 32. All hyperparameters (including the hidden size h which was set to 60) were tuned to maximize performance on the validation set.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Predicting Discriminativeness</head><p>We evaluate the ability of the model to predict attributes that discriminate the intended referent from the context. Precisely, we ask the model to return all discriminative attributes for a pair, independently of whether they are positive for the referent or for the context (given images of a cat and a building, both +is_furry and −made_ of_bricks are discriminative of the cat).  Results We compare DAN against a random baseline based on per-attribute discriminativeness probabilities estimated from the training data and an ablation model without attribute layer. We test moreover a model that is trained with supervision to predict attributes and then deterministically computes the discriminative attributes. Specifically, we implemented a neural network with one hidden layer, which takes as input a visual instance, and it is trained to predict its gold attribute vector, casting the problem as logistic regression, thus relying on supervision at the attribute level. Then, given two paired images, we let the model generate their predicted attribute vectors and compute the discriminative attributes by taking the symmetric difference of the predicted attribute vectors as we do for DAN. For the DAN and its ablation, we use a 0.5 threshold to deem an attribute discriminative, without tuning. The results in <ref type="table" target="#tab_5">Table 2</ref> confirm that, with appropriate supervision, DAN performs discriminativeness prediction reasonably well -indeed, as well as the model with similar parameter capacity requiring direct supervision on an attribute-byattribute basis, followed by the symmetric difference calculation. Interestingly, allowing the model to embed visual representations into an intermediate attribute space has a strong positive effect on performance. Intuitively, since DAN is evaluated on novel concepts, the mediating attribute layer provides more high-level semantic information helping generalization, at the expense of extra parameters compared to the ablation without attribute layer.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Predicting Attributes</head><p>Attribute learning is typically studied in supervised setups <ref type="bibr">(Ferrari and Zisserman, 2007;</ref><ref type="bibr">Farhadi et al., 2009;</ref><ref type="bibr">Russakovsky and Fei-Fei, 2010)</ref>. Our model learns to embed visual objects in an attribute space through indirect supervision about attribute discriminativeness for specific &lt;referent, context&gt; pairs. Attributes are never explicitly associated to a specific concept during training. The question arises of whether discriminativeness pushes the model to learn plausible concept attributes. Note that the idea that the semantics of attributes arises from their distinctive function within a communication system is fully in line with the classic structuralist view of linguistic meaning <ref type="bibr">(Geeraerts, 2009</ref>).</p><p>To test our hypothesis, we feed DAN the same test stimuli (visual concept vectors) as in the previous experiment, but now look at activations in the attribute layer. Since these activations are real numbers whereas gold values (i.e., the visual attributes in the ViSA dataset) are binary, we use the validation set to learn the threshold to deem an attribute active, and set it to 0.5 without tuning. Note that no further training and no extra supervision other than the discriminativeness signal are needed to perform attribute prediction. The resulting binary attribute vectorp c for concept c is compared against the corresponding gold attribute vector p c .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Results</head><p>We compare DAN to the random baseline and to an explicit attribute classifier similar to the one used in the previous experiment, i.e., a one-hidden-layer neural network trained with logistic regression to predict the attributes. We report moreover the best F1 score of <ref type="bibr">Silberer et al. (2013)</ref>, who learn a SVM for each visual attribute based on HOG visual features. Unlike in our setup, in theirs, images for the same concept are used both for training and to derive visual attributes (our setup is "zero-shot" at the concept level, i.e., we predict attributes of concepts not seen in training). Thus, despite the fact that they used presumably less accurate pre-CNN visual features, the setup is much easier for them, and we take their performance to be an upper bound on ours.</p><p>DAN reaches, and indeed surpasses, the performance of the model with direct supervision at the attribute level, confirming the power of discriminativeness as a driving force in building semantic representations. The comparison with Silberer's model suggests that there is room for improvement, although the noise inherent in concept-level annotation imposes a relatively low bound on realistic performance.  Results For 12% of the test referent, context pairs, the discriminative attribute is contained in the set of discriminative attributes predicted by DAN. A random baseline estimated from the distribution of attributes in the ViSA dataset would score 15% recall. This baseline however on average predicts 20 discriminative attributes, whereas DAN activates, only 4. Thus, the baseline has a trivial recall advantage. In order to evaluate whether in general the discriminative attributes activated by DAN would lead to referential success, we further sampled a subset of 100 referent, context test pairs. We presented them separately to two subjects (one a co-author of this study) together with the attribute that the model activated with the largest score (see <ref type="figure" target="#fig_3">Figure 1</ref> for examples). Subjects were asked to identify the intended referent based on the attribute. If both agreed on the same referent, we achieved referential success, since the modelpredicted attribute sufficed to coherently discriminate between the two images. Encouragingly, the subjects agreed on 78% of the pairs (p&lt;0.001 when comparing against chance guessing, according to a 2-tailed binomial test). In cases of disagreement, the predicted attribute was either too generic or very salient in both objects, a behaviour observed especially in same-category pairs (e.g., is_round in <ref type="figure" target="#fig_3">Figure 1</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">Concusion</head><p>We presented DAN, a model that, given a referent and a context, learns to predict their discriminative features, while also inferring visual attributes of concepts as a by-product of its training regime. While the predicted discriminative attributes can result in referential success, DAN is currently lacking all other properties of reference (Grice, 1975) (salience, linguistic and pragmatic felicity, etc). We are currently working towards adding communication (thus simulating a speaker-listener scenario <ref type="bibr">(Golland et al., 2010)</ref>) and natural language to the picture. <ref type="bibr">Robert Dale and Nicholas Haddock. 1991</ref> </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Abstract</head><p>We describe an efficient neural network method to automatically learn sentiment lexicons without relying on any manual resources. The method takes inspiration from the NRC method, which gives the best results in SemEval13 by leveraging emoticons in large tweets, using the PMI between words and tweet sentiments to define the sentiment attributes of words. We show that better lexicons can be learned by using them to predict the tweet sentiment labels. By using a very simple neural network, our method is fast and can take advantage of the same data volume as the NRC method. Experiments show that our lexicons give significantly better accuracies on multiple languages compared to the current best methods.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Sentiment lexicons contain the sentiment polarity and/or the strength of words or phrases <ref type="bibr">(Baccianella et al., 2010;</ref><ref type="bibr">Taboada et al., 2011;</ref><ref type="bibr">Tang et al., 2014a;</ref><ref type="bibr">Ren et al., 2016a)</ref>. They have been used for both rule-based <ref type="bibr">(Taboada et al., 2011) and</ref><ref type="bibr">unsupervised (Turney, 2002;</ref><ref type="bibr">Kiritchenko et al., 2014)</ref> or supervised <ref type="bibr">Tang et al., 2014b;</ref><ref type="bibr">Vo and Zhang, 2015)</ref> machine-learning-based sentiment analysis. As a result, constructing sentiment lexicons is one important research task in sentiment analysis.</p><p>Many approaches have been proposed to construct sentiment lexicons. Traditional methods manually label the sentiment attributes of words <ref type="bibr">Taboada et al., 2011)</ref>. One benefit of such lexicons is high quality. On the other hand, the methods are timeconsuming, requiring language and domain expertise. Recently, statistical methods have been exploited to learn sentiment lexicons automatically <ref type="bibr">(Esuli and Sebastiani, 2006;</ref><ref type="bibr">Baccianella et al., 2010;</ref>. Such methods leverage knowledge resources <ref type="bibr">(Bravo-Marquez et al., 2015)</ref> or labeled sentiment data <ref type="bibr">(Tang et al., 2014a)</ref>, giving significantly better coverage compared to manual lexicons.</p><p>Among the automatic methods,  proposed to use tweets with emoticons or hashtags as training data. The main advantage is that such training data are abundant, and manual annotation can be avoided. Despite that emoticons or hashtags can be noisy in indicating the sentiment of a tweet, existing research <ref type="bibr">(Go et al., 2009;</ref><ref type="bibr">Pak and Paroubek, 2010;</ref><ref type="bibr">Agarwal et al., 2011;</ref><ref type="bibr">Kalchbrenner et al., 2014;</ref><ref type="bibr">Ren et al., 2016b)</ref> has shown that effectiveness of such data when used to supervise sentiment classifiers.  collect sentiment lexicons by calculating pointwise mutual information (PMI) between words and emoticons. The resulting lexicons give the best results in a SemEval13 benchmark <ref type="bibr">(Nakov et al., 2013)</ref>. In this paper, we show that a better lexicon can be learned by directly optimizing the prediction accuracy, taking the lexicon as input and emoticon as the output. The correlation between our method and the method of  is analogous to the "predicting" vs "counting" correlation between distributional and distributed word representations .</p><p>We follow <ref type="bibr">Esuli and Sebastiani (2006)</ref> in using two simple attributes to represent each sentiment word, and take inspiration from <ref type="bibr" target="#b534">Mikolov et al. (2013)</ref> in using a very simple neural network for sentiment prediction. The method can leverage the same data as  and therefore benefits from both scale and annotation independence. Experiments show that the neural model gives the best results on standard benchmarks across multiple languages. Our code and lexicons are publicly available at https://github.com/duytinvo/acl2016.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Related work</head><p>Existing methods for automatically learning sentiment lexicons can be classified into three main categories. The first category augments existing lexicons with sentiment information. For example, Esuli and Sebastiani <ref type="formula" target="#formula_1">(2006)</ref> and <ref type="bibr">Baccianella et al. (2010)</ref> use a tuple (pos, neg, neu) to represent each word, where pos, neg and neu stand for possibility, negativity and neutrality, respectively, training these attributes by extracting features from WordNet. These methods rely on the taxonomic structure of existing lexicons, which are limited to specific languages.</p><p>The second approach expands existing lexicons, which are typically manually labeled. For example, <ref type="bibr">Tang et al. (2014a)</ref> apply a neural network to learn sentiment-oriented embeddings from a small amount of annotated tweets, and then expand a set of seed sentiment words by measuring vector space distances between words. <ref type="bibr">Bravo-Marquez et al. (2015)</ref> extend an existing lexicon by classifying words using manual features. These methods are also limited to domains and languages with manual resources.</p><p>The third line of methods constructs lexicons from scratch by accumulating statistical information over large data. <ref type="bibr">Turney (2002)</ref> proposes to estimate the sentiment polarity of words by calculating PMI between seed words and search hits.  improve the method by computing sentiment scores using distance-supervised data from emoticon-baring tweets instead of seed words. This approach can be used to automatically extract multilingual sentiment lexicons <ref type="bibr">(Salameh et al., 2015;</ref><ref type="bibr" target="#b671">Mohammad et al., 2015)</ref> without using manual resources, which makes it more flexible compared to the first two methods. We consider it as our baseline.</p><p>We use the same data source as  to train lexicons. However, rather than relying on PMI, we take a machine-learning method in optimizing the prediction accuracy of emoticons using the lexicons. To leverage large data, we use a very simple neural network to train the lexicons. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Baseline</head><p>Mohammad et al. <ref type="formula" target="#formula_0">(2013)</ref> employ emoticons and relevant hashtags contained in a tweet as the sentiment label of the tweet. Given a set of tweets with their labels, the sentiment score (SS) for a token w was computed as:</p><formula xml:id="formula_111">SS(w) = PMI(w, pos) − PMI(w, neg), (1)</formula><p>where pos represents the positive label and neg represents the negative label. PMI stands for pointwise mutual information, which is</p><formula xml:id="formula_112">PMI(w, pos) = log 2 freq(w, pos) * N freq(w) * freq(pos)<label>(2)</label></formula><p>Here freq(w , pos) is the number of times the term w occurs in positive tweets, freq(w ) is the total frequency of term w in the corpus, freq(pos) is the total number of tokens in positive tweets, and N is the total number of tokens in the corpus. PMI (w , neg) is calculated in a similar way. Thus, Equation 1 is equal to:</p><formula xml:id="formula_113">SS(w) = log 2 freq(w, pos) * freq(neg) freq(w, neg) * freq(pos)<label>(3)</label></formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Model</head><p>We follow Esuli and Sebastiani <ref type="formula" target="#formula_1">(2006)</ref>, using positivity and negativity attributes to define lexicons. In particular, each word takes the form w = (n, p), where n denotes negativity and p denotes positivity (n, p ∈ R). As shown in <ref type="figure" target="#fig_3">Figure 1</ref>, given a tweet tw = w 1 , w 2 , ..., w n , a simple neural network is used to predict its two-dimensional sentiment label y, where [1,0] for negative and [0,1] for positive tweets. The predicted sentiment probability y of a tweet is computed as:  <ref type="table" target="#tab_10">Table 1</ref>: Emoticon-based training data.</p><formula xml:id="formula_114">h = i (w i )<label>(4)</label></formula><formula xml:id="formula_115">y = softmax (hW )<label>(5)</label></formula><p>where W is fixed to the diagonal matrix (W ∈ R 2x2 ). We follow <ref type="bibr">Go et al. (2009)</ref> in defining the sentiment labels of tweets via emoticons. Each token is first initialized by random negative and positive attribute scores in <ref type="bibr">[-0.25,0.25]</ref>, and then trained by supervised learning. The cross-entropy error is employed as the objective function:</p><formula xml:id="formula_116">loss(tw) = − ŷ. log(y)<label>(6)</label></formula><p>Backpropagation is applied to learn (n, p) for each token. Optimization is done using stochastic gradient descent over shuffled mini-batches, with the AdaDelta update rule <ref type="bibr" target="#b656">(Zeiler, 2012)</ref>. All models are trained over 5 epochs with a batch size of 50. Due to its simplicity, the method is very fast, training a sentiment lexicon over 9 million tweets within 35 minutes per epoch on an Intel core™ i7-3770 CPU @ 3.40 GHz.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Sentiment Classification</head><p>The resulting lexicon can be used in both unsupervised and supervised sentiment classifiers. The former is implemented by summing the sentiment scores of all tokens contained in a given document <ref type="bibr">(Taboada et al., 2011;</ref><ref type="bibr">Kiritchenko et al., 2014)</ref>. If the total sentiment score is larger than 0, the document is classified as positive. Here only one positivity attribute is required to represent a lexicon, and we use the contrast between the positivity and negativity attributes (p − n) as the score. The supervised method makes use of sentiment lexicons as features for machine learning classification. Given a document D, we follow <ref type="bibr">Zhu et al. (2014)</ref> and extract the following features:</p><p>• The number of sentiment tokens in D, where sentiment tokens are word tokens whose sentiment scores are not zero in a lexicon;</p><p>• The total sentiment score of a document:</p><formula xml:id="formula_117">w i ∈D SS(w i );</formula><p>• The maximal score: max w i ∈D SS(w i );  • The total scores of positive and negative words in D;</p><p>• The sentiment score of the last token in D.</p><p>Again we use SS(w i ) = p w i − n w i as the sentiment score of each word w i , because the methods are based on a single sentiment score value for each word.  <ref type="bibr" target="#b147">(Fan et al., 2008)</ref> as the supervised classifier on benchmark datasets. The parameter c is tuned by making a grid search <ref type="bibr">(Hsu et al., 2003)</ref> on the accuracy of development set on the English dataset and fivefold cross validation on the Arabic dataset.</p><p>Evaluation: We follow <ref type="bibr">Kiritchenko et al. (2014)</ref> in employing precision (P), recall (R) and F1 score <ref type="bibr">(F)</ref> to evaluate unsupervised classification. We follow <ref type="bibr">Hsu et al. (2003)</ref> and use accuracy (acc), the tuning criterion, to evaluate supervised classification.</p><p>Code and lexicons: We make the Python implementation of our models and the resulting sentiment lexicons available at https://github.com/duytinvo/acl2016   <ref type="table" target="#tab_42">Table 4</ref>: Standard splits of ASTD.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.2">English Lexicons</head><p>The Twitter benchmark of SemEval13 <ref type="bibr">(Nakov et al., 2013</ref>) is used as the English test set. In order to evaluate both unsupervised and supervised methods, we follow <ref type="bibr">Tang et al. (2014b)</ref> and <ref type="bibr">Kiritchenko et al. (2014)</ref>, removing neutral tweets. The statistics is shown in <ref type="table" target="#tab_5">Table 2</ref>. We compare our lexicon with the lexicons of NRC 4 (Mohammad et al., 2013), HIT 5 <ref type="bibr">(Tang et al., 2014a)</ref> and WEKA 6 <ref type="bibr">(Bravo-Marquez et al., 2015)</ref>. As shown in <ref type="table" target="#tab_6">Table  3</ref>, using the unsupervised sentiment classification method (unsup) in Section 5, our lexicon gives significantly better result in comparison with countbased lexicons of NRC. Under both settings, our lexicon yields the best results compared to other methods.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.3">Arabic Lexicons</head><p>We employ the standard Arabic Twitter dataset ASTD <ref type="bibr">(Nabil et al., 2015)</ref>, which consists of about 10,000 tweets with 4 labels: objective (obj), negative (neg), positive (pos) and mixed subjective (mix). The standard splits of ASTD are shown in <ref type="table" target="#tab_42">Table 4</ref>. We follow Nabil et al. <ref type="formula" target="#formula_0">(2015)</ref> by merging training and validating data for learning model. We compare our lexicon with only the lexicons of NRC 7 <ref type="bibr">(Salameh et al., 2015)</ref>, because the methods of <ref type="bibr">Tang et al. (2014a)</ref>     <ref type="table" target="#tab_22">Table 5</ref>, our lexicon consistently gives the best performance on both the balanced and unbalanced datasets, showing the advantage of "predicting" over "counting". <ref type="table" target="#tab_23">Table 6</ref> shows examples of our predicting-based lexicon and the counting-based lexicon of . First, both lexicons can correctly reflect the strength of emotional words (e.g. bad, worse, worst), which demonstrates that our method can learn statistical relevance as effectively as PMI. Second, we find many cases where our lexicon gives the correct polarity (e.g. suitable, lazy) but the lexicon of Mohammad et al. <ref type="formula" target="#formula_0">(2013)</ref> does not. To quantitatively compare the lexicons, we calculated the accuracies of their polarities (i.e. sign) by using the manually-annotated lexicon of  as the gold standard. We take the intersection between the automatic lexicons and the lexicon of  as the test set, which contains 3270 words. The polarity accuracy of our lexicon is 78.2%, in contrast to 76.9% by the lexicon of , demonstrating the relative strength of our method. Third, by having two attributes (n, p) instead of one, our lexicon is better in compositionality (e.g. SS(strong memory) &gt; 0, SS(strong snowstorm) &lt; 0).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.4">Analysis</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="222">7 Conclusion</head><p>We constructed a sentiment lexicon for short text automatically using an efficient neural network, showing that prediction-based training is better than counting-based training for learning from large tweets with emoticons. In standard evaluations, the method gave better accuracies across multiple languages compared to the state-of-theart counting-based method. Dimensional sentiment analysis aims to recognize continuous numerical values in multiple dimensions such as the valencearousal (VA) space. Compared to the categorical approach that focuses on sentiment classification such as binary classification (i.e., positive and negative), the dimensional approach can provide more fine-grained sentiment analysis. This study proposes a regional CNN-LSTM model consisting of two parts: regional CNN and LSTM to predict the VA ratings of texts. Unlike a conventional CNN which considers a whole text as input, the proposed regional CNN uses an individual sentence as a region, dividing an input text into several regions such that the useful affective information in each region can be extracted and weighted according to their contribution to the VA prediction. Such regional information is sequentially integrated across regions using LSTM for VA prediction. By combining the regional CNN and LSTM, both local (regional) information within sentences and long-distance dependency across sentences can be considered in the prediction process. Experimental results show that the proposed method outperforms lexicon-based, regression-based, and NN-based methods proposed in previous studies.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>References</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Sentiment analysis has been useful in the development of online applications for customer reviews and public opinion analysis <ref type="bibr">(Pang and Lee 2008;</ref><ref type="bibr">Calvo and D'Mello 2010;</ref><ref type="bibr">Liu 2012;</ref><ref type="bibr">Feldman 2013)</ref>. In sentiment representation, the categorical approach represents emotional states as several discrete classes such as binary (i.e., positive and negative) or as multiple categories such as <ref type="bibr">Ekman's (1992)</ref> six basic emotions (anger, happiness, fear, sadness, disgust, and surprise). Classification algorithms can then be used to identify sentiment categories from texts. The dimensional approach represents emotional states as continuous numerical values in multiple dimensions such as the valence-arousal (VA) space <ref type="bibr">(Russell, 1980)</ref>. The dimension of valence refers to the degree of positive and negative sentiment, whereas the dimension of arousal refers to the degree of calm and excitement. Both dimensions range from 1 (highly negative or calm) to 9 (highly positive or excited) based on the self-assessment manikin (SAM) annotation scheme <ref type="bibr">(Bradley et al. 1994)</ref>. For example, the following passage consisting of three sentences is associated with a valence-arousal rating of (2.5, 7.8), which displays a high degree of negativity and arousal. Such high-arousal negative (or high-arousal positive) texts are usually of interest and could prioritized in product review systems. Dimensional sentiment analysis can accomplish this by recognizing the VA ratings of texts and rank them accordingly, thus providing more intelligent and fine-grained sentiment applications. Recently, word embedding  and deep neural networks (NN) such as convolutional neural networks (CNN) <ref type="bibr">(Kim, 2014;</ref><ref type="bibr">Kalchbrenner et al., 2014)</ref>, recurrent neural networks (RNN) <ref type="bibr">(Graves, 2012;</ref><ref type="bibr">Irsoy and Cardie, 2014)</ref> and long shortterm memory (LSTM)  have been successfully employed for categorical sentiment analysis. In general, CNN is capable of extracting local information but may fail to capture long-distance dependency. LSTM can address this limitation by sequentially modeling texts across sentences. Such NN-based and word embedding methods have not been well explored for dimensional sentiment analysis.</p><p>This study proposes a regional CNN-LSTM model consisting of two parts, regional CNN and LSTM, to predict the VA ratings of texts. We first construct word vectors for vocabulary words using word embedding. The regional CNN is then used to build text vectors for the given texts being predicted based on the word vectors. Unlike a conventional CNN which considers a whole text as input, the proposed regional CNN uses individual sentences as regions, dividing an input text into several regions such that the useful affective information in different regions can be extracted and weighted according to their contribution to the VA prediction. For example, in the aforementioned example text, it would be useful for the system to emphasize the two sentences/regions (r2) and (r3) containing negative affective information. Finally, such regional information is sequentially integrated across regions using LSTM for VA prediction. By combining the regional CNN and LSTM, both local (regional) information within sentences and longdistance dependency across sentences can be considered in the prediction process.</p><p>The rest of this paper is organized as follows. Section 2 describes the proposed regional CNN-LSTM model. Section 3 reports the evaluation results of the proposed method against lexiconbased, regression-based, and NN-based methods. Conclusions are finally drawn in Section 4. <ref type="figure" target="#fig_3">Figure 1</ref> shows the overall framework of the proposed regional CNN-LSTM model. First, the word vectors of vocabulary words are trained from a large corpus using the word2vec toolkit. For each given text, the regional CNN model uses a sentence as a region to divide the given text into R regions, i.e. r1,…, ri, rj, rk,…, rR. In each region, useful affective features can be extracted once the word vectors sequentially pass through a convolutional layer and max pooling layer. Such local (regional) features are then sequentially integrated across regions using LSTM to build a text vector for VA prediction.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Regional CNN-LSTM Model</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Convolutional Layer</head><p>In each region, a convolutional layer is first used to extract local n-gram features. All word embeddings are stacked in a region matrix , and x r k . In each region, we use L convolutional filters to learn local ngram features. In a window of ω words x n:n+ω-1 , a filter F l (1≤l≤L) generates the feature map y l n as follows,</p><formula xml:id="formula_118">: 1 ( ) l l l n n n y f W b ω + − = + x <label>(1)</label></formula><p>where  is a convolutional operator, </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Max-pooling Layer</head><p>Max-pooling subsamples the output of the convolutional layer. The most common way to do pooling it to apply a max operation to the result of each filter. There are two reasons to use a max-pooling layer here. First, by eliminating non-maximal values, it reduces computation for upper layers. Second, it can extract the local dependency within different regions to keep the most salient information. The obtained region vectors are then fed to a sequential layer.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Sequential Layer</head><p>To capture long-distance dependency across regions, the sequential layer sequentially integrates each region vector into a text vector. Due to the problem of gradients vanishing or exploding in RNN <ref type="bibr">(Bengio et al., 1994)</ref>, LSTM is introduced in the sequential layer for vector composition. After the LSTM memory cell sequentially traverses through all regions, the last hidden state of the sequential layer is regarded as the text representation for VA prediction.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.4">Linear Decoder</head><p>Since the values in both the valence and arousal dimensions are continuous, the VA prediction task requires a regression. Instead of using a softmax classifier, a linear activation function (also known as a linear decoder) is used in the output layer, defined as,</p><formula xml:id="formula_119">d t d y W b = + x<label>(2)</label></formula><p>where xt is the text vector learned from the sequential layer, y is the degree of valence or arousal of the target text, and Wd and bd respectively denote the weight and bias associated with the linear decoder. The regional CNN-LSTM model is trained by minimizing the mean squared error between the predicted y and actual y. Given a training set of text matrix X={x <ref type="bibr">(1)</ref> , x <ref type="bibr">(2)</ref> ,…, x <ref type="bibr">(m)</ref> }, and their VA ratings set y={y <ref type="bibr">(1)</ref> , y <ref type="bibr">(2)</ref> , …, y <ref type="bibr">(m)</ref> }, the loss function is defined as</p><formula xml:id="formula_120">2 ( ) ( ) 1 1 ( , ) ( ) 2 m i i i L h y m = = − ∑ X y x<label>(3)</label></formula><p>In the training phase, a back propagation (BP) algorithm with stochastic gradient descent (SGD) is used to learn model parameters. Details of the BP algorithm can be found in <ref type="bibr">(LeCun et al., 2012)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Experiments</head><p>This section evaluates the performance of the proposed regional CNN-LSTM model against lexicon-based, regression-based, and NN-based methods.</p><p>Datasets. This experiment used two affective corpora. i) Stanford Sentiment Treebank (SST)  contains 8,544 training texts, 2,210 test texts, and 1,101 validation texts. Each text was rated with a single dimension (valence) in the range of (0, 1). ii) Chinese ValenceArousal Texts (CVAT) <ref type="bibr" target="#b232">(Yu et al., 2016)</ref> consists of 2,009 texts collected from social forums, manually rated with both valence and arousal dimensions in the range of (1, 9) using the SAM annotation scheme <ref type="bibr">(Bradley et al. 1994)</ref>. The word vectors for English and Chinese were respectively trained using the Google News and Chinese wiki dumps (zhwiki) datasets. The dimensionality for both word vectors are 300.</p><p>Experimental Settings. Two lexicon-based methods were used for comparison: weighted arithmetic mean (wAM) and weighted geometric mean (wGM) <ref type="bibr">(Paltoglou et al., 2013)</ref>, along with two regression-based methods: average values regression (AVR) and maximum values regression (MVR) <ref type="bibr">(Malandrakis et al., 2013)</ref>. The valence ratings of English and Chinese words were respectively taken from the Extended ANEW <ref type="bibr">(Warriner et al., 2013)</ref> and Chinese ValenceArousal Words (CVAW) lexicons <ref type="bibr" target="#b232">(Yu et al., 2016)</ref>. A conventional CNN, RNN and LSTM were also implemented for comparison.</p><p>Metrics. Performance was evaluated using the root mean square error (RMSE), mean absolute error (MAE), and Pearson correlation coefficient (r), defined as</p><formula xml:id="formula_121"> Root mean square error (RMSE) ( ) 2 1 n i i i RMSE A P n = = − ∑ (4)  Mean absolute error (MAE) 1 1 | | n i i i MAE A P n = = − ∑ (5)  Pearson correlation coefficient (r) 1 1 ( )( ) 1 n i i i A P A A P P r n σ σ = − − = − ∑<label>(6)</label></formula><p>where Ai is the actual value, Pi is the predicted value, n is the number of test samples, A and P respectively denote the arithmetic mean of A and P, and σ is the standard deviation. A lower RMSE or MAE and a higher r value indicates better prediction performance. A t-test was used to determine whether the performance difference was statistically significant.   Comparative Results. <ref type="table" target="#tab_5">Tables 1 and 2</ref> respectively present the comparative results of the regional CNN-LSTM against several methods for VA prediction of texts in both English and Chinese corpora. For the lexicon-based methods, wGM outperformed wAM, which is consistent with the results presented in <ref type="bibr">(Paltoglou et al., 2013)</ref>. Instead of using the VA ratings of words to directly measure those of texts, the regressionbased methods learned the correlations between the VA ratings of words and texts, thus yielding better performance. Once the word embedding and deep learning techniques were introduced, the performance of NN-based methods (except RNN) jumped dramatically. In addition, the proposed regional CNN-LSTM outperformed the other NN-based methods, indicating the effectiveness of sequentially integrating the regional information across regions. Another observation is that the Pearson correlation coefficient of prediction in arousal is lower than that for the valence prediction, indicating that arousal is more difficult to predict.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>SST (English)</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Conclusion</head><p>This study presents a regional CNN-LSTM model to predict the VA ratings of texts. By capturing both local (regional) information within sentences and long-distance dependency across sentences, the proposed method outperformed regression-and conventional NN-based methods presented in previous studies. Future work will focus on the use of a parser to identify regions so that the structural information can be further incorporated to improve the prediction performance. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>References</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>We experiment with a multi-task learning (MTL) architecture based on deep bi-directional recurrent neural networks (bi-RNNs) <ref type="bibr">(Schuster and Paliwal, 1997;</ref><ref type="bibr">Irsoy and Cardie, 2014)</ref>. MTL can be seen as a way of regularizing model induction by sharing representations (hidden layers) with other inductions <ref type="bibr">(Caruana, 1993)</ref>. We use deep bi-RNNs with task supervision from multiple tasks, sharing one or more bi-RNNs layers among the tasks. Our main contribution is the novel insight that (what has historically been thought of as) low-level tasks are better modeled in the low layers of such an architecture. This is in contrast to previous work on deep MTL <ref type="bibr">Luong et al., 2015)</ref> , in which supervision for all tasks happen at the same (outermost) layer. Multiple-tasks supervision at the outermost layer has a strong tradition in neural net models in vision and elsewhere <ref type="bibr">(Caruana, 1993;</ref><ref type="bibr" target="#b180">Zhang and Zhang, 2014;</ref><ref type="bibr">Yim et al., 2015)</ref>. However, in NLP it is natural to think of some levels of analysis as feeding into others, typically with low-level tasks feeding into highlevel ones; e.g., POS tags as features for syntactic chunking (Sang and <ref type="bibr">Buchholz, 2000)</ref> or parsing <ref type="bibr" target="#b187">(Nivre et al., 2007)</ref>. Our architecture can be seen as a seamless way to combine multi-task and cascaded learning. We also show how the proposed architecture can be applied to domain adaptation, in a scenario in which we have high-level task supervision in the source domain, and lower-level task supervision in the target domain. As a point of comparison,  improved deep convolutional neural network models of syntactic chunking by also having task supervision from POS tagging at the outermost level. In our work, we use recurrent instead of convolutional networks, but our main contribution is observing that we obtain better performance by having POS task supervision at a lower layer. While  also experiment with NER and SRL, they only obtain improvements from MTL with POS and syntactic chunking. We show that similar gains can be obtained for CCG supertagging.</p><p>Our contributions (i) We present a MTL architecture for sequence tagging with deep bi-RNNs; (ii) We show that having task supervision from all tasks at the outermost level is often suboptimal; (iii) we show that this architecture can be used for domain adaptation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Sequence tagging with deep bi-RNNs</head><p>Notation We use x 1:n to denote a sequence of n vectors x 1 , · · · , x n . F θ (·) is a function parameterized with parameters θ. We write F L (·) as a shortcut to F θ L -an instantiation of F with a spe-cific set of parameters θ L . We use • to denote a vector concatenation operation.</p><p>Deep bi-RNNs We use a specific flavor of Recurrent Neural Networks (RNNs) <ref type="bibr">(Elman, 1990)</ref> called long short-term memory networks (LSTMs) (Hochreiter and Schmidhuber, 1997). For brevity, we treat RNNs as a black-box abstraction, and LSTMs as an instance of the RNN interface. For further details on RNNs and LSTMs, see . We view RNN as a parameterized function RN N θ (x 1:n ) mapping a sequence of n input vectors x 1:n , x i ∈ R d in to a an output vector h n ∈ R dout . The output vector h n is conditioned on all the input vectors x 1:n , and can be thought of as a summary of x 1:n . The RNN can be applied to all prefixes x 1:i , 1 ≤ i ≤ n of x 1:n , resulting in n output vectors h 1:n , where h 1:i summarizes x 1:i .</p><p>A deep RNN (or k-layer RNN) is composed of k RNN functions RN N 1 , · · · , RN N k that feed into each other: the output h 1:n of RN N becomes the input of RN N +1 . Stacking RNNs in this way was empirically shown to be effective.</p><p>A bidirectional RNN (Schuster and Paliwal, 1997; Irsoy and Cardie, 2014) is composed of two RNNs, RN N F and RN N R , one reading the sequence in its regular order, and the other reading it in reverse. Concretely, given a sequence x 1:n and a desired index i, the function BIRN N θ (x 1:n , i) is defined as:</p><formula xml:id="formula_122">BIRN N θ (x 1:n , i) = v i = h F,i • h R,i h F,i = RN N F (x 1 , x 2 , · · · , x i ) h R,i = RN N R (x n , x n−1 , · · · , x i )</formula><p>The vector v i = BIRN N (x 1:n , i) is then a representation of the ith item in x 1:n , taking into account both the entire history x 1:i and the entire future x i:n .</p><p>Finally, in a deep bidirectional RNN, both RN N F and RN N R are k-layer RNNs, and</p><formula xml:id="formula_123">BIRN N (x 1:n , i) = v i = h F,i • h R,i .</formula><p>Greedy sequence tagging with deep bi-RNNs In a sequence tagging task, we are given an input w 1 , · · · , w n and need to predict an output</p><formula xml:id="formula_124">y 1 , · · · , y n , y i ∈ [1, · · · , |L|]</formula><p>, where L is a label set of interest; i.e., in a POS tagging task, L is the part-of-speech tagset, and y i is the pos-tag for word w i .</p><p>If we take the inputs x 1:n to correspond to a sequence of sentence words w 1 , · · · , w n , we can think of v i = BIRN N (x 1:n , i) as inducing an infinite window around a focus word w i . We can then use v i as an input to a multiclass classification function f (v i ), to assign a tagŷ i to each input location i. The tagger is greedy: the tagging decisions are independent of each other. However, as shown below and in other recent work using bi-RNNs for sequence tagging, we can still produce competitive tagging accuracies, because of the richness of the representation v i that takes the entire input sequence into account.</p><p>For a k-layer bi-RNN tagger we get:</p><formula xml:id="formula_125">tag(w 1:n , i) =ŷ i = f (v k i ) v k i = BIRN N k (x 1:n , i) x 1:n = E(w 1 ), E(w 2 ), · · · , E(w n )</formula><p>where E as an embedding function mapping each word in the vocabulary into a d emb -dimensional vector, and v k i is the output of the kth BIRNN layer as defined above.</p><p>All the parameters (the embedding vectors for the different vocabulary items, the parameters of the different RNNs and the parameters of the classification function f ) are trained jointly in order to minimize the tagging loss over a sentence. The embedding vectors are often initialized using vectors that were pre-trained in a semi-supervised manner.</p><p>This sequence tagging architecture was introduced to NLP by <ref type="bibr">Irsoy and Cardie (2014)</ref>. A similar architecture (with an RNN instead of bi-RNN) was applied to CCG supertagging by .</p><p>MTL in deep bi-RNNs In a multi-task learning (MTL) setting, we have several prediction tasks over the same input space. For example, in sequence tagging, the input may be the words in the sentence, and the different tasks can be POS-tagging, named entity recognition, syntactic chunking, or CCG supertagging. Note that the different tasks do not have to be traditional NLP tasks, but also, say, two POS-annotated corpora with slightly different guidelines. Each task has its own output vocabulary (a task specific tagset), but all of them map the length n input sequence into a length n output sequence.</p><p>Intuitively, although NLP tasks such as POS tagging, syntactic chunking and CCG supertagging are different than each other, they also share lot of substructure, e.g., knowing that a word is a verb can help in determining its CCG supertag and the syntactic chunk it participate in. We would therefore like for these models to share parameters.</p><p>The common approach is to share parameters across most of the network. In the k-layers deep bi-RNN tagger described above this is naturally achieved by sharing the bi-RNN part of the network across tasks, but training a specialized classification tagger f t (v k i ) for each task t. This encourages the deep bi-RNN to learn a representation v k i that is useful for prediction of the different tasks, allowing them to share parameters.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Supervising different tasks on different layers</head><p>Previous work in NLP on cascaded learning such as <ref type="bibr">Shen and Sarkar (2005)</ref> suggests there is sometimes a natural order among the different tasks: some tasks may benefit more from other tasks, than the other way around. This suggests having task supervision for low-level tasks at the lower bi-RNN layers. This also enables task-specific deep learning of the high-level tasks.</p><p>Instead of conditioning all tasks on the outermost bi-RNN layer, we associate an RNN level (t) with each task t, and let the task specific classifier feed from that layer, e.g., pos tag(w 1:</p><formula xml:id="formula_126">n , i) = f pos (v (pos) i</formula><p>). This enables a hierarchy a task with cascaded predictions, as well as deep task-specific learning for high-level tasks. This means there will be layers shared by all tasks and layers that are specific to some tasks:</p><formula xml:id="formula_127">pos tag(w 1:n , i) = f pos (v (pos) i ) chunk tag(w 1:n , i) = f chunk (v (chunk) i ) ccg tag(w 1:n , i) = f ccg (v (ccg) i ) v i = BIRN N (x 1:n , i) x 1:n = E(w 1 ), E(w 2 ), · · · , E(w n )</formula><p>The Multi-task training protocol We assume T different training set, D 1 , · · · , D T , where each D t contains pairs of input-output sequences (w 1:n , y t 1:n ), w i ∈ V , y t i ∈ L t . The input vocabulary V is shared across tasks, but the output vocabularies (tagset) L t are task dependent.</p><p>At each step in the training process we choose a random task t, followed by a random training instance (w 1:n , y t 1:n ) ∈ D t . We use the tagger to predict the labelsŷ t i , suffer a loss with respect to the true labels y t i and update the model parameters. Notice that a task t is associated with a bi-RNN level (t). The update for a sample from task t affects the parameters of f t and BIRN N 1 , · · · , BIRN N (t) , but not the parameters of f t =t or BIRN N j&gt; (t) .</p><p>Implementation details Our implementation is based the CNN library 1 for dynamic neural networks. We use CNN's LSTM implementation as our RNN variant. The classifiers f t () take the form of a linear transformation followed by a softmax f t (v) = arg max i sof tmax(W (t) v+b t ) <ref type="bibr">[i]</ref>, where the weights matrix W (t) and bias vector b (t) are task-specific parameters. We use a cross-entropy loss summed over the entire sentence. The network is trained using back-propagation and SGD with batch-sizes of size 1, with the default learning rate. Development data is used to determine the number of iterations.</p><p>We initialize the embedding layer E with pretrained word embeddings. We use the Senna embeddings 2 in our domain adaptation experiments, but these embeddings may have been induced from data including the test data of our main experiments, so we use the Polyglot embeddings in these experiments. <ref type="bibr" target="#b471">3</ref> We use the same dimensionality for the hidden layers as in our pre-trained embeddings.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Experiments and Results</head><p>We experiment with POS-tagging, syntactic chunking and CCG supertagging.  Our CHUNKS results are competitive with stateof-the-art. <ref type="bibr">Suzuki and Isozaki (2008)</ref>, for example, reported an F 1 -score of 95.15% on the CHUNKS data. Our model also performs considerably better than the MTL model in <ref type="bibr">Collobert et al. (2011) (94.10%)</ref>. Note that our relative improvements are also bigger than those reported by . Our CCG super tagging results are also slighly better than a recently reported result in  (93.00%). Our results are significantly better (p &lt; 0.05) than our baseline, and POS supervision at the lower layer is consistently better than standard MTL.</p><p>Additional tasks? We also experimented with NER (CoNLL 2003), super senses (SemCor), and the Streusle Corpus of texts annotated with MWE brackets and super sense tags. In none of these cases, MTL led to improvements. This suggests that MTL only works when tasks are sufficiently similar, e.g., all of syntactic nature.  also observed a drop in NER performance and insignificant improvements for SRL. We believe this is an important observation, since previous work on deep MTL often suggests that most tasks benefit from each other.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Domain adaptation</head><p>We experiment with domain adaptation for syntactic chunking, based on OntoNotes 4.0. We use WSJ newswire as our source domain, and broadcast, broadcasted news, magazines, and weblogs as target domains. We assume main task (syntactic chunking) supervision for the source domain, and lower-level POS supervision for the target domains. The results in <ref type="table" target="#tab_10">Table 1</ref> indicate that the method is effective for domain adaptation when we have POS supervision for the target domain. We believe this result is worth exploring further, as the scenario in which we have target-domain training data for low-level tasks such as POS tagging, but not for the task we are interested in, is common. The method is effective only when the lower-level POS supervision is applied at the lower layer, supporting the importance of supervising different tasks at different layers.</p><p>Rademacher complexity is the ability of models to fit random noise. We use the procedure in <ref type="bibr">Zhu et al. (2009)</ref> to measure Rademacher complexity, i.e., computing the average fit to k random relabelings of the training data. The subtask in our set-up acts like a regularizer, increasing the inductive bias of our model, preventing it from learning random patterns in data. Rademacher complexity measures the decrease in ability to learn such patterns. We use the CHUNKS data in these experiments. A model that does not fit to the random data, will be right in 1/22 cases (with 22 labels). We report the Rademacher complexities relative to this.</p><formula xml:id="formula_128">LSTM(-3) LSTM(3-3) LSTM(1-3)</formula><p>1.298 1.034 0.990</p><p>Our deep single task model increases performance over this baseline by 30%. In contrast, we see that when we predict both POS and the target task at the top layer, Rademacher complexity is lower and close to a random baseline. Interestingly, regularization seems to be even more effective, when the subtask is predicted from a lower layer. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>In recent years there has been a surge of interest in relating natural language to the real world. And more and more language resources accompanied by nonlinguistic data are becoming available. Typical examples are image descriptions <ref type="bibr" target="#b613">(Yang et al., 2011;</ref><ref type="bibr">Ushiku et al., 2011) and</ref><ref type="bibr">video (Hashimoto et al., 2014)</ref>. <ref type="bibr">Ferraro et al. (2015)</ref> summarized many other image and video datasets. These datasets allow us to attempt the task of connecting language expressions to the real world, which is called symbol grounding (Harnad, 1990). <ref type="bibr">Bruni et al. (2014)</ref> proposed methods for acquiring multimodal representations by applying SVD to distributional semantics and bag-of-visual-words (BoVW). <ref type="bibr">Ngiam et al. (2011)</ref> proposed unsupervised multimodal learning based on deep restricted boltzmann machines (RBMs). In the field of natural language processing (NLP) research, * This work was done when the first author was at Ehime University. <ref type="bibr">Kiela et al. (2015)</ref> proposed to acquire bilingual lexicon based on visual similarity. Ramisa et al.</p><p>(2015) describe a method for predicting a preposition referring to positions in the image.</p><p>In this paper, we propose a method for enhancing a named entity (NE) recognizer referring to the real world. Because of the lack of datasets consisting of sentences annotated with the general NE tags such as names of people, organizations, and times <ref type="bibr" target="#b732">(Sang and Meulder, 2003)</ref>, with accompanying real world data, we take game states as the counterpart of the language and the NE tag set specialized for game commentaries such as defense formations and opening names <ref type="bibr">(Mori et al., 2016)</ref>. Similar to bio-medical NEs <ref type="bibr">(Settles, 2004;</ref><ref type="bibr">Tateisi et al., 2002)</ref>, these NEs are useful for applications in the game domain. Our method could be used to improve automatic game commentary systems <ref type="bibr">(Kameko et al., 2015b;</ref><ref type="bibr">Chen et al., 2010)</ref> or to build a state search method that uses natural language queries instead of state notations <ref type="bibr">(Ganguly et al., 2014)</ref>. In addition to these interesting applications, game states have another advantage for NLP research. They are much easier to recognize than images and video, which allows us to concentrate on the NLP problem.</p><p>In order to incorporate the real world, i.e. game states, into NE recognition (NER), we propose to use deep neural networks (DNNs), which have been reported to be successful in various NLP tasks such as word embedding , part-of-speech tagging (Tsuboi, 2014), parsing <ref type="bibr">(Socher et al., 2010;</ref><ref type="bibr" target="#b424">Socher et al., 2012;</ref><ref type="bibr">Socher et al., 2013a)</ref>, parsing <ref type="bibr">(Socher et al., 2013a)</ref>, <ref type="bibr">NER (Hammerton, 2003)</ref> , sentiment analysis <ref type="bibr">(Socher et al., 2013b)</ref> and machine translation <ref type="bibr" target="#b642">(Neubig et al., 2015)</ref>. First we build a normal NE recognizer by referring only to the text information based on DNN. Each unit of its output layer corresponds to a BIO tag for the word (see Section 3). We use post processing based on the Viterbi algorithm to choose the best tag sequence by discarding inconsistent ones. This design allows us to train the model from partially annotated sentences, in which only some words are annotated with NE tags <ref type="bibr">(Sasada et al., 2015)</ref>. Next we extend the text-based DNN with a module that refers to game states. This module is a stacked-auto-encoder (SAE) <ref type="bibr">(Bengio et al., 2007)</ref> and we first train it only from game states. The pre-training allows the model to learn game state embedding which abstracts game state information. Then we fine-tune the entire DNN for NER, consisting of both text-based DNN and SAE. As we show in later section of this paper, we end up with an NE recognizer that refers to real world information in addition to text information, which increases its accuracy.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Related Work</head><p>There are several lines of multimodal learning in the fields of pattern recognition and NLP. Most learn multimodal representations by solving unsupervised learning tasks or pseudo-supervised learning tasks, but there were only a few studies that directly learned multimodal representations for target tasks in NLP. Our method incorporates multimodal information in DNNs for NER. <ref type="bibr">Bruni et al. (2014)</ref> proposed methods for acquiring multimodal representations by applying SVD to distributional semantics and BoVW. <ref type="bibr">Lopopolo and van Miltenburg (2015)</ref> proposed a similar method for acquiring sound-based distributional semantics. Textual vectors are acquired by using latent semantic analysis (LSA) and auditory vectors are acquired by the bag-of-audio-words (BoAW) method. The multimodal representations are acquired by applying SVD. <ref type="bibr">Ngiam et al. (2011)</ref> and <ref type="bibr">Srivastava and Salakhutdinov (2012)</ref> proposed unsupervised learning methods based on deep RBMs for learning multimodal representations in hidden layers. Providing paired information such as text-image pairs or audio-video pairs to RBMs, shared representations are learned in their hidden layers. <ref type="bibr">Ngiam et al. (2011)</ref> also used deep auto-encoders for learning RBMs. After acquiring multimodal representations, they can be used as inputs for other supervised learning tasks, such as speech recognition and image retrieval, where standard linear classifiers are used for solving the tasks. Silberer and Lapata <ref type="formula" target="#formula_0">(2014)</ref> proposed a deep learning method for learning multimodal representations by solving pseudosupervised tasks to predict the input's object label, such as 'boat,' given textual and visual attributebased representations for the object. Their objective function is the weighted sum of the autoencoding error and the classification error. Though their model is for supervised learning, Multimodal representations are learned In their experiments, the acquired multimodal representations were used for evaluating the word similarity task and word clustering task.  extend word2vec  to incorporate visual information for acquiring multimodal representations. Word embedding methods including word2vec are often used for various NLP tasks instead of one hot representations, and were shown to improve the performance of NLP systems. Word embeddings are mappings from a word to a low-dimensional real vectors that represents word meanings and relations between words. Word2vec is a method for acquiring word embeddings from a neural network which solves a pseudo-supervised task to predict surrounding words. <ref type="bibr">Kiela and Clark (2015)</ref> extend word2vec to incorporate bag-of-audio-words (BoAW).  have shown that word embeddings contain much information for predicting attributes. Herbelot and Vecchi (2015) proposed a method for predicting general quantifiers such as some for predicate-subject pairs.</p><p>Similar to this paper <ref type="bibr">Kameko et al. (2015a)</ref> proposed a method for word segmentation using game states and DNNs. The main differences between their method and ours is that i) they use game states to build a term dictionary for word segmentation, but our method directly incorporates a game state to improve NER, and ii) they used manually developed features to extract game states while we automatically acquire game states by using pre-training.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Game Commentary Corpus</head><p>The game we chose for the experiments is Japanese chess, called shogi in Japanese. It is a two-player board game with professional players. The board has 9×9 squares and games are played with 40 pieces of 14 different types. Unlike chess, players can reuse captured pieces. In computer science terms, it is a deterministic perfect informa- The main idea of this paper is that the game state, i.e. the real world, provides information on the texts that describe it. In the next section, we propose a method for utilizing this information in the NER task.</p><p>1 http://www.ar.media.kyoto-u.ac.jp/ data/game/ <ref type="figure" target="#fig_3">Figure 1</ref>: Deep neural networks for shogi NER.</p><formula xml:id="formula_129">݂ ௧ ݂ ଵ ௧ ݂ ଶ ௧ ݂ ଷ ௧ ݂ ସ ௧ ݂ ହ ௧ Text-input Real-world-input Output Hu-B Hu-I O ݂ ଶ ݂ ଷ ݂ ସ ݂ ହ ݂ ݂ ଵ ݂ ܽ ଵ ܽ ଶ ܽ</formula><p>Text features 4 Utilizing Real World Information in a Named Entity Recognizer <ref type="figure" target="#fig_3">Figure 1</ref> shows the overall architecture of our DNN for NER. The left part is the DNN for textbased NER and the bottom right part is an additional DNN for referring to the real world.</p><formula xml:id="formula_130">w i−2 , w i−1 , w i , w i+1 , w i+2 w i−2 w i−1 , w i−1 w i , w i w i+1 , w i+1 w i+2 w i−2 w i−1 w i , w i w i+1 w i+2 c(w i−2 ), c(w i−1 ), c(w i ), c(w i+1 ), c(w i+2 ) pos(w i−2 ), pos(w i−1 ), pos(w i ), pos(w i+1 ), pos(w i+2 )</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Text-based NER</head><p>The text-based NER refers to the text only through the standard features for NER <ref type="bibr" target="#b732">(Sang and Meulder, 2003)</ref> listed in <ref type="table" target="#tab_5">Table 2</ref>. They consist of word n-grams in the window w i+2 i−2 = w i−2 w i−1 w i w i+1 w i+2 , where w i is the word to be labelled, the part-of-speech tags pos(w) and the character type c(w) 2 of a word w in the window w for the input word. As we mentioned in Section 1, this design makes it possible to use partially annotated data. <ref type="bibr" target="#b471">3</ref> It can, however, generate inconsistent BIO tag sequences, e.g., an NE starting with an I tag. We use a best path search module based on the Viterbi algorithm while limiting the search space into valid tag sequences <ref type="bibr">(Sasada et al., 2015)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">NER Referring to the Real World</head><p>To enable our NE recognizer to refer to the real world, we add a network to the DNN for textbased NER as shown in the bottom right in <ref type="figure" target="#fig_3">Figure 1</ref>. The input layer corresponds to the game state features depicted in <ref type="figure" target="#fig_8">Figure 2</ref> (f r 1 . . . f r m ). For shogi they are nine-by-nine binary features which represent the positions of pieces on the board for each piece type and each player. Thus we have m = 2, 268 (= 9 × 9 × 14 × 2) features for the pieces on the board and 14 (= 7 × 2) integer features which represent the number of captured pieces for each type and each player.</p><p>To incorporate the game state features we propose using an SAE <ref type="bibr">(Bengio et al., 2007)</ref> to abstract the game state information instead of directly adding the units for these features to the text-based NER. To build the SAE, we first prepare a three-layer neural network (with one hidden layer) as depicted on the left side of <ref type="figure" target="#fig_6">Figure  3</ref> and train it providing the same game states to both input and output layers. With this process we can obtain the best reduced representations for the game states as the hidden layer that reconstructs the input game state features at the output layer.   Then we duplicate the hidden layer and put another hidden layer of smaller dimension between them (see the network in the middle of <ref type="figure" target="#fig_6">Figure 3</ref>) and train it in the same manner. This time the output layer is the duplicated former hidden layer and we train the new hidden layer by minimizing the difference between the duplicated former hidden layers. We repeat this process for a fixed number of times as shown on the right side of <ref type="figure" target="#fig_6">Figure 3</ref>. This process is called pre-training. Note that during pre-training only game states are used.</p><p>After the pre-training, we cut off the top layer to obtain a network with a trapezoid shape whose top layer abstracts game states (a 1 . . . a l in <ref type="figure" target="#fig_3">Figure  1</ref>). Then we join it to the DNN for the text-based NER as shown in <ref type="figure" target="#fig_3">Figure 1</ref>. Finally, we fine-tune it from both game states and texts annotated with NE tags. Note that we also tune parameters in the pre-trained SAE.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Experimental Evaluation</head><p>In this section we describe the NER experiments we conducted to evaluate our method.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Experimental Settings</head><p>The corpus we used is the game commentary corpus (Mori et al., 2016) described in Section 3 briefly. <ref type="table" target="#tab_6">Table 3</ref> shows its specifications. <ref type="table" target="#tab_42">Table 4</ref> shows the number of dimensions in each layer for game state embeddings in pre-training. We set the number of layers in the SAE (Subsection 4.2) to four, with which we could maximize the accuracy on the development set held-out from the training data.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Models for Comparison</head><p>The baseline is text-based NER based on DNN as described in Subsection 4.1. In addition, we tested NER based on conditional random fields (CRFs) ) with the same text features, because NER is a sequence labeling problem and <ref type="figure" target="#fig_6">Figure 3</ref>: Building stacked-auto-encoder.  CRFs are the standard method used to solve it <ref type="bibr">(McCallum and Li, 2003)</ref>. We compared these baselines and our NER that refers to the real world (DNN+R) as described in Subsection 4.2. Its SAE was trained on 213,195 game states. </p><formula xml:id="formula_131">݂ ଶ ݂ ଷ ݂ ସ ݂ ହ ݂ ݂ ଶ ݂ ଷ ݂ ସ ݂ ହ ݂ ݂ ଵ ݂ ଵ ݂ ݂ ݂ ଶ ݂ ଷ ݂ ସ ݂ ହ ݂ ݂ ଵ ݂ ݂ ଶ ݂ ଷ ݂ ସ ݂ ହ ݂ ݂ ଵ ݂ ܽ ଵ ܽ ଶ ܽ …</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">Results and Discussion</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Conclusion</head><p>In this paper, we proposed a method for referring to the real world to improve NER in a specialized domain. Our method adds an SAE to a text-based DNN for NER. We first pre-train the SAE using only real world information, and then we train the entire DNN from sentences annotated with NEs and accompanied by real world information.</p><p>In our experiments, we used shogi (Japanese chess) as the example. The dataset consists of pairs of a game state and commentary sentences on it annotated with 21 shogi NE tags. We conducted NER experiments and showed that referring to the real world improves NER accuracy.</p><p>Our method has the potential to be applied to various NER problems, such as general NER with pictures and financial NER with stock charts, by changing the SAE features. An interesting area of future work is preparing datasets in these domains and testing our method on them. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>As new companies form and grow, it is important for potential investors, procurement departments, and business partners to have access to a 360-degree view describing them. The number of companies worldwide is very large and, for the vast majority, not much information is available in sources like Wikipedia. Often, only firmographics data (e.g. industry classification, location, size, and so on) is available. This creates a need for cognitive systems able to aggregate and filter the information available on the web and in news, databases, and other sources. Providing good quality natural language descriptions of companies allows for easier access to the data, for example in the context of virtual agents or with text-to-speech applications.</p><p>In this paper, we propose an entity-focused system using a combination of targeted (knowledge base driven) and data-driven generation to create company descriptions in the style of Wikipedia descriptions. The system generates sentences from RDF triples, such as those found in DBPedia and Freebase, about a given company and combines these with sentences on the web that match learned expressions of relationships. We evaluate our hybrid approach and compare it with a targeted-only approach and a data-driven-only approach, as well as a strong multi-document summarization baseline. Our results show that the hybrid approach performs significantly better than either approach alone as well as the baseline.</p><p>The targeted (TD) approach to company description uses Wikipedia descriptions as a model for generation. It learns how to realize RDF relations that have the company as their subject: each relation contains a company/entity pair and it is these pairs that drive both content and expression of the company description. For each company/entity pair, the system finds all the ways in which similar company/entity pairs are expressed in other Wikipedia company descriptions, clustering together sentences that express the same company/entity relation pairs. It generates templates for the sentences in each cluster, replacing the mentions of companies and entities with typed slots and generates a new description by inserting expressions for the given company and entity in the slots. All possible sentences are generated from the templates in the cluster, the resulting sentences are ranked and the best sentence for each relation selected to produce the final description. Thus, the TD approach is a top-down approach, driven to generate sentences expressing the relations found in the company's RDF data using realizations that are typically used on Wikipedia.</p><p>In contrast, the data-driven (DD) approach uses a semi-supervised method to select sentences from descriptions about the given company on the web. Like the TD approach, it also begins with a seed set of relations present in a few companies' DBPedia entries, represented as company/entity pairs, but instead of looking at the corresponding Wikipedia articles, it learns patterns that are typ-ically used to express the relations on the web. In the process, it uses bootstrapping <ref type="bibr">(Agichtein and Gravano, 2000)</ref> to learn new ways of expressing the relations corresponding to each company/entity pair, alternating with learning new pairs that match the learned expression patterns. Since the bootstrapping process is driven only by company/entity pairs and lexical patterns, it has the potential to learn a wider variety of expressions for each pair and to learn new relations that may exist for each pair. Thus, this approach lets data for company descriptions on the web determine the possible relations and patterns for expressing those relations in a bottom-up fashion. It then uses the learned patterns to select matching sentences from the web about a target company.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Related Work</head><p>The TD approach falls into the generation pipeline paradigm <ref type="bibr">(Reiter and Dale, 1997)</ref>, with content selection determined by the relation in the company's DBpedia entry while microplanning and realization are carried out through template generation. While some generation systems, particularly in early years, used sophisticated grammars for realization <ref type="bibr">(Matthiessen and Bateman, 1991;</ref><ref type="bibr">Elhadad, 1991;</ref><ref type="bibr">White, 2014)</ref>, in recent years, template-based generation has shown a resurgence. In some cases, authors focus on document planning and sentences in the domain are stylized enough that templates suffice <ref type="bibr">(Elhadad and Mckeown, 2001;</ref><ref type="bibr">Bouayad-Agha et al., 2011;</ref><ref type="bibr">Gkatzia et al., 2014;</ref><ref type="bibr">Biran and McKeown, 2015)</ref>. In other cases, learned models that align database records with text snippets and then abstract out specific fields to form templates have proven successful for the generation of various domains <ref type="bibr" target="#b22">(Angeli et al., 2010;</ref><ref type="bibr">Kondadadi et al., 2013)</ref>. Others, like us, target atomic events (e.g., date of birth, occupation) for inclusion in biographies <ref type="bibr">(Filatova and Prager, 2005)</ref> but the templates used in other work are manually encoded.</p><p>Sentence selection has also been used for question answering and query-focused summarization. Some approaches focus on selection of relevant sentences using probabilistic approaches <ref type="bibr">(Daumé III and Marcu, 2005;</ref><ref type="bibr">Conroy et al., 2006)</ref>, semisupervised learning <ref type="bibr">(Wang et al., 2011)</ref> and graphbased methods <ref type="bibr" target="#b335">(Erkan and Radev, 2004;</ref><ref type="bibr">Otterbacher et al., 2005)</ref>. Yet others use a mixture of targeted and data-driven methods for a pure sentence selection system <ref type="bibr">(Blair-Goldensohn et al., 2003;</ref><ref type="bibr">Weischedel et al., 2004;</ref><ref type="bibr">Schiffman et al., 2001)</ref>. In our approach, we target both relevance and variety of expression, driving content by selecting sentences that match company/entity pairs and inducing multiple patterns of expression. Sentence selection has also been used in prior work on generating Wikipedia overall articles <ref type="bibr">(Sauper and Barzilay, 2009</ref>). Their focus is more on learning domain-specific templates that control the topic structure of an overview, a much longer text than we generate.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Targeted Generation</head><p>The TD system uses a development set of 100 S&amp;P500 companies along with their Wikipedia articles and DBPedia entries to form templates. For each RDF relation with the company as the subject, it identifies all sentences in the corresponding article containing the entities in the relation. The specific entities are then replaced with their relation to create a template. For example, "Microsoft was founded by Bill Gates and Paul Allen" is converted to " company was founded by founder ," with conjoined entities collapsed into one slot. Many possible templates are created, some of which contain multiple relations (e.g., " company , located in location , was founded by founder "). In this way the system learns how Wikipedia articles express relations between the company and its key entities (founders, headquarters, products, etc).</p><p>At generation time, we fill the template slots with the corresponding information from the RDF entries of the target company. Conjunctions are inserted when slots are filled by multiple entities. Continuing with our example, we might now produce the sentence "Palantir was founded by Peter Thiel, Alex Karp, Joe Lonsdale, Stephen Cohen, and Nathan Gettings" for target company Palantir. Preliminary results showed that this method was not adequate -the data for the target company often lacked some of the entities needed to fill the templates. Without those entities the sentence could not be generated. As Wikipedia sentences tend to have multiple relations each (high information density), many sentences containing important, relevant facts were discarded due to phrases that mentioned lesser facts we did not have the data to replace. We therefore added a postprocessing step to remove, if possible, any phrases from the sentence that could not be filled; otherwise, the sentence is discarded.</p><p>This process yields many potential sentences for each relation, of which we only want to choose the best. We cluster the newly generated sentences by relation and score each cluster. Sentences are scored according to how much information about the target company they contain (number of replaced relations). Shorter sentences are also weighted more as they are less likely to contain extraneous information, and sentences with more post-processing are scored lower. The highest scored sentence for each relation type is added to the description as those sentences are the most informative, relevant, and most likely to be grammatically correct.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Data-Driven Generation</head><p>The DD method produces descriptions using sentences taken from the web. Like the TD approach, it aims to produce sentences realizing relations between the input company and other entities. It uses a bootstrapping approach <ref type="bibr">(Agichtein and Gravano, 2000)</ref> to learn patterns for expressing the relations. It starts with a seed set of company/entity pairs, representing a small subset of the desired relations, but unlike previous approaches, can generate additional relations as it goes.</p><p>Patterns are generated by reading text from the web and extracting those sentences which contain pairs in the seed set. The pair's entities are replaced with placeholder tags denoting the type of the entity, while the words around them form the pattern (the words between the tags are selected as well as words to the left and right of the tags). Each pattern thus has the form " L T1 M T2 R ," where L, M, and R are respectively the words to the left of, between, and to the right of the entities. T1 is the type of the first entity, and T2 the type of the second. Like the TD algorithm, this is essentially a template based approach, but the templates in this case are not aligned to a relation between the entity and the company; only the type of entity (person, location, organization, etc) is captured by the tag.</p><p>New entity pairs are generated by matching the learned patterns against web text. A sentence is considered to match a pattern if it has the same entity types in the same order and its L, M, and R words fuzzy match the corresponding words in the pattern. <ref type="bibr">1</ref> The entities are therefore assumed to be related since they are expressed in the same way as the seed pair. Unlike the TD approach, the actual relationship between the entities is unknown (since the only data we use is the web text, not the structured RDF data); all we need to know here is that a relationship exists.</p><p>We alternate learning the patterns and generating entity pairs over our development set of 100 companies. We then take all the learned patterns and find matching sentences in the Bing search results for each company in the set of target companies. <ref type="bibr">2</ref> Sentences that match any of the patterns are selected and ranked by number of matches (more matches means greater probability of strong relation) before being added to the description.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Pruning and Ordering</head><p>After selecting the sentences for the description, we perform a post-processing step that removes noise and redundancy. To address redundancy, we remove those sentences which were conveyed previously in the description using exactly the same wording. Thus, sentences which are equal to or subsets of other sentences are removed. We also remove sentences that come from news stories; analysis of our results on the development set indicated that news stories rarely contain information that is relevant to a typical Wikipedia description. To do this we use regular expressions to capture common newswire patterns (e.g., <ref type="bibr">[CITY, STATE: sentence]</ref>). Finally, we remove incomplete sentences ending in ". . . ", which sometimes appear on websites which themselves contain summaries.</p><p>We order the selected sentences using a scoring method that rewards sentences based on how they refer to the company. Sentences that begin with the full company name get a starting score of 25, sentences that begin with a partial company name start with a score of 15, and sentences that do not contain the company name at all start at -15 (if they contain the company name in the middle of the sentece, they start at 0). Then, 10 points are added to the score for each keyword in the sentence (keywords were selected from the most populous DBPedia predicates where the subject is a company). This scoring algorithm was tuned on the development set. The final output is ordered in descending order of scores.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Hybrid system</head><p>In addition to the two approaches separately, we also generated hybrid output from a combination of the two. In this approach, we start with the DD output; if (after pruning) it has fewer than three sentences, we add the TD output and re-order.</p><p>The hybrid approach essentially supplements the large, more noisy web content of the DD output with the small, high-quality but less diverse TD output. For companies that are not consumerfacing or are relatively young, and thus have a relatively low web presence -our target populationthis can significantly impact the description.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Experiments</head><p>To evaluate our approach, we compare the three versions of our output -generated by the TD, DD, and hybrid approach -against multi-document summaries generated (from the same search results used by our DD approach) by TextRank <ref type="bibr" target="#b349">(Mihalcea and Tarau, 2004)</ref>. For each one of the approaches as well as the baseline, we generated descriptions for all companies that were part of the S&amp;P500 as of January 2016. We used our development set of 100 companies for tuning, and the evaluation results are based on the remaining 400.</p><p>We conducted two types of experiments. The first is an automated evaluation, where we use the METEOR score <ref type="bibr">(Lavie and Agarwal, 2007)</ref> between the description generated by one of our approaches or by the baseline and the first section of the Wikipedia article for the company. In Wikipedia articles, the first section typically serves as an introduction or overview of the most important information about the company. ME-TEOR scores capture the content overlap between the generated description and the Wikipedia text. To avoid bias from different text sizes, we set the same size limit for all descriptions when comparing them. We experimented with three settings: 150 words, 500 words, and no size limit.</p><p>In addition, we conducted a crowd-sourced evaluation on the CrowdFlower platform. In this evaluation, we presented human annotators with two descriptions for the same company, one described by our approach and one by the baseline, in random order. The annotators were then asked to choose which of the two descriptions is a better overview of the company in question (they were 150 words 500 words no limit  <ref type="table" target="#tab_5">Table 2</ref>: Second experiment results: % of companies for which the approach was chosen as best by the human annotators, and average scores given provided a link to the company's Wikipedia page for reference) and give a score on a 1-5 scale to each description. For quality assurance, each pair of descriptions was processed by three annotators, and we only included in the results instances where all three agreed. Those constituted 44% of the instances. In this evaluation we only used the hybrid version, and we limited the length of both the baseline and our output to 150 words to reduce bias from a difference in lengths and keep the descriptions reasonably short for the annotators.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">Results</head><p>The results of the automated evaluation are shown in <ref type="table" target="#tab_10">Table 1</ref>. Our DD system achieves higher ME-TEOR scores than the TextRank baseline under all size variations, while TD by itself is worse in most cases. In all cases the combined approach achieves a better result than the DD system by itself. The results of the human evaluation are shown in <ref type="table" target="#tab_5">Table 2</ref>. Here the advantage of our approach becomes much more visible: we clearly beat the baseline both in terms of how often the annotators chose our output to be better (almost 75% of the times) and in terms of the average score given to our descriptions (3.81 on a 1 − 5 point scale).</p><p>All results are statistically significant, but the difference in magnitude between the results of the two experiments are striking: we believe that while the TextRank summarizer extracts sentences which are topically relevant and thus achieve results close to ours in terms of METEOR, the more structured entity-focused approach we present here is able to extract content that seems much more reasonable to humans as a general description. One example is shown in <ref type="figure" target="#fig_3">Figure 1</ref>.</p><p>Right from the start, we see that our system out-performs TextRank. Our first sentence introduces the company and provides a critical piece of history about it, while TextRank does not even immediately name it. The hybrid generation output has a more structured output, going from the origins of the company via merger, to its board, and finally its products. TextRank's output, in comparison, focuses on the employee experience and only mentions products at the very end. Our system is much more suitable for a short description of the company for someone unfamilar with it.</p><p>TextRank: The company also emphasizes stretch assignments and on-the-job learning for development, while its formal training programs include a Masters in the Business of Activision(or "MBActivision") program that gives employees a deep look at company operations and how its games are made, from idea to development to store shelves. How easy is it to talk with managers and get the information I need? Will managers listen to my input? At Activision Blizzard, 78 percent of employees say they often or almost always experience a free and transparent exchange of ideas and information within the organization. Gaming is a part of day-to-day life at Activision Blizzard, and the company often organizes internal tournaments  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8">Conclusion</head><p>We described two approaches to generating company descriptions as well as a hybrid approach. We showed that our output is overwhelmingly preferred by human readers, and is more similar to Wikipedia introductions, than the output of a stateof-the-art summarization algorithm. These complementary methods each have their advantages and disadvantages: the TD approach ensures that typical expressions in Wikipedia company descriptions -known to be about the fundamental relations of a company -will occur in the generated output. However, since it modifies them, it risks generating ungrammatical sentences or sentences which contain information about another company. The latter can occur because the sentence is uniquely tied to the original. For instance, the following Wikipedia sentence fragment -"Microsoft is the world's largest software maker by revenue" -is a useful insight about the company, but our system would not be able to correctly modify that to fit any other company.</p><p>In contrast, by selecting sentences from the web about the given company, the DD approach ensures that the resulting description will be both grammatical and relevant. It also results in a wider variety of expressions and a greater number of sentences. However, it can include nonessential facts that appear in a variety of different web venues. It is not surprising, therefore, that the hybrid approach performs better than either by itself.</p><p>While in this paper we focus on company descriptions, the system can be adapted to generate descriptions for other entities (e.g. Persons, Products) by updating the seed datasets for both approaches (to reflect the important facts for the desired descriptions) and retuning for best accuracy. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>References</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Abstract</head><p>We present a new annotation method for collecting data on relation inference in context. We convert the inference task to one of simple factoid question answering, allowing us to easily scale up to 16,000 high-quality examples. Our method corrects a major bias in previous evaluations, making our dataset much more realistic.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Recognizing entailment between natural-language relations (predicates) is a key challenge in many semantic tasks. For instance, in question answering (QA), it is often necessary to "bridge the lexical chasm" between the asker's choice of words and those that appear in the answer text. Relation inference can be notoriously difficult to automatically recognize because of semantic phenomena such as polysemy and metaphor: Q: Which drug treats headaches?</p><p>A: Aspirin eliminates headaches.</p><p>In this context, "eliminates" implies "treats" and the answer is indeed "aspirin". However, this rule does not always hold for other cases -"eliminates patients" has a very different meaning from "treats patients". Hence, context-sensitive methods are required to solve relation inference.</p><p>Many methods have tried to address relation inference, from DIRT <ref type="bibr" target="#b373">(Lin and Pantel, 2001)</ref> through Sherlock <ref type="bibr">(Schoenmackers et al., 2010)</ref> to the more recent work on PPDB <ref type="bibr">(Pavlick et al., 2015b)</ref> and RELLY <ref type="bibr">(Grycner et al., 2015)</ref>. However, the way these methods are evaluated remains largely inconsistent. Some papers that deal with phrasal inference in general <ref type="bibr">(Beltagy et al., 2013;</ref><ref type="bibr">Pavlick et al., 2015a;</ref><ref type="bibr">Kruszewski et al., 2015)</ref> use an extrinsic task, such as a recent recognizing textual entailment (RTE) benchmark <ref type="bibr">(Marelli et al., 2014)</ref>. By nature, extrinsic tasks incorporate a variety of linguistic phenomena, making it harder to analyze the specific issues of relation inference.</p><p>The vast majority of papers that do focus on relation inference perform some form of post-hoc evaluation <ref type="bibr" target="#b373">(Lin and Pantel, 2001;</ref><ref type="bibr">Szpektor et al., 2007;</ref><ref type="bibr">Schoenmackers et al., 2010;</ref><ref type="bibr">Weisman et al., 2012;</ref><ref type="bibr">Lewis and Steedman, 2013;</ref><ref type="bibr" target="#b463">Riedel et al., 2013;</ref><ref type="bibr" target="#b464">Rocktäschel et al., 2015;</ref><ref type="bibr">Grycner and Weikum, 2014;</ref><ref type="bibr">Grycner et al., 2015;</ref><ref type="bibr">Pavlick et al., 2015b)</ref>. Typically, the proposed algorithm generates several inference rules between two relation templates, which are then evaluated manually. Some studies evaluate the rules out of context (is the rule "X eliminates Y "→"X treats Y " true?), while others apply them to textual data and evaluate the validity of the rule in context (given "aspirin eliminates headaches", is "aspirin treats headaches" true?). Not only are these post-hoc evaluations oblivious to recall, their "human in the loop" approach makes them expensive and virtually impossible to accurately replicate.</p><p>Hence, there is a real need for pre-annotated datasets for intrinsic evaluation of relation inference in context. <ref type="bibr">Zeichner et al. (2012)</ref> constructed such a dataset by applying DIRT-trained inference rules to sampled texts, and then crowd-annotating whether each original text (premise) entails the text generated from applying the inference rule (hypothesis). However, this process is biased; by using DIRT to generate examples, the dataset is inherently blind to the many cases where relation inference exists, but is not captured by DIRT.</p><p>We present a new dataset for evaluating relation inference in context, which is unbiased towards one method or another, and natural to annotate. To create this dataset, we design a QA setting where annotators are presented with a single ques- tion and several automatically-retrieved text fragments. The annotators' goal is to mark which of the text fragments provide a potential answer to the question (see <ref type="figure" target="#fig_3">Figure 1)</ref>. Since the entities in the text fragments are aligned with those in the question, this process implicitly annotates which relations entail the one in the question. For example, in <ref type="figure" target="#fig_3">Figure 1</ref>, if "[US PRESIDENT] increased taxes" provides an answer to "Which US president raised taxes?", then "increased" implies "raised" in that context. Because this task is so easy to annotate, we were able to scale up to 16,371 annotated examples (3,147 positive) with 91.3% precision for only $375 via crowdsourcing.</p><p>Finally, we evaluate a collection of existing methods and common practices on our dataset, and observe that even the best combination of methods cannot recall more than 25% of the positive examples without dipping below 80% precision. This places into perspective the huge amount of relevant cases of relation inference inherently ignored by the bias in <ref type="bibr">(Zeichner et al., 2012)</ref>. Moreover, this result shows that while our annotation task is easy for humans, it is difficult for existing algorithms, making it an appealing challenge for future research on relation inference. Our code 1 and data 2 are publicly available.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Relation Inference Datasets</head><p>To the best of our knowledge, there are only three pre-annotated datasets for evaluating relation inference in context. <ref type="bibr" target="#b471">3</ref> Each example in these datasets consists of two binary relations, premise and hypothesis, and a label indicat-1 http://bitbucket.org/omerlevy/ relation_inference_via_qa 2 http://u.cs.biu.ac.il/˜nlp/resources/ downloads/relation_inference_via_qa 3 It is worth noting the lexical substitution datasets <ref type="bibr">(McCarthy and Navigli, 2007;</ref><ref type="bibr">Biemann, 2013;</ref><ref type="bibr">Kremer et al., 2014</ref>) also capture instances of relation inference. However, they do not focus on relations and are limited to single-word substitutions. Furthermore, the annotators are tasked with generating substitutions, whereas we are interested in judging (classifying) an existing substitution.</p><p>ing whether the hypothesis is inferred from the premise. These relations are essentially Open IE <ref type="bibr">(Banko et al., 2007)</ref> assertions, and can be represented as (subject, relation, object) tuples. <ref type="bibr">Berant et al. (2011)</ref> annotated inference between typed relations ("[DRUG] eliminates [SYMPTOM]"→" <ref type="bibr">[DRUG]</ref> treats [SYMP-TOM]"), restricting the definition of "context". They also used the non-standard type-system from <ref type="bibr">(Schoenmackers et al., 2010)</ref>, which limits the dataset's applicability to other corpora.  annotated inference between instantiated relations sharing at least one argument ("aspirin eliminates headaches"→"drugs treat headaches"). While this format captures a more natural notion of context, it also conflates the task of relation inference with that of entity inference ("aspirin"→"drug"). Both datasets were annotated by experts.</p><p>Zeichner et al. <ref type="formula" target="#formula_0">(2012)</ref> annotated inference between instantiated relations sharing both arguments:</p><p>aspirin eliminates headaches → aspirin treats headaches aspirin eliminates headaches aspirin murders headaches This format provides a broad definition of context on one hand, while isolating the task of relation inference. In addition, methods that can be evaluated on this type of data, can also be directly embedded into downstream applications, motivating subsequent work to use it as a benchmark <ref type="bibr">(Melamud et al., 2013;</ref><ref type="bibr">Abend et al., 2014;</ref><ref type="bibr">Lewis, 2014)</ref>. We therefore create our own dataset in this format.</p><p>The main drawback of Zeichner et al.'s process is that it is biased towards a specific relation inference method, DIRT <ref type="bibr" target="#b373">(Lin and Pantel, 2001</ref>). Essentially, Zeichner et al. conducted a post-hoc evaluation of DIRT and recorded the results. While their approach does not suffer from the major disadvantages of post-hoc evaluation -cost and irreplicability -it ignores instances that do not behave according to DIRT's assumptions. These invisible examples amount to an enormous chunk of the inference performed when answering questions, which are covered by our approach (see §4).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Collection &amp; Annotation Process</head><p>Our data collection and annotation process is designed to achieve two goals: (1) to efficiently sample premise-hypothesis pairs in an unbiased man-ner; (2) to allow for cheap, consistent, and scalable annotations based on an intuitive QA setting. We collect answer candidates according to the following criteria:</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Methodology Overview</head><p>1. a arg = q arg 2. a answer is a type of q type 3. a rel = q rel These criteria isolate the task of relation inference from additional inference tasks, because they ensure that a's arguments are entailing q's. In addition, the first two criteria ensure that enough candidate answers actually answer the question, while the third discards trivial cases. In contrast to <ref type="bibr">(Zeichner et al., 2012)</ref> and post-hoc evaluations, these criteria do not impose any bias on the relation pair a rel , q rel . Furthermore, we show in §3.2 that both a and q are both independent naturally-occurring texts, and are not machine-generated by applying a specific set of inference rules.</p><p>For each (a, q) pair, Mechanical Turk annotators are asked whether a provides an answer to q. This natural approach also enables batch annotation; for each question, several candidate answers can be presented at once without shifting the annotator's focus. To make sure that the annotators do not use their world knowledge about a answer , we mask it during the annotation phase and replace it with q type (see <ref type="figure" target="#fig_3">Figure 1 and  §3.3)</ref>.</p><p>Finally, we instantiate q type with a answer , so that each (a, q) pair fits Zeichner's format: instantiated predicates sharing both arguments.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Data Collection</head><p>We automatically collected 30,703 pairs of questions and candidate answers for annotation. Our process is largely inspired by <ref type="bibr">(Fader et al., 2014)</ref>.</p><p>Questions We collected 573 questions by manually converting questions from TREC <ref type="bibr">(Voorhees and Tice, 2000)</ref>, WikiAnswers <ref type="bibr">(Fader et al., 2013)</ref>, WebQuestions <ref type="bibr" target="#b296">(Berant et al., 2013)</ref>, to our "Which q type q rel q arg ?" format. Though many questions did fit our format, a large portion of them were about sports and celebrities, which were not applicable to our choice of corpus (Google books) and taxonomy (WordNet). <ref type="bibr">4</ref> Corpus QA requires some body of knowledge from which to retrieve candidate answers. We follow <ref type="bibr">Fader et al. (2013;</ref>, and use a collection of Open IE-style assertions <ref type="bibr">(Banko et al., 2007)</ref> as our knowledge base. Specifically, we used hand-crafted syntactic rules 5 to extract over 63 million unique subject-relation-object triplets from Google's Syntactic N-grams <ref type="bibr">(Goldberg and Orwant, 2013)</ref>. The assertions may include multiword phrases as relations or arguments, as illustrated earlier. This process yields some ungrammatical or out-of-context assertions, which are later filtered during annotation (see §3.3).</p><p>Answer Candidates In §3.1 we defined three criteria for matching an answer candidate to a question, which we now translate into a retrieval process. We begin by retrieving all assertions where one of the arguments (subject or object) is equal to q arg , ignoring stopwords and inflections. The matching argument is named a arg , while the other (non-matching) argument becomes a answer .</p><p>To implement the second criterion (a answer is a type of q type ) we require a taxonomy T , as well as a word-sense disambiguation (WSD) algorithm to match natural-language terms to entities in T . In this work, we employ WordNet's hypernymy graph <ref type="bibr" target="#b477">(Fellbaum, 1998)</ref> as T and Lesk (Lesk, 1986) for WSD (both via NLTK <ref type="bibr">(Bird et al., 2009)</ref>). While automatic WSD is prone to some errors, these cases are usually annotated as nonsensical in the final phase.</p><p>Lastly, we remove instances where a rel = q rel . 6</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Crowdsourced Annotation</head><p>Masking Answers We noticed that exposing a answer to the annotator may skew the annotation; rather than annotating whether a rel implies q rel in the given context, the annotator might annotate whether a answer answers q according to her general knowledge. For example:</p><p>Q: Which country borders Ethiopia?</p><p>A: Eritrea invaded Ethiopia.</p><p>An annotator might be misled by knowing in advance that Eritrea borders Ethiopia. Although an invasion typically requires land access, it does not imply a shared border, even in this context; "Italy invaded Ethiopia" also appears in our corpus, but it is not true that "Italy borders Ethiopia". Effectively, what the annotator might be doing in this case is substituting q type ("country") with a answer ("Eritrea") and asking herself if the assertion (a answer , q rel , q arg ) is true ("Does Eritrea border Ethiopia?"). As demonstrated, this question may have a different answer from the inference question in which we are interested ("If a country invaded Ethiopia, does that country border Ethiopia?"). We therefore mask a answer during annotation by replacing it with q type as a placeholder:</p><formula xml:id="formula_132">A: [COUNTRY] invaded Ethiopia.</formula><p>This forces the annotator to ask herself whether a rel implies q rel in this context, i.e. does invading Ethiopia imply sharing a border with it? Labels Each annotator was given a single question with several matching candidate answers (20 on average), and asked to mark each candidate answer with one of three labels:</p><p>The sentence answers the question.</p><p>The sentence does not answer the question.</p><p>? The sentence does not make sense, or is severely non-grammatical. <ref type="figure" target="#fig_3">Figure 1</ref> shows several annotated examples. The third annotation (?) was useful in weeding out noisy assertions (23% of candidate answers).</p><p>Aggregation Overall, we created 1,500 questionnaires, 7 spanning a total of 30,703 (a, q) pairs. Each questionnaire was annotated by 5 differ-7 Each of our 573 questions had many candidate answers. These were split into smaller chunks (questionnaires) of less than 25 candidate answers each. ent people, and aggregated using the unanimousup-to-one (at least 4/5) rule. Examples that did not exhibit this kind of inter-annotator agreement were discarded, and so were examples which were determined as nonsensical/ungrammatical (annotated with ?). After aggregating and filtering, we were left with 3,147 positive () and 13,224 negative () examples. <ref type="bibr">8</ref> To evaluate this aggregation rule, we took a random subset of 32 questionnaires (594 (a, q) pairs) and annotated them ourselves (expert annotation). We then compared the aggregated crowdsourced annotation on the same (a, q) pairs to our own. The crowdsourced annotation yielded 91.3% precision on our expert annotations (i.e. only 8.7% of the crowd-annotated positives were expertannotated as negative), while recalling 86.2% of expert-annotated positives.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Performance of Existing Methods</head><p>To provide a baseline for future work, we test the performance of two inference-rule resources and two methods of distributional inference on our dataset, as well as a lemma-similarity baseline. 9</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Baselines</head><p>Lemma Baseline We implemented a baseline that takes into account four features from the premise relation (a rel ) and the hypothesis relation (q rel ) after they have been lemmatized: (1) Does a rel contain all of q rel 's content words? (2) Do the relations share a verb? (3) Does the relations' active/passive voice match their arguments' alignments? (4) Do the relations agree on negation? The baseline will classify the example as positive if all features are true. PPDB 2.0 We used the largest collection of paraphrases (XXXL) from PPDB <ref type="bibr">(Pavlick et al., 2015b)</ref>. These paraphrases include argument slots for cases where word order changes (e.g. passive/active).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Entailment Graph</head><p>We used the publiclyavailable inference rules derived from <ref type="bibr">Berant et al.'s (2011)</ref> entailment graph. These rules contain typed relations and can also be applied in a context-sensitive manner. However, ignoring the types and applying the inference rules out of context worked better on our dataset, perhaps because Berant et al.'s taxonomy was learned from a different corpus.</p><p>Relation Embeddings Similar to DIRT <ref type="bibr" target="#b373">(Lin and Pantel, 2001</ref>), we create vector representations for relations, which are then used to measure relation similarity. From the set of assertions extracted in §3.2, we create a dataset of relation-argument pairs, and use word2vecf  to train the embeddings. We also tried to use the arguments' embeddings to induce a contextsensitive measure of similarity, as suggested by <ref type="bibr" target="#b511">Melamud et al. (2015)</ref>; however, this method did not improve performance on our dataset.</p><p>Word Embeddings Using Google's Syntactic N-grams <ref type="bibr">(Goldberg and Orwant, 2013)</ref>, from which candidate answers were extracted, we trained dependency-based word embeddings with word2vecf . We used the average word vector to represent multi-word relations, and cosine to measure their similarity.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Results</head><p>Under the assumption that collections of inference rules are more precision-oriented, we also try different combinations of rule-based and embeddingbased methods by first applying the rules and then calculating the embedding-based similarity only on instances that were not identified as positive by the rules. Since the embeddings produce a similarity score, not a classification, we plot all methods' performance on a single precision-recall curve <ref type="figure" target="#fig_8">(Figure 2</ref>).</p><p>All methods used the lemma baseline as a first step to identify positive examples; without it, performance drops dramatically. This is probably more of a dataset artifact than an observation about the baselines; just like we filtered examples where a rel = q rel , we could have used a more aggressive policy and removed all pairs that share lemmas.</p><p>It seems that most methods provide little value beyond the lemma baseline -the exception being <ref type="bibr">Berant et al.'s (2011)</ref> entailment graph. Unifying the entailment graph with PPDB (and, implicitly, the lemma baseline) slightly improves performance, and provides a significantly better starting point for the method based on word embeddings. Even so, performance is still quite poor in absolute terms, with less than 25% recall at 80% precision. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">The Ramifications of Low Recall</head><p>These results emphasize the huge false-negative rate of existing methods. This suggests that a massive amount of inference examples, which are necessary for answering questions, are inherently ignored in <ref type="bibr">(Zeichner et al., 2012)</ref> and post-hoc evaluations. Our dataset remedies this bias, and poses a new challenge for future research on relation inference. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>References</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>In the last decades, an impressive number of semantic classifications has been developed, both regarding manual lexicographic and/or cognitive classifications such as WordNet <ref type="bibr" target="#b477">(Fellbaum, 1998)</ref>  <ref type="bibr">(Hindle, 1990;</ref><ref type="bibr">Pereira et al., 1993;</ref><ref type="bibr">Snow et al., 2006), verbs (Merlo and</ref><ref type="bibr">Stevenson, 2001;</ref><ref type="bibr">Korhonen et al., 2003;</ref><ref type="bibr">Schulte im Walde, 2006)</ref> and adjectives <ref type="bibr">(Hatzivassiloglou and McKeown, 1993;</ref><ref type="bibr" target="#b173">Boleda et al., 2012)</ref>.</p><p>Semantic classifications are of great interest to computational linguistics, specifically regarding the pervasive problem of data sparseness in the processing of natural language. Such classifications have been used in applications such as word sense disambiguation <ref type="bibr">(Dorr and Jones, 1996;</ref><ref type="bibr">Kohomban and Lee, 2005;</ref><ref type="bibr">McCarthy et al., 2007)</ref>, parsing <ref type="bibr">(Carroll et al., 1998;</ref><ref type="bibr">Carroll and Fang, 2004)</ref>, machine translation <ref type="bibr">(Prescher et al., 2000;</ref><ref type="bibr">Weller et al., 2014)</ref>, and information extraction <ref type="bibr">(Surdeanu et al., 2003;</ref><ref type="bibr">Venturi et al., 2009</ref>).</p><p>Regarding prepositions, comparably little effort in computational semantics has gone beyond a specific choice of prepositions (such as spatial prepositions), towards a systematic classification of preposition senses, as in The Preposition Project <ref type="bibr">(Litkowski and Hargraves, 2005)</ref>. Distributional approaches towards preposition meaning and sense distinction have only recently started to explore salient preposition features, but with few exceptions (such as Baldwin <ref type="formula" target="#formula_1">(2006)</ref>) these approaches focused on token-based classification of preposition senses <ref type="bibr">(Ye and Baldwin, 2006;</ref><ref type="bibr">O'Hara and Wiebe, 2009;</ref><ref type="bibr">Tratz and Hovy, 2009;</ref><ref type="bibr">Hovy et al., 2010;</ref><ref type="bibr">Hovy et al., 2011)</ref>. This paper addresses an automatic classification of preposition types in German, comparing various clustering approaches. We aim for an unsupervised setting that does not require predefined expensive resources, such as a token-based annotation of preposition senses. Our task is challenging, because (i) prepositions are notoriously ambiguous, (ii) the interpretation of out-of-context preposition type classification is more difficult than context-embedded token interpretation, (iii) there are no established lexical resources for type-based semantic classification other than for English, and (iv) there are no established evaluation measures for ambiguous linguistic classifications. We accept the challenges, identify salient preposition features, and demonstrate the inevitability to apply soft (rather than hard) clustering in order to explore linguistic ambiguity.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Experiments 2.1 Preposition Data</head><p>In the absence of any large-scale semantic hierarchical type classification, the German grammar book by <ref type="bibr">Helbig and Buscha (1998)</ref>  classes that contained more than one preposition, and deleted prepositions that appeared &lt;10,000 times in our web corpus containing 880 million words (cf. Section 2.2). This selection process resulted in 12 semantic classes covering between 2 and 27 prepositions each (cf. <ref type="table" target="#tab_10">Table 1)</ref>, and a more fine-grained version that sub-divided the three largest classes 'local', 'modal' and 'temporal' into 6/10/7 sub-classes, respectively, and resulted in a total of 32 classes. <ref type="bibr">12</ref> The prepositions in the fine-grained version exhibit ambiguity rates of 1 (monosemous) up to 10. Out of the 49 preposition types, 23 are polysemous (46.9%).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Preposition Features</head><p>The corpus-based features for the German prepositions were induced from the SdeWaC corpus (Faaß and Eckart, 2013), a cleaned version of the German web corpus deWaC <ref type="bibr">(Baroni et al., 2009)</ref> containing approx. 880 million words. We compare three categories of distributional features:</p><p>(1) bag-of-words window co-occurrence features: we apply a standard bag-of-words model (BOW) relying on a window of 2 words to the left and to the right, and a continuous bag-of-words model (CBOW) using negative sampling with K=15 ;</p><p>(2) direct syntactic dependency: we compare the most salient preposition-related dependencies: preposition-subcategorised nouns (nouns-dep, e.g., in Buch 'in book'), prepositionsubcategorising nouns (nouns-gov, e.g., Buch von 'book by'), and prepositionsubcategorising verbs (verbs-gov, e.g., reisen nach 'to travel to');</p><p>1 While we also conducted experiments using the coarsegrained class distribution in <ref type="table" target="#tab_10">Table 1</ref>, the experiments in this paper focus on the fine-grained inventory.</p><p>2 The gold standard was previously used in <ref type="bibr" target="#b258">Springorum et al. (2013)</ref> and in <ref type="bibr">Köper and Schulte im Walde (2014)</ref>. <ref type="formula" target="#formula_6">(3)</ref> 2nd-order syntactic co-occurrence: adjectives that modify nouns subcategorised by the prepositions, and adverbs that modify verbs subcategorising the prepositions.</p><p>The dependency information was extracted from a parsed version of the SdeWaC using Bohnet's MATE dependency parser <ref type="bibr" target="#b495">(Bohnet, 2010;</ref><ref type="bibr" target="#b258">Scheible et al., 2013)</ref>. All but the CBOW features were weighted according to positive pointwise mutual information.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Clustering Approaches</head><p>As we wanted to explore hard vs. soft clustering approaches on the same task, we chose k-Means as a standard hard clustering approach (relying on WEKA's spherical k-Means implementation), and compared it to various soft clustering approaches. We transfered the hard k-Means cluster analyses to soft cluster analyses, using two alternative methods.</p><p>(1) The prep-based soft k-Means method <ref type="bibr" target="#b258">(Springorum et al., 2013)</ref> calculated the mean cosine distanced for each preposition p to the centroids z c of the clusters c, and assigned a preposition to a specific cluster if its distance to the respective cluster centroid was below a threshold t multiplied with the mean distance, with t = 0.05, 0.1, 0.15, . . . , 0.95. Additionally, (2) we propose a hard-to-soft clustering transfer prob-based soft k-Means that converts the cosine distances between the prepositions and the hard cluster centroids to membership probabilities.</p><p>Instead of transferring a hard clustering to a soft clustering we also directly applied soft clustering approaches: (1) The fuzzy c-Means algorithm extends k-means by a cluster membership function for each preposition, f m ∈ [0, 1]. (2) We applied Latent Semantic Clustering (LSC), an instance of the Expectation-Maximisation (EM) algorithm <ref type="bibr">(Baum, 1972)</ref> for unsupervised training on unannotated data <ref type="bibr">(Rooth et al., 1999)</ref>. The cluster analyses define two-dimensional soft clusters (in our case: preposition-feature clusters) with cluster membership probabilities, which are able to generalise over hidden data. <ref type="formula" target="#formula_6">(3)</ref> We used Non-negative matrix factorization (NMF), a factorisation approach with an inherent (soft) clustering property <ref type="bibr">(Ding et al., 2005)</ref>.</p><p>All variants of our hard-to-soft clustering approaches and the direct soft clustering approaches (except for k-Means/prep) 3 resulted in a preposition-cluster membership matrix with values ∈ [0, 1]. We transfered the real membership values to binary membership by applying a threshold t to decide about the cluster membership, again with t = 0.05, 0.1, 0.15, . . . , 0.95. For each clustering approach and for each number of clusters k we then identified the best threshold.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.4">Evaluation</head><p>We chose the fuzzy extension of B-Cubed <ref type="bibr" target="#b808">(Bagga and Baldwin, 1998)</ref> as evaluation measure, because it is (a) a pair-wise evaluation, which is considered as most suitable for soft clustering evaluations, and (b) distinguishes between homogeneity and completeness of a clustering, and thus resembles an evaluation by precision and recall. Pair-wise precision P determines the homogeneity of a cluster analysis, by calculating for each individual preposition p the amount of prepositions p in the same cluster c that also belong to the same gold-standard class g, cf. Equation (1). Pair-wise recall R determines the completeness of a cluster analysis, by calculating for each individual preposition p the amount of prepositions p in the same gold-standard class g that also belong to the same cluster c, cf. Equation (2). The overall B-Cubed precision and recall scores are the averages over all preposition-wise scores. We combined precision and recall by their harmonic mean, the f-score.</p><formula xml:id="formula_133">P (p, p ) = min(|c(p) ∩ c(p )|, |g(p) ∩ g(p )| |c(p) ∩ c(p )| (1) R(p, p ) = min(|c(p) ∩ c(p )|, |g(p) ∩ g(p )| |g(p) ∩ g(p )|<label>(2)</label></formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.5">Baselines</head><p>We created two baselines for our preposition clusterings: The hard baseline was computed for every number of clusters k= <ref type="bibr">[5,</ref><ref type="bibr">40]</ref>. For each k, each preposition was randomly assigned to one of the k clusters, and the resulting hard cluster analysis was evaluated. The hard cluster assignments were repeated 1,000 times for each k, and the overall evaluation score for k clusters is the average score of the 1,000 runs. The soft baseline was also created by random assignment across 1,000 runs for each k, but -integrating the fuzzy componenteach preposition was assigned to n clusters, with n a random number between 1 and the number of gold-standard classes for that specific preposition. Note that this baseline is more informed than an entirely random baseline, because the information about the number of gold-standard classes for each preposition is very helpful. For example, the baseline assigns monosemous prepositions to only one cluster, and prepositions with three senses to a random integer in <ref type="bibr">[1,</ref><ref type="bibr" target="#b471">3]</ref>.</p><p>3 Results <ref type="figure" target="#fig_3">Figure 1</ref> compares the fuzzy B-Cubed f-score values across the hard and soft clustering approaches, relying on the preposition-subcategorised nouns as one of the best features (cf. <ref type="figure" target="#fig_8">Figure 2 below)</ref>. The plot demonstrates that (i) the hard k-Means clustering approach is the only one resulting in f-scores below the soft baseline, while (ii) the vast majority of soft clustering results lies above the soft baseline. Furthermore, (iii) there is a clear tendency for all soft clustering approaches to provide the best f-scores for similar values of k clusters: 15 ≤ k ≤ 19. The overall best result is reached by NMF for a clustering with 17 clusters. <ref type="figure" target="#fig_8">Figure 2</ref> compares the f-scores across feature types, relying on NMF as the best clustering approach. The plot confirms that (i) -across features-, the vast majority of soft clustering results lies above the soft baseline. In addition, (ii) in the previously most successful range for 15 ≤ k ≤ 19 clusters, the preposition-subcategorised nouns represent the best features. (iii) The best cluster analyses relying on window vs. syntax features are similarly successful, and outperform 2nd-order co-occurrence features.</p><p>We checked the overall best cluster analysis (NMF, k = 17, nouns-dep) on the predicted degree of ambiguity (cf. <ref type="figure" target="#fig_6">Figure 3)</ref>: for 23 out of the 26 monosemous prepositions, we correctly predicted one preposition sense; for 7 out of the 23 polysemous prepositions, we predicted the correct number of senses; for 9 out of the 23 polysemous prepositions, we predicted less senses than the gold standard defines; and for 7 out of the 23 polysemous prepositions, we predicted more senses than the gold standard defines.</p><p>Our best soft-clustering approach to the preposition classification task thus demonstrates its usefulness through quantitative B-Cubed evaluation and through reliable predictions of ambiguity.    </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>259</head><p>While the results in the previous section demonstrate the success of the type-based clustering, we were interested in two specific questions: (i) Where do the differences in the quality of the cluster analyses come from? (ii) Do the best cluster analyses present linguistically reliable and useful semantic classes? From a quantitative point of view, both questions have been addressed by the evaluation measure, fuzzy B-Cubed, which we chose for reasons outlined in Section 2.4. One should keep in mind, however, that there is an ongoing discussion about cluster comparison and cluster evaluation <ref type="bibr">(Meila, 2007;</ref><ref type="bibr">Rosenberg and Hirschberg, 2007;</ref><ref type="bibr">Vinh and Bailey, 2010;</ref><ref type="bibr">Utt et al., 2014)</ref>, which demonstrates uncertainty about an optimal measure, and which concerns us, expecially regarding the linguistic aspects of soft clustering. In the following, we therefore provide qualitative analyses and discussions of the cluster approaches and analyses.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Ambiguity rate of soft-clustering approaches:</head><p>We looked into the best cluster analysis for each soft-clustering approach, and checked the ambiguities. While the number of preposition types in the cluster analyses is similar across approaches (between 44 and 48), the ambiguity rate (i.e., the number of cluster assignments per preposition type) and the number of ambiguous preposition types (i.e., the number of prepositions assigned to more than one cluster) differ strongly. For example, k-Means/prob and NMF perform an average of 3.1/3.7 assignments for each preposition, in comparison to 2.2-2.4 assignments by the other approaches. On the other hand, while kMeans/prob defines almost all preposition types (43 out of 48) as ambiguous, NMF only defines 28 out of 46 prepositions as ambiguous. NMF (best approach) thus shows a high ambiguity rate, but only 60% of the prepositions are ambiguous.</p><p>Cluster sizes: Looking into the actual cluster analyses reveals that the sizes and the structures within the individual clusters differ strongly. The best k-Means/prep and k-Means/prob analyses (k = 16, F = 0.33, and k = 19, F = 0.34), for example, each contain 7 large clusters with 10-25 prepositions. All other clusters contain only 1-3 prepositions. In comparison, the best NMF analysis (k = 17, F = 0.43) contains only one cluster with three prepositions, and all other clusters but one contain ≥ 5 and ≤ 14 prepositions. The cluster sizes of the best NMF analysis are therefore more homogeneous than for other clustering approaches.</p><p>Optimal k: While fuzzy B-Cubed determined the numbers of clusters <ref type="bibr">[15,</ref><ref type="bibr">19]</ref> as optimal for the soft-clustering approaches, we also looked into the NMF cluster analysis with k = 32, with NMF as the best approach and 32 as the number of gold standard classes. The clusters are, again, very similar in size, including only one singleton and only one cluster with 9 prepositions. All other clusters contain 2 − 6 prepositions. The smaller cluster sizes allow manual evaluations. We can indeed find reliable semantic clusters, such as {an, auf, hinter, in, mit, nach, neben, um, vor}, where 7 out of 9 prepositions belong to the gold-standard class local: not target-oriented containing a total of 12 prepositions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Conclusion</head><p>We presented variants of hard and soft clustering approaches across several sets of preposition features, to automatically classify preposition types into semantic classes. While type-based classifications for highly ambiguous word classes are a computational challenge, our best approach (NMF-based classification with 17 clusters) reached an f-score of 0.43. The clustering experiments showed that (i) the semantically most salient preposition features are indeed the most successful, and that (ii) the clustering of highly ambiguous words requires soft rather than hard clustering approaches.</p><p>Most interestingly, a qualitative analysis zoomed into the assignment behaviour of the soft clustering approaches, and revealed different attitudes towards predicting ambiguity. NMF as the best approach predicted a high ambiguity rate but only for a restricted proportion of 60% of the preposition types. Furthermore, the distribution of cluster sizes was less skewed than for other approaches. Decision-making is often dependent on uncertain data, e.g. data associated with confidence scores or probabilities. We present a comparison of different information presentations for uncertain data and, for the first time, measure their effects on human decision-making. We show that the use of Natural Language Generation (NLG) improves decision-making under uncertainty, compared to state-of-theart graphical-based representation methods. In a task-based study with 442 adults, we found that presentations using NLG lead to 24% better decision-making on average than the graphical presentations, and to 44% better decision-making when NLG is combined with graphics. We also show that women achieve significantly better results when presented with NLG output (an 87% increase on average compared to graphical presentations).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Natural Language Generation (NLG) technology can achieve comparable results to commonly used data visualisation techniques for supporting accurate human decision-making <ref type="bibr" target="#b528">(Gatt et al., 2009)</ref>. In this paper, we investigate whether NLG technology can also be used to support decision-making when the underlying data is uncertain. Current data-to-text systems assume that the underlying data is precise and correct -an assumption which is heavily criticised by other disciplines concerned with decision support, such as medicine (Gigerenzer and Muir Gray, 2011), environmental modelling <ref type="bibr" target="#b24">(Beven, 2009)</ref>, climate change <ref type="bibr">(Manning et al., 2004)</ref>, or weather forecasting <ref type="bibr">(Kootval, 2008)</ref>. However, simply presenting numerical expressions of risk and uncertainty is not enough. Psychological studies on decision making have found that a high percentage of people do not understand and can't act upon numerical uncertainty <ref type="bibr" target="#b25">(Cokely et al., 2012;</ref><ref type="bibr">Galesic and GarciaRetamero, 2010)</ref>. For example, only 28% of Germans and 25% of Americans are able to answer the question: "Which of the following numbers represents the biggest risk of getting a disease: 1 in 100, 1 in 1000, 1 in 10?" (Galesic and GarciaRetamero, 2010).</p><p>So far, the NLG community has investigated the conversion of numbers into language <ref type="bibr">(Power and Williams, 2012)</ref> and the use of vague expressions <ref type="bibr">(van Deemter, 2009)</ref>. In this work, we explore how to convert numerical representations of uncertainty into Natural Language so as to maximise confidence and correct outcomes of human decision-making. We consider the exemplar task of weather forecast generation. We initially present two NLG strategies which present the uncertainty in the input data. The two strategies are based on (1) the World Meteorological Organisation (WMO) <ref type="bibr">(Kootval, 2008)</ref> guidelines and (2) commercial forecast presentations (e.g. from BBC presenters). We then evaluate the strategies against a state-of-the-art graphical system <ref type="bibr">(Stephens et al., 2011)</ref>, which presents the uncertain data in a graphical way. <ref type="figure" target="#fig_3">Figure 1</ref> shows an example of this baseline graphical presentation. We use a gamebased setup <ref type="bibr">(Gkatzia et al., 2015)</ref> to perform taskbased evaluation, to investigate the effect that the different information presentation strategies have on human decision-making.</p><p>Weather forecast generation is a common topic within the NLG community, e.g. <ref type="bibr">(Konstas and Lapata, 2012;</ref><ref type="bibr" target="#b22">Angeli et al., 2010;</ref><ref type="bibr" target="#b23">Belz and Kow, 2010;</ref><ref type="bibr">Sripada et al., 2005)</ref>. Previous approaches have not focused on how to communicate uncertain information or the best ways of referring to probabilities of meteorological phenomena to occur. In addition, their evaluation is based on user ratings of grammatically, semantic correctness, fluency, coherence or via post-edit evaluation. Although these metrics are indicative of the quality of the text produced, they do not measure the impact the texts might have in people's comprehension of uncertainty or on their ability to make decisions based on the information conveyed.</p><p>Our contributions to the field are as follows: (1) We study a principled mapping of uncertainty to Natural Language and provide recommendations and data for future NLG systems; (2) We introduce a game-based data collection environment which extends task-based evaluation by measuring the impact of NLG on decision-making (measuring user confidence and game/task success); and (3) We show that effects of the different representations vary for different user groups, so that user adaptation is necessary when generating multimodal presentations of uncertain information.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">The Extended Weather Game</head><p>In this section, we present our extended version of the MetOffice's Weather Game <ref type="bibr">(Stephens et al., 2011)</ref>. The player has to choose where to send an ice-cream vendor in order to maximise sales, given weather forecasts for four weeks and two locations. These forecasts describe (1) predicted rainfall ( <ref type="figure" target="#fig_8">Figure 2</ref>) and (2) temperature levels together with their likelihoods in three ways: (a) through graphical representations (which is the version of the original game), (b) through textual forecasts, and (c) through combined graphical and textual forecasts. We generated the textual format using two rule-based NLG approaches as described in the next section. Users are asked to initially choose the best destination for the ice-cream vendor and then they are asked to state how confident they are with their choice. Based on their decisions and their confidence levels, the participants are finally presented with their "monetary gain". For example, the higher the likelihood of sunshine, the higher the monetary gain if the player has declared that s/he is confident that it is not going to rain and it doesn't actually rain. In the opposite scenario, the player would lose money. The decision on whether rain occurred is estimated by sampling the probability distribution. At the end of the game, users were scored according to their "risk literacy" following the Berlin Numeracy Test <ref type="bibr" target="#b25">(Cokely et al., 2012)</ref>. Further details are presented in <ref type="bibr">(Gkatzia et al., 2015)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Natural Language Generation from Uncertain Information</head><p>We developed two NLG systems, WMO-based and NATURAL, using SimpleNLG <ref type="bibr" target="#b528">(Gatt and Reiter, 2009</ref>), which both generate textual descriptions of rainfall and temperature data addressing the uncertain nature of forecasts. WMO-based: This is a rule-based system which uses the guidelines recommended by the WMO (Kootval, 2008) for reporting uncertainty, as shown in <ref type="table" target="#tab_10">Table 1</ref>. Consider for instance a forecast of sunny intervals with 30% probability of rain. This WMO-based system will generate the following forecast: "Sunny intervals with rain being possible -less likely than not". NATURAL: This system imitates forecasters and their natural way of reporting weather. The rules used in this system have been derived by observing the way that experts (e.g. BBC weather reporters) produce forecasts. For the previous example (sunny intervals with 30% probability of rain), this system will generate the following forecast: "Mainly dry with sunny spells".</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Evaluation</head><p>In − Graphics and NATURAL: This is a multi-modal representation consisting of graphics (as described in the previous condition) and text produced by the NATURAL system. − Graphics and WMO-based: This is also a multi-modal representation consisting of graphics and text produced by the WMObased system.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">NLG only:</head><p>− NATURAL only: This is a text-only representation as described above. − WMO-based system only: This is also a text-only representation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Data</head><p>We recruited 442 unique players (197 females 1 , 241 males, 4 non-disclosed) using social media. We collected 450 unique game instances (just a few people played the game twice). The anonymised data will be released as part of this submission.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Results</head><p>In order to investigate which representations assist people in decision-making under uncertainty, we analysed both the players' scores (in terms of monetary gain) and their predictions for rainfall with regard to their confidence scores. As we described in Section 2, the game calculates a monetary gain based on both the decisions and the confidence of the player, i.e. the decision-making ability of the player. Regarding confidence, we asked users to declare how confident they are on a 10-point scale. In our analysis we therefore focus on both confidence and score at the game.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.1">Results for all adults</head><p>Multi-modal vs. Graphics-only: We found that use of multi-modal representations leads to gaining significantly higher game scores (i.e. better decision-making) than the Graphics-only representation (p = 0.03, effect = +36.36). This is a 44% average increase in game score. Multi-modal vs. NLG-only: However, there is no significant difference between the NLG only and the multi-modal representation, for game score. NLG vs. Graphics-only: We found that the NLG representations resulted in a 24.8% increase in average task score (i.e. better decision-making) compared to the Graphics-only condition, see <ref type="table" target="#tab_5">Table 2</ref>: an average score increase of over 20 points. There was no significant difference found between the WMO and NATURAL NLG conditions. Confidence: For confidence, the multi-modal representation is significantly more effective than NLG only (p &lt; 0.01, effect = 17.7%). However, as <ref type="table" target="#tab_5">Table 2</ref> shows, although adults did not feel very confident when presented with NLG only, they were able to make better decisions compared to being presented with graphics only. Demographic factors: We further found that prior experience on making decisions based on risk, familiarity with weather models, and correct literacy test results are predictors of the players' understanding of uncertainty, which is translated in both confidence and game scores. In contrast, we found that the education level, the gender, or being native speaker of English does not contribute to players' confidence and game scores.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.2">Results for Females</head><p>We found that females score significantly higher at the decision task when exposed to either of the NLG output presentations, when compared to the graphics-only presentation (p &lt; 0.05, effect = +53.03). This is an increase of 87%, also see <ref type="table" target="#tab_6">Table 3</ref>. In addition, the same group of users scores significantly higher when presented with the multi-modal output as compared to graphics only (p = 0.05, effect =60.74%). Interestingly, for  this group, the multi-modal presentation adds little more in effectiveness of decision-making than the NLG-only condition, but the multi-modal presentations do enhance their confidence (+15%). We furthermore found that educated (i.e. holding a BSc or higher degree) females, who also correctly answered the risk literacy test, feel significantly more confident when presented with the multi-modal representations than with NLG only (p = 0.01, effect = 16.7%).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.3">Results for Males</head><p>We found that males obtained similar game scores with all the types of representation. This suggests that the overall improved scores (for All Adults) presented above, are largely due to the beneficial effects of NLG for women. In terms of confidence, males are more likely to be more confident if they are presented with graphics only (81% of the time) or a multi-modal representation (85% of the time) (p = 0.01).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">Conclusions and Future Work</head><p>We present results from a game-based study on how to generate descriptions of uncertain dataan issue which so far has been unexplored by data-to-text systems. We find that there are significant gender differences between multi-modal, NLG, and graphical versions of the task, where for women, use of NLG results in a 87% increase in task success over graphics. Multimodal presentations lead to a 44% increase for all adults, compared to graphics. People are also more confident of their judgements when using the multimodal representations. These are significant findings, as previous work has not distinguished between genders when comparing different representations of data, e.g. <ref type="bibr" target="#b528">(Gatt et al., 2009)</ref>. It also confirms research on gender effects in multi-modal systems, as for example reported in <ref type="bibr">(Foster and Oberlander, 2006;</ref><ref type="bibr">Rieser and Lemon, 2008;</ref><ref type="bibr">Weiss et al., 2012)</ref>. The results are also related to educational research, which shows that women perform better in verbal-logical tasks than visual-spatial tasks <ref type="bibr">(Zhu, 2007</ref>). An interesting investigation for future research is the interplay between uncertainty, risk-taking behaviour and gender, as for example reported in <ref type="bibr">(Sarin and Wieland, 2016</ref> </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>We understand from Zipf's Law that in any natural language corpus a majority of the vocabulary word types will either be absent or occur in low frequency. Estimating the statistical properties of these rare word types is naturally a difficult task. This is analogous to the curse of dimensionality when we deal with sequences of tokens -most sequences will occur only once in the training data. Neural network architectures overcome this problem by defining non-linear compositional models over vector space representations of tokens and hence assign non-zero probability even to sequences not seen during training <ref type="bibr">Kiros et al., 2015)</ref>. In this work, we explore a similar approach to learning distributed representations of social media posts by 1 https://github.com/bdhingra/tweet2vec composing them from their constituent characters, with the goal of generalizing to out-of-vocabulary words as well as sequences at test time.</p><p>Traditional Neural Network Language Models (NNLMs) treat words as the basic units of language and assign independent vectors to each word type. To constrain memory requirements, the vocabulary size is fixed before-hand; therefore, rare and out-of-vocabulary words are all grouped together under a common type 'UNKNOWN'. This choice is motivated by the assumption of arbitrariness in language, which means that surface forms of words have little to do with their semantic roles. Recently, <ref type="bibr" target="#b457">(Ling et al., 2015)</ref> challenge this assumption and present a bidirectional Long Short Term Memory (LSTM) (Hochreiter and Schmidhuber, 1997) for composing word vectors from their constituent characters which can memorize the arbitrary aspects of word orthography as well as generalize to rare and out-of-vocabulary words.</p><p>Encouraged by their findings, we extend their approach to a much larger unicode character set, and model long sequences of text as functions of their constituent characters (including whitespace). We focus on social media posts from the website Twitter, which are an excellent testing ground for character based models due to the noisy nature of text. Heavy use of slang and abundant misspellings means that there are many orthographically and semantically similar tokens, and special characters such as emojis are also immensely popular and carry useful semantic information. In our moderately sized training dataset of 2 million tweets, there were about 0.92 million unique word types. It would be expensive to capture all these phenomena in a word based model in terms of both the memory requirement (for the increased vocabulary) and the amount of training data required for effective learning. Additional benefits of the character based approach include language independence of the methods, and no requirement of NLP preprocessing such as word-segmentation.</p><p>A crucial step in learning good text representations is to choose an appropriate objective function to optimize. Unsupervised approaches attempt to reconstruct the original text from its latent representation . Social media posts however, come with their own form of supervision annotated by millions of users, in the form of hashtags which link posts about the same topic together. A natural assumption is that the posts with the same hashtags should have embeddings which are close to each other. Hence, we formulate our training objective to maximize cross-entropy loss at the task of predicting hashtags for a post from its latent representation.</p><p>We propose a Bi-directional Gated Recurrent Unit (Bi-GRU) <ref type="bibr">(Chung et al., 2014)</ref> neural network for learning tweet representations. Treating white-space as a special character itself, the model does a forward and backward pass over the entire sequence, and the final GRU states are linearly combined to get the tweet embedding. Posterior probabilities over hashtags are computed by projecting this embedding to a softmax output layer. Compared to a word-level baseline this model shows improved performance at predicting hashtags for a held-out set of posts. Inspired by recent work in learning vector space text representations, we name our model tweet2vec.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Related Work</head><p>Using neural networks to learn distributed representations of words dates back to . More recently,  released word2vec -a collection of word vectors trained using a recurrent neural network. These word vectors are in widespread use in the NLP community, and the original work has since been extended to sentences <ref type="bibr">(Kiros et al., 2015)</ref>, documents and paragraphs <ref type="bibr" target="#b233">(Le and Mikolov, 2014)</ref>, topics <ref type="bibr">(Niu and Dai, 2015)</ref> and queries <ref type="bibr">(Grbovic et al., 2015)</ref>. All these methods require storing an extremely large table of vectors for all word types and cannot be easily generalized to unseen words at test time <ref type="bibr" target="#b457">(Ling et al., 2015)</ref>. They also require preprocessing to find word boundaries which is non-trivial for a social network domain like Twitter.</p><p>In <ref type="bibr" target="#b457">(Ling et al., 2015)</ref>, the authors present a compositional character model based on bidirectional LSTMs as a potential solution to these problems. A major benefit of this approach is that large word lookup tables can be compacted into character lookup tables and the compositional model scales to large data sets better than other stateof-the-art approaches. While <ref type="bibr" target="#b457">(Ling et al., 2015)</ref> generate word embeddings from character representations, we propose to generate vector representations of entire tweets from characters in our tweet2vec model.</p><p>Our work adds to the growing body of work showing the applicability of character models for a variety of NLP tasks such as Named Entity Recognition (Santos and Guimarães, 2015), POS tagging (Santos and Zadrozny, 2014), text classification  and language modeling <ref type="bibr">(Karpathy et al., 2015;</ref><ref type="bibr">Kim et al., 2015)</ref>.</p><p>Previously, <ref type="bibr">(Luong et al., 2013)</ref> dealt with the problem of estimating rare word representations by building them from their constituent morphemes. While they show improved performance over word-based models, their approach requires a morpheme parser for preprocessing which may not perform well on noisy text like Twitter. Also the space of all morphemes, though smaller than the space of all words, is still large enough that modelling all morphemes is impractical.</p><p>Hashtag prediction for social media has been addressed earlier, for example in <ref type="bibr">(Weston et al., 2014;</ref><ref type="bibr">Godin et al., 2013)</ref>. <ref type="bibr">(Weston et al., 2014)</ref> also use a neural architecture, but compose text embeddings from a lookup table of words. They also show that the learned embeddings can generalize to an unrelated task of document recommendation, justifying the use of hashtags as supervision for learning text representations.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Tweet2Vec</head><p>Bi-GRU Encoder: <ref type="figure" target="#fig_3">Figure 1</ref> shows our model for encoding tweets. It uses a similar structure to the C2W model in <ref type="bibr" target="#b457">(Ling et al., 2015)</ref>, with LSTM units replaced with GRU units.</p><p>The input to the network is defined by an alphabet of characters C (this may include the entire unicode character set). The input tweet is broken into a stream of characters c 1 , c 2 , ...c m each of which is represented by a 1-by-|C| encoding. These one-hot vectors are then projected to a character space by multiplying with the matrix P C ∈ <ref type="figure" target="#fig_3">Figure 1</ref>: Tweet2Vec encoder for social media text R |C|×dc , where d c is the dimension of the character vector space. Let x 1 , x 2 , ...x m be the sequence of character vectors for the input tweet after the lookup. The encoder consists of a forward-GRU and a backward-GRU. Both have the same architecture, except the backward-GRU processes the sequence in reverse order. Each of the GRU units process these vectors sequentially, and starting with the initial state h 0 compute the sequence h 1 , h 2 , ...h m as follows:</p><formula xml:id="formula_134">r t = σ(W r x t + U r h t−1 + b r ), z t = σ(W z x t + U z h t−1 + b z ), h t = tanh(W h x t + U h (r t h t−1 ) + b h ), h t = (1 − z t ) h t−1 + z t h t .</formula><p>Here r t , z t are called the reset and update gates respectively, andh t is the candidate output state which is converted to the actual output state h t . W r , W z , W h are d h × d c matrices and U r , U z , U h are d h × d h matrices, where d h is the hidden state dimension of the GRU. The final states h f m from the forward-GRU, and h b 0 from the backward GRU are combined using a fully-connected layer to the give the final tweet embedding e t :</p><formula xml:id="formula_135">e t = W f h f m + W b h b 0<label>(1)</label></formula><p>Here W f , W b are d t × d h and b is d t × 1 bias term, where d t is the dimension of the final tweet embedding. In our experiments we set d t = d h . All parameters are learned using gradient descent.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Softmax:</head><p>Finally, the tweet embedding is passed through a linear layer whose output is the same size as the number of hashtags L in the data set. We use a softmax layer to compute the posterior hashtag probabilities:</p><formula xml:id="formula_136">P (y = j|e) = exp(w T j e + b j ) L i=1 exp(w T i e + b j ) .<label>(2)</label></formula><p>Objective Function: We optimize the categorical cross-entropy loss between predicted and true hashtags:</p><formula xml:id="formula_137">J = 1 B B i=1 L j=1 −t i,j log(p i,j ) + λ Θ 2 . (3)</formula><p>Here B is the batch size, L is the number of classes, p i,j is the predicted probability that the ith tweet has hashtag j, and t i,j ∈ {0, 1} denotes the ground truth of whether the j-th hashtag is in the i-th tweet. We use L2-regularization weighted by λ.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Experiments and Results</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Word Level Baseline</head><p>Since our objective is to compare character-based and word-based approaches, we have also implemented a simple word-level encoder for tweets. The input tweet is first split into tokens along white-spaces. A more sophisticated tokenizer may be used, but for a fair comparison we wanted to keep language specific preprocessing to a minimum. The encoder is essentially the same as tweet2vec, with the input as words instead of characters. A lookup table stores word vectors for the V (20K here) most common words, and the rest are grouped together under the 'UNK' token.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Data</head><p>Our dataset consists of a large collection of global posts from Twitter 2 between the dates of June 1, 2013 to June 5, 2013. Only English language posts (as detected by the lang field in Twitter API) and posts with at least one hashtag are retained. We removed infrequent hashtags (&lt; 500 posts) since they do not have enough data for good generalization. We also removed very frequent tags (&gt; 19K posts) which were almost always from automatically generated posts (ex: #androidgame) which are trivial to predict. The final dataset contains 2 million tweets for training, 10K for validation and 50K for testing, with a total of 2039 distinct hashtags. We use simple regex to preprocess the post text and remove hashtags (since these are to be predicted) and HTML tags, and replace usernames and URLs with special tokens. We also removed retweets and convert the text to lower-case.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Implementation Details</head><p>Word vectors and character vectors are both set to size d L = 150 for their respective models. There were 2829 unique characters in the training set and we model each of these independently in a character look-up table. Embedding sizes were chosen such that each model had roughly the same number of parameters <ref type="table" target="#tab_5">(Table 2)</ref>. Training is performed using mini-batch gradient descent with Nesterov's momentum. We use a batch size B = 64, initial learning rate η 0 = 0.01 and momentum parameter µ 0 = 0.9. L2-regularization with λ = 0.001 was applied to all models. Initial weights were drawn from 0-mean gaussians with σ = 0.1 and initial biases were set to 0. The hyperparameters were tuned one at a time keeping others fixed, and values with the lowest validation cost were chosen. The resultant combination was used to train the models until performance on validation set stopped increasing. During training, the learning rate is halved everytime the validation set precision increases by less than 0.01 % from one epoch to the next. The models converge in about 20 epochs. Code for training both the models is publicly available on github.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4">Results</head><p>We test the character and word-level variants by predicting hashtags for a held-out test set of posts.  post from the output posteriors, and report average precision@1, recall@10 and mean rank of the correct hashtags. These are listed in <ref type="table" target="#tab_6">Table 3</ref>. To see the performance of each model on posts containing rare words (RW) and frequent words (FW) we selected two test sets each containing 2,000 posts. We populated these sets with posts which had the maximum and minimum number of out-of-vocabulary words respectively, where vocabulary is defined by the 20K most frequent words. Overall, tweet2vec outperforms the word model, doing significantly better on RW test set and comparably on FW set. This improved performance comes at the cost of increased training time (see <ref type="table" target="#tab_5">Table 2</ref>), since moving from words to characters results in longer input sequences to the GRU.</p><p>We also study the effect of model size on the performance of these models. For the word model we set vocabulary size V to 8K, 15K and 20K respectively. For tweet2vec we set the GRU hidden state size to 300, 400 and 500 respectively. <ref type="figure">Figure</ref>   <ref type="table" target="#tab_42">Table 4</ref>: Precision @1 as training data size and number of output labels is increased. Note that the test set is different for each setting.</p><p>set described above. There is not much variation in the performance, and moreover tweet2vec always outperforms the word based model for the same number of parameters. <ref type="table" target="#tab_42">Table 4</ref> compares the models as complexity of the task is increased. We created 3 datasets (small, medium and large) with an increasing number of hashtags to be predicted. This was done by varying the lower threshold of the minimum number of tags per post for it to be included in the dataset. Once again we observe that tweet2vec outperforms its word-based counterpart for each of the three settings.</p><p>Finally, table 1 shows some predictions from the word level model and tweet2vec. We selected these to highlight some strengths of the character based approach -it is robust to word segmentation errors and spelling mistakes, effectively interprets emojis and other special characters to make predictions, and also performs comparably to the word-based approach for in-vocabulary tokens.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Conclusion</head><p>We have presented tweet2vec -a character level encoder for social media posts trained using supervision from associated hashtags. Our result shows that tweet2vec outperforms the word based approach, doing significantly better when the input post contains many rare words. We have focused only on English language posts, but the character model requires no language specific preprocessing and can be extended to other languages. For future work, one natural extension would be to use a character-level decoder for predicting the hashtags. This will allow generation of hashtags not seen in the training dataset. Also, it will be interesting to see how our tweet2vec embeddings can be used in domains where there is a need for semantic understanding of social media, such as tracking infectious diseases <ref type="bibr">(Signorini et al., 2011)</ref>. Hence, we provide an off-the-shelf encoder trained on medium dataset described above to compute vector-space representations of tweets along with our code on github. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Abstract</head><p>Constrained translation has improved statistical machine translation (SMT) by combining it with translation memory (TM) at sentence-level. In this paper, we propose using a constrained word lattice, which encodes input phrases and TM constraints together, to combine SMT and TM at phrase-level. Experiments on EnglishChinese and English-French show that our approach is significantly better than previous combination methods, including sentence-level constrained translation and a recent phrase-level combination.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>The combination of statistical machine translation (SMT) and translation memory (TM) has proven to be beneficial in improving translation quality and has drawn attention from many researchers <ref type="bibr" target="#b27">(Biçici and Dymetman, 2008;</ref><ref type="bibr">He et al., 2010;</ref><ref type="bibr">Koehn and Senellart, 2010;</ref><ref type="bibr">Ma et al., 2011;</ref><ref type="bibr">Li et al., 2014)</ref>. Among various combination approaches, constrained translation <ref type="bibr">(Koehn and Senellart, 2010;</ref><ref type="bibr">Ma et al., 2011</ref>) is a simple one and can be readily adopted.</p><p>Given an input sentence, constrained translation retrieves similar TM instances and uses matched segments to constrain the translation space of the input by generating a constrained input. Then an SMT engine is used to search for a complete translation of the constrained input.</p><p>Despite its effectiveness in improving SMT, previous constrained translation works at the sentence-level, which means that matched segments in a TM instance are either all adopted or all abandoned regardless of their individual quality . In this paper, we propose a phrase-level constrained translation approach which uses a constrained word lattice to encode the input and constraints from the TM together and allows a decoder to directly optimize the selection of constraints towards translation quality (Section 2).</p><p>We conduct experiments (Section 3) on English-Chinese (EN-ZH) and English-French (EN-FR) TM data. Results show that our method is significantly better than previous combination approaches, including sentence-level constrained methods and a recent phrase-level combination method. Specifically, it improves the BLEU (Papineni et al., 2002) score by up to +5.5% on EN-ZH and +2.4% on EN-FR over a phrase-based baseline <ref type="bibr" target="#b91">(Koehn et al., 2003)</ref> and decreases the TER <ref type="bibr" target="#b288">(Snover et al., 2006)</ref> error by up to -4.3%/-2.2%, respectively.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Constrained Word Lattice</head><p>A word lattice G = (V, E, Σ, φ, ψ) is a directed acyclic graph, where V is a set of nodes, including a start point and an end point, E ⊆ V × V is a set of edges, Σ is a set of symbols, a label function φ : E → Σ and a weight function ψ : E → R. 1 A constrained word lattice is a special case of a word lattice, which extends Σ with extra symbols (i.e. constraints).</p><p>A constraint is a target phrase which will appear in the final translation. Constraints can be obtained in two ways: addition <ref type="bibr">(Ma et al., 2011)</ref> and subtraction <ref type="bibr">(Koehn and Senellart, 2010)</ref>. <ref type="bibr">2</ref>  <ref type="figure" target="#fig_3">Figure  1</ref> exemplifies the differences between them.</p><p>The construction of a constrained lattice is very similar to that of a word lattice, except that we need to label some edges with constraints. The general process is: <ref type="figure" target="#fig_3">Figure 1</ref>: An example of generating a constrained input in two ways: addition and subtraction. While addition replaces an input phrase with a target phrase from a TM instance (an example is marked by lighter gray), subtraction removes mismatched target words and inserts mismatched input words (darker gray). Constraints are specified by &lt;&gt;. Sentences are taken from <ref type="bibr">Koehn and Senellart (2010)</ref>.</p><p>1. Building an initial lattice for an input sentence. This produces a chain.</p><p>2. Adding phrasal constraints into the lattice which produces extra nodes and edges. <ref type="figure" target="#fig_8">Figure 2</ref> shows an example of a constrained lattice for the sentence in <ref type="figure" target="#fig_3">Figure 1</ref>. In the rest of this section, we explain how to use addition and subtraction to build a constrained lattice and the decoder for translating the lattice. Notations we use in this section are: an input f and a TM instance f , e , A where f is the TM source, e is the TM target and A is a word alignment between f and e .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Addition</head><p>In addition, matched input words are directly replaced by their translations from a retrieved TM, which means that addition follows the word order of an input sentence. This property makes it easy to obtain constraints for an input phrase.</p><p>For an input phrase f , we firstly find its matched phrase f from f via string edits 3 between f and f , so that f = f . Then, we extract its translation e from e , which is consistent with the alignment A (Och and Ney, 2004).</p><p>To build a lattice using addition, we directly add a new edge to the lattice which covers f and is labeled by e . For example, dash-dotted lines in <ref type="figure" target="#fig_8">Figure 2</ref> are labeled by constraints from addition. <ref type="bibr" target="#b471">3</ref> String edits, as used in the Levenshtein distance <ref type="bibr">(Levenshtein, 1966)</ref>, include match, substitution, deletion, and insertion with a priority in this paper: match &gt; substitution &gt; deletion &gt; insertion.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Subtraction</head><p>In subtraction, mismatched input words in f are inserted into e and mismatched words in e are removed. The inserted position is determined by A. The advantage of subtraction is that it keeps the word order of e . This is important since the reordering of target words is one of the fundamental problems in SMT, especially for language pairs which have a high degree of syntactic reordering.</p><p>However, this property makes it hard to build a lattice from subtraction, as -different from the addition -subtraction does not directly produce a constraint for an input phrase. Thus, for some generated constraints, there is not a specific corresponding phrase in the input. In addition, when adding a constraint to the lattice, we need to consider its context so that the lattice keeps target word order.</p><p>To solve this problem, in this paper we propose to segment an input sentence into a sequence of phrases according to information from a matched TM (i.e. the string edit and word alignment) and then create a constrained input for each phrase and add them to the lattice.</p><p>Formally, we produce a monotonic segmentation, f 1 , f 1 , e 1 · · · f N , f N , e N , for each sentence triple: f, f , e . Each f i , f i , e i tuple is obtained in two phases: (1) According to the alignment A, f i and e i are produced. (2) Based on string edits between f and f , f i is recognized. The resulting tuple is subject to several restrictions: 1. Each &lt; f i , e i &gt; is consistent with the word alignment A and at least one word in f i is aligned to words in e i .  <ref type="figure" target="#fig_3">Figure 1</ref>. Dash-dotted lines are generated by addition and dotted lines are generated by subtraction. Constraints are specified by &lt;&gt;.</p><p>2. Each boundary word in f i is either the first word or the last word of f or aligned to at least one word in e , so that mismatched input words in f i which are unaligned can find their position in the current tuple.</p><p>3. The string edit for the first word of f i , where i = 1, is not "deletion". That means the first word is not an extra input word. This is because, in subtraction, the inserted position of a mismatched unaligned word depends on the alignment of the word before it.</p><p>4. No smaller tuples may be extracted without violating restrictions 1-3. This allows us to obtain a unique segmentation where each tuple is minimal.</p><p>After obtaining the segmentation, we create a constrained input for each f i using subtraction and add it to the lattice by creating a path covering f i . The path contains one or more edges, each of which is labeled either by an input word or a constraint in the constrained input.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Decoding</head><p>The decoder for integrating word lattices into the phrase-based model <ref type="bibr" target="#b91">(Koehn et al., 2003)</ref> works similarly to the phrase-based decoder, except that it tracks nodes instead of words <ref type="bibr">(Dyer et al., 2008)</ref>: given the topological order of nodes in a lattice, the decoder builds a translation hypothesis from left to right by selecting a range of untranslated nodes.</p><p>The decoder for a constrained lattice works similarly except that, for a constrained edge, the decoder can only build its translation directly from the constraint. For example, in <ref type="figure" target="#fig_8">Figure 2</ref>, the translation of the edge "1 → 5" is ", le texte du deuxième alinéa". </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>EN-ZH Sentences W/S (EN) W/S (ZH)</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Experiment</head><p>In our experiments, a baseline system PB is built with the phrase-based model in Moses . We compare our approach with three other combination methods. ADD combines PB with addition <ref type="bibr">(Ma et al., 2011)</ref>, while SUB combines PB with subtraction <ref type="bibr">(Koehn and Senellart, 2010)</ref>. WANG combines SMT and TM at phraselevel during decoding <ref type="bibr">Li et al., 2014)</ref>. For each phrase pair applied to translate an input phrase, WANG finds its corresponding phrase pairs in a TM instance and then extracts features which are directly added to the loglinear framework (Och and Ney, 2002) as sparse features. We build three systems based on our approach: CWL add only uses constraints from addition; CWL sub only uses constraints from subtraction; CWL both uses constraints from both. <ref type="table" target="#tab_10">Table 1</ref> shows a summary of our datasets. The EN-ZH dataset is a translation memory from Symantec. Our EN-FR dataset is from the publicly available JRC-Acquis corpus. <ref type="bibr">4</ref> Word alignment is performed by GIZA++ (Och and Ney, 2003) with heuristic function grow-diag-final-and.  <ref type="table" target="#tab_5">Table 2</ref>: Experimental results of comparing our approach (CWL x ) with previous work. All scores reported are an average of 3 runs. Scores with * are significantly better than that of the baseline PB at p &lt; 0.01. Bold scores are significantly better than that of all previous work at p &lt; 0.01.</p><p>We use SRILM (Stolcke, 2002) to train a 5-gram language model on the target side of our training data with modified Kneser-Ney discounting <ref type="bibr" target="#b28">(Chen and Goodman, 1996)</ref>. Batch MIRA <ref type="bibr" target="#b29">(Cherry and Foster, 2012</ref>) is used to tune weights. Caseinsensitive BLEU [%] and TER [%] are used to evaluate translation results. <ref type="table" target="#tab_5">Table 2</ref> shows experimental results on EN-ZH and EN-FR. We find that our method (CWL x ) significantly improves the baseline system PB on EN-ZH by up to +5.5% BLEU score and by +2.4% BLEU score on EN-FR. In terms of TER, our system significantly decreases the error by up to -4.3%/-2.2% on EN-ZH and EN-FR, respectively. Although, compared to the baseline PB, ADD and SUB work well on EN-ZH, they reduce the translation quality on EN-FR. By contrast, their phrase-level countparts (CWL add and CWL sub ) bring consistent improvements over the baseline on both language pairs. This suggests that a combination approach based on constrained word lattices is more effective and robust than sentencelevel constrained translation. Compared to system WANG, our method produces significantly better translations as well. In addition, our approach is simpler and easier to adopt than WANG.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Results</head><p>Compared with CWL add , CWL sub produces better translations. This may suggest that, for a constrained word lattice, subtraction generates a better sequence of constraints than addition since it keeps target words and the word order. However,  combining them together (i.e. CWL both ) does not bring a further improvement. We assume the reason for this is that addition and subtraction share parts of the constraints generated from the same TM. For example, in <ref type="figure" target="#fig_8">Figure 2</ref>, the edge "1 → 5" based on addition and the edge "11 → 7" based on subtraction are labeled by the same constraint.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Influence of Fuzzy Match Scores</head><p>Since a fuzzy match scorer 5 is used to select the best TM instance for an input and thus is an important factor for combining SMT and TM, it is interesting to know what impact it has on the translation quality of various approaches. <ref type="table" target="#tab_6">Table 3</ref> shows statistics of each test subset on EN-ZH and EN-FR where sentences are grouped by their fuzzy match scores. <ref type="figure" target="#fig_6">Figure 3</ref> shows BLEU scores of systems evaluated on these subsets. We find that BLEU scores increasingly grow when match scores become higher. While ADD achieves better BLEU scores than SUB on lower fuzzy ranges, SUB performs better than ADD on higher fuzzy scores. In addition, our approaches (CWL x ) are better than the baseline on all ranges but show much more improvement on ranges with higher fuzzy scores. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Conclusion</head><p>In this paper, we propose a constrained word lattice to combine SMT and TM at phrase-level. This method uses a word lattice to encode all possible phrasal constraints together. These constraints come from two sentence-level constrained approaches, including addition and subtraction. Experiments on English-Chinese and EnglishFrench show that compared with previous combination methods, our approach produces significantly better translation results.</p><p>In the future, we would like to consider generating constraints from more than one fuzzy match and using fuzzy match scores or a more sophisticated function to weight constraints. It would also be interesting to know if our method will work better when discarding fuzzy matches with very low scores. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Abstract</head><p>We present a neural network based automatic post-editing (APE) system to improve raw machine translation (MT) output. Our neural model of APE (NNAPE) is based on a bidirectional recurrent neural network (RNN) model and consists of an encoder that encodes an MT output into a fixed-length vector from which a decoder provides a post-edited (PE) translation. APE translations produced by NNAPE show statistically significant improvements of 3.96, 2.68 and 1.35 BLEU points absolute over the original MT, phrase-based APE and hierarchical APE outputs, respectively. Furthermore, human evaluation shows that the NNAPE generated PE translations are much better than the original MT output.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>For many applications the performance of stateof-the-art MT systems is useful but often far from perfect. MT technologies have gained wide acceptance in the localization industry. Computer aided translation (CAT) has become the de-facto standard in large parts of the translation industry which has resulted in a surge of demand for professional post-editors. This, in turn, has resulted in substantial quantities of PE data which can be used to develop APE systems.</p><p>In the context of MT, "post-editing" (PE) is defined as the correction performed by humans over the translations produced by an MT system (Veale and Way, 1997), often with minimal amount of manual effort (TAUS Report, 2010) and as a process of modification rather than revision <ref type="bibr">(LofflerLaurian, 1985)</ref>.</p><p>MT systems primarily make two types of errors -lexical and reordering errors. However, due to the statistical and probabilistic nature of modelling in statistical MT (SMT), the currently dominant MT technology, it is non-trivial to rectify these errors in the SMT models. Post-edited data are often used in incremental MT frameworks as additional training material. However, often this does not fully exploit the potential of these rich PE data: e.g., PE data may just be drowned out by a large SMT model. An APE system trained on human post-edited data can serve as a MT post-processing module which can improve overall performance. An APE system can be considered as an MT system, translating predictable error patterns in MT output into their corresponding corrections.</p><p>APE systems assume the availability of source language input text (SL IP ), target language MT output (T L M T ) and target language PE data (T L P E ). An APE system can be modelled as an MT system between SL IP T L M T and T L P E . However, if we do not have access to SL IP , but have sufficiently large amounts of parallel T L M T -T L P E data, we can still build an APE model between T L M T and T L P E .</p><p>Translations provided by state-of-the-art MT systems suffer from a number of errors including incorrect lexical choice, word ordering, word insertion, word deletion, etc. The APE work presented in this paper is an effort to improve the MT output by rectifying some of these errors. For this purpose we use a deep neural network (DNN) based approach. Neural MT (NMT) (Kalchbrenner and <ref type="bibr" target="#b89">Blunsom, 2013;</ref><ref type="bibr">Cho et al., 2014a;</ref><ref type="bibr">Cho et al., 2014b</ref>) is a newly emerging approach to MT. On the one hand DNNs represent language in a continuous vector space which eases the modelling of semantic similarities (or distance) between phrases or sentences, and on the other hand it can also consider contextual information, e.g., utilizing all available history information in deciding the next target word, which is not an easy task to model with standard APE systems.</p><p>Unlike phrase-based APE systems <ref type="bibr">(Simard et al., 2007a;</ref><ref type="bibr">Simard et al., 2007b;</ref><ref type="bibr">Pal, 2015;</ref><ref type="bibr">Pal et al., 2015)</ref>, our NNAPE system builds and trains a single, large neural network that accepts a 'draft' translation (T L M T ) and outputs an improved translation (T L P E ).</p><p>The remainder of the paper is organized as follows. Section 2 gives an overview of relevant related work. The proposed NNAPE system is described in detail in Section 3. We present the experimental setup in Section 4. Section 5 presents the results of automatic and human evaluation together with some analysis. Section 6 concludes the paper and provides avenues for future work.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Related Work</head><p>APE has proved to be an effective remedy to some of the inaccuracies in raw MT output. APE approaches cover a wide methodological range. Recently, a number of papers have presented the application of neural networks in MT (Kalchbrenner and <ref type="bibr" target="#b89">Blunsom, 2013;</ref><ref type="bibr">?;</ref><ref type="bibr">Cho et al., 2014b;</ref>. These approaches typically consist of two components: an encoder encodes a source sentence and a decoder decodes into a target sentence.</p><p>In this paper we present a neural network based approach to automatic PE (NNAPE). Our NNAPE model is inspired by the MT work of  which is based on bidirectional recurrent neural networks (RNN). Unlike Bahdanau et al. <ref type="formula" target="#formula_0">(2014)</ref>, we use LSTMs rather than GRUs as hidden units. RNNs allow processing of arbitrary length sequences, however, they are susceptible to the problem of vanishing and exploding gradients <ref type="bibr">(Bengio et al., 1994)</ref>. To tackle vanishing gradients in RNNs, two architectures are generally used: gated recurrent units (GRU) <ref type="bibr">(Cho et al., 2014b</ref>) and long-short term memory (LSTM) (Hochreiter and Schmidhuber, 1997). According to empirical studies <ref type="bibr">(Chung et al., 2014;</ref><ref type="bibr">Józefowicz et al., 2015)</ref> both architectures yield comparable performance. GRUs tend to train faster than LSTMs. On the other hand, given sufficient amounts of training data, LSTMs may lead to better results. Since our task is monolingual and we have more than 200K sentence pairs for training, we use a full LSTM (as the hidden units) to model our NNAPE system.</p><p>The model takes T L M T as input and provides T L P E as output. To the best of our knowledge the work presented in this paper is the first approach to APE using neural networks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Neural Network based APE</head><p>The NNAPE system is based on a bidirectional (forward-backward) RNN based encoder-decoder.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">A Bidirectional RNN APE Encoder-Decoder</head><p>Our NNAPE model encodes a variable-length sequence of T L M T (e.g. x = x 1 , x 2 , x 3 ...x m ) into a fixed-length vector representation and then decodes a given fixed-length vector representation back into a variable-length sequence of T L P E (e.g. y = y 1 , y 2 , y 3 ...y n ). Input and output sequence lengths, m and n, may differ. A Bidirectional RNN encoder consists of forward and backward RNNs. The forward RNN encoder reads in each x sequentially from x 1 to x m and at each time step t, the hidden state h t of the RNN is updated by using a non-linear activation function f (Equation 1), an elementwise logistic sigmoid with an LSTM unit.</p><formula xml:id="formula_138">h t = f (h t−1 , x t )<label>(1)</label></formula><p>Similarly, the backward RNN encoder reads the input sequence and calculates hidden states in reverse direction (i.e. x m to x 1 and h m to h 1 respectively). After reading the entire input sequence, the hidden state of the RNN is provided a summary c context vector ('C' in <ref type="figure" target="#fig_3">Figure 1</ref>) of the whole input sequence. The decoder is another RNN trained to generate the output sequence by predicting the next word y t given the hidden state η t and the context vector c t (c.f., Figure1). The hidden state of the decoder at time t is computed as given below.</p><formula xml:id="formula_139">P (y t |y 1 , ...y t−1 , x) = f (η t , y t−1 , c t )<label>(2)</label></formula><formula xml:id="formula_140">η t = f (η t−1 , y t−1 , c t )<label>(3)</label></formula><p>The context vector c t can be computed as</p><formula xml:id="formula_141">c t = m i=1 α ti h i<label>(4)</label></formula><p>Here, α ti , is the weight of each h i and can be computed as</p><formula xml:id="formula_142">α ti = exp(e ti ) m j=1 exp(e tj )<label>(5)</label></formula><p>where e ti = a(η t−1 , h i ) is an alignment model which provides a matching score between the inputs around position i and the output at position t. The alignment score is based on the i th annotation h i of the input sentence and the RNN hidden state η t−1 . The alignment model itself is a feedforward neural network which directly computes a soft alignment that allows the gradient of the cost function to be backpropagated through. The gradient is used to train the alignment model as well as the T L M T -T L P E translation model jointly. The alignment model is computed m × n times as follows:</p><formula xml:id="formula_143">a(η t−1 , h i ) = v T a tanh(W a η t−1 + U a h i ) (6)</formula><p>where W a ∈ R n h ×n h , U a ∈ R n h ×2n h and v a ∈ R n h are the weight matrices of n h hidden units.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Experiments</head><p>We evaluate the model on an English-Italian APE task, which is detailed in the following subsections.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Data</head><p>The training data used for the experiments was developed in the MateCat 1 project and consists of 312K T L M T -T L P E parallel sentences. The parallel sentences are (English to) Italian MT output and their corresponding (human) post-edited Italian translations. Google Translate (GT) is the MT engine which provided the original Italian T L M T output. The data includes sentences from the Europarl corpus as well as news commentaries. Since the data contains some non-Italian sentences, we applied automatic language identification (Shuyo, 2010) in order to select only Italian sentences. Automatic cleaning and pre-processing of the data was carried out by sorting the entire parallel training corpus based on sentence length, filtering the parallel data on maximum allowable sentence length of 80 and sentence length ratio of 1:2 (either direction), removing duplicates and applying tokenization and punctuation normalization using Moses  scripts. After cleaning the corpus we obtained a sentencealigned T L M T -T L P E parallel corpus containing 213,795 sentence pairs. We randomly extracted 1000 sentence pairs each for the development set and test set from the pre-processed parallel corpus and used the remaining (211,795) as the training corpus. The training data features 57,568 and 61,582 unique word types in T L M T and T L P E , respectively. We chose the 40,000 most frequent words from both T L M T and T L P E to train our NNAPE model. The remaining words which are not among the most frequent words are replaced by a special token ([UNK]). The model was trained for approximately 35 days, which is equivalent to 2,000,000 updates with GPU settings.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Experimental Settings</head><p>Our bidirectional RNN Encoder-Decoder contains 1000 hidden units for the forward backward RNN encoder and 1000 hidden units for the decoder.</p><p>The network is basically a multilateral neural network with a single maxout unit as hidden layer <ref type="bibr" target="#b643">(Goodfellow et al., 2013)</ref> to compute the conditional probability of each target word. The word embedding vector dimension is 620 and the size of the maxout hidden layer in the deep output is 500. The number of hidden units in the alignment model is 1000. The model has been trained on a mini-batched stochastic gradient descent (SGD) with 'Adadelta' (Zeiler, 2012). The main reason behind the use of 'Adadelta' is to automatically adapt the learning rate of each parameter ( = 10 −6 and ρ = 0.95). Each SGD update direction is computed using a mini-batch of 80 sentences.</p><p>We compare our NNAPE system with state-ofthe-art phrase-based <ref type="bibr">(Simard et al., 2007b)</ref> as well as hierarchical phrase-based APE (Pal, 2015) systems. We also compare the output provided by our system against the original GT output. For building the phrase-based and hierarchical phrasebased APE systems, we set maximum phrase length to 7. A 5-gram language model built using KenLM <ref type="bibr" target="#b716">(Heafield, 2011)</ref> was used for decoding. System tuning was carried out using both k-best MIRA <ref type="bibr" target="#b29">(Cherry and Foster, 2012)</ref> and Minimum Error Rate Training (MERT) <ref type="bibr" target="#b91">(Och, 2003)</ref> on the held-out development set (devset). After parameters were tuned, decoding was carried out on the held out test set.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Evaluation</head><p>The performance of the NNAPE system was evaluated using both automatic and human evaluation methods, as described below.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Automatic Evaluation</head><p>The output of the NNAPE system on the 1000 sentences testset was evaluated using three MT evaluation metrics: BLEU <ref type="bibr" target="#b284">(Papineni et al., 2002)</ref>, TER <ref type="bibr" target="#b288">(Snover et al., 2006)</ref> and <ref type="bibr">Meteor (Denkowski and Lavie, 2011)</ref>. <ref type="table" target="#tab_10">Table 1</ref> provides a comparison of our neural system performance against the baseline phrase-based APE (S 1 ), baseline hierarchical phrase-based APE (S 2 ) and the original GT output. We use a, b, c, and d to indicate statistical significance over GT, S 1 , S 2 and our NNAPE system (NN), respectively. For example, the S 2 BLEU score 63.87 a,b in <ref type="table" target="#tab_10">Table 1</ref> means that the improvement provided by S 2 in BLEU is statistically significant over Google Translator and phrase-based APE. <ref type="table" target="#tab_10">Table 1</ref> shows that S 1 provides statistically significant (0.01 &lt; p &lt; 0.04) improvements over GT across all metrics. Similarly S 2 yields statistically significant (p &lt; 0.01) improvements over both GT and S 1 across all metrics. The NN system performs best and results in statistically significant (p &lt; 0.01) improvements over all other systems across all metrics. A systematic trend (N N &gt; S 2 &gt; S 1 &gt; GT ) can be observed in Table 1 and the improvements are consistent across the different metrics. The relative performance gain achieved by NN over GT is highest in TER.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>System</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Human Evaluation</head><p>Human evaluation was carried out by four professional translators, native speakers of Italian, with professional translation experience between one and two years. Since human evaluation is very costly and time consuming, it was carried out on a small portion of the test set consisting of 145 randomly sampled sentences and only compared NN with the original GT output. We used a polling scheme with three different options. Translators choose which of the two (GT or NN) outputs is the better translation or whether there is a tie ('uncertain'). To avoid any bias towards any particular system, the order in which two system outputs are presented is randomized so that the translators do not know which system they are contributing their votes to.</p><p>We analyzed the outcome of the voting process (4 translators each giving 145 votes) and found that the winning NN system received 285 (49.13%) votes compared to 99 (17.07%) votes received by the GT system, while the rest of the votes (196, 33.79%) go to the 'uncertain' option. We measured pairwise inter-annotator agreement between the translators by computing Cohen's κ coefficient <ref type="bibr">(Cohen, 1960)</ref> reported in <ref type="table" target="#tab_5">Table 2</ref>. The overall κ coefficient is 0.330. According to <ref type="bibr">(Landis and Koch, 1977)</ref>   <ref type="table" target="#tab_5">Table 2</ref>: Pairwise correlation between translators in the evaluation process.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">Analysis</head><p>The results of the automatic evaluation show that NNAPE has advantages over the phrase-based and hierarchical APE approaches. On manual inspection we found that the NNAPE system drastically reduced the preposition insertion and deletion error in Italian GT output and was also able to handle the improper use of prepositions and determiners (e.g. "states" → "dei stati", "the states" → "gli stati"). The use of a bidirectional RNN neural model makes the model sensitive towards contexts. Moreover, NNAPE captures global reordering by capturing contextual features which helps to reduce word ordering errors to some extent.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Conclusion and Future Work</head><p>The NNAPE system provides statistically significant improvements over existing state-of-theart APE models and produces significantly better translations than GT which is very difficult to beat. This enhancement in translation quality through APE should reduce human PE effort. Human evaluation revealed that the NNAPE generated PE translations contain less lexical errors, NNAPE rectifies erroneous word insertions and deletions, and improves word ordering. In future, we would like to test our system in a real-life translation scenario to analyze productivity gains in a commercial environment. We also want to extend the APE system by incorporating source language knowledge into the network and compare LSTM against GRU hidden units.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgments</head><p>We would like to thank all the anonymous reviewers for their feedback. We are also thankful to Translated SRL, Rome, Italy. They have shared their data for the experiments and enabled the manual evaluation of our system. Santanu Pal is supported by the People Programme (Marie Curie Actions) of the European </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Abstract</head><p>We address the problem of automatically cleaning a large-scale Translation Memory (TM) in a fully unsupervised fashion, i.e. without human-labelled data. We approach the task by: i) designing a set of features that capture the similarity between two text segments in different languages, ii) use them to induce reliable training labels for a subset of the translation units (TUs) contained in the TM, and iii) use the automatically labelled data to train an ensemble of binary classifiers. We apply our method to clean a test set composed of 1,000 TUs randomly extracted from the English-Italian version of MyMemory, the world's largest public TM. Our results show competitive performance not only against a strong baseline that exploits machine translation, but also against a state-of-the-art method that relies on human-labelled data.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Translation Memories (TMs) are one of the main sources of knowledge supporting human translation with the so-called Computer-assisted Translation (CAT) tools. A TM is a database that stores (source, target) segments called translation units (TUs). These segments can be sub-sentential fragments, full sentences or even paragraphs in two languages and, ideally, they are perfect translations of each other. Their use in a CAT framework is based on computing a "fuzzy match" score between an input sentence to be translated and the left-hand side (the source) of each TU stored in the TM. If the score is above a certain threshold, the right-hand side (the target) is presented to the user as a translation suggestion. When translating a document with a CAT tool, the user can store each translated (source, target) pair in the TM for future use. Each newly added TU contributes to the growth of the TM which, as time goes by, will become more and more useful to the user. Due to such constant growth, in which they evolve incorporating users style and terminology, the socalled private TMs represent an invaluable asset for individual translators and translation companies. Collaboratively-created public TMs grow in a less controlled way (e.g. incorporating potentially noisy TUs supplied by anonymous contributors or automatically extracted from the Web) but still remain a practical resource for the translators' community at large.</p><p>Together with the quantity, the quality of the stored material is a crucial factor that determines the usefulness of the TM and, all in all, its value. For this reason, the growth of the TM should go hand in hand with its continuous maintenance. This problem is usually addressed through manual (hence costly) revision, or by applying simple (hence approximate) automatic filtering routines. Advanced automatic methods for tidying up an existing TM would contribute to reduce management costs, increase its quality, speed-up and simplify the daily work of human translators.</p><p>Focusing on TM maintenance, we explore an automatic method to clean a large-scale TM by identifying the TUs in which the target is a poor translation of the source. Its main strength is the reliance on a fully unsupervised approach, which makes it independent from the availability of human-labelled data. As it allows us to avoid the burden of acquiring a (possibly large) set of annotated TUs, our method is cost-effective and highly portable across languages and TMs. This contrasts with supervised strategies like the one presented in <ref type="bibr">(Barbu, 2015)</ref> or those applied in closely-related tasks such as cross-lingual seman-   <ref type="formula" target="#formula_0">(2013)</ref> usually rely on redundancy-based approaches that reward parallel segments containing phrase pairs that are frequent in a training corpus. This idea is wellmotivated in the SMT framework but scarcely applicable in the CAT scenario, in which it is crucial to manage and reward rare phrases as a source of useful suggestions for difficult translations.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">The problem</head><p>We consider as "problematic TUs" those containing translation errors whose correction during the translation process can reduce translators' productivity. <ref type="table" target="#tab_10">Table 1</ref> provides some examples extracted from the English-Italian training data recently released for the NLP4TM 2016 shared task on cleaning translation memories. 2 As can be seen in the table, TU quality can be affected by a variety of problems. These include: 1. minor formatting errors like the casing issue in example (a), the casing+punctuation issue in (b) and the missing space in (c), 2. misspelling errors like the one in (d), <ref type="bibr" target="#b471">3</ref> 3. missing or extra words in the translation, as in (e) 1 http://alt.qcri.org/semeval2016/task1/ 2 http://rgcl.wlv.ac.uk/nlp4tm2016/shared-task/ 3 "somministARzione" instead of "somministRAzione". and (f), 4. situations in which the translation is awkward (due to mistranslations and/or untranslated terms) like in (g) or it is completely unrelated to the source sentence like in (h).</p><p>Especially in the case of collaboratively-created public TMs, these issues are rather frequent. For instance, in the NLP4TM shared task training data (randomly sampled from MyMemory) the instances affected by any of these error types are about 38% of the total.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Method</head><p>Our unsupervised TM cleaning method exploits the independent views of three groups of similarity-based features. These allow us to infer a binary label for a subset of the TUs stored in a large-scale TM. The inferred labels are used to train an ensemble of binary classifiers, specialized to capture different aspects of the general notion of translation quality. Finally, the ensemble of classifiers is used to label the rest of the TM. To minimize overfitting issues, each base classifier exploits features that are different from those used to infer the label of the training instances.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">General workflow</head><p>Given a TM to be cleaned, our approach consists of two main steps: i) label inference and ii) training of the base classifiers.</p><p>Label inference. The first step aims to infer a reliable binary label (1 or 0, respectively for "good" and "bad") for a subset Z of unlabelled TUs randomly selected from the input TM. To this aim, the three groups of features described in §3.2 (say A, B, C) are first organised into combinations of two groups (i.e. AB, AC, BC). As the features are different in nature, each combination reflects a particular "view" of the data, which is different from the other combinations.</p><p>Then, for each TU in Z, we extract the features belonging to each combination. Being designed and normalized to return a similarity score in the [0-1] interval, the result of feature extraction is a vector of numbers whose average value can be computed to sort each TU from the best (avg. close to 1, indicating a high similarity between source and target) to the worst (avg. close to 0). This is done separately for each feature combination, so that the independent views they provide will produce three different ranked lists for the TUs in Z.</p><p>Finally, the three ranked lists are processed to obtain different sets of positive/negative examples, whose variable size depends on the amount of TUs taken from the top and the bottom of the lists.</p><p>Training of the base classifiers. Each of the three inferred annotations of Z (say z 1 , z 2 , z 3 ) reflects the specific view of the two groups of features used to obtain it (i.e. AB for z 1 , AC for z 2 , BC for z 3 ). Based on each view, we train a binary classifier using the third group of features (i.e. C for z 1 , B for z 2 , A for z 3 ). This results in three base classifiers:Â,B andĈ that, in spite of the same shared purpose, are by construction different from each other. This allows us to create an ensemble of base classifiers and to minimize the risk of overfitting, in which we would have incurred by training one single classifier with the same features (A,B,C) used as labelling criterion.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Features</head><p>Our features capture different aspects of the similarity between the source and the target of a TU. The degree of similarity is mapped into a numeric score in the [0-1] interval. The full set consists of 31 features, which are organized in three groups. <ref type="bibr">4</ref> Basic features (8). This group represents a slightly improved variant of those proposed by <ref type="bibr">Barbu (2015)</ref>. They aim to capture translation quality by looking at surface aspects, such as the possible mismatches in the number of dates, numbers, URLs and XML tags present in the source and target segments. <ref type="bibr">5</ref> The consistency between the actual source and target languages and those indicated in the TM is also verified. Language identification, carried out with the Langid tool (Lui and Baldwin, 2012), is a highly predictive feature since sometimes the two languages are inverted or even completely different. Other features model the similarity between source and target by computing the direct and inverse ratio between the number of characters and words, as well as the average word length in the two segments. Finally, two features look at the presence of uncommon character or word repetitions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>QE-derived features (18)</head><p>. This group contains features borrowed from the closely-related task of MT quality estimation, in which the complexity of the source, the fluency of the target and the adequacy between source and target are modeled as quality indicators. Focusing on the adequacy aspect, we exploit a subset of the features proposed by Camargo de <ref type="bibr">Souza et al. (2013)</ref>. They use word alignment information to link source and target words and capture the quantity of meaning preserved by the translation. For each segment of a TU, word alignment information is used to calculate: i) the proportion of aligned and unaligned word n-grams (n=1,2), ii) the ratio between the longest aligned/unaligned word sequence and the length of the segment, iii) the average length of the aligned/unaligned word sequences, and iv) the position of the first/last unaligned word, normalized by the length of the segment. Word alignment models were trained on the whole TM, using MGIZA++ <ref type="bibr">(Gao and Vogel, 2008)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Word embeddings (5)</head><p>. This is a newly developed group of features that rely on cross-lingual word embeddings to identify "good" and "bad" TUs. Cross-lingual word embeddings provide a common vector representation for words in different languages and allow us to build features that look at the same time at the source and target segments. Cross-lingual word embeddings are computed using the method proposed in . Differently from the original paper, which takes advantage of bilingual documents as atomic concepts to bridge the two languages, we use the TUs contained in the whole TM to build the embeddings. Given a TU and a 100-dimensional vector representation of each word in the source and target segments, the new features are: i) the cosine similarity between source and target segment vectors obtained by averaging (or using the median) the source and target word vectors; ii) the average embedding alignment score obtained by computing the cosine similarity between each source word and all the target words and averaging over the largest cosine score of each source word; iii) the average cosine similarity between source/target word alignments; iv) a score that merges features (ii) and (iii) by complementing word alignments (obtained using MGIZA++) with the alignments obtained from word embedding and averaging all the alignment weights.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Experiments</head><p>Data. We experiment with the English-Italian version of MyMemory, 6 the world's largest public TM. This collaboratively built TM contains about 11M TUs coming from heterogeneous sources: aggregated private TMs or automatically extracted from the web/corpora, and anonymous contributions of (source, target) bi-segments. Being large and free, the TM is of great utility for professional translators. Its uncontrolled sources, however, call for accurate cleaning methods (e.g. to make it more accurate, smaller and manageable). From the TM we randomly extracted: i) subsets of variable size to automatically obtain training data for the base classifiers and ii) a collection of 2,500 TUs manually annotated with binary labels. Data annotation was done by two Italian native speakers properly trained with the same guidelines prepared by the TM owner for periodic manual revisions. After agreement computation (Cohen's kappa is 0.7838), a reconciliation ended up with about 65% positive and 35% negative examples. This pool is randomly split in two parts. One (1,000 instances) is used as test set for our evaluation. The other (1,500 instances) is used to replicate the approach of Barbu (2015) used as term of comparison.</p><p>Learning algorithm. Our base classifiers are trained with the Extremely Randomized Trees algorithm <ref type="bibr">(Geurts et al., 2006)</ref>, optimized using 10-fold cross-validation in a randomized search process and combined in a majority voting schema.</p><p>Evaluation metric. To handle the imbalanced (65%-35%) data distribution, and equally reward the correct classification on both classes, we evaluate performance in terms of balanced accuracy 6 https://mymemory.translated.net/ (BA), computed as the average of the accuracies on the two classes <ref type="bibr">(Brodersen et al., 2010)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Terms of comparison.</head><p>We evaluate our approach against two terms of comparison, both stronger than the trivial random baseline achieving a BA of 50.0%. The first competitor (MT-based) is a translation-based solution that exploits Bing translator 7 to render the source segment of a TU in the same language of the target. Then, the similarity between the translated source and the target segment is measured in terms of Translation Edit Rate (TER <ref type="bibr" target="#b288">(Snover et al., 2006)</ref>). The TU is marked as "good" if the TER is smaller than 0.4 ("bad" otherwise). This value is chosen based on the findings of <ref type="bibr">Turchi et al. (2013)</ref>, which suggests that only for TER values lower than 0.4 human translators consider MT suggestions as good enough for being post-editable. In our scenario we hence assume that "good" TUs are those featuring a small TER distance between the target and an automatic translation of the source.</p><p>The second competitor (Barbu15) is the supervised approach proposed by <ref type="bibr">Barbu (2015)</ref>, which leverages human-labelled data to train an SVM binary classifier. To the best of our knowledge, it represents the state-of-the-art in this task. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Results and Discussion</head><p>The result of the "label inference" step described in §3.1 is a set of automatically labelled TUs to train the base classifiers. Positive and negative examples are respectively the top and the bottom k elements extracted from a list of TUs (of size Z) ranked according to the inferred similarity between source and target. In this process, the size 7 https://www.bing.com/translator/ 290 of the list and the value of k clearly have influence on the separability between the training instances belonging to the two classes. Long lists and small values of k will result in highly polarized training data, with a very high similarity between the instances assigned to each class and feature values respectively close to 1 and 0. Vice-versa, short lists and large values of k will result in less separable training data, with higher variability in the points assigned to each class and in the respective feature values. In light of this trade-off, we analyse performance variations as a function of: i) the amount (Z) of data considered to initialise the label inference step, and ii) the amount (k) of training instances used to learn the base classifiers. For the first dimension, we consider four values: 50K (a value compatible with the size of most of the existing TMs), 100K, 500K and 1M units (a value compatible only with a handful of largescale TMs). For the second dimension we experiment with four balanced training sets, respectively containing: 1.5K (the same amount used in (Barbu, 2015)), 5K, 10K and 15K instances. <ref type="figure" target="#fig_3">Figure 1</ref> illustrates the performance of our TM cleaning method for different values of Z and k. Each of the four dashed learning curves refers to one of the four chosen values of Z. BA variations for the same line are obtained by increasing the number of training instances k and averaging over three random samples of size Z. As can be seen from the figure, the results obtained by our classifiers trained with the inferred data always outperform the MT-based system and, in one case (Z=50K, k=15K), also the Barbu15 classifier trained with human labelled data. <ref type="bibr">8</ref> Considering that all our training data are collected without any human intervention, hence eliminating the burden and the high costs of the annotation process, this is an interesting result.</p><p>Overall, for the same value of k, smaller values of Z consistently show higher performance. At the same time, for the same value of Z, increasing k consistently yields higher results. Such improvements, however, are less evident when the pool of TUs used for the label inference step is larger (Z&gt;100K). These observations confirm the intuition that classifiers' performance is highly influenced by the relation between the amount and the polarization of the training data. Indeed, looking 8 Improvements are statistically significant with ρ &lt; 0.05, measured by approximate randomization <ref type="bibr">(Noreen, 1989).</ref> at the average feature values used to infer the positive and negative instances, we noticed that, for the considered values of k, these scores are closer to 0 and 1 for the 1M curve than for the 50K curve. In the former case, highly polarized training data limit the generalisation capability of the base classifiers (and their ability, for instance, to correctly label the borderline test instances), which results in lower BA results.</p><p>Nevertheless, it's worth remarking that our larger value of k (15K) represents 30% of the data in the case of Z=50K, but just 1.5% of the data in case of Z=1M. This suggests that for large values of Z, more training points would be probably needed to introduce enough variance in the data and improve over the almost flat curves shown in <ref type="figure" target="#fig_3">Figure 1</ref>. Exploring this possibility was out of the scope of this initial analysis but would be doable by applying scalable algorithms capable to manage larger quantities of training data (up to 300K, in the case of Z=1M). For the time being, a statistically significant improvement of ∼1 BA point over a supervised method in the most normal conditions (Z=50K) is already a promising step.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Conclusion</head><p>We presented a fully unsupervised method to remove useless TUs from a large-scale TM. Focusing on the identification of wrongly translated segments, we exploited the independent views of different sets of features to: i) infer a binary label for a certain amount of TUs, and ii) use the automatically labelled units as training data for an ensemble of binary classifiers. Such independent labelling/training routines exploit the "wisdom of the features" to bypass the need of human annotations and obtain competitive performance. Our results are not only better than a strong MT-based baseline, but they also outperform a state-of-theart approach relying on human-labelled data. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Neural network models have recently gained much attention in research on statistical machine translation. Several groups have reported strong improvements over state-of-the-art baselines when combining phrase-based translation with feedforward neural network-based models (FFNN) <ref type="bibr">(Schwenk et al., 2006;</ref><ref type="bibr">Vaswani et al., 2013;</ref><ref type="bibr">Schwenk, 2012;</ref><ref type="bibr">Devlin et al., 2014)</ref>, as well as with recurrent neural network models (RNN) <ref type="bibr">(Sundermeyer et al., 2014)</ref>. Even in alternative translation systems they showed remarkable performance <ref type="bibr" target="#b80">Bahdanau et al., 2015)</ref>. The main drawback of a feed-forward neural network model compared to a recurrent neural network model is that it can only have a limited context length on source and target sides. Using the Bag-of-Words (BoW) model as additional input of a neural network based language model, <ref type="bibr" target="#b384">(Mikolov et al., 2015)</ref> have achieved very similar perplexities on automatic speech recognition tasks in comparison to the long short-term memory (LSTM) neural network, whose structure is much more complex. This suggests that the bagof-words model can effectively store the longer term contextual information, which could show improvements in statistical machine translation as well. Since the bag-of-words representation can cover as many contextual words without further modifying the network structure, the problem of limited context window size of feed-forward neural networks is reduced. Instead of predefining fixed decay rates for the exponentially decaying bag-of-words models, we propose to learn the decay rates from the training data like other weight parameters in the neural network model.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">The Bag-of-Words Input Features</head><p>The bag-of-words model is a simplifying representation applied in natural language processing. In this model, each sentence is represented as the set of its words disregarding the word order. Bagof-words models are used as additional input features to feed-forward neural networks in addition to the one-hot encoding. Thus, the probability of the feed-forward neural network translation model with an m-word source window can be written as:</p><formula xml:id="formula_144">p(e I 1 | f J 1 ) ≈ I i=1 p(e i | f b i +∆m b i −∆m , f BoW,i )<label>(1)</label></formula><p>where ∆ m = m−1 2 and b i is the index of the single aligned source word to the target word e i . We applied the affiliation technique proposed in <ref type="bibr">(Devlin et al., 2014)</ref> for obtaining the one-to-one align-ments. The bag-of-words input features f BoW,i can be seen as normalized n-of-N vectors as demonstrated in <ref type="figure" target="#fig_3">Figure 1</ref>, where n is the number of words inside each bag-of-words. We omit the hidden and output layers for simplification, since they remain unchanged.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Contents of Bag-of-Words Features</head><p>Before utilizing the bag-of-words input features we have to decide which words should be part of it. We tested multiple different variants:</p><p>1. Collecting all words of the sentence in one bagof-words except the currently aligned word.</p><p>2. Collecting all preceding words in one bag-ofwords and all succeeding words in a second bag-of-words.</p><p>3. Collecting all preceding words in one bag-ofwords and all succeeding words in a second bag-of-words except those already included in the source window.</p><p>All of these variants provide the feed-forward neural network with an unlimited context in both directions. The differences between these setups only varied by 0.2% BLEU and 0.1% TER. We choose to base further experiments on the last variant since it performed best and seemed to be the most logical choice for us.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Exponentially Decaying Bag-of-Words</head><p>Another variant is to weight the words within the bag-of-words model. In the standard bagof-words representation these weights are equally distributed for all words. This means the bag-ofwords input is a vector which marks if a word is given or not and does not encode the word order. To avoid this problem, the exponential decay approach proposed in (Clarkson and Robinson, 1997) has been adopted to express the distance of contextual words from the current word. Therefore the bag-of-words vector with decay weights can be defined as following:</p><formula xml:id="formula_145">f BoW,i = k∈S BoW d |i−k|f k<label>(2)</label></formula><p>where i, k Positions of the current word and words within the BoW model respectively.</p><p>f BoW,i The value vector of the BoW input feature for the i-th word in the sentence.</p><p>f k One-hot encoded feature vector of the kth word in the sentence.</p><p>S BoW Indices set of the words contained in the BoW. If a word appears more than once in the BoW, the index of the nearest one to the current word will be selected.</p><p>d Decay rate with float value ranging from zero to one. It specifies how fast weights of contextual words decay along with distances, which can be learned like other weight parameters of the neural network.</p><p>Instead of using fixed decay rate as in <ref type="bibr">(Irie et al., 2015)</ref>, we propose to train the decay rate like other weight parameters in the neural network. The approach presented by <ref type="bibr" target="#b384">(Mikolov et al., 2015)</ref> is comparable to the corpus decay rate shown here, except that their work makes use of a diagonal matrix instead of a scalar as decay rate. In our experiments, three different kinds of decay rates are trained and applied:</p><p>1. Corpus decay rate: all words in vocabulary share the same decay rate.</p><p>2. Individual decay rate for each bag-of-words: each bag-of-words has its own decay rate given the aligned word.</p><p>3. Individual decay rate for each word: each word uses its own decay rate.</p><p>We use the English sentence "friends had been talking about this fish for a long time"</p><p>as an example to clarify the differences between these variants. A five words contextual window centered at the current aligned word fish has been applied: {about, this, fish, for, a}.  <ref type="bibr" target="#b91">Och, 2003)</ref> with BLEU as optimization criterion on the development sets. The systems are evaluated using MultEval <ref type="bibr" target="#b71">(Clark et al., 2011)</ref>. In the experiments the maximum size of the n-best lists applied for reranking is 500. For the translation experiments, the averaged scores are presented on the development set from three optimization runs. Experiments are performed using the Jane toolkit <ref type="bibr">(Vilar et al., 2010;</ref><ref type="bibr">Wuebker et al., 2012)</ref> with a log-linear framework containing following feature functions:</p><p>• Phrase translation probabilities both directions</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>• Word lexicon features in both directions</head><p>• Enhanced low frequency counts <ref type="bibr">(Chen et al., 2011)</ref> • 4-gram language model</p><p>• 7-gram word class language model (Wuebker et al., 2013)</p><p>• Word and phrase penalties</p><p>• Hierarchical reordering model <ref type="bibr" target="#b308">(Galley and Manning, 2008)</ref> Additionally, a neural network translation model, similar to <ref type="bibr">(Devlin et al., 2014)</ref>, with following configurations is applied for reranking the n-best lists:</p><p>• Projection layer size 100 for each word</p><p>• Two non-linear hidden layers with 1000 and 500 nodes respectively</p><p>• Short-list size 10000 along with 1000 word classes at the output layer</p><p>• 5 one-hot input vectors of words Unless otherwise stated, the investigations on bagof-words input features are based on this neural network model. We also integrated our neural network translation model into the decoder as proposed in <ref type="bibr">(Devlin et al., 2014)</ref>. The relative improvements provided by integrated decoding and reranking are quite similar, which can also be confirmed by <ref type="bibr">(Alkhouli et al., 2015)</ref>. We therefore decided to only work in reranking for repeated experimentation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Exponentially Decaying Bag-of-Words</head><p>As shown in Section 2.2, the exponential decay approach is applied to express the distance of contextual words from the current word. Thereby the information of sequence order can be included into bag-of-words models. We demonstrated three different kinds of decay rates for words in the bagof-words input feature, namely the corpus general decay rate, the bag-of-words individual decay rate and the word individual decay rate.  <ref type="table" target="#tab_10">Table 1</ref>: Experimental results of translations using exponentially decaying bag-of-words models with different kinds of decay rates. Improvements by systems marked by * have a 95% statistical significance from the baseline system, whereas † denotes the 95% statistical significant improvements with respect to the BoW Features system (without decay weights). We experimented with several values for the fixed decay rate (DR) and 0.9 performed best. The applied RNN model is the LSTM bidirectional translation model proposed in <ref type="bibr">(Sundermeyer et al., 2014)</ref>.</p><p>translation tasks. Here we applied two bag-ofwords models to separately contain the preceding and succeeding words outside the context window. We can see that the bag-of-words feature without exponential decay weights only provides small improvements. After appending the decay weights, four different kinds of decay rates provide further improvements to varying degrees. The bag-of-words individual decay rate performs the best, which gives us improvements by up to 0.5% on BLEU and up to 0.6% on TER. On these tasks, these improvements even help the feedforward neural network achieve a similar performance to the popular long short-term memory recurrent neural network model <ref type="bibr">(Sundermeyer et al., 2014)</ref>, which contains three LSTM layers with 200 nodes each. The results of the word individual decay rate are worse than that of the bag-of-words decay rate. One reason is that in word individual case, the sequence order can still be missing. We initialize all values for the tunable decay rates with 0.9. In the IWSLT 2013 German→English task, the corpus decay rate is tuned to 0.578. When investigating the values of the trained bag-of-words individual decay rate vector, we noticed that the variance of the value for frequent words is much lower than for rare words. We also observed that most function words, such as prepositions and conjunctions, are assigned low decay rates. We could not find a pattern for the trained value vector of the word individual decay rates.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Comparison between Bag-of-Words and Large Context Window</head><p>The main motivation behind the usage of the bagof-words input features is to provide the model with additional context information. We compared the bag-of-words input features to different source side windows to refute the argument that simply increasing the size of the window could achieve the same results. Our experiments showed that increasing the source side window beyond 11 gave no more improvements while the model that used the bag-of-words input features is able to achieve the best result <ref type="figure" target="#fig_8">(Figure 2)</ref>. A possible explanation for this could be that the feed-forward neural network learns its input position-dependent. If one source word is moved by one position the feedforward neural network needs to have seen a word with a similar word vector at this position during training to interpret it correctly. The likelihood of precisely getting the position decreases with a larger distance. The bag-of-words model on the other hand will still get the same input only slightly stronger or weaker on the new distance and decay rate.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Conclusion</head><p>The aim of this work was to investigate the influence of exponentially decaying bag-of-words input features with trained decay rates on the feedforward neural network translation model. Applying the standard bag-of-words model as an additional input feature in our feed-forward neural network translation model only yields slight im- The change of BLEU scores on the eval11 set of the IWSLT 2013 German→English task along with the source context window size. The source windows are always symmetrical with respect to the aligned word. For instance, window size five denotes that two preceding and two succeeding words along with the aligned word are included in the window. The average sentence length of the corpus is about 18 words. The red line is the result of using a model with bag-of-words input features and a bag-of-words individual decay rate.</p><p>provements, since the original bag-of-words representation does not include information about the ordering of each word. To avoid this problem, we applied the exponential decay weight to express the distances between words and propose to train the decay rate as other weight parameters of the network. Three different kinds of decay rates are proposed, the bag-of-words individual decay rate performs best and provides improvements by averagely 0.5% BLEU on three different translation tasks, which is even able to outperform a bidirectional LSTM translation model on the given tasks. By contrast, applying additional one-hot encoded input vectors or enlarging the network structure can not achieve such good performances as bagof-words features. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>We report on investigations motivated by the idea that the structured search spaces defined by syntactic machine translation approaches such as <ref type="bibr">Hiero (Chiang, 2007)</ref> can be used to guide Neural Machine Translation (NMT) <ref type="bibr" target="#b89">(Kalchbrenner and Blunsom, 2013;</ref><ref type="bibr" target="#b80">Bahdanau et al., 2015)</ref>. NMT and Hiero have complementary strengths and weaknesses and differ markedly in how they define probability distributions over translations and what search procedures they use. The NMT encoder-decoder formalism provides a probability distribution over translations y = y T 1 of a source sentence x as <ref type="bibr" target="#b80">(Bahdanau et al., 2015)</ref> P (y</p><formula xml:id="formula_146">T 1 |x) = T t=1 P (y t |y t−1 1 , x) = T t=1 g(y t−1 , s t , c t )</formula><p>(1) where s t = f (s t−1 , y t−1 , c t ) is a decoder state variable and c t is a context vector depending on the source sentence and the attention mechanism.</p><p>This posterior distribution is potentially very powerful, however it does not easily lend itself to sophisticated search procedures. Decoding is done by 'beam search to find a translation that approximately maximizes the conditional probability' <ref type="bibr" target="#b80">(Bahdanau et al., 2015)</ref>. Search looks only one word ahead and no deeper than the beam.</p><p>Hiero defines a synchronous context-free grammar (SCFG) with rules: X → α, γ , where α and γ are strings of terminals and non-terminals in the source and target languages. A target language sentence y can be a translation of a source language sentence x if there is a derivation D in the grammar which yields both y and </p><formula xml:id="formula_147">y = y    argmax D:x(D)=x P G (D)P LM (y(D)) λ LM S(D)    (2)</formula><p>where P LM is an n-gram language model and</p><formula xml:id="formula_148">P G (D) ∝ (X→ γ,α )∈D i φ i (X → γ, α ) λ i .</formula><p>Hiero decoders attempt to avoid search errors when combining the translation and language model for the translation hypotheses <ref type="bibr">(Chiang, 2007;</ref><ref type="bibr">Iglesias et al., 2009</ref>). These procedures search over a vast space of translations, much larger than is considered by the NMT beam search. However the Hiero context-free grammars that make efficient search possible are weak models of translation. The basic Hiero formalism can be extended through 'soft syntactic constraints' <ref type="bibr">(Venugopal et al., 2009;</ref><ref type="bibr">Marton and Resnik, 2008)</ref> or by adding very high dimensional features <ref type="bibr">(Chiang et al., 2009)</ref>, however the translation score assigned by the grammar is still only the product of probabilities of individual rules. From the modelling perspective, this is an overly strong conditional independence assumption. NMT clearly has the potential advantage in incorporating long-term context into translation scores.</p><p>NMT and Hiero differ in how they 'consume' source words. Hiero applies the translation rules to the source sentence via the CYK algorithm, with each derivation yielding a complete and unambiguous translation of the source words. The NMT beam decoder does not have an explicit mechanism for tracking source coverage, and there is evidence that may lead to both 'over-translation <ref type="bibr">' and 'under-translation' (Tu et al., 2016)</ref>.</p><p>NMT and Hiero also differ in their internal representations. The NMT continuous representation captures morphological, syntactic and semantic similarity <ref type="bibr">(Collobert and Weston, 2008</ref>) across words and phrases. However, extending these representations to the large vocabularies needed for open-domain MT is an open area of research <ref type="bibr">(Jean et al., 2015a;</ref><ref type="bibr">Luong et al., 2015;</ref><ref type="bibr" target="#b98">Sennrich et al., 2015;</ref><ref type="bibr">Chitnis and DeNero, 2015)</ref>. By contrast, Hiero (and other symbolic systems) can easily use translation grammars and language models with very large vocabularies <ref type="bibr" target="#b15">(Heafield et al., 2013;</ref><ref type="bibr">Lin and Dyer, 2010)</ref>. Moreover, words and phrases can be easily added to a fully-trained symbolic MT system. This is an important consideration for commercial MT, as customers often wish to customise and personalise SMT systems for their own application domain. Adding new words and phrases to an NMT system is not as straightforward, and it is not clear that the advantages of the continuous representation can be extended to the new additions to the vocabularies.</p><p>NMT has the advantage of including long-range context in modelling individual translation hypotheses. Hiero considers a much bigger search space, and can incorporate n-gram language models, but a much weaker translation model. In this paper we try to exploit the strengths of each approach. We propose to guide NMT decoding using Hiero. We show that restricting the search space of the NMT decoder to a subset of Y spanned by Hiero effectively counteracts NMT modelling errors. This can be implemented by generating translation lattices with Hiero, which are then rescored by the NMT decoder. Our approach addresses the limited vocabulary issue in NMT as we replace NMT OOVs with lattice words from the much larger Hiero vocabulary. We also find good gains from neural and Kneser-Ney n-gram language models.</p><p>2 Syntactically Guided NMT (SGNMT)</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Hiero Predictive Posteriors</head><p>The Hiero decoder generates translation hypotheses as weighted finite state acceptors (WFSAs), or lattices, with weights in the tropical semiring. For a translation hypothesis y(D) arising from the Hiero derivation D, the path weight in the WFSA is − log S(D), after Eq. 2. While this representation is correct with respect to the Hiero translation grammar and language model scores, having Hiero scores at the path level is not convenient for working with the NMT system. What we need are predictive probabilities in the form of Eq. 1.</p><p>The Hiero WFSAs are determinised and minimised with epsilon removal under the tropical semiring, and weights are pushed towards the initial state under the log semiring (Mohri and Riley, 2001). The resulting transducer is stochastic in the log semiring, i.e. the log sum of the arc log probabilities leaving a state is 0 (= log 1). In addition, because the WFSA is deterministic, there is a unique path leading to every state, which corresponds to a unique Hiero translation prefix. Suppose a path to a state accepts the translation prefix y t−1</p><p>1 . An outgoing arc from that state with symbol y has a weight that corresponds to the (negative log of the) conditional probability</p><formula xml:id="formula_149">P Hiero (y t = y|y t−1 1 , x).<label>(3)</label></formula><p>This conditional probability is such that for a Hiero translation y T 1 = y(D) accepted by the WFSA</p><formula xml:id="formula_150">P Hiero (y T 1 ) = T t=1 P Hiero (y t |y t−1 1 , x) ∝ S(D).</formula><p>(4) The Hiero WFSAs have been transformed so that their arc weights have the negative log of the conditional probabilities defined in Eq. 3. All the probability mass of this distribution is concentrated on the Hiero translation hypotheses. The complete translation and language model scores computed over the entire Hiero translations are pushed as far forward in the WFSAs as possible. This is commonly done for left-to-right decoding in speech recognition <ref type="bibr">(Mohri et al., 2002)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">NMT-Hiero Decoding</head><p>As above, suppose a path to a state in the WFSA accepts a Hiero translation prefix y t−1 1 , and let y t be a symbol on an outgoing arc from that state. We define the joint NMT+Hiero score as log P (y t |y t−1 1 , x) = λ Hiero log P Hiero (y t |y</p><formula xml:id="formula_151">t−1 1 , x) + λ N M T log P N M T (y t |y t−1 1 , x) y t ∈ Σ N M T log P N M T (unk|y t−1 1 , x) y t ∈ Σ N M T<label>(5)</label></formula><p>Note that the NMT-HIERO decoder only considers hypotheses in the Hiero lattice. As discussed earlier, the Hiero vocabulary can be much larger than the NMT output vocabulary Σ N M T . If a Hiero translation contains a word not in the NMT vocabulary, the NMT model provides a score and updates its decoder state as for an unknown word.</p><p>Our decoding algorithm is a natural extension of beam search decoding for NMT. Due to the form of Eq. 5 we can build up hypotheses from left-toright on the target side. Thus, we can represent a partial hypothesis h = (y t 1 , h s ) by a translation prefix y t 1 and an accumulated score h s . At each iteration we extend the current hypotheses by one target token, until the best scoring hypothesis reaches a final state of the Hiero lattice. We refer to this step as node expansion, and in Sec. 3.1 we report the number of node expansions per sentence, as an indication of computational cost.</p><p>We can think of the decoding algorithm as breath-first search through the translation lattices with a limited number of active hypotheses (a beam). Rescoring is done on-the-fly: as the decoder traverses an edge in the WFSA, we update its weight by Eq. 5. The output-synchronous char- acteristic of beam search enables us to compute the NMT posteriors only once for each history based on previous calculations. Alternatively, we can think of the algorithm as NMT decoding with revised posterior probabilities: instead of selecting the most likely symbol y t according the NMT model, we adjust the NMT posterior with the Hiero posterior scores and delete NMT entries that are not allowed by the lattice. This may result in NMT choosing a different symbol, which is then fed back to the neural network for the next decoding step.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Experimental Evaluation</head><p>We evaluate SGNMT on the WMT news-test2014 test sets (the filtered version) for English-German (En-De) and English-French (En-Fr). We also report results on WMT news-test2015 En-De.</p><p>The En-De training set includes Europarl v7, Common Crawl, and News Commentary v10. Sentence pairs with sentences longer than 80 words or length ratios exceeding 2.4:1 were deleted, as were Common Crawl sentences from other languages (Shuyo, 2010). The En-Fr NMT system was trained on preprocessed data (Schwenk, 2014) used by previous work <ref type="bibr" target="#b80">Bahdanau et al., 2015;</ref><ref type="bibr">Jean et al., 2015a)</ref>, but with truecasing like our Hiero baseline. Following <ref type="bibr">(Jean et al., 2015a)</ref>, we use news-test2012 and news-test2013 as a development set. The NMT vocabulary size is 50k for En-De and 30k for En-Fr, taken as the most frequent words in training <ref type="bibr">(Jean et al., 2015a)</ref>. Tab. 1 provides statistics and shows the severity of the OOV problem for NMT.</p><p>The BASIC NMT system is built using the Blocks framework <ref type="bibr">(van Merriënboer et al., 2015)</ref> based on the Theano library (Bastien et al., 2012) with standard hyper-parameters <ref type="bibr" target="#b80">(Bahdanau et al., 2015)</ref>: the encoder and decoder networks consist of 1000 gated recurrent units . The decoder uses a single maxout <ref type="bibr" target="#b643">(Goodfellow et al., 2013)</ref> output layer with the feed-forward attention model <ref type="bibr" target="#b80">(Bahdanau et al., 2015)</ref>.</p><p>The En-De Hiero system uses rules which encourage verb movement <ref type="bibr">(de Gispert et al., 2010)</ref>. The rules for En-Fr were extracted from the full data set available at the WMT'15 website using a shallow-1 grammar <ref type="bibr">(de Gispert et al., 2010)</ref>. 5-gram Kneser-Ney language models (KN-LM) for the Hiero systems were trained on WMT'15 parallel and monolingual data <ref type="bibr" target="#b15">(Heafield et al., 2013)</ref>. <ref type="bibr">(Jean et al., 2015a, Tab.</ref>    <ref type="table" target="#tab_6">Table 3</ref>: BLEU English-German news-test2015 scores calculated with mteval-v13a.pl.</p><p>Our SGNMT system 1 is built with the Pyfst interface 2 to OpenFst (Allauzen et al., 2007).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">SGNMT Performance</head><p>Tab. 2 compares our combined NMT+Hiero decoding with NMT results in the literature. We use a beam size of 12. In En-De and in En-Fr, we find that our BASIC NMT system performs similarly (within 0.5 BLEU) to previously published results <ref type="bibr">(16.31 vs. 16.46 and 30.42 vs. 29.97</ref>). In NMT-HIERO, decoding is as described in Sec. 2.2, but with λ Hiero = 0. The decoder searches through the Hiero lattice, ignoring the Hiero scores, but using Hiero word hypotheses in place of any UNKs that might have been produced by NMT. The results show that NMT-HIERO is much more effective in fixing NMT OOVs than the 'UNK Replace' technique <ref type="bibr">(Luong et al., 2015)</ref>; this holds in both En-De and En-Fr.</p><p>For the NMT-HIERO+TUNING systems, lattice MERT <ref type="bibr">(Macherey et al., 2008</ref>) is used to optimise λ Hiero and λ N M T on the tuning sets. This yields further gains in both En-Fr and En-De, suggesting that in addition to fixing UNKs, the Hiero predictive posteriors can be used to improve the NMT translation model scores.</p><p>Tab. 3 reports results of our En-De system with reshuffling and tuning on news-test2015. BLEU scores are directly comparable to WMT'15 results <ref type="bibr" target="#b471">3</ref> . By comparing row 3 to row 10, we see that constraining NMT to the search space defined by the Hiero lattices yields an improvement of +0.8 BLEU for single NMT. If we allow Hiero to fix NMT UNKs, we see a further +2.7 BLEU gain (row 11). The majority of gains come from fixing UNKs, but there is still improvement from the constrained search space for single NMT.</p><p>We next investigate the contribution of the Hiero system scores. We see that, once lattices are generated, the KN-LM contributes more to rescoring than the Hiero grammar scores (rows 12-14). Further gains can be achieved by adding a feed-forward neural language model with NPLM (Vaswani et al., 2013) (row 15). We observe that n-best list rescoring with NMT (Neubig et al., 2015) also outperforms both the Hiero and NMT   baselines, although lattice rescoring gives the best results (row 9 vs. row 15). Lattice rescoring with SGNMT also uses far fewer node expansions per sentence. We report n-best rescoring speeds for rescoring each hypothesis separately, and a depthfirst (DFS) scheme that efficiently traverses the nbest lists. Both these techniques are very slow compared to lattice rescoring. <ref type="figure" target="#fig_3">Fig. 1</ref> shows that we can reduce the beam size from 12 to 5 with only a minor drop in BLEU. This is nearly 100 times faster than DFS over the 1000-best list.</p><p>Cost of Lattice Preprocessing As described in Sec. 2.1, we applied determinisation, minimisation, and weight pushing to the Hiero lattices in order to work with probabilities. Tab. 4 shows that those operations are generally fast 4 .</p><p>Lattice Size For previous experiments we set the Hiero pruning parameters such that lattices had 8,510 nodes on average. <ref type="figure" target="#fig_8">Fig. 2</ref> plots the BLEU score over the lattice size. We find that SGNMT works well on lattices of moderate or large size, but pruning lattices too heavily has a negative effect as they are then too similar to Hiero first best hypotheses. We note that lattice rescoring involves nearly as many node expansions as unconstrained NMT decoding. This confirms that the lattices at 8,510 nodes are already large enough for SGNMT. Local Softmax In SGNMT decoding we have the option of normalising the NMT translation probabilities over the words on outgoing words from each state rather than over the full 50,000 words translation vocabulary. There are ∼4.5 arcs per state in our En-De'14 lattices, and so avoiding the full softmax could cause significant computational savings. We find this leads to only a modest 0.5 BLEU degradation: 21.45 BLEU in En-De'14, compared to 21.87 BLEU using NMT probabilities computed over the full vocabulary.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Modelling Errors vs. Search Errors In our En-</head><p>De'14 experiments with λ Hiero = 0 we find that constraining the NMT decoder to the Hiero lattices yields translation hypotheses with much lower NMT probabilities than unconstrained BA-SIC NMT decoding: under the NMT model, NMT hypotheses are 8,300 times more likely (median) than NMT-HIERO hypotheses. We conclude (tentatively) that BASIC NMT is not suffering only from search errors, but rather that NMT-HIERO discards some hypotheses ranked highly by the NMT model but lower in the evaluation metric.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Conclusion</head><p>We have demonstrated a viable approach to Syntactically Guided Neural Machine Translation formulated to exploit the rich, structured search space generated by Hiero and the long-context translation scores of NMT. SGNMT does not suffer from the severe limitation in vocabulary size of basic NMT and avoids any difficulty of extending distributed word representations to new vocabulary items not seen in training data. Very quaffable and great fun: Applying NLP to wine reviews </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Abstract</head><p>We automatically predict properties of wines on the basis of smell and flavor descriptions from experts' wine reviews. We show wine experts are capable of describing their smell and flavor experiences in wine reviews in a sufficiently consistent manner, such that we can use their descriptions to predict properties of a wine based solely on language. The experimental results show promising F-scores when using lexical and semantic information to predict the color, grape variety, country of origin, and price of a wine. This demonstrates, contrary to popular opinion, that wine experts' reviews really are informative.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Describing smells and flavors is something the average person is not particularly good at. If people are asked to identify familiar smells such as cinnamon and chocolate, they are only able to correctly name the smell around 50% of the time <ref type="bibr">(Cain, 1979;</ref><ref type="bibr">Olofsson and Gottfried, 2015)</ref>. In comparison to the elaborate vocabulary we have for visual and auditory phenomena, English and other languages spoken in Western societies appear to have few words to describe smells and flavors <ref type="bibr">(Levinson and Majid, 2014;</ref><ref type="bibr">Majid and Burenhult, 2014)</ref>. Instead, speakers often refer to the source as the name of the smell ('it smells like banana').</p><p>Flavor is a complex experience that combines the multisensory sensations of taste, touch and smell. Flavor descriptions contain basic taste descriptors (e.g., sweet, sour, salty, bitter), with metaphorical (e.g., 'elegant') and source-based terminology (e.g., 'it tastes buttery').</p><p>The lack of vocabulary for smells and flavors contrasts starkly with the interest people in the West have for flavors and fragrances, and what they are willing to spend on such products. The flavor and fragrance industry is estimated to be worth over $20 billion in 2015 1 . In this context, experts' recommendations are used by the public in order to help them make decisions about purchases. But are the expert recommendations meaningful, given the limitations of language for smells and flavors?</p><p>We are interested in the relation between language and sensory information, and how this information is put into words. We focus on descriptions produced by a select group of people who have considerable experience naming smells and flavors, i.e., sommeliers and wine journalists. Through their descriptions, wine experts can influence consumers' purchasing patterns <ref type="bibr">(McCoy, 2006;</ref><ref type="bibr">Horverak, 2009</ref>), suggesting their descriptions are written in an informative manner. In this paper we aim to discover whether we can extract the properties of a wine based on the tasting notes written by a wine expert. This should be possible if wine experts are capable of translating their sensory experiences into words in a consistent manner.</p><p>Previous experimental studies provide a mixed picture as to whether wine experts' language is consistent. Some studies find similar levels of agreement in smell descriptions generated by wine experts and those generated by novices <ref type="bibr">(Lawless, 1984;</ref><ref type="bibr">Parr et al., 2002)</ref>, and wine experts use more metaphorical descriptions to describe wine (Caballero and Suárez-Toste, 2010; Paradis and EegOlofsson, 2013), which potentially are not as informative about properties of the wine itself. In contrast, others find wine experts use more specific vocabulary <ref type="bibr">(Zucco et al., 2011;</ref><ref type="bibr">Sezille et al., 2014)</ref>, and find that wine experts are, in fact, more consistent than non-experts, when they describe wines <ref type="bibr">(Croijmans and Majid, 2016)</ref>.</p><p>We examined the following wine properties and aimed to predict these solely on the basis of the review content: color, grape variety, price, and country of origin. The outcomes of this investigation are interesting for two reasons. First, we test the ability of experts to review wines with consistent language using naturalistic materials. Most previous studies about wine experts and their reviewing consistency are performed in experimental settings and cover some dozens of wine reviews (see for example <ref type="bibr">(Gawel and Godden, 2008;</ref><ref type="bibr">Hopfer and Heymann, 2014)</ref>). With automatic analysis we are able to scale up to a much larger and more representative set of reviews.</p><p>Second, we gather new insights into the specific vocabulary and type of lexical descriptors used to describe smells and flavors, and what words are most distinctive for different wine characteristics. Market analyses <ref type="bibr">(Vigar-Ellis et al., 2015)</ref> show that consumers increasingly select wines based on information provided by experts, for example through expert descriptions and recommender systems, and that wine apps become ever more popular. This is a positive development, as research suggests that informed consumers are able to benefit more from the loose relationship between price and quality in wine <ref type="bibr">(Oczkowski and Doucouliagos, 2014)</ref>.</p><p>In the long run, as we are training automatic systems to predict wine properties, we could use such systems for automatic metadata prediction and error correction in wine review databases. These systems are also a first step towards a recommender system for wines based on review content and flavor descriptions. Current recommender systems such as the mobile apps Vivino 2 or Delectable 3 work with metadata and user-based filtering, i.e. the principle of 'other users also bought . . .'. So there is potential here for contentbased recommender systems to be developed. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Related work</head><p>The relationship between wines and wine reviews has been studied from many different perspectives, aside from those discussed in the previous section. Economically, the relationship between price, wine quality and wine ratings is interesting as a high rating by a famous wine expert can make a substantial difference to product sales <ref type="bibr">(McCoy, 2006)</ref>. Goldstein and colleagues <ref type="formula" target="#formula_1">(2008)</ref> investigated whether a jury of wine experts vs nonexperts can taste the difference between expensive and cheap wines, and found while wine experts could distinguish the difference, non-experts could not. <ref type="bibr">Lecocq and Visser (2006)</ref> investigated what wine properties determine wine prices. They showed wine experts based their overall wine quality ratings on sensory information, and that expert ratings together with features such as region, vintage and designation explained price differences for a subset of French red wines. The relationship between the chemical substances in a wine and wine quality have also been the focus of research <ref type="bibr">(Chen et al., 2009;</ref><ref type="bibr">Cortez et al., 2009</ref>).</p><p>Brochet and Dubourdieu <ref type="formula" target="#formula_0">(2001)</ref> conducted a lexical analysis of four corpora of wine reviews from a cognitive linguistic perspective and concluded wine reviews are not only describing sensory properties of the wine, but also include idealistic and hedonistic information from wine prototypes based on previous experiences. Anthropologists have noted that wine experts form their own discourse community with a particular style and vocabulary <ref type="bibr">(Silverstein, 2006)</ref>. In this research we aim to discover stylistic and lexical patterns with which we can relate wine reviews to wine properties automatically.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Data set</head><p>The website http://www.winemag.com/, owned by Wine Enthusiast Companies, hosts a substantial catalog of wine descriptions. We downloaded the available reviews 4 and gathered a total of 76,585 wine reviews. The catalog data is structured and contains information about the wine such as the producer, appellation region and country, grape variety, color, alcohol percentage, price, and where to buy it. The expert who writes the wine review also rates the wine by assigning it a score between 80 and 100. The reviews are writ-ten by 33 different experts, and can be considered concise, with an average length of 39 words.</p><p>Wine reviews have a distinct style and vocabulary, which tends to focus on smell and flavor descriptions, as shown in example reviews 1 and 2 from our data. As noted previously, wine experts use creative metaphors to characterize the smell and flavor of a wine, as well as source-based descriptions. The metaphors perhaps add variation to otherwise dull or repetitive descriptions (Paradis and Eeg-Olofsson, 2013; Suárez Toste, 2007).</p><p>1. There is not a great deal of dolcetto grown in the Northwest, but this is the best version I've yet seen. Its vivid, spicy fruit core expresses the soil, the plant and the grape in equal proportion. Sappy flavors of spiced plum and wild berry hold the fort; it's built like a race car, sleek and stylish, with a powerful, tannic frame.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>2.</head><p>Here's a fragrant and very aromatic Grillo with cheerful notes of peach, passion fruit and mango. The wine has an easy approach and would pair perfectly with appetizers or finger foods.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Methodology</head><p>In our classification experiments, we evaluated the viability of predicting the following four wine properties: color, grape variety, price, and country of origin. Wines can be categorized into three different colors: white, red and rosé. The database of winemag.com is not complete in all metadata fields. We excluded reviews with missing metadata from our experiments, and performed this selection separately for each metadata field. For instance, we excluded 5,328 wines without a color label in the color labeling experiment. For grape variety we only considered those wines that were produced from a single grape and for which we had at least 200 reviews in the training set, leading to 33 categories. We disregarded all wines with grape blends, as these can have different ratios of different grape varieties. When different names were used for the same grape, we normalized these to the same category; e.g., Pinot Gris (French) and Pinot Grigio (Italian) were mapped together manually.</p><p>The sample contained wines from 47 different countries, ranging from South Korea (3 wines) to USA (31,401 wines). Even though price itself is an objective value, a division into cheap and expensive prices is a rather subjective choice. We tested two alternatives: a discretization where cheap wine costs less than $10 and expensive wine at least $100; and a more relaxed version where cheap means less then $15 and expensive at least $50. Wines between these prices were left out in both price experiments.</p><p>We pre-processed the data set automatically with the Stanford toolkit : we tokenized, PoS-tagged and lemmatized the reviews. For the classification experiments, we split the randomized data set into an 80% training and 20% test set. As information sources, we use both lexical and semantic features. A first experimental setup merely uses a bag-of-words (BoW) representation of the wine reviews. To construct these BoW features, we lowercased all lemmas in the review and selected only the content words (PoStag noun, verb or adjective) that occurred at least twice in the training set.</p><p>As the reviews are short and only contain about 23 content words on average, we decided to also add semantic features to reduce data sparsity. As shown by Kusner and colleagues <ref type="formula" target="#formula_0">(2015)</ref>, semantic representations such as Latent Semantic Indexing and Latent Dirichlet Allocation (LDA) can outperform a BoW representation. For our second experimental setup, we combined our set of BoW features with (1) 100 topics generated with Latent Dirichlet Allocation , and (2) 100 clusters based on word embeddings generated with Word2Vec . We ran initial experiments with exemplar-based classification and experimented with different cluster (Word2Vec) and topic (LDA) sizes of 100, 500, 1000, 2000 on the training set. For LDA <ref type="bibr" target="#b604">(McCallum, 2002)</ref>, we also varied the threshold to assign a topic only to a text when it covered 1%, 2%, or 5% of the text. The best results were obtained with 100 topics and a proportion threshold of 1%. We used these settings throughout our experiments. Two examples of LDA topics are shown here:</p><p>LDA42 color rosé strawberry raspberry pink flavor aroma wine light red cherry pale rise dry fresh LDA49 flavor acidity wine crisp dry clean lime peach citrus lemon fruit pineapple white vanilla</p><p>To create the word embeddings we ran Word2Vec on the training corpus, applying the BoW model, a context size of 8, and a word vector dimensionality of 200 features. In a next step, K-means clustering (with k = 100) was applied on the resulting word vectors. As an example, we show part of the terms contained by cluster 20, which all have the connotation of "dark/intense": The Word2Vec clusters were then implemented as binary features, meaning that for each instance containing a word occurring in one of the clusters, the respective cluster is coded by "1" in the feature vector, while the other cluster features are coded as "0".</p><p>As a classifier, we used LIBSVM <ref type="bibr" target="#b618">(Chang and Lin, 2011)</ref>, with the RBF kernel and optimized parameters c and g per prediction task. The parameters for SVM were optimized by means of a Grid search on a randomized subset (5,000 instances) of the training data, resulting in the following parameter settings:</p><p>• color: c = 8.0, g = 0.0078125 • variety: c =8.0, g =0.0078125</p><p>• country: c =32.0, g=0.00048828125 • price big difference: c =8.0, g=0.03125 • price small difference: c =8.0, g=0.0078125 <ref type="table" target="#tab_10">Table 1</ref> presents the classification results per wine property for three system flavors: (1) feature vectors including BoW, (2) feature vectors combining BoW features, LDA and Word2Vec clusters, and (3) combined feature vectors trained with an SVM classifier with optimized hyperparameters c and g. The results confirm the initial hypothesis that adding semantic information helps the classifier. In addition, optimizing the c and g parameters for the LIBSVM RBF kernel results in markedly higher classification scores.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Results</head><p>To get some insight into what terms are important for these classification results, we computed chi-square feature weights on the training set of examples for the different tasks. The top-10 features with highest chi-square values are shown in <ref type="table" target="#tab_5">Table 2</ref>   The classifier for color achieves a rather high Fscore, as illustrated in <ref type="table" target="#tab_6">Table 3</ref>. The rosé category is the odd one out with a markedly lower F-score. There are two main reasons for this. First, rosé is a low-frequency class compared to the other two classes. Second, rosé wine is made from red grapes, but the grapes are processed in a different way to red wines. Therefore, we expect to find a certain amount of overlap between red and rosé. When we examine the confusion matrix of the classifiers' predictions on the test set, we see that, indeed, most errors are due to misclassifying rosé as red wine.</p><p>One could argue color prediction from wine reviews is trivial where the wine color is actually mentioned in the review. Therefore, we also performed an additional experiment with a BoW feature set (with optimized SVM parameters) where the words red, white, and rosé were removed. This affected the overall F-score by 2.2 points, with the 5 The variety features are all grape names. For the country features: prokubac is a Serbian grape variety, meoru is a Korean grape that grows at mount Jiri. Yves refers to a French producer. Calatrasus is an erroneous lemma form predicted by the Stanford toolkit for the Italian wine producer Calatrasi. color rosé, cherry, tannin, apple, peach, citrus, pear, blush, black, pineapple, chardonnay variety aglianico, barbera, prosecco, viognier, moscato, malbec, sirah, carmenère, chenin, zin, franc country korea, jiri, rose-like, meoru, morocco, serbian, yves, calatrasus, chocolate-cherry, prokupac price year, tannin, age, rich, blackberry, black, vineyard, cellar, currant, vintage, simple  <ref type="table" target="#tab_6">Table 3</ref>: Results with optimized and combined SVM for color classification on the test set.</p><p>decrease due mostly to the performance drop of the rosé class from an F-score of 76.0 to 31.7.</p><p>For the property country we see that more training material has a positive effect on the individual scores, as visualized in <ref type="figure" target="#fig_3">Figure 1</ref>.</p><p>For grape varieties we find individual F-scores varying between 82.4 (Chardonnay grape) and 30.8 (Grenache). The Tempranillo grape, for example, is known for its rather neutral profile, and as a consequence it is often used in blends. The classifier could only distinguish the Tempanillo variety at a moderate rate (F-score 47.5), and the confusion matrix showed it is confused with Cabernet Sauvignon, Malbec, Pinot Noir, and Syrah. Varieties that were relatively easy to predict were Grüner Veltliner (F-score 74.3) and Nebbiolo (F-score 78.6). These grapes are rather strictly bound to geographic areas (Nebbiolo is from the region Piemonte, Italy and Grüner Veltliner is a typical Austrian grape). Cabernet Sauvignon (F-score 68.4) and Syrah (F-score 65.2) are common grapes for which we had many training examples, but they were often wrongly predicted as labels, leading to low precision. We are aware the location of wineries can strongly influence the sensory properties of a wine. The higher scores for grape varieties which are clearly tied to a particular region further confirms this.</p><p>With regard to the price, the more relaxed version (price big difference) does not seem to benefit from adding semantic features. An analysis of the classification output revealed the trained SVM model nearly always predicts the majority class for both the BoW and combined features, whereas the optimised version predicts both classes with an Fscore of 94.6%. In future research, we intend to recast the price classification as a regression task.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Conclusions</head><p>We have demonstrated that wine experts are capable of describing wines in a sufficiently consistent manner that we can use their descriptions to predict the properties of a wine based solely on its review. Using existing NLP tools and techniques, we were able to produce classifiers that could predict the color, grape variety, price and country of origin of thousands of wines with high F-scores.</p><p>This study is a first step in a larger investigation into the relationship between expert language and sensory descriptions. We are particularly interested in lexical descriptors used for smells and flavors, and aim to study the specific terminology at the phrase level. It would also be informative to know to what extent the wines were classified on the basis of smell and flavor descriptions per se, as opposed to other information provided in the reviews, such as vineyard or producer descriptions, for example. The present models cannot address this. In addition, it is interesting to investigate questions of genre and style. For example, we could ask to what extent does the writing style of an author, or the wine ratings, affect these results. Finally, we expect there are differences in the way wines are described in different countries and different languages. Ultimately a multilingual, multinational comparison of wine reviews could uncover further insights into the human linguistic potential for describing complex smells and flavors. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>The widespread use of social media enables researchers to examine human behavior at a scale hardly imaginable before. Research in text profiling has recently shown that a diverse set of user traits is predictable from language use. Examples range from demographics such as age <ref type="bibr">(Rao et al., 2010)</ref>, gender <ref type="bibr" target="#b37">(Burger et al., 2011;</ref>, popularity (Lampos et al., 2014), occupation (Preoţiuc-Pietro et al., 2015a) and location <ref type="bibr">(Eisenstein et al., 2010)</ref> to psychological traits such as personality <ref type="bibr">(Schwartz et al., 2013)</ref>    have shown that the age of the authors should be taken into account when building and using part-of-speech taggers. Likewise, socioeconomic factors have been found to influence language use <ref type="bibr">(Labov, 2006)</ref>. Understanding these biases and their underlying factors in detail is important to develop NLP tools without sociodemographic bias. Writing style measures have initially been created to be applied at the document level, where they are often used to assess the quality of a document (Louis and Nenkova, 2013) or a summarization (Louis and Nenkova, 2014) , or even to predict the success of a novel <ref type="bibr" target="#b33">(Ashok et al., 2013</ref>). In contrast to these document-level studies, we adopt a user-centric approach to measuring stylistic differences. We examine writing style of users on Twitter in relation to their age and income. Both attributes should be closely related to writing style: users of older age write on average more standard-conform (up to a certain point), and higher income is an indicator of education and conscientiousness <ref type="bibr">(Judge et al., 1999)</ref>, which determines writing style. Indeed, many features that aim to measure the complexity of the language use have been developed in order to study human cognitive abilities, e.g., cognitive decline <ref type="bibr" target="#b36">(Boyé et al., 2014;</ref><ref type="bibr">Le et al., 2011)</ref>.</p><p>The relationship between age and language has been extensively studied by psychologists, and more recently by computational linguists in various corpora, including social media. Pennebaker et al. In this paper we analyze two data sets of millions of tweets produced by thousands of users annotated with their age and income. We define a set of features ranging from readability and style to syntactic features. We use both linear and non-linear machine learning regression methods to predict and analyze user income and age. We show that writing style measures give large correlations with both age and income, and that writing style is predictive of income even beyond age. Finally, Twitter data allows the unique possibility to study the variation in writing with time. We explore the effects of time of day in user behavior dependent in part on the socio-demographic group.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Data</head><p>We study two large data sets of tweets. Each data set consists of users and their historical record of tweet content, profile information and trait level features extracted with high precision from their profile information. All data was tokenized using the Trendminer pipeline (Preoţiuc-Pietro et al., 2012), @-mentions and URL's collapsed, automatically filtered for English using the langid.py tool (Lui and Baldwin, 2012) and part-of-speech tagged using the ArkTweet POS tagger <ref type="bibr">(Gimpel et al., 2011)</ref>.</p><p>Income (D 1 ) First, we use a large data set consisting of 5,191 Twitter users mapped to their income through their occupational class. This data set, introduced in (Preoţiuc-Pietro et al., 2015a; Preoţiuc-Pietro et al., 2015b), relies on a standardised job classification taxonomy (the UK Standard Occupational Classification) to extract job-related keywords, search user profile fields for users having those jobs and map them to their mean UK income, independently of user location. The final data set consists of 10,796,836 tweets.</p><p>Age (D 2 ) The age data set consists of 4,279 users mapped to their age from <ref type="bibr" target="#b803">(Volkova and Bachrach, 2015)</ref>. The final data set consists of 574,095 tweets.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Features</head><p>We use a variety of features to capture the language behavior of a user. We group these features into:</p><p>Surface We measure the length of tweets in words and characters, and the length of words. As shorter words are considered more readable <ref type="bibr">(Gunning, 1969;</ref><ref type="bibr">Pitler and Nenkova, 2008)</ref>, we also measure the ratio of words longer than five letters. We further calculate the type-token ratio per user, which indicates the lexical density of text and is considered to be a readability predictor <ref type="bibr">(Oakland and Lane, 2004</ref>). Additionally we capture the number of positive and negative smileys in the tweet and the number of URLs.</p><p>Readability After filtering tweets to contain only words, we use the most prominent readability measures per user: the Automatic Readability Index <ref type="bibr">(Senter and Smith, 1967)</ref>, the FleschKincaid Grade Level <ref type="bibr">(Kincaid et al., 1975)</ref>, the Coleman-Liau Index <ref type="bibr" target="#b39">(Coleman and Liau, 1975)</ref>, the Flesch Reading Ease <ref type="bibr">(Flesch, 1948)</ref>, the LIX Index <ref type="bibr" target="#b31">(Anderson, 1983)</ref>, the SMOG grade <ref type="bibr">(McLaughlin, 1969</ref>) and the Gunning-Fog Index <ref type="bibr">(Gunning, 1969)</ref>. The majority of those are computed using the average word and sentence lengths and number of syllables per sentence, combined with weights.</p><p>Syntax Researchers argue about longer sentences not necessarily being more complex in terms of syntax <ref type="bibr">(Feng et al., 2009;</ref><ref type="bibr">Pitler and Nenkova, 2008)</ref>. However, advanced sentence parsing on Twitter remains a challenging task. We thus limit ourselves in this study to the part-of-speech (POS)  information. In previous work on writing style <ref type="bibr">(Pennebaker et al., 2003;</ref><ref type="bibr" target="#b32">Argamon et al., 2009;</ref><ref type="bibr">Rangel et al., 2014)</ref>, a text with more nouns and articles as opposed to pronouns and adverbs is considered more formal. We thus measure the ratio of each POS using the universal tagset <ref type="bibr" target="#b518">(Petrov et al., 2012)</ref>.</p><p>Style We implemented a contextuality measure, based on the work of <ref type="bibr">Heylighen and Dewaele (2002)</ref>, which assesses explicitness of the text based on the POS used and serves as a proxy for formality. Using Stanford Named Entity Recognizer , we measure the proportion of named entities <ref type="bibr">(3-classed)</ref> to words, as their presence potentially decreases readability <ref type="bibr" target="#b35">(Beinborn et al., 2012)</ref>, and netspeak aspects such as the proportion of elongations (wooow) and words with numbers (good n8). We quantify the number of hedges <ref type="bibr">(Hyland, 2005)</ref> and abstract words 1 used, and the ratio of standalone numbers stated per user as these are indicators of specificity <ref type="bibr">(Pennebaker et al., 2003;</ref><ref type="bibr">Pitler and Nenkova, 2008)</ref>. We also capture the ratio of hapax legomena, and of superlatives and plurals using Stanford POS Tagger 1 www.englishbanana.com <ref type="bibr">(Toutanova et al., 2003</ref>) using the Twitter model.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Temporal Patterns in Style</head><p>Social media data offers the opportunity to interpret the features in a richer context, including time or space. In our income data set, a timestamp is available for each message. Golder and Macy <ref type="formula" target="#formula_0">(2011)</ref> showed user-level diurnal and seasonal patterns of mood across the world using Twitter data, suggesting that individuals awaken in a good mood that deteriorates as the day progresses. In this work we explore user-level daily temporal trends in style for the 1500 highest-and 1500 lowest-income users (mean income ≥ £35,000 vs mean income ≤ £25,000). In <ref type="figure" target="#fig_3">Figure 1</ref> we present normalized temporal patterns for a selected set of features. While the difference between groups is most striking, we also observe some consistent daily patterns. These display an increase in readability <ref type="figure" target="#fig_3">(Figure 1a</ref>) starting in the early hours of the morning, peaking at 10AM and then decreasing constantly throughout the day, which is in accordance with the mood swings reported by <ref type="bibr">Golder and Macy (2011)</ref>. The proportion of pronouns <ref type="figure" target="#fig_3">(Figure 1b)</ref> and interjections <ref type="figure" target="#fig_3">(Figure 1c)</ref> follows the exact opposite pattern, with a peak in frequency during nights. This suggests that the language gets more contextual <ref type="bibr">(Heylighen and Dewaele, 2002)</ref> towards the end of the day. Finally, named entities <ref type="figure" target="#fig_3">(Figure 1d</ref>) display a very distinctive pattern, with a constant increase starting mornings, which increases throughout the day. While the first three patterns mirror the active parts of the day, coinciding with regular working hours, the latter pattern is possibly associated with mentions of venues or news. An increase in usage of named entities in the evening is steeper for low-income users -we hypothesize that this phenomenon could be reasoned by a stronger association of named entities with leisure in this user group. Overall, we notice a similarity between income groups, which, despite strongly separated, follow similar -perhaps universal -patterns.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Analysis</head><p>We view age and income as continuous variables and model them in a regression setup. This is in contrast to most previous studies on age as a categorical variable <ref type="bibr">(Rangel et al., 2014)</ref> to allow for finer grained predictions useful for downstream applications which use exact values of user traits, as opposed to being limited to broad classes such as young vs. old. We apply linear regression with Elastic Net regularization <ref type="bibr">(Zou and Hastie, 2005)</ref> and support vector regression with an RBF kernel (as a non-linear counterpart) for comparison <ref type="bibr">(Vapnik, 1998)</ref>. We report Pearson correlation results on 10-fold cross-validation. We also study if our features are predictive of income above age, by controlling for age assigned by a state-of-the-art model trained on social media data <ref type="bibr">(Sap et al., 2014)</ref>. Similar results have been obtained with log-scaling the income variable. <ref type="table" target="#tab_10">Table 1</ref> presents our prediction results. The strength of the correlation to the income and age, together with the sign of the correlation coefficient, are visually displayed in <ref type="figure" target="#fig_8">Figure 2</ref>.</p><p>As expected, all features correlate with age and income in the same direction. However, some features and groups are more predictive of one or the other (depicted above or below the principal diagonal in <ref type="figure" target="#fig_8">Figure 2</ref>). Most individual surface features correlate with age stronger than with income, with the exception of punctuation and, especially, words longer than 5 characters. The correlation of each readability measure is remarkably stronger with high income than with age, despite the fact Numbers in bold represent the highest correlations from the specific block of features and data set. All correlations are significant on p &lt; 0.001 level except for those in brackets.</p><p>these are to a large extent based on the surface features. Notably, Flesch Reading Ease -previously reported to correlate with education levels at a community level <ref type="bibr">(Davenport and DeLine, 2014)</ref> and with the usage of pronouns (Štajner et al., 2012) -is highly indicative for income. On the syntactic level we observe that increased use of nouns, determiners and adjectives is correlated higher with age as opposed to income, while a high ratio of pronouns and interjections is a good predictor of lower income but, only to a lesser extent, younger age, with which it is traditionally associated <ref type="bibr">(Schler et al., 2006)</ref>. From the stylistic features, the contextuality measure stands out as being correlated waele <ref type="formula" target="#formula_1">(2002)</ref>, but is almost orthogonal to income. Similarly, the frequency of named entities is correlated with higher income, while elongations have stronger association with younger age. Our results show, that based on the desired application, one can exploit these differences to tailor the style of a document without altering the topic to suit either age or income individually.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Conclusions and Future Work</head><p>Using two large data sets from thousands of users, annotated with their age and income, we presented the first study which analyzes these variables jointly, in relation to writing style. We have shown that the stylistic measures not only obtain significant correlations with both age and income, but are predictive of income beyond age. Moreover, we explored temporal patterns in user behavior on Twitter, discovering intriguing trends in writing style. While the discovery of these patterns provides useful psychosocial insight, it additionally hints to future research and applications that piggyback on author profiling in social media e.g., taking the message timestamp into account for stylistic features may yield improved results in user sociodemographic predictions. Likewise, utilizing additional proxies to control for income and education may lead to improvements in user age prediction. <ref type="bibr">James RA Davenport and Robert DeLine. 2014</ref> </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Abstract</head><p>Optimism is linked to various personality factors as well as both psychological and physical health, but how does it relate to the way a person tweets? We analyze the online activity of a set of Twitter users in order to determine how well machine learning algorithms can detect a person's outlook on life by reading their tweets. A sample of tweets from each user is manually annotated in order to establish ground truth labels, and classifiers are trained to distinguish between optimistic and pessimistic users. Our results suggest that the words in people's tweets provide ample evidence to identify them as optimists, pessimists, or somewhere in between. Additionally, several applications of these trained models are explored.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Optimists believe that future events are going to work out for the best; pessimists expect the worst <ref type="bibr">(Carver et al., 2010)</ref>. Research has shown that optimism is correlated with many positive life outcomes including improvements in life expectancy <ref type="bibr">(Diener and Chan, 2011)</ref>, physical health <ref type="bibr">(Peterson and Bossio, 2001)</ref>, and mental health <ref type="bibr">(Achat et al., 2000)</ref>. Previously, it was found that optimism and pessimism are differentiable but related: pessimism was principally associated with neuroticism and negative affect while optimism was primarily associated with extraversion and positive affect <ref type="bibr">(Marshall et al., 1992)</ref>. Another study found that optimism was correlated with personality factors, including extraversion, emotional stability, conscientiousness, and agreeableness <ref type="bibr">(Sharpe et al., 2011)</ref>.</p><p>It is clear that optimism relates to a wide variety of psychological and social variables, but how might optimism influence the way a person utilizes a social media platform? What features distinguish optimistic users from pessimistic ones? In order to answer these questions, we must first establish a means by which we can measure people's levels of optimism and pessimism. The Life Orientation Test (LOT) is commonly used to assess the degree to which a person is an optimist <ref type="bibr">(Scheier and Carver, 1985)</ref>. This short survey asks respondents to evaluate their own agreement with a number of short statements using a fivepoint scale. However, distributing such a survey over a large population requires both time and a form of incentive. Recent work has shown that open-ended text samples can be computationally analyzed to provide a more comprehensive view of a person's personal values than can be achieved using a more constrained, forced choice survey <ref type="bibr">(Boyd et al., 2015)</ref>. Furthermore, we know that language use is an independent and meaningful way of exploring personality <ref type="bibr">(Pennebaker and King, 1999)</ref>, and personality is correlated with optimism <ref type="bibr">(Sharpe et al., 2011)</ref>. Given a large enough text corpus, it may therefore be possible to build computational models that can automatically recognize optimism itself by looking at the words people use. The vast amount of publicly available social media data provides an excellent source of data that can be used to build models of users' psychological traits, as was done in previous studies that trained machines to predict aspects of personality from tweets <ref type="bibr">(Golbeck et al., 2011;</ref><ref type="bibr">Sumner et al., 2012)</ref>.</p><p>A tool that could identify optimists and pessimists by analyzing their text would aid in large scale studies of optimism among social media or other web users by providing a large number of subjects to analyze. This would open the door to massive studies of the relationships between optimism, pessimism, and a range of online behaviors. On the other hand, an optimism classification system could help improve the social platform itself. For example, by learning more about the psychological traits of its users, Twitter could improve its "who to follow" suggestions so that they reflect people who have a similar outlook on life.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Data and Method</head><p>As a data source, we chose Twitter because it is widely used and is ripe with short pieces of text (i.e., tweets) containing people's everyday thoughts, observations, and conversations. We used Twitter's basic search function to look for users whose tweets include words and phrases that indicate that they might identify as optimistic or pessimistic. Looking for phrases such as "I am optimistic" within a user's tweets to find potentially optimistic users, we identified 714 candidates. Finding pessimistic Twitter users proved more difficult because users would not usually tweet something negative such as "I am pessimistic" and present themselves in an unflattering way. We instead searched for keywords such as "hate," "unfair," and "disgust," which may indicate a pessimistic nature. This led to 640 potential pessimists. For each user, we crawled their 2,000 most recent tweets (or all their tweets if the user had less than 2,000). In order to verify that the accounts identified were owned mostly by individual users (as opposed to organizations), we manually inspected a random sample of 50 accounts and found only one that appeared to be related to an organization.</p><p>Using the collected data set, which we expected would be more representative of optimistic or pessimistic nature than the norm based on the content of their tweets, we selected a fraction of the users to create a ground truth set for our task. We used Amazon Mechanical Turk (MTurk) 1 to obtain human annotatations for a subset of our corpus. We randomly selected 500 users who were retrieved by the optimistic queries and 500 users found when searching for pessimists. For each user, we randomly selected 15 tweets for a total of 15,000 tweets to be labeled on a scale of −3 (very pessimistic) to 3 (very optimistic) by five independent annotators. Before labeling began, we provided clear definitions of optimism and pessimism to the annotators.</p><p>In order to pick the tweets from each user that had a stronger emotional signal, we took advantage of the "positive emotions" and "negative emotions" word categories included in the Linguistic Inquiry and Word Count Tool <ref type="bibr">(Pennebaker et al., 2001)</ref>. <ref type="bibr">2</ref> If any of the original 15 tweets did not contain at least one word from either category, the tweet was removed and a new tweet was chosen at random to replace it. This process was repeated until we had a set of 15 tweets per user without skewing that user's true distribution of positive and negative tweets.</p><p>During the MTurk annotation, to identify workers who were quickly selecting options without even reading the tweets, we added a "check" question that asked the workers to choose a specific value for that question. All the workers who did not correctly answer this "check" question were removed from the annotation. When a worker's annotations had to be thrown out, the tweets were put back onto MTurk for reannotation. Additionally, we compared the scores of each annotator with the average score and removed workers who deviated significantly from the others. The final agreement (Krippendorf's alpha) between the five annotators was measured at 0.731, assuming an interval scale.</p><p>For each individual tweet, we assigned a label of "optimistic," "pessimistic," or "neutral". Any tweet with an average score greater than one (slightly optimistic or higher in the annotation task) was considered an "optimistic" tweet, and those with an average score less than one (slightly pessimistic or lower) were given the "pessimistic" class label. The tweets with average MTurk annotation scores between -1 and 1 were considered to be "neutral."</p><p>We also assigned a class label to each user. To accomplish this, we calculated the average of the assigned scores, sorted the Twitter users by their level of optimism, and considered the top 25% of users as optimists, the bottom 25% as pessimists, and the remaining ones as neutral.</p><p>Before moving on, we decided to investigate the online behaviors and attributes of the optimistic and pessimistic users in our new data set. A summary of some of the differences between the two groups is shown in other users than the more pessimistic users. On the other hand, the pessimists tend to tweet much more frequently, with a mean and median number of tweets both more than twice as large as the optimist group. This is not just a factor of the pessimists having been around longer to build up a history of tweets-we also compute the "tweet rate" for each user by dividing their total number of tweets by the total number of days since the activation of their Twitter account. Looking at this variable, we see that the average number of tweets per day is much higher for the pessimists. Optimists are also included in more lists, while pessimists choose to label things as a "favorite" more often.</p><p>In order to build computational models to differentiate between the optimistic and pessimistic users, we use five different methods from the scikit-learn python library 3 : Naive Bayes (NB), Nearest Neighbor (NN), Decision Tree (DT), Random Forest Classifier (RFC), Gradient Boosting Classifier (GBC) and Stochastic Gradient Descent (SGD). The default parameters are used for each. The preprocessing method was the same for all different classifiers: the text was preprocessed by removing mentions (@), web links, and the phrase RT. We also used the Emoji unicode tables to replace all Emoji unicodes to their corresponding meanings (e.g., "&lt;smiling-face&gt;"). We tried performing classification both with and without removing stopwords to see what the effect was. For all different classifiers, we tested with different settings: with and without stopwords; and adding a user's profile information as additional features or not. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Results</head><p>We first evaluate the ability of our classifiers to distinguish between optimistic and pessimistic tweets (two-way classification) or among optimistic, pessimistic, and neutral tweets (threeway classification). We randomly selected 1,000 tweets from each class. <ref type="figure" target="#fig_3">Figure 1</ref> shows the tenfold cross validation results obtained using the six classifiers. During each classification, we made sure that tweets from the same user were not shared between the training and testing folds. In both cases, the best setting was using the Naive Bayes classifier and not including profile information as features. Stopword removal had no noticeable effect. Note that the majority baseline is a score of 50% in the two-class case, while it is 33% in the three-class case.</p><p>For additional insight, <ref type="table" target="#tab_5">Table 2</ref> shows some of the top features for the optimistic and pessimistic class, sorted by the probability of the feature given the class. We can see that, as one might expect, the useful words for detecting optimists are generally very positive, while the pessimistic features are negative and sprinkled with profanity. Since we formulated the problem as a three-way classification, it is reasonable that some words may have high scores for both optimistic and pessimistic classes. These words distinguish optimism/pessimism from the neutral class.</p><p>We perform our next evaluation at the user level, which means that we consider all tweets from a user as a single document. The classification is performed using a randomly selected set of 100, 200, 300, and 400 users from the annotated set (each set adds 100 new users to the previous group). In each case, the 25% users with highest annotation score are considered the optimistic group, 25% users with lowest annotation score as pessimist group, and the other 50% of users is the neutral group. The results of the ten-fold cross validation are shown in <ref type="figure" target="#fig_8">Figure 2</ref>. In this setting, the Gradient Boosting Classifier usually outperforms the others and achieves an accuracy of 73.33% on the 400 user data set. We also sought to discover how accurate the classifiers would be if the objective was simply to identify the top N optimists or pessimists. For example, if we wanted to find the 10 users out of a group with the greatest number of optimistic tweets, how accurately could this be done? To   carry out this analysis, we sorted the users by the probabilities that they belonged to either the optimistic class or the pessimistic class as predicted by a Naive Bayes classifier ( <ref type="figure" target="#fig_6">Figure 3</ref>). Then, we compute the accuracy for the top N optimists and pessimists. As we can see, it is possible to predict the most pessimistic 14 users with perfect accuracy. On the other hand, some of the most likely optimistic users actually belonged to another class based on the ground truth labels. With a larger number of users to classify, it becomes easier to correctly label optimists than pessimists.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Applications</head><p>What kinds of things can we learn with a tool for classifying optimists and pessimists? First, we look at groups of users from three major cities in the United States: Chicago, Los Angeles, and New York. We found users who listed their location as one of these three cities (494 users from Chicago, 433 from Los Angeles, 480 from New York), then collected 2,000 tweets from each user. Using our best models from the user-level experiments, we obtain predictions for the optimism/pessimism of the users. The breakdown of predicted optimists, pessimists, and neutral users is listed in <ref type="table" target="#tab_6">Table 3</ref>.</p><p>Chicago and New York are fairly balanced with roughly 40% of people falling into each category (leaving 20% as neutral). However, pessimists were predicted much more often than optimists in Los Angeles. For a second sample application, we went to the official twitter accounts of six presidential candidates: Hillary Clinton, Donald Trump, Marco Rubio, Martin O'Malley, Bernie Sanders and Ben Carson. We randomly picked approximately 500 followers of each of the candidates and predicted the optimism/pessimism of them <ref type="table" target="#tab_42">(Table  4)</ref>. <ref type="bibr">4</ref> While these scores are only estimates, we see that O'Malley's followers tend to be the users who posted a greater number of optimistic tweets, while the users who tweeted lots of pessimistic tweets are those keeping up-to-date with Rubio's campaign. Overall, we see that most of the followers of these candidates are optimistic.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Conclusions and Future Work</head><p>We have shown that we can use Twitter to collect a data set 5 of optimistic and pessimistic users, and predict the most (top 25%) optimistic/pessimistic users with greater than 70% accuracy. The optimistic users on Twitter tended to have more social connections, but tweet less often than the pessimists. In the future, we hope to explore the social effects of optimism, such as the degree to which optimistic users follow one another and whether or not optimistic comments receive more "favorites" and retweets. Finally, we would like to compare the optimism and pessimism scores that our model predicts with those received when taking the LOT in order to compare the text-based analysis with a widely used tool for measuring optimism. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>While huge volumes of unlabeled data are generated and made available in various domains, the cost of acquiring data labels remains high. Domain Adaptation problems arise each time when one leverage labeled data in one or more related source domains, to learn a classifier for unseen data in a target domain which is related, but not identical. The majority of domain adaptation methods makes an assumption of largely available source collections; this allows to measure the discrepancy between distributions and either build representations common to both target and sources, or directly reuse source instances for a better target classification <ref type="bibr" target="#b689">(Xu and Sun, 2012)</ref>. Numerous approaches have been proposed to address domain adaptation for statistical machine translation <ref type="bibr">(Koehn and Schroeder, 2007)</ref>, opinion mining, part of speech tagging and document ranking <ref type="bibr">(Daumé, 2009), (Pan and</ref><ref type="bibr">Yang, 2010)</ref>, <ref type="bibr">(Zhou and Chang, 2014)</ref>. Most effective techniques include feature replication , pivot features <ref type="bibr">(Blitzer et al., 2006)</ref>, <ref type="bibr">(Pan et al., 2010)</ref> and finding topic models shared by source and target collections <ref type="bibr">(Chen and Liu, 2014)</ref>. Domain adaptation has equally received a lot of attention in computer vision <ref type="bibr">(Gopalan et al., 2015)</ref> where domain shift is a consequence of changing conditions, such as background, location and pose, etc.</p><p>More recently, domain adaptation has been tackled with word embedding techniques or deep learning. <ref type="bibr">(Bollegala et al., 2015)</ref> proposed an unsupervised method for learning domain-specific word embedding while (Yang and Eisenstein, 2014) relied on word2vec models <ref type="bibr" target="#b375">(Mikolov et al., 2013)</ref> to compute feature embedding. Deep learning has been considered as a generic solution to domain adaptation <ref type="bibr">(Vincent et al., 2008;</ref><ref type="bibr">Glorot et al., 2011</ref><ref type="bibr">), (Chopra et al., 2013</ref> and transfer learning problems <ref type="bibr">(Long et al., 2015)</ref>. For instance, denoising autoencoders are successful models which find common features between source and target collection. They are trained to reconstruct input data from partial random corruption and can be stacked into a multi-layered network where the weights are fine-tuned with backpropagation <ref type="bibr">(Vincent et al., 2008)</ref> or marginalized out . Domain adaptation is also very attractive for service companies operating customer business processes as it can reduce annotation costs. For instance, opinion mining components deployed in a service solution can be customized to a new customer and adapted with few annotations in order to achieve a contractual performance.</p><p>But, in reality, the simplifying assumption of having access to source data rarely holds and limits therefore the application of existing domain adaptation methods. Source data are often a subject of legal, technical and contractual constraints between data owners and data customers. Often, customers are reluctant to share their data. Instead, they often put in place decision making procedures. This allows to obtain predictions for new data under a black box scenario. Note that this scenario is different from the differential privacy setting <ref type="bibr">(Dwork and Roth, 2014)</ref> in the sense that no queries to the raw source database are allowed whereas, in our case, only requests for predicting labels of target documents are permitted. This makes privacy preserving machine learning methods inapplicable here <ref type="bibr">(Chaudhuri and Monteleoni, 2008)</ref>, <ref type="bibr">(Agrawal and Srikant, 2000)</ref>.</p><p>In addition, black boxes systems are frequent in natural language processing applications. For instance, Statistical Machine Translation (SMT) systems are often used as black box to extract features <ref type="bibr">(Specia et al., 2009)</ref>. Similarly, the problem of adapting SMT systems for cross lingual retrieval has been addressed in <ref type="bibr">(Nikoulina et al., 2012)</ref> where target document collections cannot be accessed and the retrieval engine works as a black box.</p><p>In this paper we address the problem of adapting classifiers trained on the source data and available as black boxes. The case of available source classifiers has been studied by <ref type="bibr">(Duan et al., 2009)</ref> to regularize supervised target classifiers, but we consider here a transductive setting, where the source classifiers are used to predict class scores for a set of available target instances.</p><p>We then apply the denoising principle <ref type="bibr">(Vincent et al., 2008)</ref> and consider these predictions on target instances as corrupted by the domain shift from the source to target. More precisely, we use the stacked Marginalized Denoising Autoencoders  to reconstruct the predictions by exploiting the correlation between the target features and the predicted scores. This method has the advantage of coping with unsupervised cases where no labels in the target domain is available. We test the prediction denoising method on two benchmark text classification datasets and demonstrate its capacity to significantly improve the classification accuracy.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Transductive Prediction Adaptation</head><p>The domain adaptation problem consists of leveraging the source labeled and target unlabeled data to derive a hypothesis performing well on the target domain. To achieve this goal, most DA methods compute correlation between features in source and target domains. With no access to source data, we argue that the above principle can be extended to the correlation between target features and the source class decisions. We tune an adaptation trick by considering predicted class scores as augmented features for target data. In other words, we use the source classifiers as a pivot to transfer knowledge from source to target. In addition, one can exploit relations between the predictions scores and the target feature distribution to provide adapted predictions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Marginalized Denoising Autoencoder</head><p>The stacked Marginalized Denoising Autoencoder (sMDA) is a version of the multi-layer neural network trained to reconstruct input data from partial random corruption <ref type="bibr">(Vincent et al., 2008)</ref> proposed by , where the random corruption is marginalized out yielding the optimal reconstruction weights in the closed form.</p><p>The basic building block of the method is a onelayer linear denoising autoencoder where a set of N input documents x n are corrupted M times by random feature dropout with the probability p. It is then reconstructed with a linear mapping W : R d → R d by minimizing the squared reconstruction loss 1 :</p><formula xml:id="formula_152">L(W) = N n=1 M m=1 ||x n − Wx nm || 2 .<label>(1)</label></formula><p>LetX be the concatenation of M replicated version of the original data andX be the matrix representation of the M corrupted versions.</p><p>Then, the solution of <ref type="formula" target="#formula_0">(1)</ref> can be expressed as the closed-form solution for ordinary least squares W = PQ −1 with Q =XX and P =XX , where the solution depends on the re-sampling of x 1 , . . . , x N and which features are randomly corrupted.</p><p>It is preferable to consider all possible corruptions of all possible inputs when the denoising transformation W is computed, i.e. letting m → ∞. By the weak law of large numbers, the matrices P and Q converge to their expected values E[Q], E[P] as more copies of the corrupted data are created. In the limit, one can derive their expectations and express the corresponding mapping for W in a closed form as W = E[P] E[Q] −1 , where:</p><formula xml:id="formula_153">E[Q] ij = S ij q i q j , if i = j, S ij q i , if i = j,</formula><p>and E[P] ij = S ij q j where q = [1 − p, . . . , 1 − p, 1] ∈ R d+1 and S = XX is the covariance matrix of the uncorrupted data. This closed form denoising layer with a unique noise p is referred in the following as marginalized denoising autoencoder (MDA). It was shown by  that MDA can be applied with success to domain adaptation where the source set X s and target set X t are concatenated to form X and the mapping W can exploit the correlation between source and target features. The case of fully available source and target data is referred as a dream case in the evaluation section.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Prediction Adaptation</head><p>Without access to X s , MDA cannot be directly applied to [X s ; X t ]. Instead, we augment the feature set X t with the class predictions represented as vector f s (x t ) of class predictions P s (Y = y|x t n ), n = 1, . . . , N . Let u t n = [x t n ; f s (x t n )] be the target instance augmented with the source classifier predictions and U = [u t 1 u t 2 . . . u t N ] be the input to the MDA. Then we compute the optimal mapping W * = min W ||U − WŨ|| 2 that takes into account the correlation between the target features x t and class predictions f s (x t ). The reconstructed class predictions can be obtained as</p><formula xml:id="formula_154">W * [1:N,d+1:d+C] · f s (x t )</formula><p>, where C is the number of classes, and used to label the target data. Algorithm 1 summarizes all steps of the transductive prediction adaptation for a single source domain; the generalization to multiple sources is straightforward 2 .</p><p>Algorithm 1 Transductive prediction adaptation. bag-of-words, used in previous studies on domain adaptation <ref type="bibr">(Blitzer et al., 2011)</ref>. We consider the 10,000 most frequent features and four domains used in the studies: kitchen (k), dvd (d), books (b) and electronics (e) with roughly 5,000 documents per domain. We use all the source dataset as training and test on the whole target dataset. We set the MDA noise level p to high values (e.g. 0.9), as document representations are sparse and adding low noise have no effect on the features already equal to zero.</p><formula xml:id="formula_155">Require: Unlabeled target dataset X t ∈ R N ×d . Require: Class predictions f s (x t ) = [P s (Y = 1|x t i ), . . . , P s (Y = C|x t n )] ∈ R C . 1: Compose U ∈ R N ×(d+C) with u t n = [x t n ; f s (x t n )]</formula><p>In <ref type="table" target="#tab_10">Table 1</ref>, we show the performance of the Transductive Prediction Adaptation (TPA) on 12 adaptation tasks in the AMT dataset. The first column shows the accuracies for the dream case where the standard MDA is applied to both source and target data. The second column shows the baseline results (f s (X t )) obtained directly as class predictions by the source classifier. The classification model is an l 2 regularized Logistic Regression 3 cross-validated with regularized parameter C ∈ [0.0001, 0.001, 0.1, 1, 10, 50, 100].</p><p>The two last columns show the results obtained with two versions of TPA (results are underlined when improving over the baseline and in bold when yielding the highest values). In the first version, target instances x t n contains only features (words and bigrams) appearing in the source documents and used to make the predictions f (x t n ). In the second version, denoted as TPAe, we extend TPA with words unseen in the source documents. If the extension part is denoted v t n , we obtain an augmented representation u t n = [x t n ; v t n ; f (x t n )] as input to MDA. As we can see, both TPA and TPAe significantly outperform the baseline f s (X t ) obtained with no adaptation. Furthermore, extending TPA with words present in target documents only allows to further improve the classification accuracy in most cases. Finally, TPAe often outperforms the dream case and also on average (note however that MDA * uses the features common to source and target documents as input).</p><p>To understand the effect of prediction adaptation we analyze the book → electronics adaptation task. In the mapping W, we sort the weights corresponding to the correlation between the positive class and the target features. Features with the highest weights (up-weighted by TPA) are great, my, sound, easy, excellent, good, easy to, best, yo, a great, when, well, the best. On contrary, the words that got the smallest weight (down-weighted by TPA) are <ref type="bibr">no, was, number, don't, after, money, if, work, bad, get, buy.</ref> As TPA is totally unsupervised, we run additional experiments to understand its practical usefulness. We compare TPA to the case of weakly annotated target data, where few target examples are labelled and used for training a target classifier. Trained with 40, 100 and 200 target examples, a logistic regression yields an average accuracy of 64.63%, 68.01% and 75.13% over 12 tasks and a Multinomial Naives Bayes reports 65.82%, 71.49% and 76%, respectively. Even with 200 labeled target documents, the target versus target classification results are significantly below the 79.8% average accuracy of the baseline source classifier.</p><p>All these values are therefore significantly below the 83.73% obtained with TPAe. This strongly supports the domain adaptation scenario, when a sentiment analysis classifier trained on a larger source set and adapted to target documents can do better than a classifier trained on a small set of labeled target documents. Furthermore, we have seen that the baseline can be significantly improved by TPA and even more by TPAe without the need of even a small amount of manual labeling of the target set.</p><p>The second group of evaluation tests is on the 20Newsgroup dataset. It contains around 20,000 documents of 20 classes and represents a standard testbed for text categorization. For the domain adaptation, we follow the setting described in <ref type="bibr">(Pan et al., 2012)</ref>. We filter out rare words (appearing less than 3 times) and keep at most 10,000 features for each task with a tf-idf termweighting. As all documents are organized as a hierarchy, the domain adaptation tasks are defined on category pairs with sources and targets corresponding to subcategories. For example, for the 'comp vs sci' task, subcategories such as comp.sys.ibm.pc.hardware and sci.crypt are set as source domains and comp.sys.ibm.mac.hardware and sci.med as targets, respectively.</p><p>In our experiments we consider 5 adaptation tasks on category pairs ( 'comp vs sci','rec vs talk', 'rec vs sci', 'sci vs talk' and 'comp vs rec' as in <ref type="bibr">(Pan et al., 2012)</ref> ), and run the baseline, TPA and TPAe methods. For each category pair, we additionally inverse the source and target roles; this explains two sets of experimental results for each pair. We show the evaluation results in <ref type="table" target="#tab_5">Table 2</ref>. It is easy to observe again the significant improvement over the baseline f s (x t n ) and the positive effect of including the unseen words in the TPA. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Conclusion</head><p>In this paper we address the domain adaptation scenario without access to source data and where source classifiers are available as black boxes. In the transductive setting, the source classifiers can predict class scores for target instances, and we consider these predictions as corrupted by domain shift. We use the Marginalized Denoising Autoencoders  to reconstruct the predictions by exploiting the "correlation" between the target features and the predicted scores. We test the transductive prediction adaptation on two known benchmarks and demonstrate that it can significantly improve the classification accuracy, comparing to the baseline and to the case of full access to source data. This is an encouraging result because it demonstrates that domain adaptation can still be effective despite the absence of source data. Lastly, in the future, we would like to explore the adaptation of other language processing components, such as named entity recognition, with our method. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>References</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Abstract</head><p>Microblogging sites have emerged as major platforms for bloggers to create and consume posts as well as to follow other bloggers and get informed of their updates. Due to the large number of users, and the huge amount of posts they create, it becomes extremely difficult to identify relevant and interesting blog posts.</p><p>In this paper, we propose a novel convex collective matrix completion (CCMC) method that effectively utilizes user-item matrix and incorporates additional user activity and topic-based signals to recommend relevant content. The key advantage of CCMC over existing methods is that it can obtain a globally optimal solution and can easily scale to large-scale matrices using Hazan's algorithm. To the best of our knowledge, this is the first work which applies and studies CCMC as a recommendation method in social media. We conduct a large scale study and show significant improvement over existing state-ofthe-art approaches.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>The usage of social media sites has significantly increased over the years. Every minute people upload thousands of new videos on YouTube, write blogs on Tumblr 1 , take pictures on Flickr and Instagram, and send messages on Twitter and Facebook. This has lead to an information overload that makes it hard for people to search and discover relevant information.</p><p>Social media sites have attempted to mitigate this problem by allowing users to follow, or subscribe to updates from specific users. However, as 1 www.tumblr.com the number of followers grows over time, the information overload problem returns. One possible solution to this problem is the usage of recommendation systems, which can display to users items and followers that are related to their interests and past activities.</p><p>Over time recommender methods have significantly evolved. By observing the history of useritem interactions, the systems learn the preferences of the users and use this information to accurately filter through vast amount of items and allowing the user to quickly discover new, interesting and relevant items such as movies, clothes, books and posts. There is a substantial body of work on building recommendation systems for discovering new items, following people in social media platforms, predicting what people like <ref type="bibr">(Purushotham et al., 2012;</ref><ref type="bibr" target="#b43">Chua et al., 2013;</ref><ref type="bibr">Kim et al., 2013)</ref>. However, these models either do not consider the characteristics of user-item adoption behaviors or cannot scale to the magnitude of data.</p><p>It is important to note that the problem of recommending blog posts differs from the traditional collaborative filtering settings, such as the Netflix rating prediction problem in two main aspects. First, the interactions between the users and blogs are binary in the form of follows and there is no explicit rating information available about the user's preference. The follow information can be represented as an unidirectional unweighted graph and popular proximity measures based on the structural properties of the graph have been applied to the problem <ref type="bibr" target="#b614">(Yin et al., 2011)</ref>. Second, the blog recommendation inherently has richer side information additional to the conventional user-item matrix (i.e. follower graph).</p><p>In Tumblr, text data includes a lot of information, since posts have no limitation in length, compared to other microblogging sites such as Twitter. While such user generated content charac-terizes various blogs, user activity is a more direct and informative signal of user preference as users can explicitly express their interests by liking and reblogging a post. This implies that users who liked or reblogged the same posts are likely to follow similar blogs. The challenge is how to combine multiple sources of information (text and activity) at the same time. For the purpose, we propose a novel convex collective matrix completion (CCMC) social media recommender model, which can scale to million by million matrix using Hazan's algorithm <ref type="bibr" target="#b45">(Gunasekar et al., 2015)</ref>. Our contributions are as follows:</p><p>• We propose a novel CCMC based Tumblr blog post recommendation model. • We represent users and blogs with an extensive set of side information sources such as the user/blog activity and text/tags.</p><p>• We conduct extensive experimental evaluations on Tumblr data and show that our approach significantly outperforms existing methods.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Convex Collective Matrix Completion</head><p>In this section, we formulate the Tumblr blog post recommendation task as collective matrix factorization problem and we describe our large-scale convect collective matrix completion method with Hazan's algorithm <ref type="bibr" target="#b45">(Gunasekar et al., 2015)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Model Description</head><p>Let X 1 ∈ {0, 1} nr 1 ×nc 1 denote the user-blog (follower) matrix, where n r 1 is the number of users and n c 1 is the number of blogs. In this matrix, if the user i likes blog j, the (i, j)th element is set to 1. In addition to the user-blog matrix, we have other auxiliary matrices denoted by X 2 ∈ R nr 2 ×nc 2 and X 3 ∈ R nr 3 ×nc 3 . For example, if we have an user activity matrix, we can use it as X 2 , where n r 2 = n r 1 and n c 2 is the number of activities. Moreover, if we have the content information of articles, we can use them as X 3 . In this case, n c 1 = n c 3 is the number of blogs, and n r 3 is the number of topics in LDA. Note that, X 1 tends to be a sparse matrix, while X 2 and X 3 tend to be denser matrices. The final goal is to factorize X 1 with the help of the auxiliary matrices X 2 and/or X 3 . First, we form a large matrix M by concatenating all matrices [X v ] V v=1 and then factorizing M together with the regularizations.</p><p>In this paper, we adopt a convex approach <ref type="bibr" target="#b42">(Bouchard et al., 2013;</ref><ref type="bibr" target="#b45">Gunasekar et al., 2015)</ref>.</p><p>For example, for V = 3 , the matrix M is given as</p><formula xml:id="formula_156">M =     · X 1 X 2 · X 1 · · X 3 X 2 · · · · X 3 · ·     .<label>(1)</label></formula><p>This framework is called convex collective matrix completion (CMC) <ref type="bibr">(Singh and Gordon, 2008)</ref>. The key advantage of the CCMC approach is that the sparse user-blog matrix X 1 is factorized precisely with the help of the dense matrices X 2 and/or X 3 . Moreover, it has been recently shown that the sample complexity of the CCMC algorithm can be smaller than that of the simple matrix factorization approach (i.e., only factorize X 1 ) <ref type="bibr" target="#b45">(Gunasekar et al., 2015)</ref>. Finally, the CCMC method can easily incorporate multiple sources of information. Over time if Tumblr provides new signals or if we decide to incorporate new features, CCMC can easily adopt them. Therefore, we believe that CCMC is very suitable for solving the Tumblr recommendation task.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">CCMC-Hazan Algorithm</head><p>One of the key challenges of CCMC for Tumblr data is the scalability, since Tumblr has more than million users and hundred millions of blog posts. The original CCMC approach adopts Singular Value Thresholding (SVT) to solve the problem, and it works for small scale problems. However, SVT needs to solve N × N dimensional eigenvalue decomposition on each iteration, and thus it is not feasible to deal directly with the Tumblr data. Recently, Gunasekar et al. proposed an Atomic norm minimization algorithm for CCMC <ref type="bibr" target="#b45">(Gunasekar et al., 2015)</ref> using the approximate SDP solver of Hazan <ref type="bibr" target="#b46">(Hazan, 2008;</ref><ref type="bibr" target="#b48">Jaggi and Sulovsky, 2010)</ref>. The optimization problem is given as</p><formula xml:id="formula_157">min Z 0 V v=1 P Ωv (X v − P v (Z)) 2 F s.t. tr(Z) ≤ η,<label>(2)</label></formula><p>where X F is the Frobenius norm of matrix X , P Ωv , which extracts the elements in the set, Ω v is the set of non-zero indexes of X v , P v (Z) = Z v ∈ R nr v ×nc v , and η ≥ 0 is a regularization parameter. The Hazan's algorithm for CMF is summarized in Algorithm 1.</p><p>Algorithm 1 CCMC with Hazan's Algorithm of <ref type="formula" target="#formula_1">(2)</ref> Parameters: T (Number of iterations) Rescale loss:</p><formula xml:id="formula_158">fη(Z) = v PΩ v (Xv − Pv(ηZ)) 2 F Initialize Z (1) for all t = 1, 2 . . . , T = 4 do Compute u (t) = approxEV − ∇fη(Z (t) ), 1 t 2 2 αt := 2 2+t Z (t+1) = Z (t) + αtu (t) u (t) end forreturn [Pv(Z (T ) )] V v=1</formula><p>The advantage of CCMC-Hazan is that it needs to compute only a top eigenvector on each iteration. Practically, on each iteration t in Algorithm 1, we just need to compute an 1 t 2 -approximate largest eigenvalue of the sparse matrix with |Ω| non-zero elements, which needs O( |Ω| t ) computation using Lanczos algorithm. On the other hand, the original CCMC algorithms adopt Singular Value Thresholding (SVT) method, which converges much faster than CCMC-Hazan. However, the SVT approach has to compute all eigenvalues in each iteration. Thus, CCMC-Hazan is more suited for large-scale dataset than CCMC-SVT. The details of CMC with Hazan's algorithm, please refer to <ref type="bibr" target="#b45">(Gunasekar et al., 2015)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Task Definition</head><p>We define our task as given a set of users and their Tumblr post adoption behavior over a period of time, the goal is to build a model that can discover and recommend relevant Tumblr posts to the users.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Evaluation Setup and Data</head><p>We set up our Tumblr post evaluation framework by considering the posting or reblogging of an item j by a user i as an adopted item, and otherwise as unadopted. We present each user with top k items sorted by their predicted adoption score and evaluate how many of the recommended items (posts) were actually adopted by the users.</p><p>For our post recommendation study, we used Tumblr data from July until September. We used the data from July to August for training, and tested on the data from September. This experimental set up simulates A/B testing.</p><p>From the derived data, we sampled 15, 000 active users and 35, 000 posts resulting in 5 million user-item adoptions for training and 8.6 million user-item adoptions for testing.</p><p>2 approxEV(X, computes the approximate top eigen vector of X upto error.</p><p>In post recommendation our CCMC-Hazan method uses an user-item matrix X 1 ∈ {0, 1} 15000×35000 and an item-topic matrix X 2 ∈ R 35000×1000 . To learn the topics we use Latent Dirichlet Allocation (LDA) . We represent a document as a collection of post description, captions and hashtags. We use 1000 topics for our experiments. <ref type="figure" target="#fig_3">Figure 1</ref> shows some examples of the learned topics from the Tumblr posts. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Evaluation Metrics</head><p>To evaluate the performance of our collaborative matrix factorization approach for Tumblr post recommendation, we calculate precision (P), recall (R) and normalized discounted cumulative gain (nDCG) for top-k recommended posts.</p><p>-P@k as the fraction of adopted items by each user in top-k items in the list. We aveage precision@k across all users.</p><p>-R@k as the fraction of adopted items that are successfully discovered in top-k ranked list out of all adopted items by each user. We average recall@k across all users.</p><p>-nDCG@k computes the weighted score of adopted items based on the position in the top-k list. We average nDCG@k of all users. We set k to 10 since recommending too many posts is unrealistic. While nDCG@k uses the position of correct answer in the top-k ranked list, it does not penalize for unadopted posts or missing adopted posts in the top-k ranked list. Therefore, to judge the performance of the algorithms, one has to consider all three metrics together. Intuitively a good performing model is the one that has high P@k, R@k and nDCG@k.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Comparison Against State-of-art Models</head><p>In addition to evaluating the performance of our algorithm on Tumblr post recommendation, we also conducted a comparative study against existing state-of-the-art models. Item-based <ref type="bibr" target="#b471">3</ref> The item-based model recommends items that are similar to what the users have already adopted <ref type="bibr" target="#b49">(Karypis, 2001)</ref>. The model does not use textual information and only uses adopted items to compute the similarity between the items. The similarity metric is the Tanimoto Coefficient, which is used to handle binary ratings. User-based The user-based model recommends items that are adopted by other users with similar taste <ref type="bibr" target="#b47">(Herlocker et al., 1999)</ref>. The model does not use textual information and only uses adopted items to compute the similarity between the users. Similar to the item-based recommendation, we use the Tanimoto Coefficient. We choose top k items using k-Nearest Neighbor of similar users. MC 4 Alternating least squares (ALS) is matrix completion (MC) based collaborative filtering model, which was originally introduced to model user-movie rating prediction using meansquare loss function with weighted λ regularization <ref type="bibr">(Zhou et al., 2008)</ref>. The model does not use textual information or signals for adopted items. PMC 5 Probabilistic Matrix Completion <ref type="bibr">(Salakhutdinov and Mnih, 2008</ref>) is a probabilistic linear model with Gaussian observation noise that handles very large data sets and is robust to sparse user-item matrix. Similar to MC, PMC models the user-item adoption as the product of two K-dimensional lower-rank user and item hidden variables. The model does not use textual information, but unlike the previous methods it uses information on unadopted items. CF Collaborative Filtering model with softmax function <ref type="bibr" target="#b44">(Guadagni and Little, 1983;</ref><ref type="bibr">Manski, 1975;</ref><ref type="bibr">McFadden, 1974)</ref> captures the adoption and un-adoption behavior of users on items in social media. The model does not use textual information, but it uses signals on unadopted items. CF allows us to study the gain of performance in post recommendation when softmax function is used instead of the objective functions used in MC and PMC. CTR Collaborative Topic Regression <ref type="bibr">(Wang and Blei, 2011)</ref> was originally introduced to recommend scientific articles. It combines collaborative filtering PMC and probabilistic topic model-  <ref type="table" target="#tab_10">Table 1</ref> shows the obtained results of the proposed CCMC-Hazan method against the remaining recommendation models. The simple user and item based recommendations have the lowest performance. This shows that for accurate post recommendation using direct post and user information is insufficient and one needs stronger context driven signals. This is shown in the performance of the CF and CTR methods, which model context information with LDA and perform better than the rest of the models. However, when we compare the performance of our collaborative matrix completion method, we can see that the rest of the models have significantly lower performance. The main reasons are due to the dense information of CCMC-Hazan method and the fact that our method optimizes a convex function whereas the MC, CF and CTF models can get stuck in local optima.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">Results</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Conclusions</head><p>Recommending blog posts is one of the major tasks for user engagement and revenue generation in online microblogging sites such as Tumblr. In this paper, we propose a convex collective matrix completion based recommendation method that effectively utilizes the user-item matrix as well as rich side information from users and/or items. We evaluate the proposed method on real-world dataset collected from Tumblr. Extensive experiments demonstrate the effectiveness of the proposed method in comparison to existing state-ofthe-art approaches. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Sentence-level text simplification is the problem of automatically modifying sentences so that they become easier to read, while maintaining most of the relevant information in them. This can benefit applications as pre-processing for machine translation (Bernth, 1998) and assisting technologies for readers with reduced literacy <ref type="bibr">(Carroll et al., 1999;</ref><ref type="bibr">Watanabe et al., 2009;</ref><ref type="bibr">Rello et al., 2013)</ref>. Sentence-level text simplification ignores sentence splitting and reordering, and typically focuses on compression (deletion of words) and paraphrasing or lexical substitution <ref type="bibr" target="#b333">(Cohn and Lapata, 2008)</ref>. We include paraphrasing and lexical substitution here, while previous work in sentence simplification has often focused exclusively on deletion. Approaches that address compression and paraphrasing (or more tasks) integrally include <ref type="bibr" target="#b168">(Zhu et al., 2010;</ref><ref type="bibr">Narayan and Gardent, 2014;</ref><ref type="bibr">Mandya et al., 2014)</ref>.</p><p>Simplification beyond deletion is motivated by Pitler's (2010) observation that abstractive sentence summaries written by humans often "include paraphrases or synonyms ('said' versus 'stated') and use alternative syntactic constructions ('gave John the book' versus 'gave the book to John')." Such lexical or syntactic alternations may contribute strongly to the readability of a sentence if they replace difficult words with shorter or more familiar ones, in particular for low-literacy readers <ref type="bibr">(Rello et al., 2013)</ref>. Our joint approach to deletion and paraphrasing works against the limitation that abstractive simplifications "are not capable of being generated by [...] most sentence compression algorithms" <ref type="bibr">(Pitler, 2010)</ref>.</p><p>Furthermore, a central concern in text simplification is to ensure the grammaticality of the output, especially with low-proficiency readers as the target audience. Our approach to this problem is to remove or paraphrase entire syntactic units in the original sentence, thus avoiding to remove phrase heads without removing their arguments or modifiers. Like Filippova and Strube (2008), we rely on dependency structures rather than constituent structures, which promises more robust syntactic analysis and allows us to operate on discontinuous syntactic units.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Contributions</head><p>We present a sentence simplification model which is, to the best of our knowledge, the first model that uses structured prediction over dependency trees and models compression and paraphrasing jointly. Our model uses Viterbi decoding rather than scoring of all candidates and outputs probabilities reflecting model confidence.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Data</head><p>We use the publicly available Google compression data set, 1 which consists of 10,000 English sentence triples with (1) the original sentence as present in the body of an online news article, (2) a headline based on the original sentence, and (3) a compression that is automatically derived from the original such that it only contains word forms (1) In official documents released earlier this month it appears the Queen of England used the wrong name for the Republic of Ireland when writing to president Patrick Hillery.</p><p>(2) Queen elizabeth ii used wrong name for Republic The data is pre-processed with the Stanford CoreNLP tools , retrieving lemmas, parts-of-speech, named entities and dependency trees. We reserve the first 200 sentences from the data set for evaluation, the next 200 for tuning parameters (including the used PPDB versions, see next paragraph), and use the remaining 9,600 sentences for training our model. Deletion and paraphrase targets As our approach operates on dependency trees, aiming to prune or paraphrase subtrees from the dependency tree of a sentence, we identify deleted or paraphrased subtrees, marking their heads with a corresponding label. A subtree receives a Delete label if none of the words subsumed by this subtree occur in the compressed version of the sentence.</p><p>We identify paraphrased subsequences in an original sentence by looking up the subsequence string in the Paraphrase Database (PPDB) <ref type="bibr">(Ganitkevitch et al., 2013)</ref> and testing if one of its possible paraphrases occurs in the headline version of the sentence in question. The Paraphrase Database 1.0 is a set of phrasal and lexical pairs that were automatically acquired from bilingual parallel corpora, and thus contain a portion of flawed paraphrase pairs. The database comes in a number of different sizes, where small editions are restricted to high-precision paraphrases with relatively high paraphrase probabilities. As the two smallest editions of PPDB only yield a very low number of paraphrase targets (less than 100 in the entire Google compression data set), we opt to employ a medium-sized version of the resource (size 'L') and find a total of 510 phrasal and lexical paraphrases in the corpus.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Method</head><p>We assume that text simplification is a generative process on syntactic dependency graphs with a paraphrase dictionary. A dependency graph G = (V, A) is a labeled directed graph in the standard graph-theoretic sense and consists of nodes, V , and arcs, A, such that for sentence S = w 0 w 1 . . . w n and label set R, V ⊆ {w 0 , w 1 , . . . , w n }, and A ⊆ V × R × V hold, and if (w i , r, w j ) ∈ A then (w i , r , w j ) = A for all r = r. We restrict the dependency graphs to the class of trees, i.e., for (w i , r, w j ) ∈ A, if (w k , r, w j ) ∈ A then k = i.</p><p>The generative process traverses the tree in a top-down fashion, deleting or paraphrasing subtrees (see <ref type="figure" target="#fig_3">Figure 1)</ref>. Note that elements in subtrees dominated by a deleted node are automatically deleted (analogously for paraphrases).</p><p>For each dependency tree G = (V, A) in a training set of T sentences, we derive an input sequence of K-dimensional feature vectors x = x 1 , . . . , x n and an output sequence of y = y 1 , . . . , y n . Our tree-to-string simplification model is a second-order linear-chain conditional random field (CRF)</p><formula xml:id="formula_159">p(y|x) = 1 Z(x) n i=1 exp{ K k=1 θ k f k (y t , y t−1 , x t )}</formula><p>with y i = Delete if and only if x i represents the least upper bound in G covering a deleted span in the training data, and y i = Paraphrase if and only if x i represents the least upper bound in G covering a paraphrased span in the training data. For example, if the entire sentence is deleted, and (w 0 , r, w i ) ∈ A, then y i = Delete (but y j = Leave for j = i).</p><p>This encoding means that theoretically we can predict to paraphrase a subtree that is dominated by a node which is in turn predicted to be deleted (or vice versa). However, once an operation is carried out on a subtree, none of its dominated nodes are considered in the remainder of the top-down simplification process. Giving preference to operations at higher-level syntactic environments in this manner serves as a mechanism to resolve ambiguities in the decision process by taking a wider context into account.</p><p>Furthermore, predicting a node to get paraphrased at the right corner of a deleted subtree can potentially influence labeling decisions outside this subtree as a consequence of the dynamicprogram Viterbi decoding. We acknowledge that this is a theoretical drawback of the presented approach, but given that we do not observe any such dependency graphs in our data, we do not expect this to be a serious problem in most cases.</p><p>Whenever our model predicts that a subtree be paraphrased, we look up the respective token sequence in PPDB and replace it with the candidate paraphrase (if available) that maximises the product of frequency and translation probability according to PPDB.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Features for CRF model</head><p>We train a secondorder CRF model using MarMoT <ref type="bibr" target="#b706">(Mueller et al., 2013)</ref>, an efficient higher-order CRF implementation. The model computes its observational probabilities from features based on properties of the subtree root token (incl. POS, language model probability, NE mention, word difficulty), of the internal structure of the subtree (incl. number of children, depth, length of sequence), and of the external grammatical structure (incl. dependency relation, parent POS, distance from parent, position in sentence).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Evaluation</head><p>Baselines In the following experiments, we compare our approach to state-of-the-art approaches to sentence compression and joint compression/paraphrasing. For the first of these two categories, we consider the LSTM system described in <ref type="bibr">Filippova et al. (2015)</ref> as well as the results reported therein for the MIRA system <ref type="bibr">(McDonald, 2006)</ref>. As a joint approach, we consider Reluctant Trimmer (RT), a simplification system that employs synchronous dependency grammars <ref type="bibr">(Mandya et al., 2014)</ref>. Since the LSTM system requires great amounts of training data, which were not available to us, we cannot reproduce its out-  <ref type="table" target="#tab_10">Table 1</ref>: Performance on joint deletion and paraphrasing detection for our tree labeling system (evaluating both on entire subtrees and token level) as well as for the RT baseline (tokens only). Note that RT is trained on the (Simple) English Wikipedia, not on the Google compressions, and therefore the results may not be directly comparable.</p><p>put and therefore limit our comparison of human rankings to the eleven output examples provided in the paper.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>F-Scores</head><p>We first evaluate our tree labeling model (TL) on its ability to predict subtree deletion and paraphrasing (i.e. whether a subtree should be paraphrased, independent of the actual replacement). The results for this evaluation setup, as well as word-level performance, are listed in <ref type="table" target="#tab_10">Table 1</ref> and compared to RT. Note that for deletion and paraphrasing, our model consistently has higher precision than recall, thus generating more confident simplifications and less ungrammatical output. <ref type="table" target="#tab_5">Table 2</ref> reports the compression ratio (CR, percentage of retained words) as well as automated readability scores that our model achieves on the test set and compares it to the output of the RT baseline. Our system manages to compress the original texts by more than one third, but the gold simplifications (headlines and compressions) are still considerably shorter.   1948) and the Dale-Chall formula <ref type="bibr">(Dale and Chall, 1948)</ref>. The former score measures textual difficulty as a function of sentence length and the number of syllables per word, while the latter aims to estimate a US school grade level at which a text can be well understood, based on a vocabulary list. Both metrics deem the output of our system easier to read than the original texts, while the DaleChall formula also rates our system better than the gold simplifications. <ref type="bibr">Following Filippova et al. (2015)</ref> in their evaluation setup for the sake of comparability, we ask raters to assign scores on a one-to-five Likert scale to the first 200 sentences from the Google compression data paired with the output of our system. Each pair is rated by three native or near-native speakers of English. The raters are asked to evaluate the sentence ric is due to an over-representation of longer words in headlines.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Automated Readability Scores</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Human Readability Ratings</head><p>pairs for readability and informativeness. The former, following <ref type="bibr">Filippova et al. (2015)</ref>, "covers the grammatical correctness, comprehensibility and fluency of the output." The latter metric pertains to the relation between the original sentence and the system output as it "measures the amount of important content preserved in the compression." <ref type="table" target="#tab_6">Table 3</ref>   <ref type="formula" target="#formula_0">(2015)</ref>as well as the respective output from Reluctant Trimmer; see the lower part of <ref type="table" target="#tab_6">Table 3</ref>. The results suggest that, compared to the compression-only LSTMs, our approach yields comparable performance in terms of readability, while maintaining more of the central information in the original sentences. Compared to RT, our system does considerably better in terms of readability and retains slightly more of the important information.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Related Work</head><p>Several approaches to sentence compression have been presented in the last decade. <ref type="bibr">Knight and Marcu (2002)</ref> and <ref type="bibr">Turner and Charniak (2005)</ref> apply noisy channel models, using language models to control for grammaticality. <ref type="bibr">McDonald (2006)</ref> introduces a different approach, discriminatively training a scoring function, informed by syntactic features, to score all possible subtrees of a sentence. His work was inspired by <ref type="bibr">Riezler et al. (2003)</ref> scoring substrings generated from LFG parses. A third approach to sentence compression is sequence labeling, which has been explored by Elming et al. <ref type="formula" target="#formula_0">(2013)</ref>  Most recent approaches to sentence compression make use of syntactic analysis, either by operating directly on trees <ref type="bibr">(Riezler et al., 2003;</ref><ref type="bibr">Nomoto, 2007;</ref><ref type="bibr">Filippova and Strube, 2008;</ref><ref type="bibr" target="#b333">Cohn and Lapata, 2008;</ref><ref type="bibr">Cohn and Lapata, 2009)</ref> or by incorporating syntactic information in their model <ref type="bibr">(McDonald, 2006;</ref><ref type="bibr">Clarke and Lapata, 2008)</ref>. <ref type="bibr">Recently, however, Filippova et al. (2015)</ref> presented an approach to sentence compression using Original Sentence &amp; Simplifications O OG&amp;E is warning customers about a prepaid debit card scam that is targeting utility customers across the county. C OG&amp;E is warning customers about a scam. R OG&amp;E is warning customers about a debit card scam that is targeting utility customers across the country. T OG&amp;E is warning customers regarding a prepaid debit card scam. O The husband of murdered Melbourne woman Jill Meagher will return to Ireland later this month "to clear his head" while fighting for parole board changes. C The husband of murdered woman Jill Meagher will return to Ireland. R The husband of Melbourne woman Jill Meagher will return to Ireland this month to clear his head fighting for parole board changes. T The husband of murdered Melbourne woman Jill Meagher will return to Ireland. O A research project has found that taxi drivers often don't know what the speed limit is. C Taxi drivers don't know the speed limit is. R A research project has found that drivers often do not know what the speed limit is. T A project has found taxi drivers don't know what the speed limit is. <ref type="table" target="#tab_42">Table 4</ref>: Example output for original sentences (O) as generated by the Reluctant Trimmer baseline (R) and our tree labeling system (T), as well as the headline-generated Google compressions (C).</p><p>LSTMs with word embeddings, with no syntactic features. We return to working directly on trees, presenting a tree-to-string model of sentence simplification. Our model has interesting similarities to <ref type="bibr">(Riezler et al., 2003)</ref>, but uses Viterbi decoding rather than scoring of all candidates. Also, it follows <ref type="bibr" target="#b333">Cohn and Lapata (2008)</ref> in going beyond most of these models, modeling compression and paraphrasing.</p><p>For lexical simplification, most systems typically use pre-compiled dictionaries <ref type="bibr">(Devlin, 1999;</ref><ref type="bibr">Inui et al., 2003)</ref> and select the synonym candidate with the highest frequency. More recently, <ref type="bibr">BaezaYates et al. (2015)</ref> introduced an algorithm for lexical simplification in Spanish that selects the best synonym candidate in a context-sensitive fashion.</p><p>Cohn and Lapata <ref type="formula" target="#formula_1">(2008)</ref> </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Conclusion</head><p>We presented a new approach to sentence simplification that uses linear-chain conditional random fields over dependency graphs to jointly predict compression and paraphrasing of entire syntactic units. The objective of our model is to delete or paraphrase entire subtrees in dependency graphs as a strategy to avoid ungrammatical output. Our approach makes innovative use of a three-fold parallel monolingual corpus that features headlines and compressions to learn paraphrases and deletions, respectively. Human evaluation shows that our approach leads to readability figures that are comparable to previous stateof-the-art approaches to the more basic sentence compression task, and better than previous work on joint compression and paraphrasing. While our model does rely on syntactic analysis, it only needs a tiny fraction (less than 0.5%) of the training data used by <ref type="bibr">Filippova et al. (2015)</ref>. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Much of the work on applying NLP to the analysis of literature has focused on literary figures/characters in the text, e.g. in the context of social network analysis <ref type="bibr" target="#b58">(Elson et al., 2010;</ref><ref type="bibr" target="#b51">Agarwal et al., 2013;</ref><ref type="bibr" target="#b52">Ardanuy and Sporleder, 2015)</ref> or analysis of characterization . Named entity recognition (NER) of person names is generally the first step in identifying characters; locations are also a prevalent NE type, and can be useful when tracking different plot threads (Wallace, 2012), or trends in the settings of fiction. There are not, to our knowledge, any NER systems that are specifically targeted at literature, and most related work has used Stanford CoreNLP as an off-the-shelf solution <ref type="bibr" target="#b73">Vala et al., 2015)</ref>. In this paper, we show that it is possible to take advantage of the properties of fiction texts, in particular the repetition of names, to build a high-performing 3-class NER system which distinguishes people and locations from other capitalized words and phrases. Notably, we do this without any hand-labelled data whatsoever, bootstrapping a text-level context classifier from a low-dimensional Brown clustering of the Project Gutenberg corpus.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Related work</head><p>The standard approach to NER is to treat it as a supervised sequential classification problem, typically using conditional random fields or similar models, based on local context features as well as properties of the token itself. Relevant to the present work is the fact that, despite there being some work on enforcing tag consistency across multiple instances of the same token  and the use of non-local features ) to improve supervised sequential models, the consensus seems to be that this nonlocal information has a relatively modest effect on performance in standard datasets, and as a result off-the-shelf NER systems in practice treat each sentence as a separate document, with multiple instances of the same token in different sentences viewed as entirely independent classification problems. We also note that although supervised NER is the norm, there is a smaller body of work in semi-supervised and unsupervised approaches to NER and semantic lexicon induction, for instance pattern bootstrapping <ref type="bibr" target="#b68">(Nadeau et al., 2006;</ref><ref type="bibr" target="#b72">Thelen and Riloff, 2002;</ref><ref type="bibr" target="#b66">McIntosh et al., 2011)</ref> as well as generative approaches <ref type="bibr" target="#b57">(Elsner et al., 2009</ref>).</p><p>In the context of literature, the most closely related task is character identification <ref type="bibr" target="#b73">(Vala et al., 2015)</ref>, which is itself an intermediate task for character speech identification , analysis of characterization , and analysis of social networks <ref type="bibr" target="#b58">(Elson et al., 2010;</ref><ref type="bibr" target="#b51">Agarwal et al., 2013;</ref><ref type="bibr" target="#b52">Ardanuy and Sporleder, 2015)</ref>. In addition to NER, character identifica-tion also involves clustering multiple aliases of the same character, and discarding person names that don't correspond to characters. <ref type="bibr" target="#b73">Vala et al. (2015)</ref> identify some of the failures of off-the-shelf NER with regards to character identification, and attempt to fix them; their efforts are focused, however, on characters that are referred to by description rather than names or aliases.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Method</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Corpus preparation and segmentation</head><p>The corpus we use for building and testing our NER system is the 2010 image of the (US) Project Gutenberg corpus, 1 a reasonably comprehensive collection of out-of-copyright English literary texts, to our knowledge the largest that is publicly available in a machine-readable, full-text format. We access the texts via the GutenTag tool <ref type="bibr" target="#b54">(Brooke et al., 2015)</ref>, which allows both filtering of texts by genre as well as within-text filtering to remove Project Gutenberg copyright information, front and back matter (e.g. table of contents), and headers. We focus here only on fiction texts (i.e. novels and short stories); other kinds of literature (e.g. plays) are rare in the corpus and have very different properties in terms of the distribution of names. The final corpus size is 10844 texts.</p><p>GutenTag also provides an initial segmentation of tokens into potential names, using a simple rule-based system which segments contiguous capitalized words, potentially with common intervening function words like of as well as leading the (e.g. the King of Westeros). It largely (but not entirely) overcomes the problem of sentenceinitial capitalization in English by generalizing over an entire text; as long as a capitalized word or phrase appears in a non-sentence initial position at least once in a text, it will be tagged in the sentence-initial position as well. To improve precision, the name tagger in the version of GutenTag used for this paper (0.1.3) has lower bounds on token count (at least 10) and an upper bound on the length of names (no longer than 3 words). For this work, however, we remove those restrictions to maximize recall. Though not our primary concern, we return to evaluate the quality of the initial segmentation in Section 5.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Brown clustering</head><p>The next step is to induce Brown clusters  over the pre-segmented corpus (including potential names), using the tool of <ref type="bibr" target="#b64">Liang (2005)</ref>. Briefly, Brown clusters are formed using an agglomerative hierarchical cluster of terms based on their immediate context, placing terms into categories to maximize the probability of consecutive terms over the entire corpus. Note that using information from Brown clusters is a well established technique in NER, but more typically as features within a supervised framework <ref type="bibr" target="#b67">(Miller et al., 2004;</ref><ref type="bibr" target="#b64">Liang, 2005;</ref><ref type="bibr" target="#b71">Ritter et al., 2011)</ref>; we are unaware of any work using them directly as a source of bootstrapped training examples. We used default settings except for the number of clusters (c): 50. The rationale for such a small cluster size-the default is 1000, and NER systems which use Brown clusters as features do better with even more <ref type="bibr" target="#b56">(Derczynski et al., 2015)</ref>-is that we want to have clusters that correspond to major noun categories (e.g. <ref type="bibr">PERSON</ref> and LOCATION), which we consider the next most fundamental division beyond part-of-speech; 50 was selected because it is roughly comparable to the size of the Penn Treebank tagset <ref type="bibr" target="#b65">(Marcus et al., 1993)</ref>. We did not tune this number, except to observe that larger numbers (e.g. 100 or 200) resulted in increasingly fragmented clusters for our entities of interest.</p><p>To automatically extract a seed list of people and locations, we ranked the clusters by the total (token) count of names (as identified by GutenTag), and took the first cluster to be PER-SON, and the second to be LOCATION; all other clusters are considered OTHER, our third, catchall category. Alternatively, we could have set c higher and manually grouped the clusters based on the common words in the clusters, adding a thin layer of supervision to the process; with a low c, however, this was unnecessary since the composition and ranking of the clusters conformed exactly to our expectations. The top-5 clusters by token count of names are given in <ref type="table" target="#tab_10">Table 1</ref>. <ref type="bibr">2</ref> Note the presence of the multiword name New York in the second cluster, as a result of the segmentation.</p><p>The most common words in the first two clusters are mostly what we would expect, though there is a bit of noise, e.g. Him included as a place. The other clusters are messier, but still in-  <ref type="bibr" target="#b73">(Vala et al., 2015)</ref>. In any case, Brown clustering works fairly well for common names, but for rarer ones, the clustering is haphazard. Fiction, though, has many rare names and locations, since authors will often invent them. Another problem with Brown clustering is that ignores possible sense distinctions: for instance, Florence is both a city and a person name. To avoid confusion, authors will generally preserve one-sense-per-document, but this is not true at the corpus level.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Text-level context classifier</head><p>The central element of our NER system is a textlevel classifier of names based on context. By text-level, we mean that it assumes one-sense-perdocument, classifying a name for an entire document, based on all instances of the name in the document <ref type="bibr" target="#b60">(Gale et al., 1992)</ref>. It is trained on the (text-level) "instances" of relatively common names (appearing more than 100 times in the corpus) from the 3 NE label types derived based on the Brown clustering. That is, to build a training set, we pass through the corpus and each time we come across a common name in a particular document, we build a feature vector corresponding to all the contexts in that document, with the label taken from the clustering. Our rationale here is that the challenging part of NER in literature is names that appear only in one text; by limiting our context for common words to a single text, we simulate the task for rarer words. Mary is a common name, and may be a major character in one text, but a minor one in another; hence, we build a classifier that deals with both context-rich and context-poor situations. The noisy training set thus constructed has about 1 million examples. Our feature set consists of filtered word features in a 2-word window (w −2 w −1 w 0 w +1 w +2 ) around the token occurrences w 0 of a target type in a given text, made up of position-indexed unigrams (w −2 , w −1 , w +1 and w +2 ) and bigrams (w −2 w −1 , w +1 w +2 and w −1 w +1 ), excluding unigrams when a subsuming bigram feature matched (e.g. if we match trust in, we do not add trust and in). For this we used the name-segmented corpus, and when one of the words in the context was also a name, we take the category from the Brown clustering as the word (so w 2 for London in from London to New York is LOCATION, not New). Across multiple tokens of the same type, we count the same context only once, creating a binary feature vector which was normalized by dividing by the count of all non-zero entries once all contexts were collected. To be included as features, the n-grams had to occur with ≥ 10 different w 0 target word types. Note that given our bootstrapping setup, the word type itself cannot be used directly as a feature.</p><p>For classification, we use logistic regression from scikit-learn  trained with SGD using L2 regularization (C = 1). <ref type="bibr" target="#b471">3</ref> The only non-standard setting that we use is the "balanced" option, which weights classes by the inverse of their count in the training set, countering the preference for the majority class; we do this because our bootstrapped distribution is an unreliable reflection of the true distribution, and also because it makes it a fairer comparison to off-theshelf models with no access to this distribution.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">Improved phrase classification</head><p>Relative to (true) supervised models, our bootstrapped model suffers from being able to use only context, and not the identity of the name itself. In the case of names which are phrases, this is troubling because there are many generalizations to be made; for instance names ending with City are locations. Our final model addresses this failing somewhat by using more information from our Brown clustering: from each of the initial and final words across all names, we extract a set of words W s that appear at least ten times in position s ∈ S, S = {initial, f inal} across all phrases. Let c(w, t, s) be the the number of times a word w ∈ W s appears in the corpus at position s in phrases which were Brown clustered into the entity type t ∈ T , and p(t|r) be the original probability of phrase r being type t as determined by the logistic regression classifier. For our two homogenous entity types <ref type="figure">(PERSON and LOCATION)</ref>, we calculate a new score p :</p><formula xml:id="formula_160">p (t|r) = p(t|r) + s∈S c(r s , t, s) t ∈T c(r s , t , s) − w ∈Ws c(w ,t,s) t ∈T c(w ,t ,s) |W s | (1)</formula><p>The first term in the outermost summation in <ref type="figure" target="#fig_3">Equation 1</ref> is the proportion of occurrences of the given expression in position s which correspond to type t. To avoid applying too much weight to the homogeneous classes, the second term in the summation subtracts the average number of occurrences in the given position for all words in W s . As such, the total effect on the score can be negative. Note that if r s / ∈ W s , no modification is made, and for the OTHER type p (t|r) = p(t|r). Once we have calculated p (t|r) for each class, we choose the t with the highest p (t|r).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Evaluation</head><p>Our interest is in a general NER system for literature. Though there are a few novels which have been tagged for characters <ref type="bibr" target="#b73">(Vala et al., 2015)</ref>, we wanted to test our system relative to a much wider range of fiction. To this end, we randomly sampled texts, sentences, and then names within those sentences from our name-segmented Project Gutenberg corpus to produce a set of 1000 examples. These were tagged by a single annotator, an English native speaker with a PhD in English Literature. The annotator was presented with the sentence and the pre-segmented name of interest, and asked (via written instructions) to categorize the indicated name into PERSON, LOCATION, OTHER, UNCERTAIN due to ambiguity, or segmentation error. We ran a separate two-annotator agreement study over 200 examples which yielded a Cohen's Kappa of 0.84, suggesting high enough reliability that a single annotator was sufficient. The class  We compare our system to a selection of publicly available, off-the-shelf NER systems: OpenNLP, 4 LingPipe, 5 and Stanford CoreNLP , as well as the initial Brown clustering. OpenNLP allowed us to classify only PERSON and LOCATION, but for Stanford CoreNLP and LingPipe we used the existing 3-entity systems, with the ORGANI-ZATION tag collapsed into OTHER (as it was in our guidelines; instances of ORGANIZATION are rare in literature). Since the exact segmentation guidelines likely varied across these systems-in particular, we found that Stanford CoreNLP often left off the title in names such as Mr. Smithand we didn't want to focus on these issues, we did not require exact matches of our name segmentation; instead, we consider the entire name as PERSON or LOCATION if any of the tokens were tagged as such (names with both tags were considered OTHER). For our system (LitNER), we test a version where only the immediate sentence context is used ("sentence"), and versions based on text context ("text") with or without our phrase improvement ("±phrase").</p><p>We evaluate using two standard metrics: accuracy ("Acc"), and macroaveraged F-score ("F M ").</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Results</head><p>The results in <ref type="table" target="#tab_5">Table 2</ref> show that our system easily bests the off-the-shelf systems when it is given the contextual information from the entire text; the difference is more stark for accuracy (+0.085 absolute), though consistent for F M (+0.041 absolute). Stanford CoreNLP is the only competitive off-the-shelf system-the other two are far too conservative when encountering names they haven't seen before. LitNER is also clearly better than the Brown clusters it was trained on, particularly for F M (+0.120 absolute). With regards to different options for LitNER, we see a major benefit from considering all occurrences of the name in the texts rather than just the one we are testing on (Section 3.3), and a more modest benefit from using the information on parts of phrases taken from the Brown clustering (Section 3.4).</p><p>For the segmentation errors, we compared our corrected segmentations with the segmentation provided by the CRF-based Stanford CoreNLP system, our best competitor. Only 2 of the 15 were segmented correctly by Stanford CoreNLP. This potential 0.002 improvement is tiny compared to the 0.085 difference in accuracy between the two systems.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Discussion</head><p>Aspects of the method presented here could theoretically be applied to NER in other genres and other languages, but one important point we wish to make is that our approach clearly takes advantage of specific properties of (English) literature. The initial rule-based segmentation, for instance, depends on reliable capitalization of names, which is often not present in social media, or in most nonEuropean languages. We have found more subtle genre effects as well: for comparison, we applied the preliminary steps of our approach to another corpus of published texts which is of comparable (token) size to the Project Gutenberg corpus, namely the Gigaword newswire corpus <ref type="bibr" target="#b62">(Graff and Cieri, 2003)</ref>, and noted degraded performance for both segmentation and Brown clustering. With respect to the former, the obvious issue is considerably more complex proper nouns phrases such as governmental organizations and related titles. For the latter, there were several clusters in the top 10 (including the first one) which corresponded to LOCATION, while the first (fairly) clean PERSON cluster was the 15th largest; in general, individual people, organizations, and other groupings of people (e.g. by country of origin) were not well distinguished by Brown clustering in the Gigaword corpus, at least not with the same low number of clusters that worked well in the Project Gutenberg corpus.</p><p>Also less than promising is the potential for using text-level classification in other genres: whereas the average number of token occurrences of distinct name types within a single text in the Project Gutenberg corpus is 5.9, this number is just 1.6 for the much-shorter texts of the Gigaword corpus. Except in cases where it is possible to collapse texts into appropriately-sized groups where the use of a particular name is likely to be both common and consistent-an example might be a collection of texts written by a single author, which in social media such as Twitter seems to obey the classic one-sense-per-discourse rule <ref type="bibr" target="#b61">(Gella et al., 2014</ref>)-it's not clear that this approach can be applied successfully in cases where texts are relatively short, which is a far more common situation. We also note that relying primarily on contextual classification while eschewing resources such as gazetteers makes much less sense outside the context of fiction; we would expect relatively few fictitious entities in most genres.</p><p>LitNER tags names into only two main classes, PERSON and LOCATION, plus a catch-all OTHER. This coarse-grained tag set reflects not only the practical limitations of the method, but also where we believe automatic methods have potential to provide useful information for literary analysis. The other clusters in <ref type="table" target="#tab_10">Table 1</ref> reflect word categories which are relatively closed-class and much less central to the fictional narratives as character and setting; we don't see a compelling case for tagging them. When these and non-entities are excluded from OTHER, what remains is eclectic, including names referring to small groups of people (e.g. families), animals, gods, ships, and titles of other works of literature.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">Conclusion</head><p>In this paper, we have presented LitNER, an NER system targeted specifically at fiction. Our results show that a simple classifier, trained only with noisy examples derived in an unsupervised fashion, can easily beat a general-purpose supervised system, provided it has access to the full context of the text. Finally, we note that the NER tagging provided by LitNER has been integrated into the GutenTag tool (as of version 0.1.4). <ref type="bibr">6</ref> The Enemy in Your Own Camp: How Well Can We Detect Statistically-Generated Fake ReviewsAn Adversarial Study</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Dirk Hovy Center for Language Technology</head><p>University of Copenhagen 2300 Copenhagen, Denmark dirk.hovy@hum.ku.dk</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Abstract</head><p>Online reviews are a growing market, but it is struggling with fake reviews. They undermine both the value of reviews to the user, and their trust in the review sites. However, fake positive reviews can boost a business, and so a small industry producing fake reviews has developed. The two sides are facing an arms race that involves more and more natural language processing (NLP). So far, NLP has been used mostly for detection, and works well on human-generated reviews. But what happens if NLP techniques are used to generate fake reviews as well? We investigate the question in an adversarial setup, by assessing the detectability of different fake-review generation strategies. We use generative models to produce reviews based on meta-information, and evaluate their effectiveness against deceptiondetection models and human judges. We find that meta-information helps detection, but that NLP-generated reviews conditioned on such information are also much harder to detect than conventional ones.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Online reviews written by customers are a booming market. Several companies cater to a wide variety of audiences, supplying-among othersreviews for restaurants (Yelp), travel (TripAdvisor), businesses (Trustpilot), and specialized communities, such as beer (RateBeer). While the revenue of the providers is in the billions of dollars, the currency this industry is built on is consumer trust. The majority of consumers uses such reviews to inform themselves before buying. 1 On-line review companies therefore put considerable effort into maintaining this trust, by addressing the greatest threat to consumer trust (and therefore income)-fake reviews.</p><p>Identifying fake reviews is a natural fit for NLP, since they presumably contain linguistic cues that indicate their nature. Indeed, a number of previous works have dealt with the detection of fake reviews <ref type="bibr">(Jindal and Liu, 2007;</ref><ref type="bibr">Mackiewicz, 2008;</ref><ref type="bibr">Jindal et al., 2010;</ref>. However, in those cases, human writers were producing reviews to fool a human audience, not an NLP model. The detection models were therefore able to exploit the regularities resulting from the writers' tendency to follow a pattern to minimize their effort.</p><p>Writing fake reviews has become a lucrative business <ref type="bibr">(Streitfeld, 2012)</ref>, and so there is now an arms race going on between producers and detectors <ref type="bibr">(Roberts, 2012)</ref>. What if fake review writers become aware of the ways to game a detection algorithm? 2 As NLP technology becomes more common, we should expect to also see fake reviews generated by NLP models. This pits technology against technology.</p><p>In this paper, we explore the impact fake review generation has on NLP models' ability to detect them, and an ethical challenge in our development of NLP technology: the fact that it can be used for both sides <ref type="bibr">(Hovy and Spruit, 2016)</ref>.</p><p>Our contributions We set up an adversarial evaluation approach inspired by <ref type="bibr" target="#b739">(Smith, 2012)</ref>, using graphical models to build various language models that generate fake reviews, with and without recurrence to meta-information. We then test customers-buying-decisions-infographic-01280945 2 Similarly, some members of the Mechanical Turk community have adapted to the presence of assessment tools. Figure 1: Age distribution of gaming reviews for men and women in the US how well a logistic regression model can distinguish real from fake reviews from both models under two settings (the model has access to metainformation or not), and how well human judges can detect fake reviews generated by the model with meta-information.</p><p>Our results indicate that fake review generation could be a serious problem for detection mechanisms that solely rely on textual features.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Data</head><p>We use data extracted from the American and British versions of the review site Trustpilot. <ref type="bibr" target="#b471">3</ref> It comprises reviews for a variety of online businesses, as well as information about users' age and gender. <ref type="bibr">4</ref> We extracted all reviews that contained the full set of meta-information. We lower-case and tokenize by words, but leave reviews intact, rather than splitting them up into sentences. This results in 120,976 review instances. We reserve 10,000 for evaluation purposes, and use the rest to induce our adversarial generative models, and to derive features for the detection model (see below).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Review Generation Models</head><p>The basic approach is a simple Markov chain with a sufficiently large horizon to generate fluent reviews. Such an n-gram language model (LM) is a function that assigns probability to any sentence S, where S is a sequence w 0 , w 1 , · · · , w n , and P (S) =  <ref type="figure" target="#fig_8">Figure 2 a)</ref>. Since this is a generative model, it can not only be used to assign probability to observed sentences, but also generate new sentences based on the model parameters. However, extra-linguistic information, if available, can improve classification performance <ref type="bibr" target="#b801">(Volkova et al., 2013;</ref><ref type="bibr" target="#b757">Hovy, 2015)</ref>, and fakereview detection models often also exploit metainformation about the author and their behavior <ref type="bibr">(Lim et al., 2010)</ref>, looking for irregularities. We therefore use a generative story that assumes that people of different age and gender review different things, which in turn influences the type of business reviewed, and the choice of words. This assumption is borne out in the data (cf. <ref type="figure" target="#fig_3">Figure 1)</ref>. We extend this model by conditioning on latent variables age (A), gender (G), and review category (C). <ref type="bibr">5</ref> In the generative story of this model, we first draw a user from one of the two genders in our data, select an age based on gender-specific age distributions, and choose a review category dependent on the two previous variables. We then then generate a sentence conditioned on all of these settings and the Markov horizon. Our model is depicted as plate diagram in <ref type="figure" target="#fig_8">Figure 2</ref> b) (we omit the start token and the Markov horizon for clarity). It can formally be written as:</p><formula xml:id="formula_161">P (S|G, A, C) =P (G) · P (A|G) · P (C|G, A) · N i P (w i |w i−n:i−1 , C, G, A)</formula><p>5 These factors could of course be extended to cover other information, including ratings. We do not condition on ratings here, but a commercial system for fake reviews would presumably be restricted to positive scores.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>352</head><p>CATEGORY AGE GROUP SEX TEXT Hotels 30-45 F i ordered a new toner for our printer and after price matching the best i could find they also honoured a free delivery on top .</p><p>Computer Accessories 45-60 M this is a company that takes customer care seriously . we received really impressive service when we contacted the company . <ref type="table" target="#tab_10">Table 1</ref>: Generated examples from unconditional (top) and conditional (bottom) LM.</p><p>We can now use either model to generate fake reviews. In both cases, we use a Markov horizon of 6 words, i.e., a 7-gram model. For the unconditioned LM, meta-information is generated at random. This simulates a fake-review writer who is unaware of the context effects, but knows that companies might take profile information into account. Two examples are shown in <ref type="figure" target="#fig_3">Figure 1</ref>. Both examples are fluent, but the unconditioned one suffers from two problems: somewhat streamof-consciousness-like sentences and a for human readers obvious mismatch between the category and the discussed topic.</p><p>Conditional LMs, on the other hand, suffer from a certain sparsity: the more meta-information we condition on, the sparser the n-gram counts become. They are therefore more likely to faithfully re-generate the training data. We use interpolation between genders, but this could also be addressed with a wide variety of techniques <ref type="bibr" target="#b76">(Chen and Goodman, 1998)</ref>.</p><p>Even though the classifier does not have access to the training data, we want to make the task as difficult as possible, so we remove all duplicates, as well as any generated reviews that do not end in a punctuation mark, that exceed 200 words, or that have a category not contained in our real-review test set, and select from the rest by lowest entropy.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Experiments</head><p>In our experiments, we pit an adversary (i.e., the two LMs we experiment with) against a judge (a classifier or human annotator). The goal of the adversary is to produce fake reviews that convince the judge.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Logistic Regression Model</head><p>As classifier, we use a logistic regression model, regularized with L 2 norm, and fit it on a data set of 10,000 true reviews and a varying amount of fake reviews. In one setting, we use 1600 fake reviews , based on current estimates of 16% <ref type="bibr">(Luca and Zervas, 2015)</ref>. In a second setting, we use 10,000 fake reviews, a scenario where 50% of all reviews are fake. Given the ease of generating fake reviews with the models presented here, the rate could quickly go up in the future, so this ration gives a bound on how much our detection models could decline.</p><p>The base features of the classifier are word ngrams, with n ranging from 1 to 4. Depending on the setting, we also add meta-information features, including combinations of the n-grams with each category (e.g., category=Hotels &amp; word="soft bed"), and the average PMI score for the words in the sentence and each category (e.g., PMI(Hotels, soft bed)). That way, we hope to capture mismatches between the stated category and the review content.</p><p>We measure F1 performance over 5-fold stratified cross-validation.</p><p>Initially, we would like to establish whether conditioning LMs on demographic information has any effect on detection. For this purpose, we compare the performance of the logistic regression model on (1) a test set including fake reviews generated by an unconditioned 7-gram LM and (2) a test set whose fake reviews have been conditioned on meta-information. In both cases, the detector has only access to the base features, i.e., ignores demographic information. This is equivalent to a situation where the judge can only see the text, not the meta information.</p><p>As mentioned before, though, many companies employ meta-information in order to capture fake reviews, and if a spammer knew this, they could simply generate some meta-information. The question is: does this meta-information have to follow a coherent generative story? Intuitively, we expect the answer to be "yes": we would be surprised to see a teenager review retirement homes.</p><p>To test this assumption, we compare the performance of the classifier when having access to the base features plus meta-information under two settings: (3) with each piece of meta-information generated independently at random, and (4) with meta-information generated as part of our generative process.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Human Judges</head><p>The first experiment tests the detectability of fake reviews by statistical means. How hard is it for humans, though, to distinguish the fake reviews generated by this model from real reviews, and do they exploit meta-information?</p><p>To answer these questions, we also conduct a human judges study on Crowdflower 6 . We select 200 items at random (100 real reviews and 100 from the conditional model, half of each with meta-information), and ask annotators to rate them as real or fake. Judges were not informed about the nature of the reviews, only advised to use their best judgement. The task involved 8 test questions to bar bad annotators from entering. 76 unique judges participated, and rated the task as relatively difficult (3.5/5).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Results</head><p>Bear in mind that this is an adversarial setup: we are trying to improve the fake reviews to "trick" the judge into producing as many false positives as possible. A low F1-score thus means that the respective LM has managed to fool the classifier. <ref type="table" target="#tab_5">Table 2</ref> shows the results. Note also that the fake reviews are generated independent of the classification model, i.e., the generative LM does not take the classification model into account.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Logistic Regression Model</head><p>In order to assess whether the differences in performance are statistically significant, we conduct a bootstrap sampling test <ref type="bibr" target="#b78">(Efron and Tibshirani, 1993)</ref> with 10,000 repetitions on the overall predictions.</p><p>The numbers are generally in a high range, which is encouraging, since it means that our models can detect fake reviews fairly reliably. However, we also see that the conditional models introduced here quickly become significantly harder to detect than the regular LM.</p><p>Adding meta-information leads to sometimes small, but always significant increases in perfor-  As the number of fake reviews grows, though, detection gets more difficult, and the rift between the two generation models becomes more apparent: at 50% fake reviews, the conditional LM is almost twice as hard to detect as the regular LM when using meta-information.</p><p>Feature Analysis Finally, we analyze the features (word-based and meta-information) to find the most predictive elements of fake reviews. For each feature, we average over all folds of our cross-validation. Features which are selected frequently, irrespective of the exact training conditions, can be assumed to be robust predictors.</p><p>Unsurprisingly, the most predictive features are PMI(gender, ·) and PMI(category, ·), followed by gender-and age-specific words (gender=M &amp; word="delivery", age-group=3 &amp; word="."), categoryspecific words (category=Package Service &amp; word="parcel"), and individual words (service, easy, quick)</p><p>For the unconditional models, the PMI-category coefficients dominate other features in a powerlaw distribution, while for the conditional model, the PMI-age score is only slightly ahead.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Human Judges</head><p>The general tendency among human judges was to assume reviews are real: overall, 87% of the individual answers judged a review to be real. That is, only a minority of judges suspected fraud, irrespective of whether they had access to the metainformation or not. Whatever signal the logistic regression model picks up seems to be more subtle than what the average human can perceive.</p><p>This tendency plays out in the F1 scores (see <ref type="table" target="#tab_6">Table 3</ref>): human judges have a much lower detection rate than the logistic regression model, even though the availability of meta-information improves performance here as well.</p><p>These results hold whether we treat each vote as an individual item or aggregating the five votes for each instance by an item-response model . In the latter case, the performance for both conditions and the average increases, more so for the instances without meta-information, but still not reaching the same level.</p><p>ACCESS <ref type="bibr">TO</ref>   <ref type="table" target="#tab_6">Table 3</ref>: Human performance (F1) with different amounts of information on reviews generated by conditional model</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Related Work</head><p>Reviews are a rich source of studies for NLP, and a variety of recent papers <ref type="bibr">(McAuley et al., 2012;</ref><ref type="bibr" target="#b77">Danescu-Niculescu-Mizil et al., 2013;</ref><ref type="bibr">Reschke et al., 2013;</ref><ref type="bibr">Jurafsky et al., 2014;</ref> have explored it.  also use real and fake reviews and LMs, but in almost exactly the opposite setup: they select features that have high discriminative power in distinguishing real from fake reviews to include in their LMs. However, they use a review corpus that is more than an order of magnitude smaller, focus on tri-and quad-gram features, and do not take meta-information into account.</p><p>The work of  is similar in that they also deal with fake review detection. However, they do not use an adversarial setup, but focus on the use of an item-response model to detect fake-review writers. Their corpus is considerably smaller than ours, but the detection rate they report is similar to the one we find when not using meta-information.</p><p>To our knowledge, only Lappas (2012) has taken the view from the adversary's point of view, although the paper does not generate fake reviews, but assesses the presence of several defined measures of meretriciousness.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">Conclusion</head><p>We have investigated the detectability of fake reviews generated with meta-information. We find that (1) using access to meta-information can significantly improve the detection of fake reviews, and (2) generated reviews conditioned on metainformation are considerably harder to detect than the ones generated without. We also see that statistical models fare better than human judges. Our results indicate the viability of an adversarial setup to test detection tasks, but also highlight the fact that NLP techniques can be used for either side. We should therefore be more vigilant and willing to play devil's advocate, pitting potential models as adversaries against our solutions. In this paper, we propose a neural MT system using character-based embeddings in combination with convolutional and highway layers to replace the standard lookup-based word representations. The resulting unlimited-vocabulary and affixaware source word embeddings are tested in a state-of-the-art neural MT based on an attention-based bidirectional recurrent neural network. The proposed MT scheme provides improved results even when the source language is not morphologically rich. Improvements up to 3 BLEU points are obtained in the German-English WMT task.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Machine Translation (MT) is the set of algorithms that aim at transforming a source language into a target language. For the last 20 years, one of the most popular approaches has been statistical phrase-based MT, which uses a combination of features to maximise the probability of the target sentence given the source sentence <ref type="bibr" target="#b91">(Koehn et al., 2003)</ref>. Just recently, the neural MT approach has appeared <ref type="bibr" target="#b89">(Kalchbrenner and Blunsom, 2013;</ref><ref type="bibr" target="#b80">Bahdanau et al., 2015)</ref> and obtained state-of-the-art results.</p><p>Among its different strengths neural MT does not need to pre-design feature functions beforehand; optimizes the entire system at once because it provides a fully trainable model; uses word embeddings ) so that words (or minimal units) are not independent anymore; and is easily extendable to multimodal sources of information <ref type="bibr" target="#b87">(Elliott et al., 2015)</ref>. As for weaknesses, neural MT has a strong limitation in vocabulary due to its architecture and it is difficult and computationally expensive to tune all parameters in the deep learning structure.</p><p>In this paper, we use the neural MT baseline system from <ref type="bibr" target="#b80">(Bahdanau et al., 2015)</ref>, which follows an encoder-decoder architecture with attention, and introduce elements from the characterbased neural language model <ref type="bibr" target="#b90">(Kim et al., 2016)</ref>. The translation unit continues to be the word, and we continue using word embeddings related to each word as an input vector to the bidirectional recurrent neural network (attention-based mechanism). The difference is that now the embeddings of each word are no longer an independent vector, but are computed from the characters of the corresponding word. The system architecture has changed in that we are using a convolutional neural network (CNN) and a highway network over characters before the attention-based mechanism of the encoder. This is a significant difference from previous work <ref type="bibr" target="#b98">(Sennrich et al., 2015)</ref> which uses the neural MT architecture from <ref type="bibr" target="#b80">(Bahdanau et al., 2015)</ref> without modification to deal with subword units (but not including unigram characters).</p><p>Subword-based representations have already been explored in Natural Language Processing (NLP), e.g. for POS tagging (Santos and Zadrozny, 2014), name entity recognition (Santos and aes, 2015), parsing , normalization <ref type="bibr" target="#b85">(Chrupala, 2014)</ref> or learning word representations . These previous works show different advantages of using character-level information. In our case, with the new character-based neural MT architecture, we take advantage of intra-word information, which is proven to be extremely useful in other NLP applications <ref type="bibr" target="#b97">(Santos and Zadrozny, 2014;</ref><ref type="bibr" target="#b93">Ling et al., 2015a)</ref>, especially when dealing with morphologically rich languages. When using the character-based source word embeddings in MT, there ceases to be unknown words in the source input, while the size of the target vocabulary remains unchanged. Although the target vocabulary continues with the same limitation as in the standard neural MT system, the fact that there are no unknown words in the source helps to reduce the number of unknowns in the target. Moreover, the remaining unknown target words can now be more successfully replaced with the corresponding source-aligned words. As a consequence, we obtain a significant improvement in terms of translation quality (up to 3 BLEU points).</p><p>The rest of the paper is organized as follows. Section 2 briefly explains the architecture of the neural MT that we are using as a baseline system. Section 3 describes the changes introduced in the baseline architecture in order to use characterbased embeddings instead of the standard lookupbased word representations. Section 4 reports the experimental framework and the results obtained in the German-English WMT task. Finally, section 5 concludes with the contributions of the paper and further work.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Neural Machine Translation</head><p>Neural MT uses a neural network approach to compute the conditional probability of the target sentence given the source sentence <ref type="bibr" target="#b80">Bahdanau et al., 2015)</ref>. The approach used in this work <ref type="bibr" target="#b80">(Bahdanau et al., 2015)</ref> follows the encoder-decoder architecture.First, the encoder reads the source sentence s = (s 1 , ..s I ) and encodes it into a sequence of hidden states h = (h 1 , ..h I ). Then, the decoder generates a corresponding translation t = t 1 , ..., t J based on the encoded sequence of hidden states h. Both encoder and decoder are jointly trained to maximize the conditional log-probability of the correct translation.</p><p>This baseline autoencoder architecture is improved with a attention-based mechanism <ref type="bibr" target="#b80">(Bahdanau et al., 2015)</ref>, in which the encoder uses a bi-directional gated recurrent unit (GRU). This GRU allows for a better performance with long sentences. The decoder also becomes a GRU and each word t j is predicted based on a recurrent hidden state, the previously predicted word t j−1 , and a context vector. This context vector is obtained from the weighted sum of the annotations h k , which in turn, is computed through an alignment model α jk (a feedforward neural network). This neural MT approach has achieved competitive results against the standard phrase-based system in the WMT 2015 evaluation .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Character-based Machine Translation</head><p>Word embeddings have been shown to boost the performance in many NLP tasks, including machine translation. However, the standard lookupbased embeddings are limited to a finite-size vocabulary for both computational and sparsity reasons. Moreover, the orthographic representation of the words is completely ignored. The standard learning process is blind to the presence of stems, prefixes, suffixes and any other kind of affixes in words.</p><p>As a solution to those drawbacks, new alternative character-based word embeddings have been recently proposed for tasks such as language modeling <ref type="bibr" target="#b90">(Kim et al., 2016;</ref><ref type="bibr" target="#b93">Ling et al., 2015a)</ref>, parsing  or POS tagging <ref type="bibr" target="#b93">(Ling et al., 2015a;</ref><ref type="bibr" target="#b97">Santos and Zadrozny, 2014)</ref>. Even in MT <ref type="bibr" target="#b94">(Ling et al., 2015b)</ref>, where authors use the character transformation presented in <ref type="bibr" target="#b93">Ling et al., 2015a)</ref> both in the source and target. However, they do not seem to get clear improvements. Recently, <ref type="bibr" target="#b95">(Luong and Manning, 2016)</ref> propose a combination of word and characters in neural MT.</p><p>For our experiments in neural MT, we selected the best character-based embedding architecture proposed by <ref type="bibr" target="#b90">Kim et al. (Kim et al., 2016)</ref> for language modeling. As the <ref type="figure" target="#fig_3">Figure 1</ref> shows, the computation of the representation of each word starts with a character-based embedding layer that associates each word (sequence of characters) with a sequence of vectors. This sequence of vectors is then processed with a set of 1D convolution filters of different lengths (from 1 to 7 characters) followed with a max pooling layer. For each convolutional filter, we keep only the output with the maximum value. The concatenation of these max values already provides us with a representation of each word as a vector with a fixed length equal to the total number of convolutional ker-nels. However, the addition of two highway layers was shown to improve the quality of the language model in <ref type="bibr" target="#b90">(Kim et al., 2016)</ref> so we also kept these additional layers in our case. The output of the second Highway layer will give us the final vector representation of each source word, replacing the standard source word embedding in the neural machine translation system. In the target size we are still limited in vocabulary by the softmax layer at the output of the network and we kept the standard target word embeddings in our experiments. However, the results seem to show that the affix-aware representation of the source words has a positive influence on all the components of the network. The global optimization of the integrated model forces the translation model and the internal vector representation of the target words to follow the affix-aware codification of the source words.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Experimental framework</head><p>This section reports the data used, its preprocessing, baseline details and results with the enhanced character-based neural MT system.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Data</head><p>We used the German-English WMT data 1 including the EPPS, NEWS and Commoncrawl. Preprocessing consisted of tokenizing, truecasing, normalizing punctuation and filtering sentences with more than 5% of their words in a language </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Baseline systems</head><p>The phrase-based system was built using Moses , with standard parameters such as grow-final-diag for alignment, GoodTuring smoothing of the relative frequencies, 5-gram language modeling using Kneser-Ney discounting, and lexicalized reordering, among others. The neural-based system was built using the software from DL4MT 2 available in github. We generally used settings from previous work : networks have an embedding of 620 and a dimension of 1024, a batch size of 32, and no dropout. We used a vocabulary size of 90 thousand words in German-English. Also, as proposed in  we replaced unknown words (UNKs) with the corresponding source word using the alignment information. <ref type="table" target="#tab_6">Table 3</ref> shows the BLEU results for the baseline systems (including phrase and neural-based, NN) and the character-based neural MT (CHAR). We also include the results for the CHAR and NN systems with post-processing of unknown words, which consists in replacing the UNKs with the corresponding source word (+Src), as suggested in . BLEU results improve by almost 1.5 points in German-to-English and by more than 3 points in English-to-German. The reduction in the number of unknown words (after postprocessing) goes from 1491 (NN) to 1260 (CHAR) in the direction from German-to-English and from 3148 to 2640 in the opposite direction. Note the   number of out-of-vocabulary words of the test set is shown in <ref type="table" target="#tab_10">Table 1</ref>. The character-based embedding has an impact in learning a better translation model at various levels, which seems to include better alignment, reordering, morphological generation and disambiguation. <ref type="table" target="#tab_5">Table 2</ref> shows some examples of the kind of improvements that the character-based neural MT system is capable of achieving compared to baseline systems. Examples 1 and 2 show how the reduction of source unknowns improves the adequacy of the translation. Examples 3 and 4 show how the character-based approach is able to handle morphological variations. Finally, example 5 shows an appropriate semantic disambiguation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Results</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Conclusions</head><p>Neural MT offers a new perspective in the way MT is managed. Its main advantages when compared with previous approaches, e.g. statistical phrase-based, are that the translation is faced with trainable features and optimized in an end-to-end scheme. However, there still remain many challenges left to solve, such as dealing with the limitation in vocabulary size.</p><p>In this paper we have proposed a modification to the standard encoder/decoder neural MT architecture to use unlimited-vocabulary character-based source word embeddings. The improvement in BLEU is about 1.5 points in German-to-English and more than 3 points in English-to-German.</p><p>As further work, we are currently studying different alternatives <ref type="bibr" target="#b86">(Chung et al., 2016)</ref> to extend the character-based approach to the target side of the neural MT system.  <ref type="formula" target="#formula_0">(2014)</ref>, when viewing translations in a second language as a semantic annotation as the original language text. We show that compositional objectives based on phrase translation pairs outperform compositional objectives based on bilingual sentences and on monolingual paraphrases.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>The effectiveness of new representation learning methods for distributional word representations  has brought renewed interest to the question of how to compose semantic representations of words to capture the semantics of phrases and sentences. These representations offer the promise of capturing phrasal or sentential semantics in a general fashion, and could in principle benefit any NLP applications that analyze text beyond the word level, and improve their ability to generalize beyond contexts seen in training.</p><p>While most prior work has focused either on composing words into short phrases <ref type="bibr">(Mitchell and Lapata, 2010;</ref><ref type="bibr">Baroni and Zamparelli, 2010;</ref><ref type="bibr">Hermann et al., 2012;</ref><ref type="bibr">Fyshe et al., 2015)</ref>, or on supervised task-specific composition functions <ref type="bibr">Iyyer et al., 2015;</ref><ref type="bibr" target="#b464">Rocktäschel et al., 2015;</ref><ref type="bibr" target="#b305">Iyyer et al., 2014;</ref><ref type="bibr">Tai et al., 2015</ref>, inter alia), <ref type="bibr">Wieting et al. (2016)</ref> recently showed that a simple composition architecture (vector averaging) can yield sentence models that consistently perform well in semantic textual similarity tasks in a wide range of domains, and outperform more complex sequence models <ref type="bibr">(Tai et al., 2015)</ref>. Interestingly, these models are trained using PPDB, the paraphrase database <ref type="bibr">(Ganitkevitch et al., 2013)</ref>, which was learned from bilingual parallel corpora.</p><p>In bilingual settings, there are also a few examples of bilingual sentence models <ref type="bibr" target="#b470">(Zou et al., 2013;</ref><ref type="bibr">Hermann and Blunsom, 2014;</ref><ref type="bibr">Lauly et al., 2014;</ref><ref type="bibr">Gouws et al., 2014)</ref>. However, they have only been evaluated in cross-lingual transfer settings (e.g., cross-lingual document classification, or machine translation), which do not directly evaluate the quality of the sentence-level semantic representations learned.</p><p>In this work, we directly evaluate the usefulness of modeling semantic equivalence using compositional models of translated texts for detecting semantic textual similarity in a single language. For instance, in addition to using translated texts to model cross-lingual transfer from English to a foreign language, we can view English translations as a semantic annotation of the foreign text, and evaluate the usefulness of the resulting foreign representations. While learning representations in languages other than English is a pressing practical problem, this paper will focus on evaluating English sentence representations learned on English semantic similarity tasks to facilitate comparison with prior work.</p><p>Our results show that sentence representations learned using a bilingual compositional objective outperform representations learned using monolingual evidence, whether compositional or not. In addition, phrasal translations yield better representations than full sentence translations, even when applied to sentence-level tasks. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Models</head><p>Inspired by the bilingual model of <ref type="bibr">(Hermann and Blunsom, 2014)</ref>, and paraphrase model of <ref type="bibr">(Wieting et al., 2016)</ref>, representations for multi-word segments are built with a simple bag-of-word additive combination of word representations, which are trained to minimize the distance between semantically equivalent segments.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Three Views of Semantic Equivalence</head><p>The different types of semantic equivalence used for training are illustrated in <ref type="table" target="#tab_10">Table 1</ref>.</p><p>Parallel Sentences occur naturally, and provide training examples that are more consistent with downstream applications. However, they can be noisy due to automatic sentence alignment and one-to-many mappings, and bag-of-word representations of sentence meaning are likely to be increasingly noisier as segments get longer.</p><p>Monolingual Paraphrases are invaluable resources, but rarely occur naturally , and creating paraphrase resources therefore requires considerable effort. Ganitkevitch et al. (2013) automatically-created paraphrase resources for many languages using parallel corpora.</p><p>Parallel Phrases or phrasal translations might provide a tighter definition of semantic equivalence than longer sentence pairs, but phrase pairs have to be extracted automatically based on word alignments, an automatic and noisy process.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Models and Learning Objectives</head><p>Our main model is based on the bilingual composition model of <ref type="bibr">Hermann and Blunsom (2014)</ref>, which learns a word embedding matrix W from a training set X of aligned sentence pairs x 1 , x 2 . Each of x 1 and x 2 is represented as a bag-ofwords, i.e. a superset of column indices in W . Each aligned pair x 1 , x 2 is augmented with k randomly selected sentences that are not aligned to x 1 , and another k that are not aligned to x 2 . Given this augmented example x 1 , x 2 ,x 1 1 , ...,x k 1 ,x 1 2 , ...,x k 2 , the model training objective is defined as follows:</p><formula xml:id="formula_162">J bi (W ) = λ 2 ||W || 2 F + x 1 ,x 2 ,x 1 ,x 2 k i=1 [δ + ||g(x 1 ) − g(x 2 )|| 2 − ||g(x 1 ) − g(x i 2 )|| 2 ] h [δ + ||g(x 1 ) − g(x 2 )|| 2 − ||g(x 2 ) − g(x i 1 )|| 2 ] h<label>(1)</label></formula><p>where g(x) = i∈x W :i , <ref type="bibr">[.]</ref> h is the hinge function (i.e.</p><p>[v] h = max(0, v)) whose margin is given by δ and λ is a regularization parameter.</p><p>The paraphrase-based model of <ref type="bibr">Wieting et al. (2016)</ref> shares the same structure as the bilingual model above, but differs in the nature of segments used to define semantic equivalence (sentence pairs vs. paraphrases), the distance function used (Euclidean distance vs. cosine similarity), as well as the negative sampling strategies, and word embeddings initialization and regularization. We  <ref type="bibr">3M 3 PPDB XL (Ganitkevitch et al., 2013)</ref> provide empirical comparisons with the Wieting et al. <ref type="formula" target="#formula_0">(2016)</ref> embeddings, and also define a simplified version of that objective, J pa , to allow for controlled comparisons with J bi . J pa uses random initialization and penalizes large values in W with a ||W || 2 F regularization term 1 . The choice of distance function (Euclidean distance or cosine similarity) and of the negative sampling strategy 2 are viewed as tunable hyperparameters.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Experiments</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Evaluating Sentence Representations</head><p>Following <ref type="bibr">Wieting et al. (2016)</ref>, the models above are evaluated on the four Semantic Textual Similarity (STS) datasets <ref type="bibr">(Agirre et al., 2012;</ref><ref type="bibr">Agirre et al., 2013;</ref><ref type="bibr">Agirre et al., 2014;</ref><ref type="bibr">Agirre et al., 2015)</ref>, which provide pairs of English sentences from different domains (e.g., Tweets, news, webforums, image captions), annotated with human judgments of similarity on a 1 to 5 scale. Systems have to output a similarity score for each pair. Systems are evaluated using the Pearson correlation between gold and predicted rankings.</p><p>The Sentences Involving Compositional Knowledge (SICK) test set <ref type="bibr">(Marelli et al., 2014)</ref> provides a complementary evaluation. It consists of sentence pairs annotated with semantic relatedness scores. While STS examples were simply drawn from existing NLP datasets, SICK examples were constructed to avoid non-compositional phenomena such as multiword expressions, named entities and world knowledge.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Experimental Conditions</head><p>At training time we learn word embeddings for each combination of objective (Section 2.2) and type of training examples <ref type="table" target="#tab_5">(Table 2)</ref>, using modified implementations of open-source implementations for J bi (Hermann and Blunsom, 2014) and J pa <ref type="bibr">(Wieting et al., 2016)</ref>. This results in six model configurations. Each was trained for 10 epochs using tuned hyperparameters.</p><p>At tuning time we use the SMT-europarl subset of STS-2012. We consider mini-batch sizes of {25, 50, 100}, δ ∈ {1, 10, 100} with Euclidean distance, δ ∈ {0.4, 0.6, 0.8} with cosine similarly, and λ ∈ {1, 10 −3 , 10 −5 , 10 −7 , 10 −9 }. In J bi , we consider k ∈ {1, 5, 10, 15}, and in J pa we tuned over the sampling strategy ∈ {M IX, M AX} and the distance function used. To speed up tuning for J pa , we follow <ref type="bibr">Wieting et al. (2016)</ref>, by limiting training to 100k pairs, and tuning to 5 epochs.</p><p>Tuning results confirmed the importance of negative sampling and distance function in our models: in J bi , increasing k consistently helps the bilingual models, whereas the correlation score for monolingual models degrade for k &gt; 10. In J pa , M AX always outperforms M IX. Euclidean distance was consistently chosen for bilingual sentences and monolingual phrases, while cosine similarity was chosen for bilingual phrases.</p><p>At test time we construct sentence-level embeddings by averaging the representations of words in each sentence, and compute cosine similarity to capture the similarity between sentences. <ref type="table" target="#tab_6">Table 3</ref> reports the Pearson correlation scores achieved for each approach and dataset.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Findings</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Bilingual phrases yield the best models in controlled settings</head><p>Overall, the best representations are obtained using bilingual phrase pairs and the J bi objective. They outperform all other compositional models for all tasks, except for one subset of STS-2015.</p><p>The best objective for a given type of training example varies: J pa generally yields better <ref type="table" target="#tab_6">Table 3</ref>: Pearson correlation scores obtained on the English STS sets (with per year averages) and on semantic-relatedness task (SICK). The left columns report results based on new representations learned in this work, while the 2 rightmost columns report reference results from prior work <ref type="bibr">(Wieting et al., 2016</ref> results with monolingual phrases, while J bi performs better with bilingual examples. Bilingual phrases seem to benefit from larger number of randomly selected negative samples and from using the Euclidean distance rather than cosine similarity. The best bilingual compositional representations are better than non-compositional Glove embeddings , but worse than compositional Paragram embeddings <ref type="bibr">(Wieting et al., 2016)</ref>. However, Paragram initialization requires large amounts of text and human word similarity judgments for tuning, while our models were initialized randomly. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Bilingual sentences vs. bilingual phrases</head><p>Why do bilingual phrases outperform the bilingual sentences they are extracted from? In this section, we verify that this is not explained by systematic biases in the distribution of training examples. First, <ref type="table" target="#tab_42">Table 4</ref> shows that bilingual sentences have the smallest ratios of undertrained words, and are therefore not penalized by rare words more than bilingual phrases <ref type="bibr" target="#b471">3</ref> .</p><p>Second, we see that the rankings are not biased due to memorization of the phrases seen during training. Rankings of models does not change when testing on unseen word sequences, as shown by SICK results with models trained using J bi on a filtered training set that contains none of the bigrams observed at test time <ref type="table" target="#tab_22">(Table 5)</ref>.</p><p>Third, the advantage of bilingual phrases over bilingual sentences is not due to the larger number of training examples. 1.9M (and even 1M ) bilin- gual phrase pairs still outperform the 1.9M bilingual sentence pairs on all subsets (See <ref type="table" target="#tab_23">Table 6</ref>). Taken together, these additional results support our initial intuition that the main advantage of bilingual phrases over bilingual sentences is that phrase pairs have stronger semantic equivalence than sentence pairs, since phrase pairs are shorter and are constructed by identifying strongly aligned subsets of sentence pairs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Monolingual vs. bilingual phrases</head><p>Based on the analysis thus far, we hypothesize that paraphrase pairs with overlapping tokens make the compositional training objective less useful. Around 40% of the paraphrase training pairs differ only by one token. With Euclidean distance in the training objective, overlapping tokens cancel each other out of the composition term. For example, the pair healthy and stable, healthy and steady yields the compositional term ||(healthy + and + stable)− (healthy + and + steady)|| 2 = ||stable − steady|| 2</p><p>In contrast, overlap cannot occur in the bilingual setting, and all words within bilingual phrases contribute to the compositional objective. Furthermore, bilingual pairs provide a more explicit semantic signal as translations can disambiguate polysemous words <ref type="bibr">(Diab, 2004;</ref><ref type="bibr">Carpuat and Wu, 2007)</ref> and help discover synonyms by pivoting <ref type="bibr" target="#b230">Yao et al., 2012)</ref>.</p><p>All these factors might contribute to the ability of training with bilingual phrases of taking advantage of larger number of negative samples k.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Conclusion</head><p>We conducted the first evaluation of compositional representations learned using bilingual supervi- sion on monolingual textual similarity tasks.</p><p>Phrase and sentence representations are constructed by composing word representations using a simple additive composition function. We considered two training objective that encourage the resulting representations to distinguish EnglishSpanish segment pairs that are semantically equivalent or not. The resulting English sentence representations consistently outperform compositional models trained to detect monolingual paraphrases on five different English semantic textual similarity tasks from SemEval.</p><p>Bilingual phrase pairs are consistently the best evidence of semantic equivalence in our experiments. They yield better results than the sentence pairs they are extracted from, despite the noise introduced by the automatic extraction process.</p><p>Furthermore the composed representations outperform non-compositional word representations derived from monolingual co-occurrence statistics. While sizes of monolingual vs. bilingual corpora are not directly comparable, it is remarkable that representations learned with only 500k bilingual phrase pairs outperform GloVe embeddings trained on 840B tokens.</p><p>Since our best models still underperform Paragram vectors, which require a more sophisticated initialization process, we will turn to improving our initialization strategies in future work. Nevertheless, current results provide further evidence of the usefulness of compositional text representations, even with a simple bag-of-word additive composition function, and of bilingual translation pairs as a strong signal of semantic equivalence.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Abstract</head><p>Traditional event detection methods heavily rely on manually engineered rich features. Recent deep learning approaches alleviate this problem by automatic feature engineering. But such efforts, like tradition methods, have so far only focused on single-token event mentions, whereas in practice events can also be a phrase. We instead use forward-backward recurrent neural networks (FBRNNs) to detect events that can be either words or phrases. To the best our knowledge, this is one of the first efforts to handle multi-word events and also the first attempt to use RNNs for event detection. Experimental results demonstrate that FBRNN is competitive with the state-of-the-art methods on the ACE 2005 and the Rich ERE 2015 event detection tasks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Automatic event extraction from natural text is an important and challenging task for natural language understanding. Given a set of ontologized event types, the goal of event extraction is to identify the mentions of different event types and their arguments from natural texts. In this paper we focus on the problem of extracting event mentions, which can be in the form of a single word or multiple words. In the current literature, events have been annotated in two different forms:</p><p>• Event trigger: a single token that is considered to signify the occurrence of an event.</p><p>Here a token is not necessarily a word, for example, in order to capture a death event, the phrase "kick the bucket" is concatenated into a single token "kick the bucket". This scheme has been used in the ACE and Light ERE data and has been followed in most studies on event extraction.</p><p>• Event nugget: a word or a phrase of multiple words that most clearly expresses the occurrence of an event. This scheme is recently introduced to remove the limitation of singletoken event triggers and has been adopted by the rich ERE data for event annotation.</p><p>Existing event extraction work often heavily relies on a rich set of hand-designed features and utilizes existing NLP toolkits and resources <ref type="bibr">(Ji and Grishman, 2008;</ref><ref type="bibr">Patwardhan and Riloff, 2009;</ref><ref type="bibr">Liao and Grishman, 2010;</ref><ref type="bibr">McClosky et al., 2011;</ref><ref type="bibr">Huang and Riloff, 2012;</ref><ref type="bibr">Li et al., 2013a;</ref><ref type="bibr">Li et al., 2013b;</ref><ref type="bibr">Li et al., 2014)</ref>. Consequently, it is often challenging to adapt prior methods to multi-lingual or nonEnglish settings since they require extensive linguistic knowledge for feature engineering and mature NLP toolkits for extracting the features without severe error propagation. By contrast, deep learning has recently emerged as a compelling solution to avoid the aforementioned problems by automatically extracting meaningful features from raw text without relying on existing NLP toolkits. There have been some limited attempts in using deep learning for event detection <ref type="bibr">(Nguyen and Grishman, 2015;</ref> which apply Convolutional Neural Networks (CNNs) to a window of text around potential triggers to identify events. These efforts outperform traditional methods, but there remain two major limitations:</p><p>• So far they have, like traditional methods, only focused on the oversimplified scenario of single-token event detection.</p><p>• Such CNN-based approaches require a fixed size window. In practice it is often unclear <ref type="figure" target="#fig_3">Figure 1</ref>: The Proposed Forward-Backward Recurrent Neural Network (FBRNN) Model, with the example sentence "an unknown man had [broken into] a house last November" and event nugget candidate "broken into"</p><p>how large this window needs to be in order to capture necessary context to make decision for an event candidate.</p><p>Recurrent Neural Networks (RNNs), by contrast, is a natural solution to both problems above because it can be applied to inputs of variable length which eliminates both the requirement of single-token event trigger and the need for a fixed window size. Using recurrent nodes with Long Short Term Memory (LSTM) (Hochreiter and Schmidhuber, 1997) or Gated Recurrent Units (GRU) , RNN is potentially capable of selectively deciding the relevant context to consider for detecting events.</p><p>In this paper we present a forward-backward recurrent neural network (FBRNN) to extract (possibly multi-word) event mentions from raw text. Although RNNs have been studied extensively in other NLP tasks <ref type="bibr">(Cross and Huang, 2016;</ref><ref type="bibr">Tai et al., 2015;</ref><ref type="bibr">Paulus et al., 2014)</ref>, to the best of our knowledge, this is the first work to use RNNs for event detection. This is also one of the first efforts to handle multi-word event nuggets. Experimental results confirm that FBRNN is competitive compared to the state-ofthe-art on the ACE 2005 dataset and the Rich ERE 2015 event detection task.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Proposed Model</head><p>Let x = [w 0 , w 1 , ..., w n ] be a sentence. We first go over each word and phrase and heuristically extract a set of event candidates. The task is then to predict for each candidate given the sentence whether it is an event and, if so, its type. <ref type="figure" target="#fig_3">Figure 1</ref> demonstrates our proposed model for this task.</p><p>For each event candidate, which consists of a continuous span of texts [w i , ..., w j ], we split the sentence into three parts: the left context [w 0 , ..., w i−1 ], the event nugget candidate [w i , ..., w j ] and the right context [w j+1 , ..., w n ]. For instance, for event candidate "broken into" and given sentence "an unknown man had broken into a house last November"; <ref type="bibr">[an, unknown, man, had]</ref>, <ref type="bibr">[broken, into]</ref> and <ref type="bibr">[a, house, last, November]</ref> are the left context, the event nugget candidate and the right context respectively. For each part, we learn a separate RNN to produce a representation. Before feeding the data into the network, each word is represented as a real-valued vector that is formed by concatenating a word embedding with a branch embedding, which we describe below:</p><p>• Word embedding: Several studies have investigated methods for representing words as real-valued vectors in order to capture the hidden semantic and syntactic properties of words <ref type="bibr">(Collobert and Weston, 2008;</ref><ref type="bibr" target="#b534">Mikolov et al., 2013)</ref>. Such embeddings are typically learned from large unlabeled text corpora, consequently can serve as good initializations. In our work, we initialize the word embedding with the pretrained 300-diemension word2vec .</p><p>• Branch embedding: The relative position of a word to the current event nugget candidate may contain useful information toward how the word should be used or interpreted in identifying events. It is thus a common practice to include an additional embedding for each word that characterizes its relative position to the event nugget candidate. In this work, to reduce the complexity of our model and avoid overfitting, we only learn embeddings for three different positions: the left branch, the nugget branch and the right branch respectively. This is illustrated using three different colors in <ref type="figure" target="#fig_3">Figure 1</ref>. Now each word is represented as a real-valued vector, formed by concatenating its word and branch embeddings. The sequence of words in the left, nugget and right branches will each pass through a separate Recurrent Neural Network. For the left and nugget branches, we process the words from left to right, and use the opposite direction (from right to left) for the right context, thus the name Forward- <ref type="figure">Backward RNN (FBRNN)</ref>.</p><p>The output of each recurrent neural network is a fixed size representation of its input. We concatenate the representations from the three branches and pass it through a fully connected neural network with a softmax output node that classifies each event candidate as an event of specific type or a non-event. Note that in cases where an event candidate can potentially belong to multiple event types, one can replace the softmax output node with a set of binary output nodes or a sigmoid to allow for multi-label prediction for each event candidate.</p><p>To avoid overfitting, we use dropout <ref type="bibr" target="#b682">(Hinton et al., 2012;</ref><ref type="bibr">Srivastava et al., 2014)</ref> with rate of 0.5 for regularization. The weights of the recurrent neural networks as well as the fully connected neural network are learned by minimizing the log-loss on the training data via the Adam optimizer (Kingma and Ba, 2015) which performs better that other optimization methods like AdaDelta (Zeiler, 2012), AdaGrad <ref type="bibr" target="#b269">(Duchi et al., 2011)</ref>, RMSprop and SGD. During training, the word and branch embeddings are updated to learn effective representations for this specific task.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Experiments</head><p>In this section, we first empirically examine some design choices for our model and then compare the proposed model to the current state-of-the-art on two different event detection datasets.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Datasets, candidate generation and hyper-parameters</head><p>We experiment on two different corpora, ACE 2005 and Rich ERE 2015.</p><p>• ACE 2005: The ACE 2005 corpus is annotated with single-token event triggers and has eight event types and 33 event subtypes that, along with the "non-event" class, constitutes a 34-class classification problem. In our experiments we used the same train, development and test sets as the previous studies on this dataset <ref type="bibr">(Nguyen and Grishman, 2015;</ref><ref type="bibr">Li et al., 2013b)</ref>. Candidate generation for this corpus is based on a list of candidate event trigger words created from the training data and the PPDB paraphrase database. Given a sentence, we go over each token and extract the tokens that appear in this high-recall list as event candidates, which we then classify with our proposed FBRNN model.</p><p>• Rich ERE 2015: The Rich ERE 2015 corpus was released in the TAC 2015 competition and annotated at the nugget level, thus addressing phrasal event mentions. The Rich ERE 2015 corpus has nine event types and 38 event subtypes, forming a 39-class classification problem (considering "non-event" as an additional class). We utilized the same train and test sets that have been used in the TAC 2015 event nugget detection competition. A subset of the provided train set was set aside as our development set. To generate event nugget candidates, we first followed the same strategy that we used for the ACE 2005 dataset experiment to identify singletoken event candidates. We then expand the single-token event candidates using a heuristic rule based on POS tags.</p><p>There are a number of hyper-parameters for our model, including the dimension of the branch embedding, the number of recurrent layers in each RNN, the size of the RNN outputs, the dropout rates for training the networks. We tune these parameters using the development set.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Exploration of different design choices</head><p>We first design some experiments to evaluate the impact of the following design choices:  <ref type="bibr" target="#b293">(Nguyen, 2015)</ref> 71.9 63.8 67.6 FBRNN 66.8 68.0 67.4 <ref type="table" target="#tab_5">Table 2</ref>: Comparison with reported performance by event detection systems without using gold entity mentions and types on the ACE 2005 corpus.</p><p>i) Different RNN structures: LSTM and GRU are two popular recurrent network structures that are capable of extracting long-term dependencies in different ways. Here we compare their performance for event detection.</p><p>ii) The effect of branch embedding: A word can present different role and concept when it is in a nugget branch or other branches. Here we would examine the effect of including branch embedding. <ref type="table" target="#tab_10">Table 1</ref> shows the results of our model with different design choices on the development set of the Rich ERE 2015 corpus. We note that the performance of GRU is slightly better than that of LSTM. We believe this is because GRU is a less complex structure compared to LSTM, thus less prone to overfitting given the limited training data for our task. From the results we can also see that the branch embedding performs a crucial role for our model, producing significant improvement for both LSTM and GRU. Based on the results presented above, for the remaining experiments we will focus on GRU structure with branch embeddings.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Results on ACE 2005</head><p>Many prior studies employ gold-standard entity mentions and types from manual annotation,  which would not be available in reality during testing. <ref type="bibr">Nguyen and Grishman (2015)</ref> examined the performance of a number of traditional systems <ref type="bibr">(Li et al., 2013b)</ref> in a more realistic setting, where entity mentions and types are acquired from an automatic high-performing name tagger and information extraction system. In <ref type="table" target="#tab_5">Table 2</ref> we compare the performance of our system with these results reported by <ref type="bibr">Nguyen and Grishman (2015)</ref>.</p><p>We first note that the deep learning methods (CNN and FBRNN) achieve significantly better F1 performance compared to traditional methods using manually engineered features (both local and global). Compared to CNN, our FBRNN model achieved better recall but the precision is lower. For the overall F1 measure, our model is comparable with the CNN model. <ref type="table" target="#tab_6">Table 3</ref> reports the test performance of our model and shows that it is competitive with the topranked results obtained in the TAC 2015 event nugget detection competition. It is interesting to note that FBRNN is again winning in recall, but losing in precision, a phenomenon that is consistently observed in both corpora and a topic worth a closer look for future work.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">Results on Rich ERE 2015</head><p>Finally, in Rich ERE test data, approximately 9% of the events are actually multi-labeled. Our current model uses softmax output layer and is thus innately incapable of making multi-label predictions. Despite this limitation, FBRNN achieved competitive result on Rich ERE with only 0.8% difference from the best reported system in the TAC 2015 competition.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Conclusions</head><p>This paper proposes a novel language-independent event detection method based on RNNs which can automatically extract effective features from raw text to detect event nuggets. We conducted two experiments to compare FBRNN with the state-ofthe-art event detection systems on the ACE 2005 and Rich ERE 2015 corpora. These experiments demonstrate that FBRNN achieves competitive results compared to the current state-of-the-art. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>References</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Abstract</head><p>We describe the Iraq Body Count Corpus (IBC-C) dataset, the first substantial armed conflict-related dataset which can be used for conflict analysis. IBC-C provides a ground-truth dataset for conflict specific named entity recognition, slot filling, and event de-duplication. IBC-C is constructed using data collected by the Iraq Body Count project which has been recording incidents from the ongoing war in Iraq since 2003. We describe the dataset's creation, how it can be used for the above three tasks and provide initial baseline results for the first task (named entity recognition) using Hidden Markov Models, Conditional Random Fields, and Recursive Neural Networks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Many reports about armed conflict related incidents are published every day. However, these reports on the deaths and injuries of civilians and combatants often get forgotten or go unnoticed for long periods of time. Automatically extracting casualty counts from such reports would help better track ongoing conflicts and understand past ones. One popular approach of discovering incidents is to identify them from textual reports and extract casualty, and other, information from them. This can either be done by hand or automatically. The Iraq Body Count (IBC) project has been directly recording casualties since 2003 for the ongoing conflict in Iraq <ref type="bibr" target="#b106">(IBC, 2016;</ref><ref type="bibr" target="#b105">Hicks et al., 2011)</ref>. IBC staff collect reports, link them to unique incidents, extract casualty information, and save the information on a per incident basis as can be seen in <ref type="table" target="#tab_5">Table 2</ref>.</p><p>Direct recording by hand is a slow process and notable efforts to do so have tended to lag behind the present. Information extraction systems capable of automating this process must explicitly or implicitly successfully solve three tasks: (1) find and extract casualty information in reports (2) detect events mentioned in reports (3) deduplicate detected events into unique events which we call incidents. The three tasks correspond to named entity recognition, slot filling, and de-duplication.</p><p>In this work we introduce the report based IBC-C dataset. 1 Each report can contain one or more sections; each section, one or more sentences; each sentence, one or more words. Each word is tagged with one of nine entity tags in the insideoutside-beginning (IOB) style. A visual representation of the dataset can be seen in <ref type="figure" target="#fig_3">Figure 1</ref> and its statistics in <ref type="table" target="#tab_10">Table 1</ref>.</p><p>To the best of our knowledge apart from the significantly smaller MUC-3 and MUC-4 datasets (which aren't casualty-specific) there are no other publicly available datasets made specifically for tasks (1), (2) or (3). The IBC-C dataset can be used to train supervised models for all three tasks.</p><p>We provide baseline results for task (1) which we posit as a sequence-classification problem and solve using an HMM, a CRF, and an RNN.</p><p>Since the 1990s the conflict analysis and NLP/IE communities have diverged. With the IBC-C dataset we hope to bring the two communities closer again. The IBC-C dataset visualised. A report is split into one or more non overlapping sections. A section is comprised of sentences which are comprised of words. Each section is linked to exactly one incident which in turn can be linked to one or more sections.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>ties.</head><p>The 1990s saw a series of message understanding conferences (MUCs) of which MUC-3 and MUC-4 are closely related to our work and contain reports of terrorist incidents in Central and South America. MUC data is most often used for slot filling and although MUC-3 and MUC-4 contain more slots than IBC-C they are at the same time much smaller (MUC4 contains 1,700 reports) and cannot be used for incident de-duplication.</p><p>Although various ACE, CoNNL, and TAC-KBP tasks contain within them conflict-related reports, none of them are specific to conflict and haven't been studied for conflict-related information extraction specifically.</p><p>Studies more directly related to our dataset include work by Tanev and Piskorski <ref type="bibr">(Tanev et al., 2008)</ref> who use pattern matching to count casualties. They report a 93% accuracy on counting the wounded. However, they have access to only 29 unique conflict events. Other non-casualty conflict-related work in the domain also suffers from a lack of data, for example, <ref type="bibr">(King and Lowe, 2003)</ref> only deal with 711 reports.</p><p>Despite work in the NLP and IE communities, the conflict analysis community is still reliant on   <ref type="bibr" target="#b101">(Chojnacki et al., 2012)</ref>, UCDP <ref type="bibr" target="#b103">(Gleditsch et al., 2002)</ref>, and GTD <ref type="bibr" target="#b104">(GTD, 2015)</ref>.</p><p>To the best of our knowledge there are no efforts to fully automate casualty counting. However, efforts using NLP/IE tools to automate incident detection do exist but their ability to de-deduplicate incidents has been called into question <ref type="bibr">(Weller and McCubbins, 2014)</ref>.</p><p>Three notable such efforts originating in the conflict analysis community are GDELT (Leetaru and Schrodt, 2013), ICEWS (Obrien, 2010), and OEDA <ref type="bibr">(Schrodt, 2016)</ref>. All three use pattern matching software such as TABARI <ref type="bibr">(Schrodt, 2001)</ref> and to categorise reports using the CAMEO coding scheme <ref type="bibr">(Schrodt et al., 2008)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Creating the IBC-C Dataset</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Preprocessing</head><p>The Iraq Body Count project (IBC) has been recording conflict-related incidents from the Iraq war since 2003. An incident is a unique event related to war or other forms of violence which led to the death or injury of people. An example can be seen in <ref type="table" target="#tab_5">Table 2</ref>.</p><p>The recording of incidents by the IBC works as follows: IBC staff first collect relevant reports before highlighting sections of them which they deem relevant to individual incidents. Parts of the report outside the highlighted sections are discarded. Sections can be seen in <ref type="figure" target="#fig_3">Figure 1</ref>. Because of the way IBC staff highlight sections there are no overlapping sections in the IBC-C dataset. Events are then recognised from the highlighted sections and de-duplicated into incidents. A final descrip-  tion of the incident (e.g. death and injury counts, location and date) is agreed upon after multiple rounds of human checking.</p><p>In the preprocessing step we gathered all incidents which occurred between March 20th, 2003 and December 31st, 2013. We removed spurious incidents (e.g. where the minimum number killed is larger than the maximum number killed) and cleaned the section text by removing all formatting and changing all written-out numbers into their numeric form (e.g. 'three' to 3).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Annotation</head><p>Using the information extracted by the IBC (see <ref type="table" target="#tab_5">Table 2</ref>) we annotated each section word with one of ten tags: KNUM and INUM for numbers representing the number killed and injured respectively; KSUB and ISUB for named individuals were killed or injured; KOTHER and IOTHER for unnamed people who were killed or injured (for example "The doctor was injured yesterday."); LOCATION for the location in which an incident occurred; WEAPON for any weapons used in an attack; DATE for words which identify when the incident happened; and, O for all other words.</p><p>Our data generation process can be thought of as a form of distant supervision (Mintz et al., 2009) where we use agreed upon knowledge about an incident to label words contained within its sections instead of having hand-labeled individual words. This inevitably introduces errors which we try to mitigate using a filtration step where we remove ambiguous data. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Filtration</head><p>Simply annotating words based on the information in <ref type="table" target="#tab_5">Table 2</ref> can lead to wrong annotations. For example, if two people were recorded as having died in an incident, then, if another number two appears in the same sentence, this might lead to a wrong annotation. The sentence, "2 civilians were killed after 2 rockets hit the compound" could lead to the second '2' being annotated as a KNUM. The actual cardinality of a number makes little difference to a sequence classifier compared to the difference a misannotated number would make. To minimise such misannotations we remove sentences and reports which do not pass all filtration criteria. Our filtration criteria consist of boolean functions over sentences, sections and incidents which return false if a test isn't passed.</p><p>The goal of filtration is to remove as much ambiguously labelled data as possible without biasing against any particular set of linguistic forms. There is thus a tradeoff which must be struck between linguistic richness and the quality of annotation.</p><p>In our case we found that simple combinations of pattern matching and semantic functions, as in 3, worked well. No syntactic functions were used.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.1">Incident Filtration</head><p>Incidents are filtered using a single criterion: if the minimum number of people killed or injured does not equal the maximum number of people killed or injured, respectively, (Table 2) then the incident is removed. We do this so as to minimise any ambiguity in our named entity tagging (the only task for which we provide baseline results). This has the adverse effect of removing any incidents where reports mention different casualty counts. To compile a dataset which disregards this criterion, or considers a permissible window of casual-   <ref type="table" target="#tab_6">Table 3</ref>: Filtration criteria. An example of a set of boolean functions (columns one through five) applied to sentences to filter out ambiguous KNUM annotations. Sentences which we wish to allow are identified by a '+' in the toConsider column. Sentence counts are given in the last column. Only rows with non-zero counts are shown. Shaded rows indicate sentences which are ambiguous are shaded and identified by a '-'. We show only the KNUM table due to lack of space.</p><p>ties, a parameter in our dataset generating program may be changed.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.2">Sentence Filtration</head><p>Filtering sentences is by far the hardest step. It is here where we must be careful to not bias against any linguistic forms. A separate set of boolean functions are applied to each sentence for the KNUM and INUM entity tags. An example for the KNUM tag can be seen in <ref type="table" target="#tab_6">Table 3</ref>. Every sentence passes through four boolean functions (the first four columns) and is then labeled as either having passed or failed the test (fifth column). The fifth column was decided upon by us in advance. In the case of <ref type="table" target="#tab_6">Table 3</ref>: hasKNUM indicates whether the sentence contains a word tagged as KNUM; isKillSentence indicates whether any of its words are connected to death or killing (by matching them against a list of predefined words); hasOneTaggedAsKNUM indicates whether the number '1' is tagged as a KNUM (remember that we convert written out numbers such as 'three' to '3' and that 'one', and thus '1', can also be a pronoun); hasNumber indicates whether a sentence has a number; and, otherKNUMsInSection indicates whether there are other words tagged as KNUM in the section.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.3">Report Filtration</head><p>Report filtering is simple and again done using only one rule. If any sentence a report contains fails to pass a single sentence-level test, then the whole report is removed.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">Tasks</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4.1">Named Entity Recognition</head><p>Each word in the IBC-C dataset is tagged with one of nine (excluding O) entity tags as can be seen in <ref type="table" target="#tab_10">Table 1</ref> which can be thought of as subsets of more common named entity tags such as person or location. The dataset can be used to train a supervised NER model for conflict-specific named entity tags. This is important for relationship extraction which relies on good named entity tags.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4.2">Slot Filling and Relationship Extraction</head><p>Each IBC-C event can be thought of as a 9-slot event template where each slot is named after an entity tag. The important thing to keep in mind is that a report may contain more than one section so just correctly recognising the entities isn't enough to solve the slot filling task. Instead, if a report mentions two events then two separate templates must be created and their slots filled.</p><p>A common sub-problem of slot filling is relationship extraction. Because we know which incident every section refers to, generating groundtruth relationships is trivial because we may be sure that an entity which appears in one of the sections is related to every other entity in that same section. For example, finding a KSUB and a LOCATION means that we can build a killed in(KSUB, LOCATION) relationship.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4.3">Event De-duplication</head><p>Since the IBC-C dataset preserves the links between sections and incidents it may be used as a ground-truth training set for training event deduplication models.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Experiments</head><p>Baseline results were computed for the named entity recognition task using an 80:20 tag split across sentences (we ignore report or section boundaries). We compare three different sequenceclassification models as seen in <ref type="table" target="#tab_42">Table 4</ref>: a Hidden Markov Model <ref type="bibr">(Zhou and Su, 2002</ref>), a Conditional Random Field <ref type="bibr">(McCallum and Li, 2003)</ref>, and a Elman-style Recursive Neural Network similar to the one used in <ref type="bibr">(Mesnil et al., 2013)</ref>. For the HMM we use bigram features in combination with the current word and the current base named entity features 2 . We trained the HMM in CRF form using LBFGS.</p><p>For the CRF we find that using bigram features and a 13-word window, across words and base named entities, gives us the best result. We train the CRF using LBFGS. All CRF training, including the HMM, was done using CRFSuite <ref type="bibr">(Okazaki, 2007)</ref>.</p><p>For the Elman-style recurrent network we use randomly initialised 100 dimensional word vectors as input, the network has 100 hidden units, and we use a 13-word context window again. The RNN was implemented using Theano <ref type="bibr" target="#b100">(Bastien et al., 2012)</ref>. We train the RNN using stochastic gradient descent on a single GPU.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Evaluation</head><p>The first thing which strikes us is how low the ISUB scores are. The CRF returns a recall score of 0.24. At the same time, the precision is relatively high at 0.89. Low recall indicates a lot of false negative classifications -i.e. there were many injured people who were mistakingly tagged as uninjured. A high precision rate means a low false positive rate -i.e. most uninjured people were correctly tagged as uninjured. In short, the classifier was too generous with tagging people as having been injured. Looking at the dataset we realise that in contrast to KSUBS, words which we associate with injury such as "wounded" or "injured" are often very far away from an ISUB. Increasing the window size with the CRF didn't help (such large features are often never expressed during the test phase).</p><p>Low recall scores across multiple tags indicate that long-distance dependencies determine a word's classification. K/INUM recall is exceptionally high because K/INUMs are usually surrounded by words such as "killed". We were surprised to see the RNN perform relatively poorly and expected it to be able to factor in long-distance dependencies. We believe this has more to do with our hyper-parameter settings than deficiencies in the actual model.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Conclusion</head><p>We present IBC-C, a new dataset for armed conflict analysis which can be used for entity recognition, slot filling, and incident de-duplication.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Acknowledgements</head><p>We would like to thank members of the IBC, especially Hamit Dardagan for his help with procuring and helping us understand the data collected by the IBC. We would also like to thank Gregory Chockler, Mike Spagat, and Andrew Evans for their insightful discussions and suggestions. This work was partially supported by EPSRC grant EP/K033344/1 ('Mining the Network Behaviour of Bots'). </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Abstract</head><p>Uncovering thematic structures of SNS and blog posts is a crucial yet challenging task, because of the severe data sparsity induced by the short length of texts and diverse use of vocabulary. This hinders effective topic inference of traditional LDA because it infers topics based on document-level co-occurrence of words. To robustly infer topics in such contexts, we propose a latent concept topic model (LCTM). Unlike LDA, LCTM reveals topics via co-occurrence of latent concepts, which we introduce as latent variables to capture conceptual similarity of words. More specifically, LCTM models each topic as a distribution over the latent concepts, where each latent concept is a localized Gaussian distribution over the word embedding space. Since the number of unique concepts in a corpus is often much smaller than the number of unique words, LCTM is less susceptible to the data sparsity. Experiments on the 20Newsgroups show the effectiveness of LCTM in dealing with short texts as well as the capability of the model in handling held-out documents with a high degree of OOV words.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Probabilistic topic models such as Latent Dirichlet allocation (LDA) , are widely used to uncover hidden topics within a text corpus. LDA models each document as a mixture of topics where each topic is a distribution over words. In essence, LDA reveals latent topics in a corpus by implicitly capturing document-level word cooccurrence patterns <ref type="bibr">(Wang and McCallum, 2006)</ref>.</p><p>In recent years, Social Networking Services and blogs have become increasingly prevalent due to the explosive growth of the Internet. Uncovering the themantic structures of these posts is crucial for tasks like market review, trend estimation <ref type="bibr" target="#b107">(Asur and Huberman, 2010)</ref> and so on. However, compared to more conventional documents, such as news articles and academic papers, analyzing the thematic content of blog posts can be challenging, because of their typically short length and the use of diverse vocabulary by various authors. These factors can substantially decrease the chance of topically related words co-occurring in the same post, which in turn hinders effective topic inference in conventional topic models. Additionally, sometimes small corpus size can further exacerbate topic inference, since word co-occurrence statistics becomes more sparse as the number of documents decreases.</p><p>Recently, word embedding models, such as word2vec  and GloVe  have gained much attention with their ability to form clusters of conceptually similar words in the embedding space. Inspired by this, we propose a latent concept topic model (LCTM) that infers topics based on documentlevel co-occurrence of references to the same concept. More specifically, we introduce a new latent variable, termed a latent concept to capture conceptual similarity of words, and redefine each topic as a distribution over the latent concepts. Each latent concept is then modeled as a localized Gaussian distribution over the embedding space. This is illustrated in <ref type="figure" target="#fig_3">Figure 1</ref>, where we denote the centers of the Gaussian distributions as concept vectors. We see that each concept vector captures a representative concept of surrounding words, and the Gaussian distributions model the small variation between the latent concepts and the actual use of words. Since the number of unique concepts that are referenced in a corpus is often much smaller than the number of unique words, we expect topically-related latent concepts to co-occur many times, even in short texts with diverse usage of words. This in turn promotes topic inference in LCTM.</p><p>LCTM further has the advantage of using continuous word embedding. Traditional LDA assumes a fixed vocabulary of word types. This modeling assumption prevents LDA from handling out of vocabulary (OOV) words in held-out documents. On the other hands, since our topic model operates on the continuous vector space, it can naturally handle OOV words once their vector representation is provided.</p><p>The main contributions of our paper are as follows: We propose LCTM that infers topics via document-level co-occurrence patterns of latent concepts, and derive a collapsed Gibbs sampler for approximate inference. We show that LCTM can accurately represent short texts by outperforming conventional topic models in a clustering task. By means of a classification task, we furthermore demonstrate that LCTM achieves superior performance to other state-of-the-art topic models in handling documents with a high degree of OOV words.</p><p>The remainder of the paper is organized as follows: related work is summarized in Section 2, while LCTM and its inference algorithm are presented in Section 3. Experiments on the 20News-groups are presented in Section 4, and a conclusion is presented in Section 5.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Related Work</head><p>There have been a number of previous studies on topic models that incorporate word embeddings. The closest model to LCTM is Gaussian LDA <ref type="bibr" target="#b576">(Das et al., 2015)</ref>, which models each topic as a Gaussian distribution over the word embedding space. However, the assumption that topics are unimodal in the embedding space is not appropriate, since topically related words such as 'neural' and 'networks' can occur distantly from each other in the embedding space. <ref type="bibr" target="#b293">Nguyen et al. (2015)</ref> proposed topic models that incorporate information of word vectors in modeling topic-word distributions. Similarly, Petterson et al. <ref type="bibr">(Petterson et al., 2010)</ref> exploits external word features to improve the Dirichlet prior of the topic-word distributions. However, both of the models cannot handle OOV words, because they assume fixed word types.</p><p>Latent concepts in LCTM are closely related to 'constraints' in interactive topic models (ITM) <ref type="bibr" target="#b180">(Hu et al., 2014)</ref>. Both latent concepts and constraints are designed to group conceptually similar words using external knowledge in an attempt to aid topic inference. The difference lies in their modeling assumptions: latent concepts in LCTM are modeled as Gaussian distributions over the embedding space, while constraints in ITM are sets of conceptually similar words that are interactively identified by humans for each topic. Each constraint for each topic is then modeled as a multinomial distribution over the constrained set of words that were identified as mutually related by humans. In Section 4, we consider a variant of ITM, whose constraints are instead inferred using external word embeddings.</p><p>As regards short texts, a well-known topic model is Biterm Topic Model (BTM) <ref type="bibr">(Yan et al., 2013)</ref>. BTM directly models the generation of biterms (pairs of words) in the whole corpus. However, the assumption that pairs of cooccurring words should be assigned to the same topic might be too strong .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Latent Concept Topic Model</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Generative Model</head><p>The primary difference between LCTM and the conventional topic models is that LCTM describes the generative process of word vectors in documents, rather than words themselves.</p><p>Suppose α and β are parameters for the Dirichlet priors and let v d,i denote the word embedding for a word type w d,i . The generative model for LCTM is as follows.  2. For each latent concept c</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">For each topic</head><formula xml:id="formula_163">k (a) Draw a topic concept distribution ϕ k ∼ Dirichlet(β).</formula><formula xml:id="formula_164">(a) Draw a concept vector µ c ∼ N (µ, σ 2 0 I). 3. For each document d (a) Draw a document topic distribution θ d ∼ Dirichlet(α). (b) For the i-th word w d,i in document d i. Draw its topic assignment z d,i ∼ Categorical(θ d ). ii. Draw its latent concept assignment c d,i ∼ Categorical(ϕ z d,i ). iii. Draw a word vector v d,i ∼ N (µ c d,i , σ 2 I).</formula><p>The graphical models for LDA and LCTM are shown in <ref type="figure" target="#fig_8">Figure 2</ref>. Compared to LDA, LCTM adds another layer of latent variables to indicate the conceptual similarity of words.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Posterior Inference</head><p>In our application, we observe documents consisting of word vectors and wish to infer posterior distributions over all the hidden variables. Since there is no analytical solution to the posterior, we derive a collapsed Gibbs sampler to perform approximate inference. During the inference, we sample a latent concept assignment as well as a topic assignment for each word in each document as follows:</p><formula xml:id="formula_165">p(z d,i = k | c d,i = c, z −d,i , c −d,i , v) ∝ ( n −d,i d,k + α k ) · n −d,i k,c + βc n −d,i k,· + ∑ c ′ β c ′ ,<label>(1)</label></formula><formula xml:id="formula_166">P (c d,i = c | z d,i = k, v d,i , z −d,i , c −d,i , v −d,i ) ∝ ( n −d,i k,c + βc ) · N (v d,i |µ c , σ 2 c I),<label>(2)</label></formula><p>where n d,k is the number of words assigned to topic k in document d, and n k,c is the number of words assigned to both topic k and latent concept c. When an index is replaced by '·', the number is obtained by summing over the index. The superscript −d,i indicates that the current assignments of z d,i and c d,i are ignored. N (·|µ, Σ) is a multivariate Gaussian density function with mean µ and covariance matrix Σ. µ c and σ 2 c in Eq. (2) are parameters associated with the latent concept c and are defined as follows:</p><formula xml:id="formula_167">µ c = 1 σ 2 + n −d,i ·,c σ 2 0   σ 2 µ + σ 2 0 · ∑ (d ′ ,i ′ )∈A −d,i c v d ′ ,i ′   ,<label>(3)</label></formula><formula xml:id="formula_168">σ 2 c = ( 1 + σ 2 0 n −d,i ·,c σ 2 0 + σ 2 ) σ 2 ,<label>(4)</label></formula><p>where <ref type="bibr">Murphy, 2012)</ref>. Eq. <ref type="formula" target="#formula_0">(1)</ref> is similar to the collapsed Gibbs sampler of LDA <ref type="bibr" target="#b589">(Griffiths and Steyvers, 2004)</ref> except that the second term of Eq. <ref type="formula" target="#formula_0">(1)</ref> is concerned with topic-concept distributions. Eq. (2) of sampling latent concepts has an intuitive interpretation: the first term encourages concept assignments that are consistent with the current topic assignment, while the second term encourages concept assignments that are consistent with the observed word. The Gaussian variance parameter σ 2 acts as a trade-off parameter between the two terms via σ 2 c . In Section 4.2, we study the effect of σ 2 on document representation.</p><formula xml:id="formula_169">A −d,i c ≡ {(d ′ , i ′ ) | c d ′ ,i ′ = c ∧ (d ′ , i ′ ) ̸ = (d, i)} (</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Prediction of Topic Proportions</head><p>After the posterior inference, the posterior means of {θ d }, {ϕ k } are straightforward to calculate:</p><formula xml:id="formula_170">θ d,k = n d,k + α k n d,· + ∑ k ′ α k ′ , ϕ k,c = n k,c + βc n k,· + ∑ c ′ β c ′ .<label>(5)</label></formula><p>Also posterior means for {µ c } are given by Eq. (3). We can then use these values to predict a topic proportion θ dnew of an unseen document d new using collapsed Gibbs sampling as follows:</p><formula xml:id="formula_171">p(z dnew,i = k | v dnew,i , v −dnew,i , z −dnew,i , ϕ, µ) ∝ ( n −dnew,i dnew,k + α k ) · ∑ c ϕ k,c N (v dnew,i |µ c , σ 2 c ) ∑ c ′ N (v dnew,i |µ c ′ , σ 2 c ′ ) .<label>(6)</label></formula><p>The second term of Eq. (6) is a weighted average of ϕ k,c with respect to latent concepts. We see that more weight is given to the concepts whose corresponding vectors µ c are closer to the word vector v dnew,i . This to be expected because statistics of nearby concepts should give more information about the word. We also see from Eq. (6) that the topic assignment of a word is determined by its embedding, instead of its word type. Therefore, LCTM can naturally handle OOV words once their embeddings are provided.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">Reducing the Computational Complexity</head><p>From Eqs. <ref type="formula" target="#formula_0">(1)</ref> and <ref type="formula" target="#formula_1">(2)</ref>, we see that the computational complexity of sampling per word is O(K + SD), where K, S and D are numbers of topics, latent concepts and embedding dimensions, respectively. Since K ≪ S holds in usual settings, the dominant computation involves the sampling of latent concept, which costs O(SD) computation per word. However, since LCTM assumes that Gaussian variance σ 2 is relatively small, the chance of a word being assigned to distant concepts is negligible. Thus, we can reasonably assume that each word is assigned to one of M ≪ S nearest concepts. Hence, the computational complexity is reduced to O(M D). Since concept vectors can move slightly in the embedding space during the inference, we periodically update the nearest concepts for each word type.</p><p>To further reduce the computational complexity, we can apply dimensional reduction algorithms such as PCA and t-SNE (Van der Maaten and Hinton, 2008) to word embeddings to make D smaller. We leave this to future work.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Experiments</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Datasets and Models Description</head><p>In this section, we study the empirical performance of LCTM on short texts. We used the 20Newsgroups corpus, which consists of discussion posts about various news subjects authored by diverse readers. Each document in the corpus is tagged with one of twenty newsgroups. Only posts with less than 50 words are extracted for training datasets. For external word embeddings, we used 50-dimensional GloVe 1 that were pre-trained on Wikipedia. The datasets are summarized in Table 1. See appendix A for the detail of the dataset preprocessing.</p><p>We compare the performance of the LCTM to the following six baselines:</p><p>• LFLDA <ref type="bibr" target="#b293">(Nguyen et al., 2015)</ref>, an extension of Latent Dirichlet Allocation that incorporates word embeddings information. • LFDMM <ref type="bibr" target="#b293">(Nguyen et al., 2015)</ref>, an extension of Dirichlet Multinomial Mixtures that incorporates word embeddings information.</p><p>• nI-cLDA, non-interactive constrained Latent Dirichlet Allocatoin, a variant of ITM <ref type="bibr" target="#b180">(Hu et al., 2014)</ref>, where constraints are inferred by applying k-means to external word embeddings. Each resulting word cluster is then regarded as a constraint. See appendix B for the detail of the model.</p><p>• GLDA <ref type="bibr" target="#b576">(Das et al., 2015)</ref>, Gaussian LDA.</p><p>• BTM <ref type="bibr">(Yan et al., 2013)</ref>, Biterm Topic Model.</p><p>• LDA .</p><p>In all the models, we set the number of topics to be 20. For LCTM (resp. nI-ITM), we set the number of latent concepts (resp. constraints) to be 1000. See appendix C for the detail of hyperparameter settings.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Document Clustering</head><p>To demonstrate that LCTM results in a superior representation of short documents compared to the baselines, we evaluated the performance of each model on a document clustering task. We used a learned topic proportion as a feature for each document and applied k-means to cluster the documents. We then compared the resulting clusters to the actual newsgroup labels. Clustering performance is measured by Adjusted Mutual Information (AMI) . Higher AMI indicates better clustering performance. <ref type="figure" target="#fig_6">Figure 3</ref> illustrates the quality of clustering in terms of Gaussian variance parameter σ 2 . We see that setting σ 2 = 0.5 consistently obtains good clustering performance for all the datasets with varying sizes. We therefore set σ 2 = 0.5 in the later evaluation. <ref type="figure" target="#fig_15">Figure 4</ref> compares AMI on four topic models. We see that LCTM outperforms the topic models without word embeddings. Also, we see that LCTM performs comparable to LFLDA and nl-cLDA, both of which incorporate information of word embeddings to aid topic inference. However, as we will see in the next section, LCTM can  better handle OOV words in held-out documents than LFLDA and nl-cLDA do.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Representation of Held-out Documents with OOV words</head><p>To show that our model can better predict topic proportions of documents containing OOV words than other topic models, we conducted an experiment on a classification task. In particular, we infer topics from the training dataset and predicted topic proportions of held-out documents using collapsed Gibbs sampler. With the inferred topic proportions on both training dataset and held-out documents, we then trained a multi-class classifier (multi-class logistic regression implemented in sklearn 2 python module) on the training dataset and predicted newsgroup labels of the held-out documents. We compared classification accuracy using LFLDA, nI-cLDA, LDA, GLDA, LCTM and a variant of LCTM (LCTM-UNK) that ignores OOV in the held-out documents. A higher classification accuracy indicates a better representation of unseen documents.  <ref type="table" target="#tab_5">Table 2</ref>: Proportions of OOV words and classification accuracy in the held-out documents.</p><p>of the held-out documents. We see that LCTM-UNK outperforms other topic models in almost every setting, demonstrating the superiority of our method, even when OOV words are ignored. However, the fact that LCTM outperforms LCTM-UNK in all cases clearly illustrates that LCTM can effectively make use of information about OOV to further improve the representation of unseen documents. The results show that the level of improvement of LCTM over LCTM-UNK increases as the proportion of OOV becomes greater.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Conclusion</head><p>In this paper, we have proposed LCTM that is well suited for application to short texts with diverse vocabulary. LCTM infers topics according to document-level co-occurrence patterns of latent concepts, and thus is robust to diverse vocabulary usage and data sparsity in short texts. We showed experimentally that LCTM can produce a superior representation of short documents, compared to conventional topic models. We additionally demonstrated that LCTM can exploit OOV to improve the representation of unseen documents. Although our paper has focused on improving performance of LDA by introducing the latent concept for each word, the same idea can be readily applied to other topic models that extend LDA. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A Dataset Preprocessing</head><p>We preprocessed the 20Newsgroups as follows:</p><p>We downloaded bag-of-words representation of the corpus available online 3 . Stop words 4 and words that were not covered in the GloVe were both removed. After the preprocessing, we extracted short texts containing less than 50 words for training datasets. We created three training datasets with varying numbers of documents, and one held-out dataset. Each dataset was balanced in terms of the proportion of documents belonging to each newsgroup.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B Non-Interactive Contained LDA (nI-cLDA)</head><p>We describe nI-cLDA, a variant of interactive topic model <ref type="bibr" target="#b180">(Hu et al., 2014)</ref>. nl-cLDA is noninteractive in the sense that constraints are inferred from the word embeddings instead of being interactively identified by humans. In particular, we apply k-means to word embeddings to cluster words. Each resulting cluster is then regarded as a constraint. In general, constraints can be different from topic to topic. Let r k,w be a constraint of topic k which word w belongs to. The generative process of nl-cLDA is as follows. It is essentially the same as <ref type="bibr" target="#b180">(Hu et al., 2014)</ref> 1. For each topic k</p><formula xml:id="formula_172">(a) Draw a topic constraint distribution ϕ k ∼ Dirichlet(β). (b) For each constraint s of topic k i. Draw a constraint word distribution π k,s ∼ Dirichlet(γ). 2. For each document d (a) Draw a document topic distribution θ d ∼ Dirichlet(α). (b) For the i-th word w d,i in document d i. Draw its topic assignment z d,i ∼ Categorical(θ d ). ii. Draw its constraint l d,i ∼ Categorical(ϕ z d,i ). iii. Draw a word w d,i ∼ Categorical(π z d,i ,l d,i ).</formula><p>Let V be the set of vocabulary. We note that π k,s is a multinomial distribution over W k,s , which is a subset of V , defined as W k,s ≡ {w ∈ V | r k,w = s}. W k,s represents a constrained set of words that are conceptually related to each other under topic k.</p><p>In our application, we observe documents and constraints for each topic, and wish to infer posterior distributions over all the hidden variables. We apply collapsed Gibbs sampling for the approximate inference. For the detail of the inference, see <ref type="bibr" target="#b180">(Hu et al., 2014)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C Hyperparameter Settings</head><p>For all the topic models, we used symmetric Dirichlet priors. The hyperparameters were set as follows: for our model (LCTM and LCTM-UNK), nI-cLDA and LDA, we set α = 0.1 and β = 0.01. For nl-cLDA, we set the parameter of Dirichlet prior for constraint-word distribution (γ in appendix B) as 0.1. Also for our model, we set, σ 2 0 = 1.0 and µ to be the average of word vectors. We randomly initialized the topic assignments in all the models. Also, we initialized the latent concept assignments using k-means clustering on the word embeddings. The k-means clustering was implemented using sklearn 5 python module. We set M (number of nearest concepts to sample from) to be 300, and updated the nearest concepts every 5 iterations. For LFLDA, LFDMM, BTM and Gaussian LDA, we used the original implementations available online 6 and retained the default hyperparameters.</p><p>We ran all the topic models for 1500 iterations for training, and 500 iterations for predicting heldout documents.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>There is an accumulation of evidence that the use of dense distributional lexical representations, known as word embeddings, often supports better performance on a range of NLP tasks . Consequently, word embeddings have been commonly used in the last few years for lexical similarity tasks and as features in multiple, syntactic and semantic, NLP applications.</p><p>However, keeping embedding vectors for hundreds of thousands of words for repeated use could take its toll both on storing the word vectors on disk and, even more so, on loading them into memory. For example, for 1 million words, loading 200 dimensional vectors takes up to 1.6 GB memory on a 64-bit system. Considering applications that make use of billions of tokens and multiple languages, size issues impose significant limitations on the practical use of word embeddings. This paper presents the question of whether it is possible to significantly reduce the memory needs for the use and training of word embeddings.</p><p>Specifically, we ask "what is the impact of representing each dimension of a dense representation with significantly fewer bits than the standard 64 bits?" Moreover, we investigate the possibility of directly training dense embedding vectors using significantly fewer bits than typically used.</p><p>The results we present are quite surprising. We show that it is possible to reduce the memory consumption by an order of magnitude both when word embeddings are being used and in training. In the first case, as we show, simply truncating the resulting representations after training and using a smaller number of bits (as low as 4 bits per dimension) results in comparable performance to the use of 64 bits. Moreover, we provide two ways to train existing algorithms ) when the memory is limited during training and show that, here, too, an order of magnitude saving in memory is possible without degrading performance. We conduct comprehensive experiments on existing word and phrase similarity and relatedness datasets as well as on dependency parsing, to evaluate these results. Our experiments show that, in all cases and without loss in performance, 8 bits can be used when the current standard is 64 and, in some cases, only 4 bits per dimension are sufficient, reducing the amount of space required by a factor of 16. The truncated word embeddings are available from the papers web page at https://cogcomp.cs.illinois. edu/page/publication_view/790.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Related Work</head><p>If we consider traditional cluster encoded word representation, e.g., Brown clusters , it only uses a small number of bits to track the path on a hierarchical tree of word clusters to represent each word. In fact, word embedding generalized the idea of discrete clustering representation to continuous vector representation in language models, with the goal of improving the continuous word analogy prediction and generalization ability . However, it has been proven that Brown clusters as discrete features are even better than continuous word embedding as features for named entity recognition tasks ). Guo et al.  further tried to binarize embeddings using a threshold tuned for each dimension, and essentially used less than two bits to represent each dimension. They have shown that binarization can be comparable to or even better than the original word embeddings when used as features for named entity recognition tasks. Moreover,  showed that imposing sparsity constraints over the embedding vectors can further improve the representation interpretability and performance on several word similarity and text classification benchmark datasets. These works indicate that, for some tasks, we do not need all the information encoded in "standard" word embeddings. Nonetheless, it is clear that binarization loses a lot of information, and this calls for a systematic comparison of how many bits are needed to maintain the expressivity needed from word embeddings for different tasks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Value Truncation</head><p>In this section, we introduce approaches for word embedding when the memory is limited. We truncate any value x in the word embedding into an n bit representation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Post-processing Rounding</head><p>When the word embedding vectors are given, the most intuitive and simple way is to round the numbers to their n-bit precision. Then we can use the truncated values as features for any tasks that word embedding can be used for. For example, if we want to round x to be in the range of [−r, r], a simple function can be applied as follows.</p><formula xml:id="formula_173">R d (x, n) = x if x ≤ x ≤ x + 2 x + if x + 2 &lt; x ≤ x +</formula><p>(1) where = 2 1−n r. For example, if we want to use 8 bits to represent any value in the vectors, then we only have 256 numbers ranging from -128 to 127 for each value. In practice, we first scale all the values and then round them to the 256 numbers.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Training with Limited Memory</head><p>When the memory for training word embedding is also limited, we need to modify the training algorithms by introducing new data structures to reduce the bits used to encode the values. In practice, we found that in the stochastic gradient descent (SGD) iteration in word2vec algorithms , the updating vector's values are often very small numbers (e.g., &lt; 10 −5 ). In this case, if we directly apply the rounding method to certain precisions (e.g., 8 bits), the update of word vectors will always be zero. For example, the 8-bit precision is 2 −7 = 0.0078, so 10 −5 is not significant enough to update the vector with 8-bit values. Therefore, we consider the following two ways to improve this.</p><p>Stochastic Rounding. We first consider using stochastic rounding  to train word embedding. Stochastic rounding introduces some randomness into the rounding mechanism, which has been proven to be helpful when there are many parameters in the learning system, such as deep learning systems . Here we also introduce this approach to update word embedding vectors in SGD. The probability of rounding x to x is proportional to the proximity of x to x :</p><formula xml:id="formula_174">R s (x, n) = x w.p. 1 − x− x x + w.p. x− x .<label>(2)</label></formula><p>In this case, even though the update values are not significant enough to update the word embedding vectors, we randomly choose some of the values being updated proportional to the value of how close the update value is to the rounding precision. Auxiliary Update Vectors. In addition to the method of directly applying rounding to the values, we also provide a method using auxiliary update vectors to trade precision for more space. Suppose we know the range of update value in S-GD as [−r , r ], and we use additional m bits to store all the values less than the limited numerical precision . Here r can be easily estimated by running SGD for several examples. Then the real precision is = 2 1−m r . For example, if r = 10 −4 and m = 8, then the numerical precision is 7.8 · 10 −7 which can capture much higher precision than the SGD update values have. When  the cumulated values in the auxiliary update vectors are greater than the original numerical precision , e.g., = 2 −7 for 8 bits, we update the original vector and clear the value in the auxiliary vector. In this case, we can have final n-bit values in word embedding vectors as good as the method presented in Section 3.1.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Experiments on Word/Phrase Similarity</head><p>In this section, we describe a comprehensive study on tasks that have been used for evaluating word embeddings. We train the word embedding algorithms, word2vec , based on the Oct. 2013 Wikipedia dump. <ref type="bibr">1</ref> We first compare levels of truncation of word2vec embeddings, and then evaluate the stochastic rounding and the auxiliary vectors based methods for training word2vec vectors.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Datasets</head><p>We use multiple test datasets as follows. Word Similarity. Word similarity datasets have been widely used to evaluate word embedding results. We use the datasets summarized by <ref type="bibr">Faruqui and Dyer (Faruqui and Dyer, 2014): wordsim-353, wordsim-sim, wordsim-rel, MC-30, RG-65, MTurk-287, MTurk-771, MEN 3000, YP-130, Rare-Word, Verb-143, and SimLex-999. 2</ref> We compute the similarities between pairs of words and check the Spearman's rank correlation coefficient <ref type="bibr" target="#b122">(Myers and Well., 1995)</ref> between the computer and the human labeled ranks. Paraphrases (bigrams). We use the paraphrase (bigram) datasets used in <ref type="bibr" target="#b125">(Wieting et al., 2015)</ref>, ppdb all, bigrams vn, bigrams nn, and bigrams jnn, to test whether the truncation affects phrase level embedding. Our phrase level embedding is based on the average of the words inside each phrase. Note that it is also easy to incorporate our truncation methods into existing phrase embedding algorithms. We follow <ref type="bibr" target="#b125">(Wieting et al., 2015)</ref> in using cosine similarity to evaluate the correlation between the computed similarity and annotated similarity between paraphrases.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Analysis of Bits Needed</head><p>We ran both CBOW and skipgram with negative sampling  on the Wikipedia dump data, and set the window size of context to be five. Then we performed value truncation with 4 bits, 6 bits, and 8 bits. The results are shown in <ref type="figure" target="#fig_3">Fig. 1</ref>, and the numbers of the averaged results are shown in <ref type="table" target="#tab_10">Table 1</ref>. We also used the binarization algorithm  to truncate each dimension to three values; these experiments are is denoted using the suffix "binary" in the figure. For both CBOW and skipgram models, we train the vectors with 25 and 200 dimensions respectively.</p><p>The representations used in our experiments were trained using the whole Wikipedia dump. A first observation is that, in general, CBOW performs better than the skipgram model. When using the truncation method, the memory required to store the embedding is significantly reduced, while the performance on the test datasets remains almost the same until we truncate down to 4 bits. When comparing CBOW and skipgram models, we again see that the drop in performance with 4-bit values for the skipgram model is greater than the one for the CBOW model. For the CBOW model, the drop in performance with 4-bit values is greater when using 200 dimensions than it is when using 25 dimensions. However, when using skipgram, this drop is slightly greater when using 25 dimensions than 200.</p><p>We also evaluated the binarization approach . This model uses three values, represented using two bits. We observe that, when the dimension is 25, the binarization is worse than truncation. One possible explanation has to do merely with the size of the space; while 3 25 is much larger than the size of the word space, it does not provide enough redundancy to exploit similarity as needed in the tasks. Consequently, the binarization approach results in worse performance. However, when the dimension is 200, this approach works much better, and outperforms the 4-bit truncation. In particular, binarization works better for skipgram than for CBOW with 200 dimensions. One possible explanation is that the binarization algorithm computes, for each dimension of the word vectors, the positive and negative means of the values and uses it to split the original values in that dimension, thus behaving like a model that clusters the values in each dimension. The success of the binarization then indicates that skipgram embeddings might be more discriminative than CBOW embeddings.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Comparing Training Methods</head><p>We compare the training methods for the CBOW model in <ref type="table" target="#tab_5">Table 2</ref>. For stochastic rounding, we scale the probability of rounding up to make sure that small gradient values will still update the values. Both stochastic rounding and truncation with auxiliary update vectors (shown in Sec. 3.2) require 16 bits for each value in the training phase. Truncation with auxiliary update vectors finally produces 8-bit-value based vectors while stochastic rounding produces 16-bit-value based vectors. Even though our auxiliary update algorithm uses smaller memory/disk to store vectors, its performance is still better than that of stochastic rounding. This is simply because the update values in SGD are too small to allow the stochastic round-  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Experiments on Dependency Parsing</head><p>We also incorporate word embedding results into a downstream task, dependency parsing, to evaluate whether the truncated embedding results are still good features compared to the original features. We follow the setup of <ref type="bibr" target="#b117">(Guo et al., 2015)</ref> in a monolingual setting 3 . We train the parser with 5,000 iterations using different truncation settings for word2vec embedding. The data used to train and evaluate the parser is the English data in the CoNLL-X shared task <ref type="bibr" target="#b112">(Buchholz and Marsi, 2006)</ref>. We follow <ref type="bibr" target="#b117">(Guo et al., 2015)</ref> in using the labeled attachment score (LAS) to evaluate the different parsing results. Here we only show the word embedding results for 200 dimensions, since empirically we found 25-dimension results were not as stable as 200 dimensions. The results shown in <ref type="table" target="#tab_6">Table 3</ref> for dependency parsing are consistent with word similarity and paraphrasing. First, we see that binarization for CBOW and skipgram is again better than the truncation approach. Second, for truncation results, more bits leads to better results. With 8-bits, we can again obtain results similar to those obtained from the original word2vec embedding.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Conclusion</head><p>We systematically evaluated how small can the representation size of dense word embedding be before it starts to impact the performance of NLP tasks that use them. We considered both the final size of the size we provide it while learning it. Our study considers both the CBOW and the skipgram models at 25 and 200 dimensions and showed that 8 bits per dimension (and sometimes even less) are sufficient to represent each value and maintain performance on a range of lexical tasks. We also provided two ways to train the embeddings with reduced memory use. The natural future step is to extend these experiments and study the impact of the representation size on more advanced tasks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Sequence classification tasks are often associated with temporal information, where the timestamp is available for each of the data instances. For instance, in sentiment classification of reviews in forums, opinions of users are associated with a timestamp, indicating the time at which they were posted. Similarly, in an event detection task in Twitter, tweets being posted on a continuous basis need to be analysed and classified in order to detect the occurrence of some event. Nevertheless, traditional sequence classification approaches <ref type="bibr" target="#b127">Gorrell and Bontcheva, 2016)</ref> ignore the time information in these textual data sequences. In this paper, we aim to consider the continuous time information along with the textual information for classifying sequences of temporal textual data. In particular, we consider the problem of rumour stance classification in Twitter, where tweets provide temporal information associated with the textual tweet content. Rumours spread rapidly through social media, creating widespread chaos, increasing anxiety in society and in some cases even leading to riots. For instance, during an earthquake in Chile in 2010, rumours circulating on Twitter stated that a volcano had become active and there was a tsunami warning, which were later proven false. Denials and corrections of these viral pieces of information might often come late and without the sufficient effect to prevent the harm that the rumours can produce <ref type="bibr" target="#b130">(Lewandowsky et al., 2012)</ref>. This posits the importance of carefully analysing tweets associated with rumours and the stance expressed in them to prevent the spread of malicious rumours. Determining the stance of rumour tweets can in turn be effectively used for early detection of the spread of rumours, as well as for flagging rumours as being potentially false when a large number of people are found to be countering them. The rumour stance classification task has been previously defined as that in which a classifier needs to determine whether each of the tweets is supporting, denying or questioning a rumour <ref type="bibr" target="#b134">(Qazvinian et al., 2011)</ref>. Here we add a fourth label, commenting, which is assigned to tweets that do not add anything to the veracity of a rumour.</p><p>In this paper, we propose to use Hawkes Processes <ref type="bibr" target="#b128">(Hawkes, 1971)</ref>, commonly used for modelling information diffusion in social media <ref type="bibr" target="#b136">(Yang and Zha, 2013;</ref><ref type="bibr" target="#b126">De et al., 2015)</ref>, for the task of rumour stance classification. Hawkes Processes (HP) are a self-exciting temporal point process ideal for modelling the occurrence of tweets in Twitter . The model assumes that the occurrence of a tweet will influence the rate at which future tweets will arrive. <ref type="figure" target="#fig_3">Figure 1</ref> shows the behaviour of the intensity functions associated with a multivariate Hawkes Process. Note the intensity spikes at the points of tweet occurrences. In applications such as stance classification, different labels can influence one another. This can be modelled effectively using the mutually exciting behaviour of Hawkes Processes. In the end, we demonstrate how the information gar- nered from rumour dynamics can be beneficial to stance classification of tweets around rumours.</p><p>Little work has been done on stance classification of rumour tweets. Qazvinian et al. <ref type="formula" target="#formula_0">(2011)</ref> introduced a system for classifying rumour tweets and <ref type="bibr" target="#b131">Lukasik et al. (2015a)</ref> considered this problem in a setting where the tweets associated with a new emerging rumour is the target for classification. Both works ignored the temporal information. On the other hand, research has been done on modeling dynamics of rumour propagation <ref type="bibr" target="#b132">(Lukasik et al., 2015b)</ref>. Here, we show how using information about dynamics of rumour propagation is important to the problem of rumour stance classification.</p><p>The novel contributions of this paper are: 1. Developing a Hawkes Process model for time sensitive sequence classification. 2. Demonstrating on real world data how temporal dynamics conveys important information for stance classification. 3. Establishing the new state of the art method for rumour stance classification. 4. Broadening the set of labels considered in previous work to include a new label commenting.</p><p>Software used for experiments can be found at https://github.com/mlukasik/ seqhawkes.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Problem definition</head><p>We consider a collection D of rumours,</p><formula xml:id="formula_175">D = {R 1 , · · · , R |D| }.</formula><p>Each rumour R i contains a set of tweets discussing it, R i = {d 1 , · · · , d n i }. Each tweet is represented as a tuple d j = (t j , W j , m j , y j ), which includes the following information: t j is the posting time of the tweet, W j is the text message, m j is the rumour category and y j is the label, y j ∈ Y = {supporting, denying, questioning, commenting}.</p><p>We define the stance classification task as that in which each tweet d j needs to be classified into one of the four categories, y j ∈ Y , which represents the stance of the tweet d j with respect to the rumour R i it belongs to.</p><p>We consider the Leave One Out (LOO) setting, introduced by <ref type="bibr" target="#b131">Lukasik et al. (2015a)</ref>, where for each rumour R i ∈ D we construct the test set equal to R i and the training set equal to D \ R i . The final performance scores we report in the paper are averaged across all rumours. This represents a realistic scenario where a classifier has to deal with a new, unseen rumour.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Data</head><p>We consider four Twitter rumour datasets with tweets annotated for stance <ref type="bibr" target="#b138">(Zubiaga et al., 2016)</ref>. <ref type="bibr">1</ref> The authors relied on a slightly different scheme for the annotation, given that they annotated treestructured conversation threads where a source tweet initiates a rumour and a number of replies follow responding to it. Given this structure, the source tweet of a Twitter conversation is annotated as supporting, denying or underspecified, and each subsequent tweet is annotated as agreed, disagreed, appeal for more information (questioning) or commenting with respect to the source tweet. We convert these labels into our set of four including supporting, denying, questioning and commenting, which extends the set of three labels used before in the literature <ref type="bibr" target="#b134">(Qazvinian et al., 2011;</ref><ref type="bibr" target="#b131">Lukasik et al., 2015a)</ref> adding the new label commenting. To perform this conversion, we first remove rumours where the source tweet is annotated as underspecified, keeping the rest of source tweets as supporting or denying. For the subsequent tweets, we keep their label as is for the tweets that are questioning or commenting. To convert those tweets that agree or disagree into supporting or denying, we apply the following set of rules: (1) if a tweet agrees to a supporting source tweet, we label it supporting, (2) if a tweet agrees to a denying source tweet, we label it denying, (3) if a tweet disagrees to a supporting source tweet, we label it denying and (4) if a tweet disagrees to a denying tweet, we label it supporting. The latter enables to infer stance with respect to the rumour from the original annotations that instead refer to agreement with respect to the source. <ref type="table" target="#tab_2">Ottawa shooting  58  782  161  76  64  481  Ferguson riots  46  1017  161  82  94  680  Charlie Hebdo  74  1053  236  56  51  710  Sydney siege  71  1124  89  223  99  713   Table 1</ref>: Statistics and distribution of labels for the four datasets used in our experiments. Each dataset consists of multiple rumours, and the rest of the columns offer the aggregated counts for all rumours within that dataset. <ref type="figure" target="#fig_8">Figure 2</ref> shows examples of tweets taken from the dataset along with our inferred annotations. We summarise the statistics of the resulting dataset in <ref type="table" target="#tab_10">Table 1</ref>. Note that the commenting label accounts for the majority of the tweets.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Dataset Rumours Tweets Supporting Denying Questioning Commenting</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Model</head><p>Hawkes Processes are a probabilistic framework for modelling self-exciting phenomena, which has been used for modelling memes and their spread across social networks <ref type="bibr" target="#b136">(Yang and Zha, 2013)</ref>. They have been used to model the generation of tweets over a continuous time domain . The frequency of tweets generated by them is determined by an underlying intensity function which considers the influence from past tweets. The intensity function models the self-exciting nature by adding up the influence from past tweets. We use a multi-variate Hawkes process for modelling the mutually exciting phenomena between the tweet labels. In this section we describe how we apply the Hawkes Process framework for rumour stance classification.</p><p>Intensity Function In the intensity function formulation, we assume that all previous tweets associated with a rumour influence the occurrence of a new tweet. This allows to use information on all the other tweets that have been posted about a rumour. We consider the intensity function to be summation of base intensity and the intensities associated with all the previous tweets,</p><formula xml:id="formula_176">λ y,m (t)=µ y + t &lt;t I(m = m)α y ,y κ(t − t ), (1)</formula><p>where the first term represents the constant base intensity of generating label y. The second term represents the influence from the tweets that happen prior to time of interest. The influence from each tweet decays over time and is modelled using an exponential decay term κ(t − t ) = ω exp(−ω(t − t )). The matrix α of size |Y | × |Y | encodes the degrees of influence between pairs of labels assigned to the tweets, e.g. a questioning label may influence the occurrence of a rejecting label in future tweets differently from how it would influence a commenting label.</p><p>Likelihood function The parameters governing the intensity function are learnt by maximizing the likelihood of generating the tweets. The complete likelihood function is given by</p><formula xml:id="formula_177">L(t, y, m, W ) = (2) N n=1 p(W n |y n )× N n=1 λ yn,mn (t n ) ×p(E T ),</formula><p>where the first term provides the likelihood of generating text given the label and is modelled as a multinomial distribution conditioned on the label,</p><formula xml:id="formula_178">p(W n |y n ) = V v=1 β Wnv ynv ,<label>(3)</label></formula><p>where V is the vocabulary size and β is the matrix of size |Y | × V specifying the language model for each label. The second term provides the likelihood of occurrence of tweets at times t 1 , . . . , t n and the third term provides the likelihood that no tweets happen in the interval [0, T ] except at times t 1 , . . . , t n . We estimate the parameters of the model by maximizing the log-likelihood,</p><formula xml:id="formula_179">l(t, y, m, W ) = − |Y | y=1 |D| m=1 T 0 λ y,m (s)ds+ N n=1 log λ yn,mn (t n ) + N n=1 V v=1 W nv log β ynv .<label>(4)</label></formula><p>The integral term in Equation <ref type="formula" target="#formula_7">(4)</ref> is easily computed for the intensity function since the exponential decay function and the constant function are easily integrable. Figure 2: Examples of rumour tweets associated with two different rumours.</p><p>Note that β is independent from the dynamics part, and a closed form solution after applying Laplacian smoothing takes form</p><formula xml:id="formula_180">β yv = N n=1 I(y n = y)W nv + 1 N n=1 V v=1 I(y n = y)W nv + V .</formula><p>In one approach to µ and α optimization (HP Approx.) we approximate the log term in Equation (4) by taking the log inside the summation terms in Equation (1). This approximation leads to closed form updates for µ and α,</p><formula xml:id="formula_181">µ y = N n=1 I(y n = y) T |D| , α ij = N n=1 n l=1 I(m l = m n )I(y l = i)I(y n =j) N k=1 I(y k = i)K(T − t k ) , where K(T − t k ) = 1 − exp(−ω(T − t k )) arises from the integration of κ(t − t k ).</formula><p>In a different approach (HP Grad.) we find parameters using joint gradient based optimization over µ and α, using derivatives of log-likelihood dl dµ and dl dα . In optimization, we operate in the logspace of the parameters in order to ensure positivity, and employ L-BFGS approach to gradient search. Moreover, we initialize parameters with those found by the HP Approx. method.</p><p>Similar to Yang and Zha <ref type="formula" target="#formula_0">(2013)</ref>, we fix the decay parameter ω, in our case to 0.1.</p><p>Prediction We predict the most likely label for each test tweet as the label which maximises the likelihood of occurrence of the tweet from Equation (2), or the approximated likelihood in case of HP Approx. The likelihood considers both the textual information and the temporal dynamics in predicting the label for the tweet. The predicted labels are then considered while predicting the labels for next tweets in the test data. Thus, we follow a greedy sequence classification approach.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Experiments</head><p>We conduct experiments using the rumour datasets described in <ref type="table" target="#tab_10">Table 1</ref>. We consider our Hawkes Process model described in Section 4 as well as a set of baseline and benchmark approaches.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Baselines</head><p>We compare our model against baselines: Language Model considers only the textual information through multinomial distribution defined in Equation <ref type="formula" target="#formula_6">(3)</ref>. Majority vote classifier based on the training label distribution. Naive Bayes models the text using a multinomial likelihood and a prior over label frequencies . Note that Multinomial, Majority vote and Naive Bayes approaches are special cases of our Hawkes Process model for classification, where a particular subset of parameters is fixed to 0.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Benchmark models</head><p>We compare our model against the following competitive benchmark models: SVM Support Vector Machines with the cost coefficient selected via nested cross-validation. GP Gaussian Processes have been shown by <ref type="bibr" target="#b131">Lukasik et al. (2015a)</ref> to work well, particularly in supervised settings where a multitask learning kernel has been used to learn correlations across different rumours. Here we use a single task kernel (linear) as we consider the fully unsupervised setting. CRF Conditional Random Field ) over temporally ordered sequences using both text and neighbouring label features. The model is trained using 2 penalized loglikelihood where the regularisation parame-  ters are chosen using cross-validation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">Results</head><p>The results are shown in <ref type="table" target="#tab_5">Table 2</ref>. We report accuracy (Acc) and macro average of F 1 scores across all labels (F 1 ). Each metric is calculated over combined sequences of labels from all rumours, thus conducting a micro average over rumours. We can observe that in terms of accuracy, HP Approx. beats all other methods. Notice that Language model is the worst model for this metric. On the other hand, in terms of F 1 score, Language model and GP become the best methods, with HP Approx. method not performing as well anymore. Overall, different metrics yield very different rankings of methods. Nevertheless, we can notice that HP Grad. outperforms NB under all metrics on all datasets. This is the case also for GP baseline, which turns out to be very competitive according to F 1 score. As we mentioned before, HP can be viewed as a NB classifier with a time-dependent prior. This shows, that the temporal dynamics based prior provided by HP is more helpful than the simple frequency based prior from NB according to all considered metrics.</p><p>In <ref type="figure" target="#fig_3">Figure 1</ref> we show an illustration of the intensity function of the HP Grad. model for rumour #1 from the Ferguson dataset. Notice the self-exciting property, with spikes in the intensity functions for different labels at times when tweets occur. Moreover, spikes occur even when a tweet from a different label is posted, for example around 1 hour and 50 minutes into the rumour lifespan a questioning tweet is posted which causes a spike in intensity for commenting tweets.</p><p>Another issue is the approximation used in HP Approx. which might lead to violation of the Hawkes Process mutual-excitation property. In particular, we noticed that in some scenarios occurrences of tweets cause decrease in the intensity value rather than spikes. However, the accuracy metric which has been used in previous work for this task <ref type="bibr" target="#b131">(Lukasik et al., 2015a)</ref> yielded by this method turns out to be the best, although when measuring F 1 the relative ordering changes with the GP performing best <ref type="bibr" target="#b131">(Lukasik et al., 2015a)</ref> closely followed by other techniques including HP Grad. which is competitive on all datasets.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Conclusions</head><p>We proposed a novel model based on Hawkes Processes for sequence classification of stances in Twitter which takes into account temporal information in addition to text. Using four Twitter datasets and experimenting on rumour stance classification of tweets, we have shown that HP is a competitive approach, which outperforms a range of strong benchmark methods by providing the multinomial language model with an informative prior based on temporal dynamics. Our experiments posit the importance of making use of temporal information available in tweets, which along with the textual content provide valuable information for the model to perform well on the task. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Hunting for Troll Comments in News Community Forums</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Abstract</head><p>There are different definitions of what a troll is. Certainly, a troll can be somebody who teases people to make them angry, or somebody who offends people, or somebody who wants to dominate any single discussion, or somebody who tries to manipulate people's opinion (sometimes for money), etc. The last definition is the one that dominates the public discourse in Bulgaria and Eastern Europe, and this is our focus in this paper.</p><p>In our work, we examine two types of opinion manipulation trolls: paid trolls that have been revealed from leaked "reputation management contracts" and "mentioned trolls" that have been called such by several different people. We show that these definitions are sensible: we build two classifiers that can distinguish a post by such a paid troll from one by a non-troll with 81-82% accuracy; the same classifier achieves 81-82% accuracy on so called mentioned troll vs. non-troll posts.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>The practice of using Internet trolls for opinion manipulation has been reality since the rise of Internet and community forums. It has been shown that user opinions about products, companies and politics can be influenced by opinions posted by other online users in online forums and social networks <ref type="bibr" target="#b146">(Dellarocas, 2006)</ref>. This makes it easy for companies and political parties to gain popularity by paying for "reputation management" to people that write in discussion forums and social networks fake opinions from fake profiles. * This research started in the Sofia University.</p><p>Opinion manipulation campaigns are often launched using "personal management software" that allows a user to open multiple accounts and to appear like several different people. Over time, some forum users developed sensitivity about trolls, and started publicly exposing them. Yet, it is hard for forum administrators to block them as trolls try formally not to violate the forum rules. In our work, we examine two types of opinion manipulation trolls: paid trolls that have been revealed from leaked "reputation management contracts" 1 and "mentioned trolls" that have been called such by several different people.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Related Work</head><p>Troll detection was addressed using analysis of the semantics in posts <ref type="bibr" target="#b140">(Cambria et al., 2010)</ref> and domain-adapting sentiment analysis <ref type="bibr" target="#b164">(Seah et al., 2015)</ref>. There are also studies on general troll behavior <ref type="bibr" target="#b150">(Herring et al., 2002;</ref><ref type="bibr" target="#b139">Buckels et al., 2014)</ref>.</p><p>Astroturfing and misinformation have been addressed in the context of political elections using mapping and classification of massive streams of microblogging data <ref type="bibr" target="#b162">(Ratkiewicz et al., 2011)</ref>. Fake profile detection has been studied in the context of cyber-bullying <ref type="bibr" target="#b148">(Galán-García et al., 2014)</ref>.</p><p>A related research line is on offensive language use <ref type="bibr" target="#b168">(Xu and Zhu, 2010)</ref>. This is related to cyberbullying, which has been detected using sentiment analysis , graph-based approaches over signed social networks <ref type="bibr" target="#b159">(Ortega et al., 2012;</ref><ref type="bibr" target="#b152">Kumar et al., 2014)</ref>, and lexico-syntactic features about user's writing style . <ref type="bibr">1</ref> The independent Bulgarian media Bivol published a leaked contract described the following services in favor of the government:"Monthly posting online of 250 comments by virtual users with varied, typical and evolving profiles from different (non-recurring) IP addresses to inform, promote, balance or counteract. The intensity of the provided online presence will be adequately distributed and will correspond to the political situation in the country." See https: //bivol.bg/en/category/b-files-en/b-files-trolls-en  Trustworthiness of statements on the Web is another relevant research direction <ref type="bibr" target="#b163">(Rowe and Butters, 2009</ref>). Detecting untruthful and deceptive information has been studied using both psychology and computational linguistics .</p><p>A related problem is Web spam detection, which has been addressed using spam keyword spotting <ref type="bibr" target="#b145">(Dave et al., 2003)</ref>, lexical affinity of arbitrary words to spam content , frequency of punctuation and word co-occurrence <ref type="bibr" target="#b153">(Li et al., 2006)</ref>. See <ref type="bibr" target="#b141">(Castillo and Davison, 2011)</ref> for an overview on adversarial web search.</p><p>In our previous work, we focused on finding opinion manipulation troll users <ref type="bibr" target="#b154">(Mihaylov et al., 2015a)</ref> and on modeling the behavior of exposed vs. paid trolls <ref type="bibr" target="#b155">(Mihaylov et al., 2015b)</ref>. Here, we go beyond user profile and we try to detect individual troll vs. non-troll comments in a news community forum based on both text and metadata.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Data</head><p>We crawled the largest community forum in Bulgaria, that of Dnevnik.bg, a daily newspaper (in Bulgarian) that requires users to be signed in order to read and comment. The platform allows users to comment on news, to reply to other users' comments and to vote on them with thumbs up/down. We crawled the Bulgaria, Europe, and World categories for the period 01-Jan-2013 to 01-Apr-2015, together with comments and user profiles: 34,514 publications on 232 topics with 13,575 tags and 1,930,818 comments (897,806 of them replies) by 14,598 users; see <ref type="table" target="#tab_10">Table 1</ref>. We then extracted comments by paid trolls vs. mentioned trolls vs. nontrolls; see <ref type="table" target="#tab_5">Table 2</ref>.</p><p>Paid troll comments: We collected them from the leaked reputation management documents, which included 10,150 paid troll comments: 2,000 in Facebook, and 8,150 in news community forums. The latter included 650 posted in the forum of Dnevnik.bg, which we used in our experiments.</p><p>Mentioned troll comments: We further collected 1,140 comments that have been replied to with an accusation of being troll comments. We considered a comment as a potential accusation if (i) it was a reply to a comment, and (ii) it contained words such as troll or murzi(lka). 2 Two annotators checked these comments and found 578 actual accusations. The inter-annotator agreement was substantial: Cohen's Kappa of 0.82. Moreover, a simple bag-of-words classifier could find these 578 accusations with an F 1 -score of 0.85. Here are some examples (translated):</p><p>Accusation: "To comment from "Prorok Ilia": I can see that you are a red troll by the words that you are using" Accused troll's comment: This Boyko 3 is always in your mind! You only think of him. We like Boko the Potato (the favorite of the Lamb), the way we like the Karlies.</p><p>Paid troll's comment: in the previous protests, the entire country participated, but now we only see the paid fans of GERB.</p><p>4 These are not true protests, but chaotic happenings.</p><p>Non-troll comments are those posted by users that have at least 100 comments in the forum and have never been accused of being trolls. We selected 650 non-troll comments for the paid trolls, and other 578 for the mentioned trolls as follows: for each paid or mentioned troll comment, we selected a non-troll comment at random from the same thread. Thus, we have two separate non-troll sets of 650 and of 578 comments.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Features</head><p>We train a classifier to distinguish troll (paid or mentioned) vs. non-troll comments using the following features:</p><p>Bag of words. We use words and their frequencies as features, after stopword filtering. <ref type="bibr">5</ref> Bag of stems. We further experiment with bag of stems, where we stem the words with the BulStem stemmer <ref type="bibr" target="#b157">(Nakov, 2003a;</ref><ref type="bibr" target="#b158">Nakov, 2003b)</ref>.</p><p>Word n-grams. We also experiment with 2-and 3-word n-grams.</p><p>Char n-grams. We further use character ngrams, where for each word token we extract all n consecutive characters. We use n-grams of length 3 and 4 only as other values did not help.</p><p>Word prefix. For each word token, we extract the first 3 or 4 consecutive characters.</p><p>Word suffix. For each word token, we take the last 3 or 4 consecutive characters.</p><p>Emoticons. We extract the standard HTMLbased emoticons used in the forum of Dnevnik.bg.</p><p>Punctuation count. We count the number of exclamation marks, dots, and question marks, both single and elongated, the number of words, and the number of ALL CAPS words.</p><p>Metadata. We use the time of comment posting (worktime: 9:00-19:00h vs. night: 21:00-6:00h), part of the week (workdays: Mon-Fri vs. weekend: Sat-Sun), and the rank of the comment divided by the number of comments in the thread.</p><p>Word2Vec clusters. We trained word2vec on 80M words from 34,514 publications and 1,930,818 comments in our forum, obtaining 268,617 word vectors, which we grouped into 5,372 clusters using K-Means clustering, and then we use these clusters as features.</p><p>Sentiment. We use features derived from MPQA Subjectivity Lexicon  and NRC Emotion Lexicon (Mohammad and Turney, 2013) and the lexicon of . Originally these lexicons were built for English, but we translated them to Bulgarian using Google Translate. Then, we reused the sentiment analysis pipeline from <ref type="bibr" target="#b166">(Velichkov et al., 2014)</ref>, which we adapted for Bulgarian.</p><p>Bad words. We use the number of bad words in the comment as a feature. The words come from the Bad words list v2.0, which contains 458 bad words collected for a filter of forum or IRC channels in English. <ref type="bibr">6</ref> We translated this list to Bulgarian using Google Translate and we removed duplicates to obtain Bad Words Bg 1. We further used the above word2vec model to find the three most similar words for each bad word in Bad Words Bg 1, and we constructed another lexicon: Bad Words Bg 3. 7 Finally, we generate two features: one for each lexicon.</p><p>Mentions. We noted that trolls use diminutive names or humiliating nicknames when referring to politicians that they do not like, but use full or family names for people that they respect. Based on these observations, we constructed several lexicons with Bulgarian politician names, their variations and nicknames (see footnote 7), and we generated a mention count feature for each lexicon.</p><p>POS tag distribution. We also use features based on part of speech (POS). We tag using GATE <ref type="bibr" target="#b144">(Cunningham et al., 2011</ref>) with a simplified model trained on a transformed version of the BulTreeBank-DP <ref type="bibr" target="#b165">(Simov et al., 2002)</ref>. For each POS tag type, we take the number of occurrences in the text divided by the total number of tokens. We use both fine-grained and course-grained POS tags, e.g., from the POS tag Npmsi, we generate three tags: Npmsi, N and Np.</p><p>Named entities. We also use the occurrence of named entities as features. For extracting named entities such as location, country, person name, date unit, etc., we use the lexicons that come with Gate's ANNIE <ref type="bibr" target="#b143">(Cunningham et al., 2002)</ref> pipeline, which we translated to Bulgarian. In future work, we plan to use a better named entity recognizer based on CRF <ref type="bibr" target="#b149">(Georgiev et al., 2009)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Experiments and Evaluation</head><p>We train and evaluate an L2-regularized Logistic Regression with LIBLINEAR <ref type="bibr" target="#b147">(Fan et al., 2008)</ref> as implemented in SCIKIT-LEARN , using scaled and normalized features to the [0;1] interval. As we have perfectly balanced sets of 650 positive and 650 negative examples for paid troll vs. non-trolls and 578 positive and 578 negative examples for mentioned troll vs. non-trolls, the baseline accuracy is 50%. Below, we report F-score and accuracy with cross-validation. <ref type="table" target="#tab_6">Table 3</ref>, shows the results for experiments to distinguish comments by mentioned trolls vs. such by non-trolls, using all features, as well as when excluding individual feature groups. We can see that excluding character n-grams, word suffixes and word prefixes from the features, as well as excluding bag of words with stems or stop words, yields performance gains; the most sizable gain is when excluding char n-grams, which yields one point of improvement. Excluding bad words usage and emoticons also improves the performance but insignificantly, which might be because they are covered by the bag of words features.  <ref type="table" target="#tab_6">Table 3</ref>: Mentioned troll vs. non-troll comments. Ablation excluding feature groups.</p><p>Excluding any of the other features hurts performance, the two most important features to keep being metadata (as it allows us to see the time of posting), and bag of words without stopwords (which looks at the vocabulary choice that mentioned trolls use differently from regular users). <ref type="table" target="#tab_42">Table 4</ref> shows the results for telling apart comments by paid trolls vs. such by non-trolls, using cross-validation and ablation with the same features as for the mentioned trolls. There are several interesting observations we can make. First, we can see that the overall accuracy for finding paid trolls is slightly higher, namely 81.02, vs. 79.24 for mentioned trolls. The most helpful feature again is metadata, but this time it is less helpful (excluding it yields a drop of 5 points vs. 8 points before). The least helpful feature again are character n-grams. The remaining features fall in between, and most of them yield better performance when excluded, which suggests that there is a lot of redundancy in the features.</p><p>Next, we look at individual feature groups. Table 5 shows the results for comments by mentioned trolls vs. such by non-trolls. We can see that the metadata features are by far the most important: using them alone outperforms the results when using all features by 3.5 points.  <ref type="table" target="#tab_42">Table 4</ref>: Paid troll vs. non-troll comments. Ablation excluding feature groups.</p><p>The reason could be that most troll comments are replies to other comments, while those by nontrolls are mostly not replies. Adding other features such as sentiment-based features, bad words, POS, and punctuation hurts the performance significantly. Features such as bad words are at the very bottom: they do not apply to all comments and thus are of little use alone; similarly for mentions and sentiment features, which are also quite weak in isolation. These results suggest that mentioned trolls are not that different from non-trolls in terms of language use, but have mainly different behavior in terms of replying to other users. <ref type="table" target="#tab_23">Table 6</ref> shows a bit different picture for comments by paid trolls vs. such by non-trolls. The biggest difference is that metadata features are not so useful. Also, the strongest feature set is the combination of sentiment, bad words distribution, POS, metadata, and punctuation. This suggests that paid trolls are smart to post during time intervals and days of the week as non-trolls, but they use comments with slightly different sentiment and bad word use than non-trolls. Features based on words are also very helpful because paid trolls have to defend pre-specified key points, which limits their vocabulary use, while non-trolls are free to express themselves as they wish.  <ref type="table" target="#tab_2">Table 7</ref>: Mentioned troll vs. non-troll users (not comments!). Experiments with different number of minimum mentions for January, 2015. 'Diff" is the difference from the majority class baseline.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">Conclusion and Future Work</head><p>We have presented experiments in predicting whether a comment is written by a troll or not, where we define troll as somebody who was called such by other people. We have shown that this is a useful definition and that comments by mentioned trolls are similar to such by confirmed paid trolls.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Phrase Table Pruning via Submodular Function Maximization</head><p>Masaaki Nishino and Jun Suzuki and Masaaki Nagata NTT Communication Science Laboratories, NTT Corporation 2-4 Hikaridai, Seika-cho, Soraku-gun, Kyoto, 619-0237, Japan {nishino.masaaki,suzuki.jun,nagata.masaaki}@lab.ntt.co.jp</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Abstract</head><p>Phrase table pruning is the act of removing phrase pairs from a phrase table to make it smaller, ideally removing the least useful phrases first. We propose a phrase table pruning method that formulates the task as a submodular function maximization problem, and solves it by using a greedy heuristic algorithm. The proposed method can scale with input size and long phrases, and experiments show that it achieves higher BLEU scores than state-of-the-art pruning methods.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>A phrase table, a key component of phrase-based statistical machine translation (PBMT) systems, consists of a set of phrase pairs. A phrase pair is a pair of source and target language phrases, and is used as the atomic translation unit. Today's PBMT systems have to store and process large phrase tables that contain more than 100M phrase pairs, and their sheer size prevents PBMT systems for running in resource-limited environments such as mobile phones. Even if a computer has enough resources, the large phrase tables increase turnaround time and prevent the rapid development of MT systems.</p><p>Phrase table pruning is the technique of removing ineffective phrase pairs from a phrase table to make it smaller while minimizing the performance degradation. Existing phrase table pruning methods use different metrics to rank the phrase pairs contained in the table, and then remove lowranked pairs. Metrics used in previous work are frequency, conditional probability, and Fisher's exact test score <ref type="bibr">(Johnson et al., 2007)</ref>. <ref type="bibr">Zens et al. (2012)</ref> evaluated many phrase table pruning methods, and concluded that entropy-based pruning method <ref type="bibr">(Ling et al., 2012;</ref><ref type="bibr">Zens et al., 2012)</ref> offers the best performance. The entropy-based pruning method uses entropy to measure the redundancy of a phrase pair, where we say a phrase pair is redundant if it can be replaced by other phrase pairs. The entropy-based pruning method runs in time linear to the number of phrase-pairs. Unfortunately, its running time is also exponential to the length of phrases contained in the phrase pairs, since it contains the problem of finding an optimal phrase alignment, which is known to be NP-hard <ref type="bibr">(DeNero and Klein, 2008)</ref>. Therefore, the method can be impractical if the phrase pairs consist of longer phrases.</p><p>In this paper, we introduce a novel phrase table pruning method that formulates and solves the phrase table pruning problem as a submodular function maximization problem. A submodular function is a kind of set function that satisfies the submodularity property. Generally, the submodular function maximization problem is NP-hard, however, it is known that (1 − 1/e) optimal solutions can be obtained by using a simple greedy algorithm <ref type="bibr">(Nemhauser et al., 1978)</ref>. Since a greedy algorithm scales with large inputs, our method can be applicable to large phrase tables.</p><p>One key factor of the proposed method is its carefully designed objective function that evaluates the quality of a given phrase table. In this paper, we use a simple monotone submodular function that evaluates the quality of a given phrase table by its coverage of a training corpus. Our method is simple, parameter free, and does not cause exponential explosion of the computation time with longer phrases. We conduct experiments with two different language pairs, and show that the proposed method shows higher BLEU scores than state-of-the-art pruning methods.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Submodular Function Maximization</head><p>Let Ω be a base set consisting of M elements, and g : 2 Ω → R be a set function that upon the input of X ⊆ Ω returns a real value. If g is a submodular function, then it satisfies the condition</p><formula xml:id="formula_182">g(X ∪ {x}) − g(X) ≥ g(Y ∪ {x}) − g(Y ) ,</formula><p>where X, Y ∈ 2 Ω , X ⊆ Y , and x ∈ Ω \ Y . This condition represents the diminishing return property of a submodular function, i.e., the increase in the value of the function due to the addition of item x to Y is always smaller than that obtained by adding x to any subset X ⊆ Y . We say a submodular function is monotone if g(Y ) ≥ g(X) for any X, Y ∈ 2 Ω satisfying X ⊆ Y . Since a submodular function has many useful properties, it appears in a wide range of applications <ref type="bibr">(Kempe et al., 2003;</ref><ref type="bibr">Lin and Bilmes, 2010;</ref><ref type="bibr">Kirchhoff and Bilmes, 2014)</ref>.</p><p>The maximization problem of a monotone submodular function under cardinality constraints is formulated as</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Maximize g(X)</head><p>Subject to X ∈ 2 Ω and |X| ≤ K , where g(X) is a monotone submodular function and K is the parameter that defines maximum cardinality. This problem is known to be NP-hard, but a greedy algorithm can find an approximate solution whose score is certified to be (1 − 1/e) optimal <ref type="bibr">(Nemhauser et al., 1978)</ref>. Algorithm 1 shows a greedy approximation method the can solve the submodular function maximization problem under cardinality constraints. This algorithm first sets X ← ∅, and adds item</p><formula xml:id="formula_183">x * ∈ Ω \ X that maxi- mizes g(X ∪ {x * }) − g(X) to X until |X| = K.</formula><p>Assuming that the evaluation of g(X) can be performed in constant time, the running time of the greedy algorithm is O(M K) because we need O(M ) evaluations of g(X) for selecting x * that maximizes g(X ∪ {x * }) − g(X), and these evaluations are repeated K times. If we naively apply the algorithm to situations where M is very large, then the algorithm may not work in reasonable running time. However, an accelerated greedy algorithm can work with large inputs <ref type="bibr">(Minoux, 1978;</ref><ref type="bibr">Leskovec et al., 2007)</ref>, since it can drastically reduce the number of function evaluations from M K. We applied the accelerated greedy algorithm in the following experiments, and found it Algorithm 1 Greedy algorithm for maximizing a submodular function Input: Base set Ω, cardinality K Output: X ∈ 2 Ω satisfying |X| = K.</p><formula xml:id="formula_184">1: X ← ∅ 2: while |X| &lt; K do 3: x * ← arg max x∈Ω\X g(X ∪ {x}) − g(X) 4:</formula><p>X ← X ∪ {x * } 5: output X could solve the problems in 24 hours. Moreover, further enhancement can be achieved by applying distributed algorithms <ref type="bibr">(Mirzasoleiman et al., 2013)</ref> and stochastic greedy algorithms <ref type="bibr">(Mirzasoleiman et al., 2015)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Phrase Table Pruning</head><p>We first define some notations.</p><p>Let Ω = {x 1 , . . . , x M } be a phrase table that has M phrase pairs. Each phrase pair, x i , consists of a source language phrase, p i , and a target language phrase, q i , and is written as x i = p i , q i . Phrases p i and q i are sequences of words p i = (p i1 , . . . , p i|p i | ) and q i = (q i1 , . . . , q i|q i | ), where p ij represents the j-th word of p i and q ij represents the j-th word of q i . Let t i be the i-th translation pair contained in the training corpus, namely t i = f i , e i , where f i and e i are source and target sentences, respectively. Let N be the number of translation pairs contained in the corpus. f i and e i are represented as sequences of words f i = (f i1 , . . . , f i|f i | ) and e i = (e i1 , . . . , e i|e i | ), where f ij is the j-th word of sentence f i and e ij is the j-th word of sentence e i . Definition 1. Let x j = p j , q j be a phrase pair and t i = f i , e i be a translation pair. We say x j appears in t i if p j is contained in f i as a subsequence and q j is contained in e i as a subsequence. We say phrase pair x j covers word f ik if x j appears in f i , e i and f ik is contained in the subsequence that equals p j . Similarly, we say x j covers e ik if x j appears in f i , e i and e ik is contained in the subsequence that equals q j .</p><p>Using the above definitions, we describe here our phrase-table pruning algorithm; it formulates the task as a combinatorial optimization problem. Since phrase table pruning is the problem of finding a subset of Ω, we formulate the problem as a submodular function maximization problem under cardinality constraints, i.e., the problem is finding X ⊆ Ω that maximizes objective function g(X) while satisfying the condition |X| = K, where K is the size of pruned phrase table. If g(X) is a monotone submodular function, we can apply Algorithm 1 to obtain an (1 − 1/e) approximate solution. We use the following objective function.</p><formula xml:id="formula_185">g(X) = N i=1 |f i | k=1 log [c(X, f ik ) + 1] + N i=1 |e i | k=1 log [c(X, e ik ) + 1] ,</formula><p>where c(X, f ik ) is the number of phrase pairs contained in X that cover f ik , the k-th word of the ith source sentence f i . Similarly, c(X, e ik ) is the number of phrase pairs that cover e ik . Example 1. Consider phrase table X holding phrase pairs x 1 = (das Haus), (the house) , x 2 = (Haus), (house) , and x 3 = (das Haus), (the building) .</p><p>If a corpus consists of a pair of sentences f 1 = "das Haus ist klein" and e 1 = "this house is small", then x 1 and x 2 appear in f 1 , e 1 and word f 12 = "Haus" is covered by x 1 and x 2 . Hence c(X, f 12 ) = 2.</p><p>This objective function basically gives high scores to X if it contains many words of the training corpus. However, since we take the logarithm of cover counts c(X, f ik ) and c(X, e ik ), g(X) becomes high when X covers many different words. This objective function prefers to select phrase pairs that frequently appear in the training corpus but with low redundantly. This objective function prefers pruned phrase table X that contains phrase pairs that frequently appear in the training corpus, with no redundant phrase pairs. We prove the submodularity of the objective function below. Proposition 1. g(X) is a monotone submodular function.</p><p>Proof. Apparently, every c(X, f ik ) and c(X, e ik ) is a monotone function of X, and it satisfies the diminishing return property since c(X ∪ {x},</p><formula xml:id="formula_186">f ik ) − c(X, f ik ) = c(Y ∪ {x}, f ik ) − c(Y, f ik ) for any X ⊆ Y and x ∈ Y .</formula><p>If function h(X) is monotone and submodular, then φ(h(X)) is also monotone and submodular for any concave function φ : R → R. Since log(X) is concave, every log[c(X, f ik )+1] and log[c(X, e ik )+1] is a monotone submodular function. <ref type="figure" target="#fig_3">Finally, if h 1 , .</ref> . . , h n are monotone and submodular, then i h i is also monotone and submodular. Thus g(X) is monotone and submodular.</p><p>Computation costs If we know all counts c(X, f ik ) and c(X, e ik ) for all f ik , e ik , then g(X ∪ {x}) can be evaluated in time linear with the number of words contained in the training corpus 1 . Thus our algorithm does not cause exponential explosion of the computation time with longer phrases.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Evaluation</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Settings</head><p>We conducted experiments on the ChineseEnglish and Arabic-English datasets used in NIST OpenMT 2012. In each experiment, English was set as the target language. We used Moses  as the phrase-based machine translation system. We used the 5-gram Kneser-Ney language model trained separately using the English GigaWord V5 corpus (LDC2011T07), a monolingual corpus distributed at WMT 2012, and Google Web 1T 5-gram data (LDC2006T13). Word alignments are obtained by running giza++ <ref type="bibr">(Och and Ney, 2003)</ref> included in the Moses system. As the test data, we used 1378 segments for the Arabic-English dataset and 2190 segments for the Chinese-English dataset, where all test segments have 4 references (LDC2013T07, LDC2013T03). The tuning set consists of about 5000 segments gathered from MT02 to MT06 evaluation sets (LDC2010T10, LDC2010T11, LDC2010T12, LDC2010T14, LDC2010T17). We set the maximum length of extracted phrases to 7. <ref type="table" target="#tab_10">Table 1</ref> shows the sizes of phrase tables. Following the settings used in <ref type="bibr">(Zens et al., 2012)</ref>, we reduce the effects of other components by using the same feature weights obtained by running the MERT training algorithm (Och, 2003) on full size phrase tables and tuning data to all pruned tables. We run MERT for 10 times to obtain 10 different feature weights. The BLEU scores reported in the following experiments are the averages of the results obtained by using these different feature weights.</p><p>We adopt the entropy-based pruning method used in <ref type="bibr">(Ling et al., 2012;</ref><ref type="bibr">Zens et al., 2012)</ref> as the baseline method, since it shows best BLEU Language Pair Number of phrase pairs Arabic-English 234M Chinese-English 169M <ref type="table" target="#tab_10">Table 1: Phrase table sizes.</ref> scores as per <ref type="bibr">(Zens et al., 2012)</ref>. We used the parameter value of the entropy-based method suggested in <ref type="bibr">(Zens et al., 2012)</ref>. We also compared with the significance-based method <ref type="bibr">(Johnson et al., 2007)</ref>, which uses Fisher's exact test to calculate significance scores of phrase pairs and prunes less-significant phrase pairs. <ref type="figure" target="#fig_3">Figure 1</ref> and <ref type="figure" target="#fig_8">Figure 2</ref> show the BLEU scores of pruned tables. The horizontal axis is the number of phrase pairs contained in a table, and the vertical axis is the BLEU score. The values in the figure are difference of BLEU scores between the proposed method and the baseline method that shows higher score. In the experiment with the ArabicEnglish dataset, both methods can remove 80% of phrase pairs without losing 1 BLEU point, and the proposed method shows better performance than the baseline methods for all table sizes. The difference in BLEU scores becomes larger when table sizes are small. In the experiment on the ChineseEnglish dataset, both methods can remove 80% of phrase pairs without losing 1 BLEU point, and the proposed method also shows comparable or better performance. The difference in BLEU scores also becomes larger when table sizes are small. <ref type="figure" target="#fig_6">Figure 3</ref> shows phrase table sizes in the binarized and compressed phrase table format used in Moses (Junczys-Dowmunt, 2012). The horizontal axis is the number of phrase pairs contained in the table, and the vertical axis is phrase table size. We can see that there is a linear relationship between phrase table sizes and the number of phrase pairs. The original phrase table requires 2.8GB memory. In contrast, the 90% pruned table only requires 350MB of memory. This result shows the effectiveness of phrase table pruning on reducing resource requirements in practical situations.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Results</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Related Work</head><p>Previous phrase table pruning methods fall into two groups. Self-contained methods only use resources already used in the MT system, e.g., training corpus and phrase tables. Entropy-based methods <ref type="bibr">(Ling et al., 2012;</ref><ref type="bibr">Zens et al., 2012)</ref>, a significance-based method <ref type="bibr">(Johnson et al., 2007)</ref>, and our method are self-contained methods. Non self-contained methods exploit usage statistics for phrase pairs <ref type="bibr">(Eck et al., 2007)</ref> and additional bilingual corpora <ref type="bibr">(Chen et al., 2009</ref>). Since self contained methods require additional resources, it is easy to apply to existing MT systems. Effectiveness of the submodular functions maximization formulation is confirmed in various NLP applications including text summarization <ref type="bibr">(Lin and Bilmes, 2010;</ref><ref type="bibr">Lin and Bilmes, 2011)</ref> and training data selection for machine translation (Kirchhoff and Bilmes, 2014). These methods are used for selecting a subset that contains important items but not redundant items. This paper can be seen as applying the subset selection formulation to the phrase table pruning problem.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Conclusion</head><p>We have introduced a method that solves the phrase table pruning problem as a submodular function maximization problem under cardinal- ity constraints. Finding an optimal solution of the problem is NP-hard, so we apply a scalable greedy heuristic to find (1 − 1/e) optimal solutions. Experiments showed that our greedy algorithm, which uses a relatively simple objective function, can achieve better performance than state-of-the-art pruning methods.</p><p>Our proposed method can be easily extended by using other types of submodular functions. The objective function used in this paper is a simple one, but it is easily enhanced by the addition of metrics used in existing phrase table pruning techniques, such as Fisher's exact test scores and entropy scores. Testing such kinds of objective function enhancements is an important future task.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>References</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Recently, bidirectional long short-term memory networks (bi-LSTM) <ref type="bibr" target="#b644">(Graves and Schmidhuber, 2005</ref>; Hochreiter and Schmidhuber, 1997) have been used for language modelling <ref type="bibr" target="#b457">(Ling et al., 2015)</ref>, POS tagging <ref type="bibr" target="#b457">(Ling et al., 2015;</ref>, transition-based dependency parsing <ref type="bibr">Kiperwasser and Goldberg, 2016)</ref>, fine-grained sentiment analysis , syntactic chunking <ref type="bibr" target="#b678">(Huang et al., 2015)</ref>, and semantic role labeling <ref type="bibr">(Zhou and Xu, 2015)</ref>. LSTMs are recurrent neural networks (RNNs) in which layers are designed to prevent vanishing gradients. Bidirectional LSTMs make a backward and forward pass through the sequence before passing on to the next layer. For further details, see .</p><p>We consider using bi-LSTMs for POS tagging. Previous work on using deep learning-based methods for POS tagging has focused either on a single language  or a small set of languages <ref type="bibr" target="#b457">(Ling et al., 2015;</ref><ref type="bibr" target="#b97">Santos and Zadrozny, 2014</ref>). Instead we evaluate our models across 22 languages. In addition, we compare performance with representations at different levels of granularity (words, characters, and bytes). These levels of representation were previously introduced in different efforts <ref type="bibr">(Chrupała, 2013;</ref><ref type="bibr" target="#b457">Ling et al., 2015;</ref><ref type="bibr" target="#b97">Santos and Zadrozny, 2014;</ref><ref type="bibr">Gillick et al., 2016;</ref><ref type="bibr">Kim et al., 2015)</ref>, but a comparative evaluation was missing.</p><p>Moreover, deep networks are often said to require large volumes of training data. We investigate to what extent bi-LSTMs are more sensitive to the amount of training data and label noise than standard POS taggers.</p><p>Finally, we introduce a novel model, a bi-LSTM trained with auxiliary loss. The model jointly predicts the POS and the log frequency of the next word. The intuition behind this model is that the auxiliary loss, being predictive of word frequency, helps to differentiate the representations of rare and common words. We indeed observe performance gains on rare and out-of-vocabulary words. These performance gains transfer into general improvements for morphologically rich languages.</p><p>Contributions In this paper, we a) evaluate the effectiveness of different representations in biLSTMs, b) compare these models across a large set of languages and under varying conditions (data size, label noise) and c) propose a novel bi-LSTM model with auxiliary loss (LOGFREQ).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Tagging with bi-LSTMs</head><p>Recurrent neural networks (RNNs) <ref type="bibr">(Elman, 1990)</ref> allow the computation of fixed-size vector representations for word sequences of arbitrary length. An RNN is a function that reads in n vectors x 1 , ..., x n and produces an output vector h n , that depends on the entire sequence x 1 , ..., x n . The vector h n is then fed as an input to some classifier, or higher-level RNNs in stacked/hierarchical models. The entire network is trained jointly such that the hidden representation captures the important information from the sequence for the prediction task.</p><p>A bidirectional recurrent neural network (bi-RNN) <ref type="bibr" target="#b644">(Graves and Schmidhuber, 2005)</ref> is an extension of an RNN that reads the input sequence twice, from left to right and right to left, and the encodings are concatenated. The literature uses the term bi-RNN to refer to two related architectures, which we refer to here as "context bi-RNN" and "sequence bi-RNN". In a sequence bi-RNN (bi-RNN seq ), the input is a sequence of vectors x 1:n and the output is a concatenation (•) of a forward (f ) and reverse (r) RNN each reading the sequence in a different directions:</p><formula xml:id="formula_187">v = bi-RNN seq (x 1:n ) = RNN f (x 1:n ) • RNN r (x n:1 )</formula><p>In a context bi-RNN (bi-RNN ctx ), we get an additional input i indicating a sequence position, and the resulting vectors v i result from concatenating the RNN encodings up to i:</p><formula xml:id="formula_188">v i = bi-RNN ctx (x 1:n , i) = RNN f (x 1:i ) • RNN r (x n:i )</formula><p>Thus, the state vector v i in this bi-RNN encodes information at position i and its entire sequential context. Another view of the context bi-RNN is of taking a sequence x 1:n and returning the corresponding sequence of state vectors v 1:n .</p><p>LSTMs (Hochreiter and Schmidhuber, 1997) are a variant of RNNs that replace the cells of RNNs with LSTM cells that were designed to prevent vanishing gradients. Bidirectional LSTMs are the bi-RNN counterpart based on LSTMs.</p><p>Our basic bi-LSTM tagging model is a context bi-LSTM taking as input word embeddings w. We incorporate subtoken information using an hierarchical bi-LSTM architecture <ref type="bibr" target="#b457">(Ling et al., 2015;</ref>. We compute subtokenlevel (either characters c or unicode byte b) embeddings of words using a sequence bi-LSTM at the lower level. This representation is then concatenated with the (learned) word embeddings vector w which forms the input to the context bi-LSTM at the next layer. This model, illustrated in <ref type="figure" target="#fig_3">Figure 1</ref> (lower part in left figure), is inspired by . We also test models in which we only keep sub-token information, e.g., either both byte and character embeddings <ref type="figure" target="#fig_3">(Figure 1</ref>, right) or a single (sub-)token representation alone. In our novel model, cf. <ref type="figure" target="#fig_3">Figure 1</ref> left, we train the bi-LSTM tagger to predict both the tags of the sequence, as well as a label that represents the log frequency of the next token as estimated from the training data. Our combined cross-entropy loss is now: L(ŷ t , y t ) + L(ŷ a , y a ), where t stands for a POS tag and a is the log frequency label, i.e., a = int(log(f req train (w)). Combining this log frequency objective with the tagging task can be seen as an instance of multi-task learning in which the labels are predicted jointly. The idea behind this model is to make the representation predictive for frequency, which encourages the model to not share representations between common and rare words, thus benefiting the handling of rare tokens.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Experiments</head><p>All bi-LSTM models were implemented in CNN/pycnn, 1 a flexible neural network library. For all models we use the same hyperparameters, which were set on English dev, i.e., SGD training with cross-entropy loss, no mini-batches, 20 epochs, default learning rate (0.1), 128 dimensions for word embeddings, 100 for character and byte embeddings, 100 hidden states and Gaussian noise with σ=0.2. As training is stochastic in nature, we use a fixed seed throughout. Embeddings are not initialized with pre-trained embeddings, except when reported otherwise. In that case we use offthe-shelf polyglot embeddings . <ref type="bibr">2</ref> No further unlabeled data is considered in this paper. The code is released at: https: //github.com/bplank/bilstm-aux Taggers We want to compare POS taggers under varying conditions. We hence use three different types of taggers: our implementation of a bi-LSTM; TNT -a second order HMM with suffix trie handling for OOVs. We use TNT as it was among the best performing taggers evaluated in <ref type="bibr">Horsmann et al. (2015)</ref>. <ref type="bibr" target="#b471">3</ref> We complement the NN-based and HMM-based tagger with a CRF tagger, using a freely available implementation <ref type="bibr">(Plank et al., 2014</ref>) based on crfsuite.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Datasets</head><p>For the multilingual experiments, we use the data from the Universal Dependencies project v1.2 <ref type="bibr" target="#b516">(Nivre et al., 2015)</ref> (17 POS) with the canonical data splits. For languages with token segmentation ambiguity we use the provided gold segmentation. If there is more than one treebank per language, we use the treebank that has the canonical language name (e.g., Finnish instead of Finnish-FTB). We consider all languages that have at least 60k tokens and are distributed with word forms, resulting in 22 languages. We also report accuracies on WSJ (45 POS) using the standard splits <ref type="bibr" target="#b7">(Collins, 2002;</ref><ref type="bibr" target="#b465">Manning, 2011)</ref>. The overview of languages is provided in <ref type="table" target="#tab_10">Table 1</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Results</head><p>Our results are given in <ref type="table" target="#tab_5">Table 2</ref>. First of all, notice that TNT performs remarkably well across the 22 languages, closely followed by CRF. The bi-LSTM tagger ( w) without lower-level bi-LSTM for subtokens falls short, outperforms the traditional taggers only on 3 languages. The bi-LSTM 2 https://sites.google.com/site/rmyeid/ projects/polyglot 3 They found TreeTagger was closely followed by HunPos, a re-implementation of TnT, and Stanford and ClearNLP were lower ranked. In an initial investigation, we compared Tnt, HunPos and TreeTagger and found Tnt to be consistently better than Treetagger, Hunpos followed closely but crashed on some languages (e.g., Arabic). model clearly benefits from character representations. The model using characters alone ( c) works remarkably well, it improves over TNT on 9 languages (incl. Slavic and Nordic languages). The combined word+character representation model is the best representation, outperforming the baseline on all except one language (Indonesian), providing strong results already without pre-trained embeddings. This model ( w + c) reaches the biggest improvement (more than +2% accuracy) on Hebrew and Slovene. Initializing the word embeddings (+POLYGLOT) with off-the-shelf languagespecific embeddings further improves accuracy. The only system we are aware of that evaluates on UD is Gillick et al. <ref type="formula" target="#formula_0">(2016)</ref> (last column). However, note that these results are not strictly comparable as they use the earlier UD v1.1 version. The overall best system is the multi-task bi-LSTM FREQBIN (it uses w + c and POLYGLOT initialization for w). While on macro average it is on par with bi-LSTM w + c, it obtains the best results on 12/22 languages, and it is successful in predicting POS for OOV tokens (cf. <ref type="table" target="#tab_5">Table 2</ref> OOV ACC columns), especially for languages like Arabic, Farsi, Hebrew, Finnish.</p><p>We examined simple RNNs and confirm the finding of <ref type="bibr" target="#b457">Ling et al. (2015)</ref> that they performed worse than their LSTM counterparts. Finally, the bi-LSTM tagger is competitive on WSJ, cf. Table 3.</p><p>Rare words In order to evaluate the effect of modeling sub-token information, we examine accuracy rates at different frequency rates. <ref type="figure" target="#fig_8">Figure 2</ref> shows absolute improvements in accuracy of bi-LSTM w + c over mean log frequency, for different language families. We see that especially for Slavic and non-Indoeuropean languages, having high morphologic complexity, most of the improvement is obtained in the Zipfian tail. Rare tokens benefit from the sub-token representations.   Data set size Prior work mostly used large data sets when applying neural network based approaches . We evaluate how brittle such models are with respect to their more traditional counterparts by training bi-LSTM ( w + c without Polyglot embeddings) for increas-</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>WSJ Accuracy</head><p>Convnet <ref type="bibr" target="#b97">(Santos and Zadrozny, 2014)</ref> 97.32 Convnet reimplementation <ref type="bibr" target="#b457">(Ling et al., 2015)</ref> 96.80 Bi-RNN <ref type="bibr" target="#b457">(Ling et al., 2015)</ref> 95.93 Bi-LSTM <ref type="bibr" target="#b457">(Ling et al., 2015)</ref> 97.36</p><p>Our bi-LSTM w+ c 97.22 ing amounts of training instances (number of sentences). The learning curves in <ref type="figure" target="#fig_6">Figure 3</ref> show similar trends across language families. <ref type="bibr">4</ref> TNT is better with little data, bi-LSTM is better with more data, and bi-LSTM always wins over CRF.</p><p>The bi-LSTM model performs already surprisingly well after only 500 training sentences. For non-Indoeuropean languages it is on par and above the other taggers with even less data (100 sentences). This shows that the bi-LSTMs often needs more data than the generative markovian model, but this is definitely less than what we expected.</p><p>Label Noise We investigated the susceptibility of the models to noise, by artificially corrupting training labels. Our initial results show that at low noise rates, bi-LSTMs and TNT are affected similarly, their accuracies drop to a similar degree. Only at higher noise levels (more than 30% corrupted labels), bi-LSTMs are less robust, showing higher drops in accuracy compared to TNT. This is the case for all investigated language families.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Related Work</head><p>Character embeddings were first introduced by <ref type="bibr">Sutskever et al. (2011)</ref> for language modeling. Early applications include text classification <ref type="bibr">(Chrupała, 2013;</ref>. Recently, these representations were successfully applied to a range of structured prediction tasks. For POS tagging, <ref type="bibr" target="#b97">Santos and Zadrozny (2014)</ref> were the first to propose character-based models. They use a convolutional neural network (CNN; or convnet) and evaluated their model on English (PTB) and Portuguese, showing that the model achieves state-of-the-art performance close to taggers using carefully designed feature templates. <ref type="bibr" target="#b457">Ling et al. (2015)</ref> extend this line and compare a novel bi-LSTM model, learning word representations through character embeddings. They evaluate their model on a language modeling and POS tagging setup, and show that bi-LSTMs outperform the CNN approach of <ref type="bibr" target="#b97">Santos and Zadrozny (2014)</ref>. <ref type="bibr">Similarly, Labeau et al. (2015)</ref> evaluate character embeddings for German. Bi-LSTMs for POS tagging are also reported in , however, they only explore word embeddings, orthographic information and evaluate on WSJ only. A related study is <ref type="bibr" target="#b679">Cheng et al. (2015)</ref> who propose a multi-task RNN for named entity recognition by jointly predicting the next token and current token's name label. Our model is simpler, it uses a very coarse set of labels rather then integrating an entire language modeling task which is computationally more expensive. An interesting recent study is <ref type="bibr">Gillick et al. (2016)</ref>, they build a single byte-to-span model for multiple languages based on a sequence-to-sequence RNN  achieving impressive results. We would like to extend this work in their direction.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Conclusions</head><p>We evaluated token and subtoken-level representations for neural network-based part-of-speech tagging across 22 languages and proposed a novel multi-task bi-LSTM with auxiliary loss. The auxiliary loss is effective at improving the accuracy of rare words. Subtoken representations are necessary to obtain a state-of-the-art POS tagger, and character embeddings are particularly helpful for nonIndoeuropean and Slavic languages.</p><p>Combining them with word embeddings in a hierarchical network provides the best representation. The bi-LSTM tagger is as effective as the CRF and HMM taggers with already as little as 500 training sentences, but is less robust to label noise (at higher noise rates). <ref type="bibr" target="#b97">Cicero D Santos and Bianca Zadrozny. 2014</ref> </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Distributed word representations, or word embeddings, have been successfully used in many NLP applications . Traditionally, word representations have been obtained using count-based methods , where the co-occurrence matrix is derived directly from corpus counts <ref type="bibr">(Lin, 1998)</ref> or using association measures like Point-wise Mutual Information (PMI) <ref type="bibr">(Church and Hanks, 1990)</ref> and Positive PMI (PPMI) <ref type="bibr" target="#b174">(Bullinaria and Levy, 2007;</ref>. Techniques for generating lower-rank representations have also been employed, such as PPMI-SVD  and GloVe , both achieving state-of-the-art performance on a variety of tasks.</p><p>Alternatively, vector-space models can be generated with predictive methods, which generally outperform the count-based methods , the most notable of which is Skipgram with Negative Sampling <ref type="bibr">(SGNS, Mikolov et al. (2013b)</ref>), which uses a neural network to generate embeddings. It implicitly factorizes a shifted PMI matrix, and its performance has been linked to the weighting of positive and negative co-occurrences .</p><p>In this paper, we present Lexical Vectors (LexVec), a method for factorizing PPMI matrices that combines characteristics of all these methods. On the one hand, it uses SGNS window sampling, negative sampling, and stochastic gradient descent (SGD) to minimize a loss function that weights frequent co-occurrences heavily but also takes into account negative co-occurrence. However, since PPMI generally outperforms PMI on semantic similarity tasks <ref type="bibr" target="#b174">(Bullinaria and Levy, 2007)</ref>, rather than implicitly factorize a shifted PMI matrix (like SGNS), LexVec explicitly factorizes the PPMI matrix. This paper is organized as follows: First, we describe PPMI-SVD, GloVe, and SGNS ( §2) before introducing the proposed method, LexVec ( §3), and evaluating it on word similarity and analogy tasks ( §4). We conclude with an analysis of results and discussion of future work.</p><p>We provide source code for the model at https://github.com/alexandres/ lexvec.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Related Work</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">PPMI-SVD</head><p>Given a word w and a symmetric window of win context words to the left and win to the right, the co-occurrence matrix of elements M wc is defined as the number of times a target word w and the context word c co-occurred in the corpus within the window. The PMI matrix is defined as</p><formula xml:id="formula_189">P M I wc = log M wc M * * M w * M * c<label>(1)</label></formula><p>where '*' represents the summation of the corresponding index. As this matrix is unbounded in the inferior limit, in most applications it is replaced by its positive definite version, PPMI, where negative values are set to zero. The performance of the PPMI matrix on word similarity tasks can be further improved by using contextdistribution smoothing  and subsampling the corpus . As word embeddings with lower dimensionality may improve efficiency and generalization , the improved PPMI * matrix can be factorized as a product of two lower rank matrices.</p><formula xml:id="formula_190">P P M I * wc W wW c<label>(2)</label></formula><p>where W w andW c are d-dimensional row vectors corresponding to vector embeddings for the target and context words. Using the truncated SVD of size d yields the factorization U ΣT with the lowest possible L 2 error <ref type="bibr">(Eckert and Young, 1936)</ref>.  recommend using W = U Σ p as the word representations, as suggested by <ref type="bibr" target="#b175">Bullinaria and Levy (2012)</ref>, who borrowed the idea of weighting singular values from the work of Caron <ref type="formula" target="#formula_0">(2001)</ref> on Latent Semantic Analysis. Although the optimal value of p is highly taskdependent <ref type="bibr">(Österlund et al., 2015)</ref>, we set p = 0.5 as it has been shown to perform well on the word similarity and analogy tasks we use in our experiments .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">GloVe</head><p>GloVe  factors the logarithm of the co-occurrence matrixM that considers the position of the context words in the window. The loss function for factorization is</p><formula xml:id="formula_191">L GloV e wc = 1 2 f (M wc )(W wW c +b w +b c −logM wc ) 2<label>(3)</label></formula><p>where b w andb c are bias terms, and f is a weighting function defined as</p><formula xml:id="formula_192">f (x) = (x/x max ) β if x &lt; x max 1 otherwise<label>(4)</label></formula><p>W andW are obtained by iterating over all nonzero (w, c) cells in the co-occurrence matrix and minimizing eq. <ref type="formula" target="#formula_6">(3)</ref> through SGD. The weighting function (in eq. <ref type="formula" target="#formula_6">(3)</ref>) penalizes more heavily reconstruction error of frequent cooccurrences, improving on PPMI-SVD's L 2 loss, which weights all reconstruction errors equally. However, as it does not penalize reconstruction errors for pairs with zero counts in the co-occurrence matrix, no effort is made to scatter the vectors for these pairs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Skip-gram with Negative Sampling (SGNS)</head><p>SGNS ) trains a neural network to predict the probability of observing a context word c given a target word w, sliding a symmetric window over a subsampled training corpus with the window size being sampled uniformly from the range <ref type="bibr">[1, win]</ref>. Each observed (w, c) pair is combined with k randomly sampled noise pairs (w, w i ) and used to calculate the loss function</p><formula xml:id="formula_193">L SGN S wc = log σ(W wWc )+ k i=1 E w i ∼Pn(w) log σ(−W wW w i )<label>(5)</label></formula><p>where P n (w) is the distribution from which noise words w i are sampled. 1 We refer to this routine which SGNS uses for selecting (w, c) pairs by sliding a context window over the corpus for loss calculation and SGD as window sampling. SGNS is implicitly performing the weighted factorization of a shifted PMI matrix . Window sampling ensures the factorization weights frequent co-occurrences heavily, but also takes into account negative cooccurrences, thanks to negative sampling.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">LexVec</head><p>LexVec is based on the idea of factorizing the PPMI matrix using a reconstruction loss function that does not weight all errors equally, unlike SVD, but instead penalizes errors of frequent co-occurrences more heavily, while still treating negative co-occurrences, unlike GloVe. Moreover, given that using PPMI results in better performance than PMI on semantic tasks, we propose keeping the SGNS weighting scheme by using window sampling and negative sampling, but explicitly factorizing the PPMI matrix rather than implicitly factorizing the shifted PMI matrix. The LexVec loss function has two terms</p><formula xml:id="formula_194">L LexV ec wc = 1 2 (WwWc − P P M I * wc ) 2 (6) L LexV ec w = 1 2 k i=1 E w i ∼Pn(w) (WwWw i − P P M I * ww i ) 2<label>(7)</label></formula><p>We minimize eqs. <ref type="formula" target="#formula_48">(6)</ref> and <ref type="formula" target="#formula_102">(7)</ref>   <ref type="formula" target="#formula_48">(6)</ref> and eq. <ref type="formula" target="#formula_102">(7)</ref>. The global loss for this approach is </p><formula xml:id="formula_195">L LexV ec = (w,c) #(w, c) (L LexV ec wc + L LexV ec w )<label>(8)</label></formula><p>where #(w) is the number of times w is observed in the subsampled corpus. If a pair (w, c) co-occurs frequently, #(w, c) will weigh heavily in both eqs. <ref type="formula" target="#formula_50">(8)</ref> and <ref type="formula" target="#formula_196">(9)</ref>, giving the desired weighting for frequent co-occurrences. The noise term, on the other hand, has corrections proportional to #(w) and #(w i ), for each pair (w, w i ). It produces corrections in pairs that due to frequency should be in the corpus but are not observed, therefore accounting automatically for negative co-occurrences.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Materials</head><p>All models were trained on a dump of Wikipedia from June 2015, split into sentences, with punctuation removed, numbers converted to words, and lower-cased. Words with less than 100 counts were removed, resulting in a vocabulary of 302,203 words. All models generate embeddings of 300 dimensions.</p><p>The PPMI* matrix used by both PPMI-SVD and LexVec was constructed using smoothing of α = 3/4 suggested in  and an unweighted window of size 2. A dirty subsampling of the corpus is adopted for PPMI* and SGNS with threshold of t = 10 −5 . 2 Additionally, SGNS uses 5 negative samples , a window of size 10 ( , for 5 iterations with initial learning rate set to the default 0.025. GloVe is run with a window of size 10, x max = 100, β = 3/4, for 50 iterations and initial learning rate of 0.05 .</p><p>In LexVec two window sampling alternatives are compared: W S P P M I , which keeps the same fixed size win = 2 as used to create the P P M I * matrix; or W S SGN S , which adopts identical SGNS settings (win = 10 with size randomization). We run LexVec for 5 iterations over the training corpus.</p><p>All methods generate both word and context matrices (W andW ): W is used for SGNS, PPMI-SVD and W +W for GloVe (following , and W and W +W for LexVec.</p><p>For evaluation, we use standard word similarity and analogy tasks . We examine, in particular, if LexVec weighted PPMI * factorization outperforms SVD, GloVe (weighted factorization of logM ) and Skip-gram (implicit factorization of the shifted PMI matrix), and compare the stochastic and minibatch approaches.</p><p>Word similarity tasks are: 3 WS-353 Similarity (WSim) and Relatedness (WRel) <ref type="bibr">(Finkelstein et al., 2001)</ref>, MEN <ref type="bibr" target="#b173">(Bruni et al., 2012</ref><ref type="bibr">), MTurk (Radinsky et al., 2011</ref>, RW <ref type="bibr">(Luong et al., 2013)</ref>, SimLex-999 , MC <ref type="bibr">(Miller and Charles, 1991)</ref>, <ref type="bibr">RG (Rubenstein and Goodenough, 1965)</ref>, and SCWS <ref type="bibr" target="#b424">(Huang et al., 2012)</ref>, calculated using cosine. Word analogy tasks are: Google semantic (GSem) and syntactic (GSyn)  and MSR syntactic analogy dataset , using 3CosAdd and 3CosM ul   <ref type="table" target="#tab_5">Table 2</ref>: Results on word analogy tasks, given as percent accuracy.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Results</head><p>Results for word similarity and for the analogy tasks are in tables 1 and 2, respectively. Compared with PPMI-SVD, LexVec performs better in all tasks. As they factorize the same P P M I * matrix, it is the loss weighting from window sampling that is an improvement over L 2 loss. As expected, due to PPMI, LexVec performs better than SGNS in several word similarity tasks, but in addition it also does so on the semantic analogy task, nearly approaching GloVe. LexVec generally outperforms GloVe on word similarity tasks, possibly due to the factorization of the PPMI matrix and to window sampling's weighting of negative cooccurrences. We believe LexVec fares well on semantic analogies because its vector-space does a good job of preserving semantics, as evidenced by its performance on word similarity tasks. We believe the poor syntactic performance is a result of the PPMI measure. PPMI-SVD also struggled with syntactic analogies more than any other task.  obtained similar results, and suggest that using positional contexts as done by  might help in recovering syntactic analogies.</p><p>In terms of configurations, WS SGN S performed marginally better than WS P P M I . We hypothesize it is simply because of the additional computation. While W and (W +W ) are roughly equivalent on word similarity tasks, W is better for analogies. This is inline with results for PPMI-SVD and SGNS models . Both mini-batch and stochastic approaches result in similar scores for all tasks. For the same parameter k of negative samples, the mini-batch approach uses 2 * win W S P P M I times more negative samples than stochastic when using W S P P M I , and win W S SGN S times more samples when using W S SGN S . Therefore, the stochastic approach is more computationally efficient while delivering similar performance.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Conclusion and Future Work</head><p>In this paper, we introduced LexVec, a method for low-rank, weighted factorization of the PPMI matrix that generates distributed word representations, favoring low reconstruction error on frequent co-occurrences, whilst accounting for negative co-occurrences as well. This is in contrast with PPMI-SVD, which does no weighting, and GloVe, which only considers positive co-occurrences. Finally, its PPMI factorization seems to better capture semantics when compared to the shifted PMI factorization of SGNS. As a result, it outperforms PPMI-SVD and SGNS in a variety of word similarity and semantic analogy tasks, and generally outperforms GloVe on similarity tasks.</p><p>Future work will examine the use of positional contexts for improving performance on syntactic analogy tasks. Moreover, we will explore further the hyper-parameter space to find globally optimal values for LexVec, and will experiment with the factorization of other matrices for developing alternative word representations. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>The need of frameworks for analyzing content in different languages has been discussed recently <ref type="bibr" target="#b180">(Dang et al., 2014)</ref>, and multilingual dependency parsing is no stranger to this challenge. Datadriven parsing models <ref type="bibr" target="#b188">(Nivre, 2006)</ref> can be trained for any language, given enough annotated data. On languages where treebanks are not available, cross-lingual transfer can be used to train parsers for a target language with data from one or more source languages. Data transfer approaches (e.g. ) map linguistic annotations across languages through parallel corpora. Instead, model transfer approaches (e.g. ) rely on crosslinguistic syntactic regularities to learn aspects of the source language that help parse an unseen language, without parallel corpora.</p><p>Model transfer approaches have benefitted from the development of multilingual resources that harmonize annotations.  proposed a universal tagset, and  employed it to transfer delexicalized parsers . More recently, several projects have presented treebank collections of multiple languages with their annotations standardized at the syntactic level, including HamleDT <ref type="bibr" target="#b196">(Zeman et al., 2012)</ref> and the Universal Dependency Treebanks .</p><p>In this paper we also rely on these resources, but with a different goal: we use universal annotations to train bilingual dependency parsers that effectively analyze unseen sentences in any of the learned languages. Unlike delexicalized approaches for model transfer, our parsers exploit lexical features. The results are encouraging: our experiments show that, starting with a monolingual parser, we can "teach" it an additional language for free in terms of accuracy (i.e., without significant accuracy loss on the original language, in spite of learning a more complex task) in the vast majority of cases.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Bilingual training</head><p>Universal Dependency Treebanks v2.0 ) is a set of CoNLL-formatted treebanks for ten languages, annotated with common criteria. They include two versions of PoS tags: universal tags  in the CPOSTAG column, and a refined annotation with treebankspecific information in the POSTAG column. Some of the latter tags are not part of the core universal set, and they can denote linguistic phenomena that are language-specific, or phenomena that not all the corpora have annotated in the same way.</p><p>To train monolingual parsers (our baseline), we used the official training-dev-set splits provided with the corpora. For the bilingual models, for each pair of languages L 1 , L 2 ; we simply merged their training sets into a single file acting as a training set for L 1 ∪L 2 , and we did the same for the development sets. The test sets were not merged because comparing the bilingual parsers to monolingual ones requires evaluating each bilingual parser on the two corresponding monolingual test sets.</p><p>To build the models, we relied on MaltParser <ref type="bibr" target="#b187">(Nivre et al., 2007)</ref>. Due to the large number of language pairs that complicates manual optimization, and to ensure a fair comparison, we used MaltOptimizer <ref type="bibr" target="#b177">(Ballesteros and Nivre, 2012)</ref>, an automatic optimizer for MaltParser models. This system works in three phases: Phase 1 and 2 choose a parsing algorithm by analyzing the training set, and performing experiments with default features. Phase 3 tunes the feature model and algorithm parameters. We hypothesize that the bilingual models will learn a set of features that fits both languages, and check this hypothesis by evaluating on the test sets.</p><p>We propose two training configurations: (1) a treebank-dependent tags configuration where we include the information in the POSTAG column and (2) a universal tags only configuration, where we do not use this information, relying only on the CPOSTAG column. Information that could be present in FEATS or LEMMA columns is not used in any case. This methodology plans to answer two research questions: (1) can we train bilingual parsers with good accuracy by merging harmonized training sets?, and <ref type="formula" target="#formula_1">(2)</ref> is it essential that the tagsets for both languages are the same, or can we still get accuracy gains from fine-grained PoS tags (as in the monolingual case) even if some of them are treebank-specific?</p><p>All models are freely available. 1</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Evaluation</head><p>To ensure a fair comparison between monolingual and bilingual models, we chose to optimize the models from scratch with MaltOptimizer, expecting it to choose the parsing algorithm and feature model which is most likely to obtain good results. We observed that the selection of a bilingual parsing algorithm was not necessarily related with the algorithms selected for the monolingual models. The system sometimes chose an algorithm for a bilingual model that was not selected for any of 1 http://grupolys.org/software/PARSERS/ the corresponding monolingual models. In view of this, and as it is known that different parsing algorithms can be more or less competitive depending on the language <ref type="bibr" target="#b189">(Nivre, 2008)</ref>, we ran a control experiment to evaluate the models setting the same parsing algorithm for all cases, executing only phase 3 of MaltOptimizer. We chose the arc-eager parser for this experiment, as it was the algorithm that MaltOptimizer chose most frequently for the monolingual models in the previous configuration. The aim was to compare the accuracy of the bilingual models with respect to the monolingual ones, when there is no variation on the parsing algorithm between them. The results of this control experiment are not shown for space reasons, but they were very similar to those of the original experiment. <ref type="table" target="#tab_10">Table 1</ref> compares the accuracy of bilingual models to that of monolingual ones, under the treebankdependent tags configuration. Each table cell shows the accuracy of a model, in terms of LAS and UAS. Cells in the diagonal correspond to monolingual models (the baseline), with the cell located at row i and column i representing the result obtained by training a monolingual parser on the training set of language L i , and evaluating it on the test set of the same language L i . Each cell outside the diagonal (at row i and column j, with j = i) shows the results of training a bilingual model on the training set for L i ∪ L j , evaluated on the test set of L i .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Results on the Universal Treebanks</head><p>As we can see, in a large majority of cases, bilingual parsers learn to parse two languages with no statistically significant accuracy loss with respect to the corresponding monolingual parsers (p &lt; 0.05 with Bikel's randomized parsing evaluation comparator). This happened in 74 out of 90 cases when measuring UAS, or 69 out of 90 in terms of LAS. Therefore, in most cases where we are applying a parser to texts in a given language, adding a second language comes for free in terms of accuracy.</p><p>More strikingly, there are many cases where bilingual parsers outperform monolingual ones, even in this evaluation on purely monolingual datasets. In particular, there are 12 cases where a bilingual parser obtains statistically significant gains in LAS over the monolingual baseline, and 9 cases with significant gains in UAS. This clearly  surpasses the amount of significant gains to be expected by chance, and applying the BenjaminiHochberg procedure <ref type="bibr" target="#b178">(Benjamini and Hochberg, 1995)</ref> to correct for multiple comparisons with a maximum false discovery rate of 20% yields 8 significant improvements in LAS and UAS. Therefore, it is clear that there is synergy between datasets: in some cases, adding annotated data in a different language to our training set can actually improve the accuracy that we obtain in the original language. This opens up interesting research potential in using confidence criteria to select the data that can help parsing in this way, akin to what is done in self-training approaches <ref type="bibr" target="#b179">(Chen et al., 2008;</ref><ref type="bibr" target="#b182">Goutam and Ambati, 2011)</ref>.</p><p>Comparing the results by language, we note that the accuracy on the English and Spanish datasets almost always improves when adding a second treebank for training. Other languages that tend to get improvements in this way are French and Portuguese. There seems to be a rough trend towards the languages with the largest training corpora benefiting from adding a second language, and those with the smallest corpora (e.g. Indonesian, Italian or Japanese) suffering accuracy loss, likely because the training gets biased towards the second language.</p><p>Training bilingual models containing a significant number of non-overlapping treebankdependent tags tends to have a positive effect. En-glish and Spanish are two of the clearest examples of this. As shown in <ref type="table" target="#tab_6">Table 3</ref>, which shows a complete report of shared PoS tags for each pair of languages under the treebank-dependent tags configuration, English only shares 1 PoS tag with the rest of the corpora under the said configuration, except for Swedish, with up to 5 tags in common; and the en-sv model is the only one suffering a significant loss on the English test set. Similar behavior is observed on Spanish: sv (0), en (1), ja (10) and ko (12) are the four languages with fewest shared PoS tags, and those are the four that obtained a significant improvement on the Spanish evaluation; while with pt-br, with 15 shared PoS tags, we lose accuracy. The validity of this hypothesis is reinforced by an experiment where we differentiate the universal tags by language by appending a language code to them (e.g. <ref type="bibr">EN NOUN</ref> for an English noun). An overall improvement was observed with respect to the bilingual parsers with non-disjoint sets of features.  <ref type="table" target="#tab_6">Table 3</ref>: Shared language-specific tags between pairs of languages While all these experiments have been performed on sentences with gold PoS tags, preliminary experiments assuming predicted tags instead show analogous results: the absolute values of LAS and UAS are slightly smaller across the board, but the behavior in relative terms is the same, and the bilingual models that improved over the monolingual baseline in the gold experiments keep doing so under this setting.</p><p>On the other hand, <ref type="table" target="#tab_5">Table 2</ref> shows the performance of the monolingual and bilingual models under the universal tags only configuration. The bilingual parsers are also able to keep an acceptable accuracy with respect to the monolingual models, but significant losses are much more prevalent than under the treebank-dependent tags configuration.</p><p>Putting both tables together, our experiments clearly suggest that not only treebank-specific tags do not impair the training of bilingual models, but they are even beneficial, supporting the idea that using partially treebank-dependent tagsets helps multilingual parsing. We hypothesize that this may be because complementing the universal information at the syntactic level with languagespecific information at the lower levels (lexical and morphological) may help the parser identify specific constructions of one language that would not benefit from the knowledge learned from the other, preventing it from trying to exploit spurious similarities between languages. This explanation is coherent with work on delexicalized parser transfer <ref type="bibr" target="#b183">(Lynn et al., 2014)</ref> showing that better results can be obtained using disparate languages than closely-related languages, as long as they have common syntactic constructions. Thus, using universal PoS tags to train multilingual parsers can be, surprisingly, counterproductive.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Parsing code-switched sentences</head><p>Our bilingual parsers also show robustness on texts exhibiting code-switching. Unfortunately, there are no syntactically annotated codeswitching corpora, so we could not perform a formal evaluation. We did perform informal tests, by running the Spanish-English bilingual parsers on some such sentences. We observed that they were able to parse the English and Spanish parts of the sentences much better than monolingual models. This required training a bilingual tagger, which we did with the free distribution of the Stanford tagger <ref type="bibr" target="#b193">(Toutanova and Manning, 2000)</ref>; merging the Spanish and English corpora to train a combined bilingual tagger. Under the universal tags only configuration, the multilingual tagger obtained 98.00% and 95.88% over the monolingual test sets. Using treebank-dependent tags instead, it obtained 97.19% and 93.88% over the monolingual test sets. <ref type="figure" target="#fig_3">Figure 1</ref> shows an interesting example on how using bilingual parsers (and taggers) affects the parsing accuracy. <ref type="table" target="#tab_42">Table 4</ref> shows the performance on a tiny codeswitching treebank built on top of ten normalized tweets. 2 This confirms that monolingual pipelines perform poorly. Using a bilingual tagger helps improve the performance, thanks to accurate tags for both languages, but a bilingual parser is needed to   push both LAS and UAS up to state-of-the-art levels.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Adding more languages</head><p>To show that our approach works when more languages are added, we created a quadrilingual parser using the romanic languages and the fine PoS tag set. The results (LAS/UAS) on the monolingual sets were: 80.18/84.64 (es), <ref type="bibr">79.11/84.29 (fr), 82.16/86.15 (it) and 84.45/86.80 (pt)</ref>. In all cases, the performance is almost equivalent to the monolingual parser. <ref type="bibr">Noah's ARK group (Ammar et al., 2016)</ref> has shown that this idea can be also adapted to universal parsing. Our models are a collection of weights learned from mixing harmonized treebanks, that accurately analyze sentences in any of the learned languages and where it is possible to take advantage of linguistic universals, but they are still dependent on language-specific word forms. Instead, <ref type="bibr" target="#b176">Ammar et al. (2016)</ref> rely on multilingual word clusters and multilingual word embeddings, learning a universal representation. They also support incorporating language-specific information (e.g. PoS tags) to keep learning language-specific behavior. To address syntactic differences between languages (e.g. noun-adjective vs adjective-noun structure) they can inform the parser about the input language.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Conclusions and future work</head><p>To our knowledge, this is the first attempt to train purely bilingual parsers to analyze sentences irrespective of which of the two languages they are written in; as existing work on training a parser on two languages <ref type="bibr" target="#b191">(Smith and Smith, 2004)</ref> focused on using parallel corpora to transfer linguistic knowledge between languages.</p><p>Our results reflect that bilingual parsers do not lose accuracy with respect to monolingual parsers on their corresponding language, and can even outperform them, especially if fine-grained tags are used. This shows that, thanks to universal dependencies and shared syntactic structures across different languages, using treebank-dependent tag sets is not a drawback, but even an advantage.</p><p>The applications include parsing sentences of different languages with a single model, improving the accuracy of monolingual parsing with training sets from other languages, and successfully parsing sentences exhibiting code-switching.</p><p>As future work, our approach could benefit from simple domain adaptation techniques , to enrich the training set for a target language by incorporating data from a source language. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Coreference resolution <ref type="bibr" target="#b209">(Pradhan et al., 2011</ref><ref type="bibr" target="#b208">(Pradhan et al., , 2012</ref> is the task of clustering mentions in a document according to their referent. For instance, we need to resolve Ehud Barak, his, and he as coreferential to understand the meaning of the excerpt: While knowledge-poor approaches establish a reasonable baseline, they perform poorly when positional and surface form heuristics break down. To address this, research has extracted world knowledge from manually curated resources including <ref type="bibr">Wikipedia, Yago, Freebase, and FrameNet (e.g. Uryupina et al., 2011;</ref><ref type="bibr" target="#b211">Rahman and Ng, 2011;</ref><ref type="bibr" target="#b213">Ratinov and Roth, 2012;</ref><ref type="bibr" target="#b206">Hajishirzi et al., 2013;</ref>. Despite their intuitive appeal, results have been mixed. We instead focus on linguistic knowledge which can be extracted completely automatically, guided by insights from Accessibility theory <ref type="bibr" target="#b197">(Ariel, 2001</ref>). This result is consistent with <ref type="bibr">Wiseman et al. (2015)</ref> which similarly finds performance gains above state-of-theart from extending simple, surface-level features.</p><p>We implement a mention classification scheme based on the Accessibility hierarchy and use this for feature specialisation, yielding state-of-the-art results of 65.29 and 61.13% on CoNLL-2012 on gold and automatic preprocessing, with system extracted mentions. Our approach is simple and effective, contributing to arguments for incorporating cognitive insights in computational modelling.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Accessibility Hierarchy</head><p>Accessibility theory <ref type="bibr" target="#b197">(Ariel, 2001</ref>) builds on a body of cognitively motivated theories of discourse processing, notably Centering Theory <ref type="bibr" target="#b205">(Grosz et al., 1995)</ref>. Where Centering describes pronoun interpretation in terms of relative discourse entity salience, Accessibility theory expands from this, describing discourse entities as having corresponding human memory nodes which fluctuate in their degree of activation as the entity features in a discourse. The surface form of a reference indicates to the hearer how activated its corresponding node is expected to be. That is, surface form is an instruction for how to retrieve suitable referents, guiding the resolution of coreference. Relative degree of activation is captured in the theory's hierarchy of reference expression types, reproduced in <ref type="figure" target="#fig_3">Figure 1</ref>. Section 4 proposes a mapping of this hierarchy (derived for spoken Hebrew) to written English.</p><p>The hierarchy encodes and expands the widelyused rule of thumb that full names introduce an entity (their referent has low accessibility; it has not yet been discussed) and pronouns are anaphoric (their referent is a highly accessible, active dis-Full name + modifier &lt; Full name &lt; Long definite description &lt; Short definite description &lt; Last name &lt; First name &lt; Distal demonstrative + modifier &lt; Proximate demonstrative + modifier &lt; Distal demonstrative + NP &lt; Proximate demonstrative + NP &lt; Distal demonstrative &lt; Proximate demonstrative &lt; Stressed pronoun + gesture &lt; Stressed pronoun &lt; Unstressed pronoun &lt; Cliticised pronoun &lt; Verbal inflections &lt; Zero <ref type="figure" target="#fig_3">Figure 1</ref>: Accessibility hierarchy from Ariel <ref type="formula" target="#formula_0">(2001)</ref> course entity); the accessibility of definite descriptions is intermediate. In this work, we show that the fine-grained categorisation in the Accessibility hierarchy can be leveraged to improve the discriminative power of a strong system, compared to coarser-grained typologies from previous work. That is, this work contributes valuable empirical support for the psycholinguistic theory.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Related Work</head><p>A particularly successful way to leverage mention classification has been to specialise modelling by mention type. <ref type="bibr" target="#b201">Denis and Baldridge (2008)</ref> learn five different models, one each for proper name, definite nominal, indefinite nominal, third person pronoun, and non-third person pronoun. <ref type="bibr" target="#b198">Bengtson and Roth (2008)</ref> and <ref type="bibr" target="#b202">Durrett and Klein (2013)</ref> implement specialisation at the level of features within a model, rather than explicitly learning separate models. <ref type="bibr" target="#b198">Bengtson and Roth (2008)</ref> prefix each base feature generated with the type of the current mention, one of proper name, nominal, or pronoun, for instance nominal-head match:true. Durrett and Klein (2013) extend from this by learning a model over three versions of each base feature: unprefixed, conjoined with the type of the current mention, and conjoined with concatenation of the types of the current mention and candidate antecedent mention: nominal+nominal-head match=true.</p><p>The success of Durrett and Klein is possible due to the large training dataset provided by OntoNotes . In this work, we successfully extend data-driven specialisation still further: Section 4 shows how we can discover fine-grained patterns in reference expression usage, and Section 5 how these patterns can be used to significantly improve the performance of a strong coreference system.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Accessibility Transitions in OntoNotes</head><p>In this section, we propose an implementation of the Accessibility hierarchy for written En-  glish and how this can be used to encode finegrained discourse transitions. We discover trends in OntoNotes, over mentions automatically extracted from the DEV portion of English CoNLL-2012 <ref type="bibr" target="#b209">(Pradhan et al., 2011)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Mention classification</head><p>Our experiments start by classifying a mention's Accessibility rank value, AR. <ref type="table" target="#tab_10">Table 1</ref> gives the schema we propose for written English, along with the base distribution over extracted mentions. This mapping is a simple ordinal numbering of <ref type="figure" target="#fig_3">Figure 1</ref> with the following refinements. We have generalised last name and first name to single-word name (AR = 7) and full name to multi-word name (AR = 2) to handle non-person entities. Name modifiers are tokens without the head NER label, excluding determiners, possessive markers, and punctuation. We have introduced indefinite descriptions above definite descriptions since they are more likely to introduce discourse entities than definite descriptions are. We label any nominal started by the or a possessive pronoun as a definite; otherwise it is indefinite. Long descriptions comprise more than one token when possessive markers, punctuation, and articles are excluded. Distals start with those or that while proximates start with these or this.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Discourse Transitions</head><p>Discourse transitions are then AR tuples whose values come from mentions aligned to the same gold cluster. We chose 2-tuples, whose values come from mention-antecedent pairs, since mention-pair models have dominated the research space. However, we generate up to three pairs per mention since antecedents are latent at the entity level. That is, for he in the following, we generate pairs <ref type="bibr">(1,</ref><ref type="bibr">14)</ref> and <ref type="bibr">(14,</ref><ref type="bibr">14)</ref>. The aggregated counts for each pair type are represented in <ref type="table" target="#tab_5">Table 2</ref>, with AR(antecedent) on the vertical and AR(anaphor) on the horizontal. The first column gives the proportion of clusterinitial mentions of each AR type (e.g. 21% of gold clusters have a long indefinite description as their first mention). Each row is normalised to sum to 1 so each row indicates the probability distribution for the expected next mention of a cluster. For clarity, only values 0.05 and higher are shown.</p><p>We can see that commonly used rules of thumb are borne out in this data, though with some extra granularity. Modified and multi-word names reduce to single-word names, and both reduce to pronouns. Single word names retain their mention form and reduce to pronouns with roughly equal probability. All mention types reduce to be pronouns and, once reference has reduced to be pronominal, there is a high likelihood (82%) that this form will be retained.</p><p>Encouragingly, we can also see transitions in <ref type="table" target="#tab_6">Table 3</ref>: Proportion of singletons by AR. <ref type="table" target="#tab_5">Table 2</ref> can not be expressed with the coarsergrained typologies of prior work. Firstly, mention article is important. Long indefinite descriptions are more likely to start coreference clusters than long definite descriptions (21% vs. 14%), which are in turn much more likely to start clusters than demonstratives. Mention length is also important: short indefinite descriptions are more likely to reduce to pronouns than long definite descriptions and short definite descriptions have a higher chance of being retained throughout the discourse than long definite descriptions. Exploring further, of coreferential pairs where both mentions are short definite descriptions, 86% are head matched, compared to 60% of long definite descriptions; 60% of short definite descriptions are string matched, compared to 27% of long. <ref type="table" target="#tab_6">Table 3</ref> gives the proportion of extracted mentions which can not be aligned to gold mentions, by AR value. Modelling these discourse singletons is important for models jointly learning coreference and anaphoricity <ref type="bibr">(Webster and Curran, 2014</ref>  After pronouns, demonstratives and proper names have low proportion of singletons. Single word names are less likely to be singletons than modified and multi-word names. We highlight two contributing factors. The first is that certain names, particularly the children of an apposition, are not markable in OntoNotes. The second is that the burden of supplying disambiguation will be more worthwhile for important entities.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Anaphoricity</head><p>Consistent with <ref type="bibr" target="#b214">Recasens et al. (2013)</ref>, indefinites are more likely to be singletons than definites, and long definites are more likely than short definites. Since length and article are the key factors for AR typing, this is good evidence in favour of using the hierarchy's fine-grained classification.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Experiments</head><p>In this section, we show how fine-grained feature specialisation can significantly improve the performance of LIMERIC, a competitive coreference resolution system. This strength demonstrates that simple surface-form features have yet to be fully utilised in current modelling, and that cognitive theory can guide their development.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">LIMERIC</head><p>The system we base our work on is LIMERIC <ref type="bibr">(Webster and Curran, 2014)</ref>. We choose this system due to its cognitive motivation and strong performance. Importantly, this system already uses the coarse-grained featurisation of <ref type="bibr" target="#b202">Durrett and Klein (2013)</ref>, allowing us to directly measure the impact of our proposed fine-grained featurisation.</p><p>We, however, improve it in a number of ways. The biggest performance boosts came from using MIRA (Margin Infused Relaxation Algorithm) updates in place of standard perceptron updates and implementing the full range of common features from the literature. We also fix a number of bug fixes and improve mention extraction. This improved system forms our LIMERIC baseline in Table 4.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Fine-Grained Feature Specialisation</head><p>We build on work in discourse transition prefixing (particularly <ref type="bibr" target="#b202">Durrett and Klein, 2013)</ref>, which expands the feature space of a learner by including multiple versions of each generated feature. LIMERIC previously used three versions of each feature: one unprefixed, one prefixed with the current mention's type (one of name, nominal, or pronoun), and one prefixed with the concatenation of the types of the current and candidate antecedents. In this work, we introduce a fourth prefix, formed by concatenating the AR of the current mention with that of the closest mention in the candidate antecedent cluster.</p><p>The power of such transition features is that they allow us to learn, for instance, that pronoun to name transitions are preferred when the anaphor is distant from its antecedent and the name mention is one token, or that head match is a particularly strong indicator of coreferentiality between short definite nominals: 6+6-head match=true. <ref type="table" target="#tab_42">Table 4</ref> tabulates system performance on CoNLL-2012 TEST using system extracted mentions and v8.01 of the official scorer <ref type="bibr" target="#b207">(Pradhan et al., 2014)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">Results</head><p>Comparing feature specialisation against the LIMERIC baseline, we can see that it yields substantial performance gains on all metrics and both evaluation settings. Performance gains indicated in bold are statistically significant for the conservative p = 0.01 using bootstrap re-sampling 1 . Performance gains indicated in italics are significant at the standard threshold of p = 0.05.</p><p>We benchmark against the state-of-the-art by comparing performance to the winner of the shared task <ref type="bibr" target="#b204">(Fernandes et al., 2012)</ref>, as well as the best documented system at the time of this work <ref type="bibr" target="#b200">(Björkelund and Kuhn, 2014)</ref>. Fine-grained feature specialisation improves LIMERIC's performance to push past that of <ref type="bibr" target="#b200">Björkelund and Kuhn (2014)</ref> when using gold preprocessing. Furthermore, on the difficult automatic setting, we outperform <ref type="bibr" target="#b204">Fernandes et al. (2012)</ref> and are not significantly worse than <ref type="bibr" target="#b200">Björkelund and Kuhn (2014)</ref>. On the link-based MUC and B 3 metrics, our recall gains are larger than our precision gains. That is, specialisation enables coreference indicators to accrue sufficient weight so as to promote new coreference links, a known problem case for modern systems. We found particularly enhanced weight on features for relaxed string matching.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Conclusion</head><p>In this paper, we have found fine-grained patterns in reference expression usage based on the Accessibility hierarchy and shown how these can be used to significantly improve the performance of a strong system, LIMERIC. Despite being simple to implement, we achieve comparable or improved performance than the best reported results, furthering arguments for incorporating cognitive insights in computational modelling. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Skilled reading is a complex cognitive process that requires constant interpretation and evaluation of written content. To develop a coherent picture, one must reason from the material encountered to construct a mental representation of meaning.</p><p>As new information becomes available, this representation is continually refined to produce a globally consistent understanding. Sentence completion questions, such as those previously featured on the Scholastic Aptitude Test (SAT), were designed to assess this type of verbal reasoning ability. Specifically, given a sentence containing 1-2 blanks, the test taker was asked to select the correct answer choice(s) from the provided list of options <ref type="bibr">(College Board, 2014)</ref>. A sample sentence completion question is illustrated in <ref type="figure" target="#fig_3">Figure 1</ref>. To date, relatively few publications have focused on automatic methods for solving sentence completion questions. This scarcity is likely attributable to the difficult nature of the task, which occasionally involves logical reasoning in addition to both general and semantic knowledge <ref type="bibr">(Zweig et al., 2012b)</ref>. Fundamentally, text completion is a challenging semantic modeling problem, and solutions require models that can evaluate the global coherence of sentences <ref type="bibr">(Gubbins and Vlachos, 2013)</ref>. Thus, in many ways, text completion epitomizes the goals of natural language understanding, as superficial encodings of meaning will be insufficient to determine which responses are accurate.</p><p>In this paper, a model based on pointwise mutual information (PMI) is proposed to measure the degree of association between answer options and other sentence tokens. The PMI model considers multiple sources of information present in a sentence prior to selecting the most likely alternative.</p><p>The remainder of this report is organized as follows. Section 2 describes the high-level characteristics of existing models designed to perform automated sentence completion. This prior work provides direct motivation for the PMI model, introduced in Section 3. In Section 4, the model's performance on the Microsoft Research (MSR) Sentence Completion Challenge and a data set comprised of SAT questions are juxtaposed. Finally, Section 5 offers concluding remarks on this topic.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="438">2 Background</head><p>Previous research expounds on various architectures and techniques applied to sentence completion. Below, models are roughly categorized on the basis of complexity and type of input analyzed.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">N-gram Models</head><p>Advantages of n-gram models include their ability to estimate the likelihood of particular token sequences and automatically encode word ordering. While relatively simple and efficient to train on large, unlabeled text corpora, n-gram models are nonetheless limited by their dependence on local context. In fact, such models are likely to overvalue sentences that are locally coherent, yet improbable due to distant semantic dependencies.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Dependency Models</head><p>Dependency models circumvent the sequentiality limitation of n-gram models by representing each word as a node in a multi-child dependency tree. Unlabeled dependency language models assume that each word is (1) conditionally independent of the words outside its ancestor sequence, and (2) generated independently from the grammatical relations. To account for valuable information ignored by this model, e.g., two sentences that differ only in a reordering between a verb and its arguments, the labeled dependency language model instead treats each word as conditionally independent of the words and labels outside its ancestor path <ref type="bibr">(Gubbins and Vlachos, 2013)</ref>.</p><p>In addition to offering performance superior to n-gram models, advantages of this representation include relative ease of training and estimation, as well as the ability to leverage standard smoothing methods. However, the models' reliance on output from automatic dependency extraction methods and vulnerability to data sparsity detract from their real-world practicality.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Continuous Space Models</head><p>Neural networks mitigate issues with data sparsity by learning distributed representations of words, which have been shown to excel at preserving linear regularities among tokens. Despite drawbacks that include functional opacity, propensity toward overfitting, and elevated computational demands, neural language models are capable of outperforming n-gram and dependency models <ref type="bibr">(Gubbins and Vlachos, 2013;</ref><ref type="bibr" target="#b534">Mikolov et al., 2013;</ref><ref type="bibr">Mnih and Kavukcuoglu, 2013)</ref>. Log-linear model architectures have been proposed to address the computational cost associated with neural networks <ref type="bibr">Mnih and Kavukcuoglu, 2013)</ref>. The continuous bag-ofwords model attempts to predict the current word using n future and n historical words as context. In contrast, the continuous skip-gram model uses the current word as input to predict surrounding words. Utilizing an ensemble architecture comprised of the skip-gram model and recurrent neural networks, <ref type="bibr" target="#b534">Mikolov et al. (2013)</ref> achieved prior state-of-the-art performance on the MSR Sentence Completion Challenge.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">PMI Model</head><p>This section describes an approach to sentence completion based on pointwise mutual information. The PMI model was designed to account for both local and distant sources of information when evaluating overall sentence coherence.</p><p>Pointwise mutual information is an information-theoretic measure used to discover collocations <ref type="bibr">(Church and Hanks, 1990;</ref><ref type="bibr" target="#b260">Turney and Pantel, 2010)</ref>. Informally, PMI represents the association between two words, i and j, by comparing the probability of observing them in the same context with the probabilities of observing each independently.</p><p>The first step toward applying PMI to the sentence completion task involved constructing a word-context frequency matrix from the training corpus. The context was specified to include all words appearing in a single sentence, which is consistent with the hypothesis that it is necessary to examine word co-occurrences at the sentence level to achieve appropriate granularity. During development/test set processing, all words were converted to lowercase and stop words were removed based on their part-of-speech tags <ref type="bibr">(Toutanova et al., 2003)</ref>. To determine whether a particular part-of-speech tag type did, in fact, signal the presence of uninformative words, tokens assigned a hypothetically irrelevant tag were removed if their omission positively affected performance on the development portion of the MSR data set. This non-traditional approach, selected to increase specificity and eliminate dependence on a non-universal stop word list, led to the removal of determiners, coordinating conjunctions, <ref type="figure" target="#fig_8">Figure 2</ref>: The dependency parse tree for Question 17 in the MSR data set. Words that share a grammatical relationship with the missing word rising are underscored. Following stop word removal, the feature set for this question is <ref type="bibr">[darkness, was, hidden]</ref>.</p><p>pronouns, and proper nouns. 1 Next, feature sets were defined to capture the various sources of information available in a sentence. While feature set number and type is configurable, composition varies, as sets are dynamically generated for each sentence at run time. Enumerated below are the three feature sets utilized by the PMI model.</p><p>1. Reduced Context. This feature set consists of words that remain following the preprocessing steps described above.</p><p>2. Dependencies. Sentence words that share a semantic dependency with the candidate word(s) are included in this set <ref type="bibr" target="#b496">(Chen and Manning, 2014)</ref>. Absent from the set of dependencies are words removed during the pre-processing phase. <ref type="figure" target="#fig_8">Figure 2</ref> depicts an example dependency parse tree along with features provided to the PMI model.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>3.</head><p>Keywords. Providing the model with a collection of salient tokens effectively increases the tokens' associated weights. An analogous approach to the one described for stop word identification was applied to discover that common nouns consistently hold greater significance than other words assigned hypothetically informative part-of-speech tags.</p><p>Let X represent a word-context matrix with n rows and m columns. Row x i: corresponds to word i and column x :j refers to context j. The term x(i,j) indicates how many times word i occurs in context j. Applying PMI to X results in the n x m matrix Y, where term y(i,j) is defined by (1). To avoid overly penalizing words that are unrelated to the context, the positive variant of PMI is considered, in which negative scores are replaced with zero (4).</p><formula xml:id="formula_197">P (i, j) = x(i, j) n i=1 m j=1 x(i, j)<label>(1)</label></formula><formula xml:id="formula_198">P (i * ) = m j=1 x(i, j) n i=1 m j=1 x(i, j)<label>(2)</label></formula><formula xml:id="formula_199">P ( * j) = n i=1 x(i, j) n i=1 m j=1 x(i, j)<label>(3)</label></formula><formula xml:id="formula_200">pmi(i, j) = max 0, log P (i, j) P (i * )P ( * j)<label>(4)</label></formula><p>In addition, the discounting factor described by <ref type="bibr">Pantel and Lin (2002)</ref> is applied to reduce bias toward infrequent words (7).</p><formula xml:id="formula_201">mincontext = min( n k=1 x(k, j), m k=1 x(i, k)) (5) δ(i, j) = x(i, j) x(i, j) + 1 · mincontext mincontext + 1 (6) dpmi(i, j) = pmi(i, j) · δ(i, j)<label>(7)</label></formula><formula xml:id="formula_202">similarity(i, S) = j∈S dpmi(i, j) · γ (8)</formula><p>The PMI model evaluates each possible response to a sentence completion question by substituting each candidate answer, i, in place of the blank and scoring the option according to (8). This equation measures the semantic similarity between each candidate answer and all other words in the sentence, S. Prior to being summed, individual PMI values associated with a particular word i and context word j are multiplied by γ, which reflects the number of feature sets containing j. Ultimately, the candidate option with the highest similarity score is selected as the most likely answer.</p><p>Using the procedure described above, additional feature sets of bigrams and trigrams were created and subsequently incorporated into the semantic similarity assessment. This extended model accounts for both word-and phraselevel information by considering windowed cooccurrence statistics.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Experimental Evaluation</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Data Sets</head><p>Since its introduction, the Microsoft Research Sentence Completion Challenge (Zweig and Burges, 2012a) has become a commonly used benchmark for evaluating semantic models. The data is comprised of material from nineteenthcentury novels featured on Project Gutenberg. Each of the 1,040 test sentences contains a single blank that must be filled with one of five candidate words. Associated candidates consist of the correct word and decoys with similar distributional statistics.</p><p>To further validate the proposed method, 285 sentence completion problems were collected from SAT practice examinations given from <ref type="bibr">(College Board, 2014</ref>. While the MSR data set includes a list of specified training texts, there is no comparable material for SAT questions. Therefore, the requisite word-context matrices were constructed by computing token cooccurrence frequencies from the New York Times portion of the English Gigaword corpus <ref type="bibr">(Parker et al., 2009)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Results</head><p>The overall accuracy achieved on the MSR and SAT data sets reveals that the PMI model is able to outperform prior models applied to sentence completion. <ref type="table" target="#tab_5">Table 1 provides a comparison of the  accuracy values attained by various architectures,  while Table 2</ref> summarizes the PMI model's performance given feature sets of context words, dependencies, and keywords. Recall that the n-gram variant reflects how features are partitioned.</p><p>It appears that while introducing phrase-level information obtained from higher-order n-grams leads to gains in precision on the MSR data set, the same cannot be stated for the set of SAT ques-  <ref type="table" target="#tab_5">Table 2</ref>: PMI model performance improvements (% accurate) from incorporating feature sets of higher-order n-grams.</p><p>tions. The most probable explanation for this is twofold. First, informative context words are much less likely to occur within 2-3 tokens of the target word. Second, missing words, which are selected to test knowledge of vocabulary, are rarely found in the training corpus. Bigrams and trigrams containing these infrequent terms are extremely uncommon. Regardless of sentence structure, the sparsity associated with higher-order ngrams guarantees diminishing returns for larger values of n. When deciding whether or not to incorporate this information, it is also important to consider the significant trade-off with respect to information storage requirements.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Conclusion</head><p>This paper described a novel approach to answering sentence completion questions based on pointwise mutual information. To capture unique information stemming from multiple sources, several features sets were defined to encode both local and distant sentence tokens. It was shown that while precision gains can be achieved by augmenting these feature sets with higher-order n-grams, a significant cost is incurred as a result of the increased data storage requirements. Finally, the superiority of the PMI model is demonstrated by its performance on the Microsoft Research Sentence Completion Challenge, during which a new stateof-the-art result was established. <ref type="bibr" target="#b496">Danqi Chen and Christopher Manning. 2014</ref> </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>According to Interactive Alignment theory <ref type="bibr">(Pickering and Garrod, 2004)</ref>, mutual understanding in dialogue is helped by a variety of interconnected adaptation processes. Over the course of a conversation, interlocutors' linguistic productions assimilate at multiple levels, such as phonemes <ref type="bibr">(Pardo, 2006)</ref>, lexical choice <ref type="bibr" target="#b223">(Garrod and Anderson, 1987)</ref>, syntactic structures <ref type="bibr">(Pickering and Branigan, 1998;</ref><ref type="bibr" target="#b219">Branigan et al., 2000;</ref><ref type="bibr">Reitter et al., 2006)</ref> and so on. The alignment at these levels contributes to the establishment of aligned situation models between speakers, which is the ultimate goal of a successful conversation <ref type="bibr">(Pickering and Garrod, 2004;</ref><ref type="bibr">Reitter and</ref><ref type="bibr">Moore, 2007, 2014)</ref>. Alignment does not only refer to the mimicking and repetition of particular linguistic structures; it also includes the convergence at the statistical and ensemble level, which is known as distributional matching <ref type="bibr" target="#b216">(Abney et al., 2014)</ref>. Speech rates <ref type="bibr">(Webb, 1969)</ref>, probability distributions over syntactic forms <ref type="bibr">(Jaeger and Snider, 2008)</ref>, power law distributions of acoustic onset events <ref type="bibr" target="#b216">(Abney et al., 2014)</ref>, and social intent of the speech act  were all found to match between interlocutors.</p><p>An aspect of accommodation that presumably very much helps dialogue partners understand each other's language is syntactic complexity. Despite rich investigation of alignment in conversation, this property has been largely overlooked in the analysis of dialogue.</p><p>The general concept of syntactic complexity has, of course, been addressed in various ways. In educational psychology and applied linguistics, it is often defined as the degree of sophistication of language forms. It has broad application in the assessment of second language acquisition <ref type="bibr">(Ortega, 2003;</ref><ref type="bibr">Lu, 2010</ref><ref type="bibr">Lu, , 2011</ref>, the readability test <ref type="bibr">(MacGinitie and Tretiak, 1971)</ref>, and elementary education <ref type="bibr" target="#b215">(Abedi and Lord, 2001)</ref>. In computational linguistics, previous studies have shown that the syntactic complexity of a sentence is closely related to the amount of information being transmitted <ref type="bibr">Charniak, 2002, 2003;</ref><ref type="bibr">Jaeger and Levy, 2006;</ref><ref type="bibr">Jaeger, 2010)</ref>. However, as far as we know, syntactic complexity as a high level feature of language production has not been investigated under the theoretical lens of the Interactive Alignment Model <ref type="bibr">(Pickering and Garrod, 2004)</ref>.</p><p>Therefore, the focus of this study is to track the syntactic complexity of different interlocutors as the conversation develops. A convergence of sentence complexity between interlocutors would be compatible with two pertinent theories. The first is the Interactive Alignment Model. The second is the Uniform Information Density hypothesis (Jaeger and <ref type="bibr">Levy, 2006;</ref><ref type="bibr">Jaeger, 2010)</ref>, as it applies to syntactic structure. It postulates that speakers will strive to keep information density approximately constant. In other words, if one interlocutor decreased their rate of information transmission, the other one would increase it in response. As far as syntactic complexity is proportional to the amount of information, this would imply that if one interlocutor changes their syntactic complex- The tree depth of (a) is 4, while the value of (b) is 7. The branching factor of (a) is 1.38, while the value of (b) is 1.48 ity, their dialogue partner is likely to make the opposite change.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Methods</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Corpus data</head><p>We use the Switchboard corpus <ref type="bibr" target="#b226">(Godfrey et al., 1992)</ref> and the British National Corpus (BNC) <ref type="bibr" target="#b218">(BNC, 2007)</ref> in this study. Switchboard contains 1126 conversations over the telephone, where each conversation features exactly two native American English speakers. From the BNC, we use only a subset of the data that contains spoken conversations with exactly two participants so that the dialogue structures are consistent with Switchboard.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Metrics of syntactic complexity</head><p>We consider three candidate statistics to measure the syntactic complexity of a sentence: sentence length (number of words in a sentence), tree depth, and branching factor. The first two are straightforward: syntactically complex sentences are typically used to express complex meanings, and thus are more likely to contain more words than simple ones. More complex syntactic structures, such as relative clauses and noun clauses, also have deeper parse trees (see <ref type="figure" target="#fig_3">Figure 1)</ref>. The third statistic, branching factor, is defined as the average number of children of all non-leaf nodes in the parse tree of a sentence. In contrast to tree depth, it measures the width of a tree structure, thus a sentence with a larger branching factor looks flatter.</p><p>These three statistics are inter-correlated. For instance, tree depth has an almost linear correlation with sentence length. To come up with a measure that solely characterizes the complexity of a sentence in terms of its tree structure, we normalize tree depth and branching factor by excluding the effect of sentence length. We adopt the method proposed by <ref type="bibr" target="#b224">Genzel and Charniak (2002)</ref>. Let f be a complexity measure of a sentence (tree depth or branching factor). We compute the average measuref (n) for sentences of the same length n (n = 1, 2, . . . ):</p><formula xml:id="formula_203">f (n) = 1 /|S(n)| s∈S(n) f (s)</formula><p>( <ref type="formula" target="#formula_0">1)</ref> where s denotes a sentence, and S(n) = {s|l(s) = n} is the set of sentences of length n. The normalized complexity measure is:</p><formula xml:id="formula_204">f (s) = f (s) f (n)<label>(2)</label></formula><p>This normalized measure f is not sensitive to sentence length. This gives us five metrics of complexity: sentence length (SL), tree depth (TD), branching factor (BF), normalized tree depth (NTD), and normalized branching factor (NBF).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Topic segmentation and speaker role assignment</head><p>To verify the hypothesized convergence of a certain statistic between two speakers in dialogue, one possible method is to measure whether the difference in that statistic becomes smaller as the conversation progresses. However, this design is overly simplistic in this case for several reasons. For instance, previous studies have found that sentence complexity in written text increases with its position <ref type="bibr" target="#b225">(Genzel and Charniak, 2003)</ref>; thus even if we observed that the difference of complexity becomes smaller, a ceiling effect could be a simpler explanation. Additionally, the syntactic complexity of a sentence largely depends on the amount of meaning that is conveyed. Intuitively, when a speaker has a large amount of information to express, she tends to use more sophisticated syntactic constructions Linking this consideration to another very common scenario in dialogue: one interlocutor leads the conversation by steering the on-going topics, while the other participant follows along. Here, we are not talking about the turn-taking mechanism in dialogue, which describes the shift at the utterance level. Rather, we are describing the shift at a higher level in conversation, the topic level, which is formally referred to as topic shift in Conversation Analysis <ref type="bibr">(Ng and Bradac, 1993;</ref><ref type="bibr">Linell, 1998)</ref>. According to these related theories, a complete conversation consists of several topic episodes. Some speakers play a more active role in leading the unfolding of new topic episodes, while others play a more passive role by following the topic shift. Beginning a new topic means bringing in new information, thus it is reasonable to infer that the interlocutor's syntactic complexity would partially depend on whether he is playing the leader or the follower. Considering the fact that the leader vs. follower roles are not fixed among interlocutors (a previous leader could be a follower later and vise versa), we should not examine the convergence of syntactic complexity within the whole conversation. Rather, we want to zoom in to the finer scale of topic episodes, in which the interlocutors' roles are relatively stable. Based on these considerations, we use the TextTiling algorithm <ref type="bibr" target="#b227">(Hearst, 1997)</ref> to segment the conversation into several topic episodes. This is a sufficient topic segmentation method for our research questions, though it is less sophisticated compared to Bayesian models <ref type="bibr" target="#b222">(Eisenstein and Barzilay, 2008)</ref> or Hidden Markov Models <ref type="bibr" target="#b217">(Blei and Moreno, 2001)</ref>.</p><p>Within each topic episode that resulted from the segmentation operation, we assign roles to the two speakers. This is based on which of the interlocutors is leading this topic episode, as previously explained. We use two rules to determine this leader and follower differentiation:</p><p>Rule I: If the topic episode starts in the middle of the speaking turn of speaker A, then let A be the leader of this topic.</p><p>Rule II: If the topic episode starts with a complete speaking turn, then let the first speaker who contributes a sentence greater than N words in length in this episode be the leader.</p><p>Note that the purpose of Rule II is to select the most probable topic leader, based on the intuition that longer sentences are more likely to initiate a new topic. Thus the determination of the N words threshold here is totally empirical. We use N = 5 as the final threshold, because for N ≥ 5 our experiments draw similar results.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Results</head><p>For each sentence in conversation, we compute the five earlier-discussed metrics of syntactic complexity: SL, TD, BF, NTD, and NBF.</p><p>For the first three metrics, SL, TD and BF, we observe convergence between topic leaders and followers, for both corpora <ref type="figure" target="#fig_8">(Fig. 2)</ref>. Basically, topic leaders have higher syntactic complexity measures at the early stage of a topic episode, which drops gradually as the topic develops. The converse holds for topic followers. We fit 12 linear Within−topic position of sentence mixed models (3 metrics × 2 roles × 2 corpora) using metrics as the respective response variables, the within-topic position as a fixed effect, and a random intercept grouped by individual speakers. We find a positive effect of within-topic position for leaders, and a reliably negative effect for followers (except SL of BNC follower), which confirms the observation of convergence trend (See <ref type="table" target="#tab_10">Table 1</ref>).</p><p>For NTD and NBF, we observe convergence patterns in Switchboard, but not reliably in BNC <ref type="figure" target="#fig_6">(Figure 3)</ref>. Linear mixed models are fit in similar ways, and the β coefficients are: for NTD, β leader = −2.2 × 10 −5 , β follower = 9.7 × 10 −4 * * * ; for NBF, β leader = 6.8 × 10 −5 * , β follower = −2.9 × 10 −4 * * * (*** indicates p &lt; 0.001, and * indicates p &lt; 0.05). Thus, a general trend seems supported. As NBF is the only metric that is lower in leaders and higher in followers, it could actually be an index for syntactic simplicity.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Discussion and Conclusion</head><p>By segmenting a conversation into several topic episodes, and then differentiating the interlocutors in terms of their roles in initiating the topic, leader or follower, we show that the syntactic complexity of the two interlocutors converges within topic episodes. The syntactic complexity of the topic leader decreases, while the complexity of the topic follower increases.</p><p>From an information-theoretical point of view, the syntactic complexity of a sentence is closely related to its amount of lexical information or negative entropy <ref type="bibr">Charniak, 2002, 2003)</ref>. By starting a new topic in conversation, the leading speaker brings novelty to the existing context, which often involves relatively long and complex utterances. On the other hand, the following speaker has to accommodate this change of context, by first producing short acknowledging phrases at the early stage, and gradually increase his contribution as the topic develops. Therefore, the convergence of syntactic complexity within a topic episode is a reflection of the process in which two interlocutors contribute jointly to build up common ground <ref type="bibr" target="#b221">(Clark and Brennan, 1991)</ref> with respect to a certain topic.</p><p>We find our results explained the theoretical frameworks of common ground  and the Interactive Alignment Model <ref type="bibr">(IAM, Pickering and Garrod, 2004)</ref>, models which are sometimes characterized as opposing accounts of coordination in dialogue. From the common-ground perspective of language-as-activity, interlocutors play different roles in dialogue, and the coordination between these roles facilitates the successful unfolding of dialogue. Our account identifies two such macro-level roles: topic leader vs. follower. From the perspective of Interactive Alignment, interactions between interlocutors in a dialogue are accompanied by the alignment of linguistic elements at multiple levels, including syntactic rules. Thus, the micro-level convergence of syntactic complexity is predicted by the IAM. Therefore, our findings point to the possibility of a unified perspective that combines the two theories.</p><p>It is worth pointing out that we present some novel ideas about the scope of convergence. Existing studies focus on the alignment effect that is observable throughout the whole conversation. In our case, the convergence of syntactic complexity occurs within smaller scope: the topic episodes. Note that the direction of convergence is dynamic: a speaker of higher complexity in one episode might be of lower complexity in the next episode, depending on her role. The next questions arising from these patterns mirror those asked of other types of alignment: is complexity alignment purposeful, is it controlled by individual differences or situational goals, and can it predict task success? We leave these questions for future work.</p><p>into multi-paragraph subtopic passages. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Abstract</head><p>Nowadays, many scholarly messages are posted on Chinese microblogs and more and more researchers tend to find scholarly information on microblogs. In order to exploit microblogging to benefit scientific research, we propose a scholarly microblog recommendation system in this study. It automatically collects and mines scholarly information from Chinese microblogs, and makes personalized recommendations to researchers. We propose two different neural network models which learn the vector representations for both users and microblog texts. Then the recommendation is accomplished based on the similarity between a user's vector and a microblog text's vector. We also build a dataset for this task. The two embedding models are evaluated on the dataset and show good results compared to several baselines.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Online social networks such as microblogs have drawn growing attention in recent years, and more and more researchers are involved in microblogging websites. Besides expressing their own emotions and exchanging their life experiences just like other users, these researchers also write from time to time about their latest findings or recommend useful research resources on their microblogs, which may be insightful to other researchers in the same field. We call such microblog texts scholarly microblog texts. The volume of scholarly microblog texts is huge, which makes it time-consuming for a researcher to browse and find the ones that he or she is interested in.</p><p>In this study, we aim to build a personalized recommendation system for recommending scholarly microblogs. With such a system a researcher can easily obtain the scholarly microblogs he or she has interests in. The system first collects the latest scholarly microblogs by crawling from manually selected microblog users or by applying scholarly microblog classification methods, as introduced in <ref type="bibr">(Yu and Wan, 2016)</ref>. Second, the system models the relevance of each scholarly microblog to a researcher and make personalized recommendation. In this study, we focus on the second step of the system and aim to model the interest and preference of a researcher by embedding the researcher into a dense vector. We also embed each scholarly microblog into a dense vector, and thus the relevance of a scholarly microblog to a researcher can be estimated based on their vector representations.</p><p>In this paper, we propose two neural embedding algorithms for learning the vector representations for both users (researchers) and microblog texts. By extending the paragraph vector representation method proposed by <ref type="bibr" target="#b233">(Le and Mikolov, 2014)</ref>, the vector representations are jointly learned in a single framework. By modeling the user preferences into the same vector space with the words and texts, we can obtain the similarity between them in a straightforward way, and use this relevance for microblog recommendation. We build a real evaluation dataset from Sina Weibo. Evaluation results on the dataset show the efficacy of our proposed methods.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Related Work</head><p>There have been a few previous studies focusing on microblog recommendation.  proposed a collaborative ranking model. Their approach takes advantage of collaborative filtering based recommendation by collecting preference information from many users. Their approach takes into account the content of the tweet, user's social relations and certain other explicitly defined features. <ref type="bibr">Ma et al. (2011)</ref> generated recommendations by adding additional social regularization terms in MF to constrain the user latent feature vectors to be similar to his or her friends' average latent features. <ref type="bibr">Bhattacharya et al. (2014)</ref> proposed a method benefiting from knowing the user's topics of interest, inferring the topics of interest for an individual user. Their idea is to infer them from the topical expertise of the users whom the user follows. <ref type="bibr">Khater and Elmongu (2015)</ref> proposed a dynamic personalized tweet recommendation system capturing the user's interests, which change over the time. Their system shows the messages that correspond to such dynamic interests. <ref type="bibr" target="#b232">Kuang et al. (2016)</ref> considered three major aspects in their proposed tweet recommending model, including the popularity of a tweet itself, the intimacy between the user and the tweet publisher, and the interest fields of the user. They also divided the users into three types by analyzing their behaviors, using different weights for the three aspects when recommending tweets for different types of users.</p><p>Most of the above studies make use of the relationships between users, while in this study, we focus on leveraging only the microblog texts for addressing the task.   After crawling the microblogs from the Machine Learning Daily, we used Sina Weibo API to retrieve the list of users who retweeted or commented on those microblogs. These retweeting and commenting actions indicated that those users have interests in the microblogs they retweeted or commented, and such microblogs were considered the gold-standard (positive) microblogs for the users in the recommendation system. Then we filtered out the users who have less than two hundred positive samples to avoid the data sparseness problem. This left us with 711 users and 10,620 microblog texts in our corpus. Each user was associated with 282.3 positive microblogs on average.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Evaluation Setup</head><p>Because there is no API that can directly grant us the access to the follower and followee list for each user without authorization on Sina Weibo, when evaluating the effectiveness of our methods, we randomly choose one hundred positive samples and another four hundred negative samples randomly selected from the crawled microblogs, to simulate the timeline of a user, and use this simulated timeline as the test dataset. The remaining positive samples are used for training.</p><p>We adopt two additional baselines: Bag-ofWords and SVM on Bag-of-Words. For the Bagof-Words baseline, we use the Bag-of-Words vector of each microblog text as the microblog text vector, and average them to obtain user vectors. For the SVM on Bag-of-Words baseline, we randomly choose the same amount of negative samples as that of positive samples for training. We use the Bag-of-Words vector of each microblog text as the features, and run the SVM algorithm implemented in LibSVM 3 once for every user. Note that the Average Embedding 3 https://www.csie.ntu.edu.tw/~cjlin/libsvm/ method introduced in Section 3.3 is considered a strong baseline for comparison.</p><p>For each method and each user, we sort the microblog texts according to their similarity with the user and select the top k microblog texts as recommendation results, where k varies from 10 to 100.</p><p>Besides precision and recall values, we also compute mean reciprocal rank (MRR) to measure the recommendation results in our experiments, which is the average of the multiplicative inverse of the rank of the positive samples in the output of the recommending system, and then averaged again across all users. Note that when k is set to 100, the precision and recall value will be equal to each other.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Evaluation Results</head><p>The comparison results with respect to different k are shown in <ref type="table" target="#tab_10">Table 1</ref>. As we can see, the two proposed joint learning methods outperform the simple average embedding method and the two other baselines, indicating the effectiveness of the proposed methods. Moreover, User2Vec#2 yields better results than User2Vec#1.We believe this is because in User2Vec#2, the word vectors have a direct contribution to the user vectors, which improves the learning effect of the user  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>452</head><p>vectors learnt in the framework. Furthermore, the precision/recall scores of the embedding methods (k=100) with respect to different vector dimensions are shown in <ref type="figure" target="#fig_6">Figure 3</ref>. We can see that the dimension size has little impact on the recommendation performance, and our proposed two methods always outperform the strong baseline.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Conclusion</head><p>In this paper, we proposed two neural embedding methods for learning the vector representations for both the users and the microblog texts. We tested their performance by applying them to recommending scholarly microblogs. In future work, we will investigate leveraging user relationships and temporal information to further improve the recommendation performance. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Abstract</head><p>We propose a novel vector representation that integrates lexical contrast into distributional vectors and strengthens the most salient features for determining degrees of word similarity. The improved vectors significantly outperform standard models and distinguish antonyms from synonyms with an average precision of 0.66-0.76 across word classes <ref type="bibr">(adjectives, nouns, verbs)</ref>. Moreover, we integrate the lexical contrast vectors into the objective function of a skip-gram model. The novel embedding outperforms state-of-the-art models on predicting word similarities in SimLex-999, and on distinguishing antonyms from synonyms.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Antonymy and synonymy represent lexical semantic relations that are central to the organization of the mental lexicon <ref type="bibr" target="#b248">(Miller and Fellbaum, 1991)</ref>. While antonymy is defined as the oppositeness between words, synonymy refers to words that are similar in meaning <ref type="bibr" target="#b236">(Deese, 1965;</ref><ref type="bibr" target="#b245">Lyons, 1977)</ref>. From a computational point of view, distinguishing between antonymy and synonymy is important for NLP applications such as Machine Translation and Textual Entailment, which go beyond a general notion of semantic relatedness and require to identify specific semantic relations. However, due to interchangeable substitution, antonyms and synonyms often occur in similar contexts, which makes it challenging to automatically distinguish between them.</p><p>Distributional semantic models (DSMs) offer a means to represent meaning vectors of words and to determine their semantic "relatedness" <ref type="bibr" target="#b235">(Budanitsky and Hirst, 2006;</ref><ref type="bibr" target="#b260">Turney and Pantel, 2010)</ref>.</p><p>They rely on the distributional hypothesis <ref type="bibr" target="#b238">Firth, 1957)</ref>, in which words with similar distributions have related meaning. For computation, each word is represented by a weighted feature vector, where features typically correspond to words that co-occur in a particular context. However, DSMs tend to retrieve both synonyms (such as formal-conventional) and antonyms (such as formal-informal) as related words and cannot sufficiently distinguish between the two relations.</p><p>In recent years, a number of distributional approaches have accepted the challenge to distinguish antonyms from synonyms, often in combination with lexical resources such as thesauruses or taxonomies. For example,  used dependency triples to extract distributionally similar words, and then in a post-processing step filtered out words that appeared with the patterns 'from X to Y' or 'either X or Y' significantly often.  assumed that word pairs that occur in the same thesaurus category are close in meaning and marked as synonyms, while word pairs occurring in contrasting thesaurus categories or paragraphs are marked as opposites. <ref type="bibr" target="#b258">Scheible et al. (2013)</ref> showed that the distributional difference between antonyms and synonyms can be identified via a simple word space model by using appropriate features. <ref type="bibr" target="#b254">Santus et al. (2014a)</ref> and <ref type="bibr" target="#b255">Santus et al. (2014b)</ref> aimed to identify the most salient dimensions of meaning in vector representations and reported a new average-precisionbased distributional measure and an entropy-based measure to discriminate antonyms from synonyms (and further paradigmatic semantic relations).</p><p>Lately, antonym-synonym distinction has also been a focus of word embedding models. For example,  integrated coreference chains extracted from large corpora into a skip-gram model to create word embeddings that identified antonyms. <ref type="bibr" target="#b251">Ono et al. (2015)</ref> pro-posed thesaurus-based word embeddings to capture antonyms. They proposed two models: the WE-T model that trains word embeddings on thesaurus information; and the WE-TD model that incorporated distributional information into the WE-T model.  introduced the multitask lexical contrast model (mLCM) by incorporating WordNet into a skip-gram model to optimize semantic vectors to predict contexts. Their model outperformed standard skip-gram models with negative sampling on both general semantic tasks and distinguishing antonyms from synonyms.</p><p>In this paper, we propose two approaches that make use of lexical contrast information in distributional semantic space and word embeddings for antonym-synonym distinction. Firstly, we incorporate lexical contrast into distributional vectors and strengthen those word features that are most salient for determining word similarities, assuming that feature overlap in synonyms is stronger than feature overlap in antonyms. Secondly, we propose a novel extension of a skip-gram model with negative sampling  that integrates the lexical contrast information into the objective function. The proposed model optimizes the semantic vectors to predict degrees of word similarity and also to distinguish antonyms from synonyms. The improved word embeddings outperform state-of-the-art models on antonymsynonym distinction and a word similarity task.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Our Approach</head><p>In this section, we present the two contributions of this paper: a new vector representation that improves the quality of weighted features to distinguish between antonyms and synonyms (Section 2.1), and a novel extension of skip-gram models that integrates the improved vector representations into the objective function, in order to predict similarities between words and to identify antonyms (Section 2.2).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Improving the weights of feature vectors</head><p>We aim to improve the quality of weighted feature vectors by strengthening those features that are most salient in the vectors and by putting less emphasis on those that are of minor importance, when distinguishing degrees of similarity between words. We start out with standard corpus co-occurrence frequencies and apply local mutual information (LMI) <ref type="bibr" target="#b237">(Evert, 2005)</ref> to determine the original strengths of the word features. Our score weight SA (w, f ) subsequently defines the weights of a target word w and a feature f :</p><formula xml:id="formula_205">weight SA (w, f ) = 1 #(w,u) u∈W (f )∩S(w) sim(w, u) − 1 #(w ,v) w ∈A(w) v∈W (f )∩S(w ) sim(w , v)<label>(1)</label></formula><p>The new weight SA scores of a target word w and a feature f exploit the differences between the average similarities of synonyms to the target word (sim(w, u), with u ∈ S(w)), and the average similarities between antonyms of the target word (sim(w , v), with w ∈ A(w) and v ∈ S(w )).</p><p>Only those words u and v are included in the calculation that have a positive original LMI score for the feature f : W (f ). To calculate the similarity sim between two word vectors, we rely on cosine distances. If a word w is not associated with any synonyms or antonyms in our resources (cf. Section 3.1), or if a feature does not co-occur with a word w, we define weight SA (w, f ) = 0. The intuition behind the lexical contrast information in our new weight SA is as follows. The strongest features of a word also tend to represent strong features of its synonyms, but weaker features of its antonyms. For example, the feature conception only occurs with synonyms of the adjective formal but not with the antonym informal, or with synonyms of the antonym informal. weight SA (f ormal, conception), which is calculated as the average similarity between formal and its synonyms minus the average similarity between informal and its synonyms, should thus return a high positive value. In contrast, a feature such as issue that occurs with many different adjectives, would enforce a feature score near zero for weight SA (f ormal, issue), because the similarity scores between formal and its synonyms and informal and its synonyms should not differ strongly. Last but not least, a feature such as rumor that only occurs with informal and its synonyms, but not with the original target adjective formal and its synonyms, should invoke a very low value for weight SA (f ormal, rumor). <ref type="figure" target="#fig_3">Figure 1</ref> provides a schematic visualization for computing the new weight SA scores for the target formal.</p><p>Since the number of antonyms is usually much smaller than the number of synonyms, we enrich the number of antonyms: Instead of using the w="f o r ma l " f ="c o n c e p t i o n " f ="i s s u e " f ="r u mo r " The feature conception only occurs with formal and synonyms of formal, so weight SA (f ormal, conception) should return a positive value; the feature rumor only occurs with the antonym informal and with synonyms of informal, so weight SA (f ormal, rumor) should return a negative value; the feature issue occurs with both formal and informal and also with synonyms of these two adjectives, so weight SA (f ormal, issue) should return a feature score near zero.</p><p>direct antonym links, we consider all synonyms of an antonym w ∈ A(w) as antonyms of w. For example, the target word good has only two antonyms in WordNet (bad and evil), in comparison to 31 synonyms. Thus, we also exploit the synonyms of bad and evil as antonyms for good.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Integrating the distributional lexical contrast into a skip-gram model</head><p>Our model relies on  who showed that the objective function for a skip-gram model with negative sampling (SGNS) can be defined as follows:</p><p>w∈V c∈V {#(w, c) log σ(sim(w, c))</p><formula xml:id="formula_206">+k#(w)P 0 (c) log σ(−sim(w, c))}<label>(2)</label></formula><p>The first term in Equation <ref type="formula" target="#formula_1">(2)</ref> represents the cooccurrence between a target word w and a context c within a context window. The number of appearances of the target word and that context is defined as #(w, c). The second term refers to the negative sampling where k is the number of negatively sampled words, and #(w) is the number of appearances of w as a target word in the unigram distribution P 0 of its negative context c. To incorporate our lexical contrast information into the SGNS model, we propose the objective function in Equation <ref type="formula" target="#formula_6">(3)</ref> to add distributional contrast followed by all contexts of the target word. V is the vocabulary; σ(x) = 1 1+e −x is the sigmoid function; and sim(w 1 , w 2 ) is the cosine similarity between the two embedded vectors of the corresponding two words w 1 and w 2 . We refer to our distributional lexical-contrast embedding model as dLCE.</p><p>w∈V c∈V {(#(w, c) log σ(sim(w, c))</p><formula xml:id="formula_207">+k#(w)P 0 (c) log σ(−sim(w, c))) +( 1 #(w,u) u∈W (c)∩S(w) sim(w, u) − 1 #(w,v) v∈W (c)∩A(w) sim(w, v))} (3)</formula><p>Equation <ref type="formula" target="#formula_6">(3)</ref> integrates the lexical contrast information in a slightly different way compared to Equation (1): For each of the target words w, we only rely on its antonyms A(w) instead of using the synonyms of its antonyms S(w ). This makes the word embeddings training more efficient in running time, especially since we are using a large amount of training data.</p><p>The dLCE model is similar to the WE-TD model <ref type="bibr" target="#b251">(Ono et al., 2015)</ref> and the mLCM model ; however, while the WE-TD and mLCM models only apply the lexical contrast information from WordNet to each of the target words, dLCE applies lexical contrast to every single context of a target word in order to better capture and classify semantic contrast.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Experiments</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Experimental Settings</head><p>The corpus resource for our vector representations is one of the currently largest web corpora: EN-COW14A <ref type="bibr" target="#b256">(Schäfer and Bildhauer, 2012;</ref><ref type="bibr" target="#b257">Schäfer, 2015)</ref>, containing approximately 14.5 billion tokens and 561K distinct word types. As distributional information, we used a window size of 5 tokens for both the original vector representation and the word embeddings models. For word embeddings models, we trained word vectors with 500 dimensions; k negative sampling was set to 15; the threshold for sub-sampling was set to 10 −5 ; and we ignored all words that occurred &lt; 100 times in the corpus. The parameters of the models were estimated by backpropagation of error via stochastic gradient descent. The learning rate strategy was similar to  in which the initial learning rate was set to 0.025. For the lexical contrast information, we used WordNet <ref type="bibr" target="#b249">(Miller, 1995)</ref> and Wordnik 1 to collect antonyms and synonyms, obtaining a total of 363,309 synonym and 38,423 antonym pairs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Distinguishing antonyms from synonyms</head><p>The first experiment evaluates our lexical contrast vectors by applying the vector representations with the improved weight SA scores to the task of distinguishing antonyms from synonyms. As gold standard resource, we used the English dataset described in <ref type="bibr" target="#b253">(Roth and Schulte im Walde, 2014)</ref>, containing 600 adjective pairs (300 antonymous pairs and 300 synonymous pairs), 700 noun pairs (350 antonymous pairs and 350 synonymous pairs) and 800 verb pairs (400 antonymous pairs and 400 synonymous pairs). For evaluation, we applied Average Precision (AP) <ref type="bibr" target="#b261">(Voorhees and Harman, 1999)</ref>, a common metric in information retrieval previously used by <ref type="bibr" target="#b241">Kotlerman et al. (2010)</ref> and <ref type="bibr" target="#b254">Santus et al. (2014a)</ref>, among others. <ref type="table" target="#tab_10">Table 1</ref> presents the results of the first experiment, comparing our improved vector representations with the original LMI representations across word classes, without/with applying singular-value decomposition (SVD), respectively. In order to evaluate the distribution of word pairs with AP, we sorted the synonymous and antonymous pairs by their cosine scores. A synonymous pair was considered correct if it belonged to the first half; and an antonymous pairs was considered correct if it was in the second half. The optimal results would thus achieve an AP score of 1 for SY N and 0 for AN T . The results in the tables demonstrate that weight SA significantly 2 outperforms the original vector representations across word classes.</p><p>In addition, <ref type="figure" target="#fig_8">Figure 2</ref> compares the medians of cosine similarities between antonymous pairs (red) vs. synonymous pairs (green) across word classes, and for the four conditions (1) LMI, (2) weight SA , (3) SVD on LMI, and (4) SVD on weight SA . The plots show that the cosine similarities of the two relations differ more strongly with our improved vector representations in comparison to the original LMI representations, and even more so after applying SVD.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Effects of distributional lexical contrast on word embeddings</head><p>The second experiment evaluates the performance of our dLCE model on both antonym-synonym distinction and a word similarity task. The similarity task requires to predict the degree of similarity for word pairs, and the ranked list of predictions is evaluated against a gold standard of human ratings, relying on the Spearman rank-order correlation coefficient ρ <ref type="bibr" target="#b259">(Siegel and Castellan, 1988)</ref>.</p><p>In this paper, we use the SimLex-999 dataset  to evaluate word embedding models on predicting similarities. The resource contains 999 word pairs (666 noun, 222 verb and 111 adjective pairs) and was explicitly built to test models on capturing similarity rather than relatedness or association. <ref type="table" target="#tab_5">Table 2</ref> shows that our dLCE model outperforms both SGNS and mLCM, proving that the lexical contrast information has a positive effect on predicting similarity.     Therefore, the improved distinction between synonyms (strongly similar words) and antonyms (often strongly related but highly dissimilar words) in the dLCE model also supports the distinction between degrees of similarity.</p><p>For distinguishing between antonyms and synonyms, we computed the cosine similarities between word pairs on the dataset described in Section 3.2, and then used the area under the ROC curve (AUC) to evaluate the performance of dLCE compared to SGNS and mLCM. The results in Table 3 report that dLCE outperforms SGNS and mLCM also on this task.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Conclusion</head><p>This paper proposed a novel vector representation which enhanced the prediction of word similarity, both for a traditional distributional semantics model and word embeddings. Firstly, we significantly improved the quality of weighted features to distinguish antonyms from synonyms by using lexical contrast information. Secondly, we incorporated the lexical contrast information into a skip-gram model to successfully predict degrees of similarity and also to identify antonyms. In MTE, the goal is to decide whether a hypothesis translation conveys the same meaning as the reference translation. In cQA, it is to determine whether the comment is an appropriate answer to the question. Furthermore, in MTE we can expect shorter texts, which are typically much more similar. In contrast, in cQA, the question and the intended answers might differ significantly both in terms of length and in lexical content. Thus, it is not clear a priori whether the MTE network can work well to address the cQA problem. Here, we show that the analogy is not only convenient, but also that using it can yield state-of-the-art results for the cQA task.</p><p>To validate our intuition, we present series of experiments using the publicly available SemEval-2016 Task 3 datasets, with focus on subtask A. We show that a naïve application of the MTE architecture and features on the cQA task already yields results that are largely above the task baselines. Furthermore, by adapting the models with indomain data, and adding lightweight task-specific features, we are able to boost our system to reach state-of-the-art performance.</p><p>More interestingly, we analyze the contribution of several features and parts of the NN architecture by performing an ablation study. We observe that every single piece contributes important information to achieve the final performance. While taskspecific features are crucial, other aspects of the framework are relevant as well: syntactic embeddings, machine translation evaluation measures, and pairwise training of the network.</p><p>The rest of the paper is organized as follows: Section 2 introduces some related work. Section 3 presents the overall architecture of our MTEinspired NN framework for cQA. Section 4 summarizes the features we use in our experiments. Section 5 describes the experimenal settings and presents the results. Finally, Section 6 offers further discussion and presents the main conclusions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Related Work</head><p>Recently, many neural network (NN) models have been applied to cQA tasks: e.g., question-question similarity <ref type="bibr" target="#b268">dos Santos et al., 2015;</ref><ref type="bibr" target="#b278">Lei et al., 2016)</ref> and answer selection <ref type="bibr" target="#b286">(Severyn and Moschitti, 2015;</ref><ref type="bibr" target="#b294">Wang and Nyberg, 2015;</ref><ref type="bibr" target="#b287">Shen et al., 2015;</ref><ref type="bibr" target="#b271">Feng et al., 2015;</ref>. Most of these papers concentrate on providing advanced neural architectures in order to better model the problem at hand. However, our goal here is different: we extend and reuse an existing pairwise NN framework from a different but related problem.</p><p>There is also work that uses machine translation models as a features for cQA <ref type="bibr" target="#b265">(Berger et al., 2000;</ref><ref type="bibr" target="#b270">Echihabi and Marcu, 2003;</ref><ref type="bibr" target="#b276">Jeon et al., 2005;</ref><ref type="bibr" target="#b290">Soricut and Brill, 2006;</ref><ref type="bibr" target="#b285">Riezler et al., 2007;</ref><ref type="bibr" target="#b279">Li and Manandhar, 2011;</ref><ref type="bibr" target="#b291">Surdeanu et al., 2011;</ref><ref type="bibr" target="#b293">Tran et al., 2015)</ref> e.g., a variation of IBM model 1, to compute the probability that the question is a possible "translation" of the candidate answer. Unlike that work, here we port an entire MTE framework to the cQA problem. A preliminary version of this work was presented in <ref type="bibr" target="#b275">(Guzmán et al., 2016)</ref>. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Neural Model for Answer Ranking</head><p>The NN model we use for answer ranking is depicted in <ref type="figure" target="#fig_8">Figure 2</ref>. It is a direct adaptation of our feed-forward NN for MTE <ref type="bibr" target="#b274">(Guzmán et al., 2015)</ref>. Technically, we have a binary classification task with input (q, c 1 , c 2 ), which should output 1 if c 1 is a better answer to q than c 2 , and 0 otherwise. The network computes a sigmoid function</p><formula xml:id="formula_208">f (q, c 1 , c 2 ) = sig(w T v φ(q, c 1 , c 2 ) + b v )</formula><p>, where φ(x) transforms the input x through the hidden layer, w v are the weights from the hidden layer to the output layer, and b v is a bias term.</p><p>We first map the question and the comments to a fixed-length vector [x q , x c 1 , x c 2 ] using syntactic and semantic embeddings. Then, we feed this vector as input to the neural network, which models three types of interactions, using different groups of nodes in the hidden layer. There are two evaluation groups h q1 and h q2 that model how good each comment c i is to the question q. The input to these groups are the concatenations [x q , x c 1 ] and [x q , x c 2 ], respectively. The third group of hidden nodes h 12 , which we call similarity group, models how close c 1 and c 2 are. Its input is [x c 1 , x c 2 ]. This might be useful as highly similar comments are likely to be comparable in appropriateness, irrespective of whether they are good or bad answers in absolute terms.</p><p>In summary, the transformation φ(q, c 1 , c 2 ) = [h q1 , h q2 , h 12 ] can be written as</p><formula xml:id="formula_209">h qi = g(W qi [x q , x c i ] + b qi ), i = 1, 2 h 12 = g(W 12 [x c 1 , x c 2 ] + b 12 ),</formula><p>where g(.) is a non-linear activation function (applied component-wise), W ∈ R H×N are the associated weights between the input layer and the hidden layer, and b are the corresponding bias terms.</p><p>We use tanh as an activation function, rather than sig, to be consistent with how the word embedding vectors we use were generated.</p><p>The model further allows to incorporate external sources of information in the form of skip arcs that go directly from the input to the output, skipping the hidden layer. These arcs represent pairwise similarity feature vectors between q and either c 1 or c 2 . In these feature vectors, we encode MT evaluation measures (e.g., TER, ME-TEOR, and BLEU), cQA task-specific features, etc. See Section 4 for detail about the features implemented as skip arcs. In the figure, we indicate these pairwise external feature sets as ψ(q, c 1 ) and ψ(q, c 2 ). When including the external features, the activation at the output is f (q, c 1 ,</p><formula xml:id="formula_210">c 2 ) = sig(w T v [φ(q, c 1 , c 2 ), ψ(q, c 1 ), ψ(q, c 2 )] + b v ).</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Features</head><p>We experiment with three kinds of features: (i) input embeddings, (ii) features from MTE <ref type="bibr" target="#b274">(Guzmán et al., 2015)</ref> and (iii) task-specific features from SemEval-2015 Task 3 <ref type="bibr" target="#b283">(Nicosia et al., 2015)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Embedding Features</head><p>We used two types of vector-based embeddings to encode the input texts q, c 1 and c 2 : (1) GOOGLE VECTORS: 300-dimensional embedding vectors, trained on 100 billion words from Google News . The encoding of the full text is just the average of the word embeddings. (2) SYNTAX:</p><p>We parse the entire question/comment using the Stanford neural parser , and we use the final 25-dimensional vector that is produced internally as a by-product of parsing. Also, we compute cosine similarity features with the above vectors: cos(q, c 1 ) and cos(q, c 2 ).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. MTE features</head><p>We use the following MTE metrics (MTFEATS), which compare the similarity between the question and a candidate answer: (1) BLEU <ref type="bibr" target="#b284">(Papineni et al., 2002)</ref>; <ref type="formula" target="#formula_1">(2)</ref> NIST <ref type="bibr" target="#b267">(Doddington, 2002)</ref>; (3) TER v0.7.25 <ref type="bibr" target="#b288">(Snover et al., 2006)</ref>. <ref type="formula" target="#formula_7">(4)</ref>  BLEUCOMP. We further use as features various components involved in the computation of BLEU: n-gram precisions, n-gram matches, total number of n-grams (n=1,2,3,4), lengths of the hypotheses and of the reference, length ratio between them, and BLEU's brevity penalty.</p><p>C. Task-specific features First, we train domain-specific vectors using WORD2VEC on all available QatarLiving data, both annotated and raw (QL VECTORS).</p><p>Second, we compute various easy taskspecific features (TASK FEATURES), most of them proposed for the 2015 edition of the task <ref type="bibr" target="#b283">(Nicosia et al., 2015)</ref>.</p><p>This includes some comment-specific features:</p><p>(1) number of URLs/images/emails/phone numbers; (2) number of occurrences of the string "thank"; 3 (3) number of tokens/sentences; (4) average number of tokens; (5) type/token ratio; (6) number of nouns/verbs/adjectives/adverbs/ pronouns; (7) number of positive/negative smileys; (8) number of single/double/triple exclamation/interrogation symbols; (9) number of interrogative sentences (based on parsing); (10) number of words that are not in WORD2VEC's Google News vocabulary. <ref type="bibr">4</ref> Also some question-comment pair features: (1) question to comment count ratio in terms of sentences/tokens/nouns/verbs/adjectives/adverbs/pronouns; (2) question to comment count ratio of words that are not in WORD2VEC's Google News vocabulary. Finally, we also have two meta features: <ref type="formula" target="#formula_0">(1)</ref> is the person answering the question the one who asked it; (2) reciprocal rank of the comment in the thread.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Experiments and Results</head><p>We experiment with the data from SemEval-2016 Task 3. The task offers a higher quality training dataset TRAIN-PART1, which includes 1,412 questions and 14,110 answers, and a lower-quality TRAIN-PART2 with 382 questions and 3,790 answers. We train our model on TRAIN-PART1 with hidden layers of size 3 for 100 epochs with minibatches of size 30, regularization of 0.005, and a decay of 0.0001, using stochastic gradient descent with adagrad <ref type="bibr" target="#b269">(Duchi et al., 2011)</ref>; we use Theano <ref type="bibr" target="#b266">(Bergstra et al., 2010)</ref> for learning. We normalize the input feature values to the [−1; 1] interval using minmax, and we initialize the network weights by sampling from a uniform distribution as in <ref type="bibr" target="#b264">(Bengio and Glorot, 2010)</ref>. We train the model using all pairs of good vs. bad comments, in both orders, ignoring ties. At test time, we get the full ranking by scoring all possible pairs, and we accumulate the scores at the comment level.</p><p>We evaluate the model on TRAIN-PART2 after each epoch, and ultimately we keep the model that achieves the highest accuracy; 5 in case of a tie, we prefer the parameters from an earlier epoch. We selected the above parameter values on the DEV dataset (244 questions and 2,440 answers) using the full model, and we used them for all experiments below, where we evaluate on the official TEST dataset (329 questions and 3,270 answers). We report mean average precision (MAP), which is the official evaluation measure, and also average recall (AvgRec) and mean reciprocal rank (MRR). <ref type="table" target="#tab_10">Table 1</ref> shows the evaluation results for three configurations of our MTE-based cQA system. We can see that the vanilla MTE system (MTE vanilla ), which only uses features from our original MTE model, i.e., it does not have any task-specific features (TASK FEATURES and QL VECTORS), performs surprisingly well despite the differences in the MTE and cQA tasks. It outperforms a random baseline (Baseline rand ) and a chronological baseline that assumes that early comments are better than later ones (Baseline time ) by large margins: by about 11 and 17 MAP points absolute, respectively. For the other two measures the results are similar.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Results</head><p>We can further see that adding the task-specific features in MTE-CQA pairwise improves the results by another 8 MAP points absolute. Finally, the second line shows that adapting the network to do classification (MTE-CQA classif ication ), giving it a question and a single comment as input, yields a performance drop of 0.6 MAP points absolute compared to the proposed pairwise learning model. Thus, the pairwise training strategy is confirmed to be better for the ranking task, although not by a large margin.  <ref type="table" target="#tab_5">Table 2</ref>: Results of the ablation study. <ref type="table" target="#tab_5">Table 2</ref> presents the results of an ablation study, where we analyze the contribution of various features and feature groups to the performance of the overall system. For the purpose, we study ∆ MAP , i.e., the absolute drop in MAP when the feature group is excluded from the full system. Not surprisingly, the most important turn out to be the TASK FEATURES (contributing over five MAP points) as they handle important information sources that are not available to the system from other feature groups, e.g., the reciprocal rank alone contributes about two points.</p><p>Next in terms of importance come word embeddings, QL VECTORS (contributing over 2 MAP points), trained on text from the target forum, QatarLiving. Then come the GOOGLE VECTORS (contributing over one MAP point), which are trained on 100 billion words, and thus are still useful even in the presence of the domain-specific QL VECTORS, which are in turn trained on four orders of magnitude less data.</p><p>Interestingly, the MTE-motivated SYNTAX vectors contribute half a MAP point, which shows the importance of modeling syntax for this task. The other two MTE features, MTFEATS and BLEU-COMP, together contribute 0.8 MAP points. It is interesting that the BLEU components manage to contribute on top of the MTFEATS, which already contain several state-of-the-art MTE measures, including BLEU itself. This is probably because the other features we have do not model n-gram matches directly.</p><p>Finally, <ref type="table" target="#tab_6">Table 3</ref> puts the results in perspective. We can see that our system MTE-CQA would rank first on MRR, second on MAP, and fourth on AvgRec in <ref type="bibr">SemEval-2016 Task 3 competition. 6</ref> These results are also 5 and 16 points above the average and the worst systems, respectively. <ref type="bibr">6</ref> The full results can be found on the task website: http://alt.qcri.org/semeval2016/task3/index.php?id=results System MAP AvgRec MRR 1st <ref type="bibr" target="#b272">(Filice et al., 2016)</ref>   <ref type="bibr" target="#b262">(Barrón-Cedeño et al., 2016)</ref>  <ref type="bibr">77.66</ref> 88.05 84.93 3rd <ref type="bibr" target="#b280">(Mihaylov and Nakov, 2016)</ref>   This is remarkable given the lightweight taskspecific features we use, and confirms the validity of the proposed neural approach to produce stateof-the-art systems for this particular cQA task.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Conclusion</head><p>We have explored the applicability of machine translation evaluation methods to answer ranking in community Question Answering, a seemingly very different task, where the goal is to rank the comments in a question-answer thread according to their appropriateness to the question, placing all good comments above all bad ones.</p><p>In particular, we have adopted a pairwise neural network architecture, which incorporates MTE features, as well as rich syntactic and semantic embeddings of the input texts that are non-linearly combined in the hidden layer. The evaluation results on benchmark datasets have shown stateof-the-art performance, with sizeable contribution from both the MTE features and from the network architecture. This is an interesting and encouraging result, as given the difference in the tasks, it was not a-priori clear that an MTE approach would work well for cQA.</p><p>In future work, we plan to incorporate other similarity measures and better task-specific features into the model. We further want to explore the application of this architecture to other semantic similarity problems such as question-question similarity, and textual entailment.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Science Question Answering using Instructional Materials Mrinmaya Sachan</head><p>Avinava Dubey Eric P. Xing School of Computer Science Carnegie Mellon University {mrinmays, akdubey, epxing}@cs.cmu.edu</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Abstract</head><p>We provide a solution for elementary science tests using instructional materials. We posit that there is a hidden structure that explains the correctness of an answer given the question and instructional materials and present a unified max-margin framework that learns to find these hidden structures (given a corpus of questionanswer pairs and instructional materials), and uses what it learns to answer novel elementary science questions. Our evaluation shows that our framework outperforms several strong baselines.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>We propose an approach for answering multiplechoice elementary science tests <ref type="bibr" target="#b299">(Clark, 2015)</ref> using the science curriculum of the student and other domain specific knowledge resources. Our approach learns latent answer-entailing structures that align question-answers with appropriate snippets in the curriculum. The student curriculum usually comprises of a set of textbooks. Each textbook, in-turn comprises of a set of chapters, each chapter is further divided into sections -each discussing a particular science concept. Hence, the answer-entailing structure consists of selecting a particular textbook from the curriculum, picking a chapter in the textbook, picking a section in the chapter, picking a few sentences in the section and then aligning words/multi-word expressions (mwe's) in the hypothesis (formed by combining the question and an answer candidate) to words/mwe's in the picked sentences. The answerentailing structures are further refined using external domain-specific knowledge resources such as science dictionaries, study guides and semistructured tables (see <ref type="figure" target="#fig_3">Figure 1)</ref>. These domainspecific knowledge resources can be very useful forms of knowledge representation as shown in previous works <ref type="bibr" target="#b298">(Clark et al., 2016)</ref>.</p><p>Alignment is a common technique in many NLP applications such as MT <ref type="bibr" target="#b297">(Blunsom and Cohn, 2006)</ref>, RTE <ref type="bibr" target="#b313">(Sammons et al., 2009;</ref><ref type="bibr" target="#b308">MacCartney et al., 2008;</ref><ref type="bibr" target="#b316">Sultan et al., 2014)</ref>, QA <ref type="bibr" target="#b296">(Berant et al., 2013;</ref><ref type="bibr" target="#b317">Yao and Van Durme, 2014;</ref>, etc. Yet, there are three key differences between our approach and alignment based approaches for QA in the literature: (i) We incorporate the curriculum hierarchy (i.e. the book, chapter, section bifurcation) into the latent structure. This helps us jointly learn the retrieval and answer selection modules of a QA system. Retrieval and answer selection are usually designed as isolated or loosely connected components in QA systems <ref type="bibr" target="#b303">(Ferrucci, 2012)</ref> leading to loss in performance -our approach mitigates this shortcoming. (ii) Modern textbooks typically provide a set of review questions after each section to help students understand the material better. We make use of these review problems to further improve our model. These review problems have additional value as part of the latent structure is known for these questions.</p><p>(ii) We utilize domain-specific knowledge sources such as study guides, science dictionaries or semistructured knowledge tables within our model.</p><p>The joint model is trained in max-margin fashion using a latent structural SVM (LSSVM) where the answer-entailing structures are latent. We train and evaluate our models on a set of 8 th grade science problems, science textbooks and multiple domain-specific knowledge resources. We achieve superior performance vs. a number of baselines.  <ref type="figure" target="#fig_3">Figure 1</ref>: An example answer-entailing structure. The answer-entailing structure consists of selecting a particular textbook from the curriculum, picking a chapter in the textbook, picking a section in the chapter, picking sentences in the section and then aligning words/mwe's in the hypothesis (formed by combining the question and an answer candidate) to words/mwe's in the picked sentences or some related "knowledge" appropriately chosen from additional knowledge stores. In this case, the relation (greenhouse gases, cause, greenhouse effect) and the equivalences (e.g. carbon dioxide = CO2) -shown in violet -are hypothesized using external knowledge resources. The dashed red lines show the word/mwe alignments from the hypothesis to the sentences (some word/mwe are not aligned, in which case the alignments are not shown), the solid black lines show coreference links in the text and the RST relation (elaboration) between the two sentences. The picked sentences do not have to be contiguous sentences in the text. All mwe's are shown in green.</p><p>consider the case when review questions are not used. For each question q i ∈ Q, let A i = {a i1 , . . . , a im } be the set of candidate answers to the question 1 . We cast the science QA problem as a textual entailment problem by converting each question-answer candidate pair (q i , a i,j ) into a hypothesis statement h ij (see <ref type="figure" target="#fig_3">Figure 1)</ref> 2 . For each question q i , the science QA task thereby reduces to picking the hypothesisĥ i that has the highest likelihood of being entailed by the curriculum among the set of hypotheses h i = {h i1 , . . . , h im } generated for that question. Let h * i ∈ h i be the correct hypothesis corresponding to the correct answer. Latent Answer-Entailing Structures help the model in providing evidence for the correct hypothesis. As described before, the structure depends on: (a) snippet from the curriculum hierarchy chosen to be aligned to the hypothesis, (b) external knowledge relevant for this entailment, and (c) the word/mwe alignment. The snippet from the curriculum to be aligned to the hypothesis is determined by walking down the curriculum hierarchy and then picking a set of sentences from the section chosen. Then, a subset of relevant external knowledge in the form of triples and equivalences (called knowledge bits) is selected from our 1 Candidate answers may be pre-defined, as in multiplechoice QA, or may be undefined but easy to extract with a degree of confidence (e.g., by using a pre-existing system) <ref type="bibr">2</ref> We use a set of question matching/rewriting rules to achieve this transformation. The rules match each question into one of a large set of pre-defined templates and applies a unique transformation to the question &amp; answer candidate to achieve the hypothesis. Code provided in the supplementary. reservoir of external knowledge (science dictionaries, cheat sheets, semi-structured tables, etc). Finally, words/mwe's in the hypothesis are aligned to words/mwe's in the snippet or knowledge bits. Learning these alignment edges helps the model determine which semantic constituents should be compared to each other. These alignments are also used to generate more effective features. The choice of snippets, choice of the relevant external knowledge and the alignments in conjunction form the latent answer-entailing structure. Let z ij represent the latent structure for the question-answer candidate pair (q i , a i,j ). Max-Margin Approach: We treat science QA as a structured prediction problem of ranking the hypothesis set h i such that the correct hypothesis is at the top of this ranking. We learn a scoring function S w (h, z) with parameter w such that the score of the correct hypothesis h * i and the corresponding best latent structure z * i is higher than the score of the other hypotheses and their corresponding best latent structures. In fact, in a max-margin fashion, we want that S w (h * i , z * i ) &gt; S(h ij , z ij ) + 1 − ξ i for all h j ∈ h \ h * for some slack ξ i . Writing the relaxed max margin formulation:</p><formula xml:id="formula_211">min ||w|| 1 2 ||w|| 2 2 + C i max z ij ,h ij ∈h i \h * i Sw(hij, zij) + ∆(h * i , hij) −C i Sw(h * i , z * i )<label>(1)</label></formula><p>We use 0-1 cost, i.e. ∆(h * i , h ij ) = 1(h * i = h ij ) If the scoring function is convex then this objective is in concave-convex form and hence can be solved by the concave-convex programming procedure (CCCP) . We assume the scoring function to be linear:S w (h, z) = w T ψ(h, z). Here, ψ(h, z) is a feature map discussed later. The CCCP algorithm essentially alternates between solving for z * i , z ij ∀j s.t. h ij ∈ h i \ h * i and w to achieve a local minima. In the absence of information regarding the latent structure z we pick the structure that gives the best score for a given hypothesis i.e. arg max z S w (h, z). The complete procedure is given in the supplementary. Inference and knowledge selection: We use beam search with a fixed beam size (5) for inference. We infer the textbook, chapter, section, snippet and alignments one by one in this order. In each step, we only expand the five most promising (given by the current score) substructure candidates so far. During inference, we select top 5 knowledge bits (triples, equivalences, etc.) from the knowledge resources that could be relevant for this question-answer. This is done heuristically by picking knowledge bits that explain parts of the hypothesis not explained by the chosen snippets. Incorporating partially known structures: Now, we describe how review questions can be incorporated. As described earlier, modern textbooks often provide review problems at the end of each section. These review problems have value as part of the answer-entailing structure (textbook, chapter and section) is known for these problems. In this case, we use the formulation (equation 1) except that the max over z for the review questions is only taken over the unknown part of the latent structure. Multi-task Learning: Question analysis is a key component of QA systems. Incoming questions are often of different types (counting, negation, entity queries, descriptive questions, etc.). Different types of questions usually require different processing strategies. Hence, we also extend of our LSSVM model to a multi-task setting where each question q i now also has a pre-defined associated type t i and each question-type is treated as a separate task. Yet, parameters are shared across tasks,which allows the model to exploit the commonality among tasks when required. We use the MTLSSVM formulation from <ref type="bibr" target="#b301">Evgeniou and Pontil (2004)</ref> which was also used in a reading comprehension setting by . In a nutshell, the approach redefines the LSSVM feature map and shows that the MTLSSVM objective takes the same form as equation 1 with a kernel corresponding to the feature map. Hence, one can simply redefine the feature map and reuse LSSVM algorithm to solve the MTLSSVM. Features: Our feature vector ψ(h, z) decomposes into five parts, where each part corresponds to a part of the answer-entailing structure. For the first part, we index all the textbooks and score the top retrieved textbook by querying the hypothesis statement. We use tf-idf and BM25 scorers resulting in two features. Then, we find the jaccard similarity of bigrams and trigrams in the hypothesis and the textbook to get two more features for the first part. Similarly, for the second part we index all the textbook chapters and compute the tf-idf, BM25 and bigram, trigram features. For the third part we index all the sections instead. The fourth part has features based on the text snippet part of the answer-entailing structure. Here we do a deeper linguistic analysis and include features for matching local neighborhoods in the snippet and the hypothesis: features for matching bigrams, trigrams, dependencies, semantic roles, predicate-argument structure as well as the global syntactic structure: a tree kernel for matching dependency parse trees of entire sentences . If a text snippet contains the answer to the question, it should intuitively be similar to the question as well as to the answer. Hence, we add features that are the element-wise product of features for the text-question match and text-answer match. Finally, we also have features corresponding to the RST  and coreference links to enable inference across sentences. RST tells us that sentences with discourse relations are related to each other and can help us answer certain kinds of questions . For example, the "cause" relation between sentences in the text can often give cues that can help us answer "why" or "how" questions. Hence, we add additional features -conjunction of the rhetorical structure label from a RST parser and the question word -to our feature vector. Similarly, the entity and event co-reference relations allow us to reason about repeating entities or events. Hence, we replace an entity/event mention with their first mentions if that results into a greater score. For the alignment part, we induce features based on word/mwe level similarity of aligned words: (a) Surface-form match (Edit-distance), and (b) Semantic word match (cosine similarity using SENNA word vectors  and "Antonymy" 'Class-Inclusion' or 'Is-A' relations using Wordnet). Distributional vectors for mwe's are obtained by adding the vector representations of comprising words . To account for the hypothesized knowledge bits, whenever we have the case that a word/mwe in the hypothesis can be aligned to a word/mwe in a hypothesized knowledge bit to produce a greater score, then we keep the features for the alignment with the knowledge bit instead. Negation Negation is a concern for our approach as facts usually align well with their negated versions. To overcome this, we use a simple heuristic. During training, if we detect negation using a set of simple rules that test for the presence of negation words ("not", "n't", etc.), we flip the partial order adding constraints that require that the correct hypothesis to be ranked below all the incorrect ones. During test phase if we detect negation, we predict the answer corresponding to the hypothesis with the lowest score.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Experiments</head><p>Dataset: We used a set of 8 th grade science questions released as the training set in the Allen AI Science Challenge 3 for training and evaluating our model. The dataset comprises of 2500 questions. Each question has 4 answer candidates, of which exactly one is correct. We used questions 1-1500 for training, questions 1500-2000 for development and questions 2000-2500 for testing. We also used publicly available 8 th grade science textbooks available through ck12.org. The science curriculum consists of seven textbooks on Physics, Chemistry, Biology, Earth Science and Life Science. Each textbook on an average has 18 chapters, and each chapter in turn is divided into 12 sections on an average. Also, as described before, each section, on an average, is followed by 3-4 multiple choice review questions (total 1369 review questions). We collected a number of domain specific science dictionaries, study guides, flash cards and semi-structured tables (Simple English Wiktionary and Aristo Tablestore) available online and create triples and equivalences used as external knowledge. A teacher builds a model of a hydrogen atom. A red golf ball is used for a proton, and a green golf ball is used for an electron. Which is not accurate concerning the model? Baselines: We compare our framework with ten baselines. The first two baselines (Lucene and PMI) are taken from <ref type="bibr" target="#b298">Clark et al. (2016)</ref>. The Lucene baseline scores each answer candidate a i by searching for the combination of the question q and answer candidate a i in a lucene-based search engine and returns the highest scoring answer candidate. The PMI baseline similarly scores each answer candidate a i by computing the pointwise mutual information to measure the strength of the association between parts of the questionanswer candidate combine and parts of the CK12 curriculum. The next three baselines, inspired from , retrieve the top two CK12 sections querying q+a i in Lucene and score the answer candidates using these documents. The SW and SW+D baselines match bag of words constructed from the question and the answer answer candidate to the retrieved document. The RTE baseline uses textual entailment <ref type="bibr" target="#b315">(Stern and Dagan, 2012)</ref> to score answer candidates as the likelihood of being entailed by the retrieved document. Then we also tried other approaches such as the RNN approach described in <ref type="bibr" target="#b298">Clark et al. (2016)</ref>, Jacana aligner  and two neural network approaches, LSTM (Hochreiter and Schmidhuber, 1997) and QANTA <ref type="bibr" target="#b305">(Iyyer et al., 2014)</ref> They form our next four baselines. To test if our approach indeed benefits from jointly learning the retrieval and the answer selection modules, our final baseline Lucene+LSSVM Alignment retrieves the top section by querying q + a i in Lucene and then learns the remaining answer-entailment structure (alignment part of the answer-entailing structure in <ref type="figure" target="#fig_3">Figure 1</ref>) using a LSSVM. Task Classification for Multitask Learning: We explore two simple question classification schemes. The first classification scheme classifies questions based on the question word (what, why, etc.). We call this Qword classification. The second scheme is based on the type of the question asked and classifies questions into three coarser categories: (a) questions without context, (b) questions with context and (c) negation questions. This classification is based on the observation that many questions lay down some context and then ask a science concept based on this context. However, other questions are framed without any context and directly ask for the science concept itself. Then there is a smaller, yet, important subset of questions that involve negation that also needs to be handled separately. <ref type="table" target="#tab_10">Table 1</ref> gives examples of this classification. We call this classification Qtype classification 4 . Results: We compare variants of our method 5 where we consider our modification for negation or not and multi-task LSSVMs. We consider both kinds of task classification strategies and joint training (JT). Finally, we compare our methods against the baselines described above. We report accuracy (proportion of questions correctly answered) in our results. <ref type="figure" target="#fig_8">Figure 2</ref> shows the results. First, we can immediately observe that all the LSSVM models have a better performance than all the baselines. We also found an improvement when we handle negation using the heuristic described above <ref type="bibr">6</ref> . MTLSSVMs showed a boost over single task LSSVM. Qtype classification scheme was found to work better than Qword classification which simply classifies questions based on the question word. The multi-task learner could benefit even more if we can learn a better separation between the various strategies needed to answer science questions. We found that joint training with review questions helped improve accuracy as well. Feature Ablation: As described before, our feature set comprises of five parts, where each part corresponds to a part of the answer-entailing structure -textbook (z 1 ), chapter (z 2 ), section (z 3 ), snippets (z 4 ), and alignment (z 5 ). It is interesting to know the relative importance of these parts in our model. Hence, we perform feature ablation on our best performing model -MTLSSVM(QWord, JT) where we remove the five feature parts one by one and measure the loss in accuracy. <ref type="figure" target="#fig_15">Figure   4</ref> We wrote a set of question matching rules (similar to the rules used to convert question answer pairs to hypotheses) to achieve this classification <ref type="bibr">5</ref> We tune the SVM regularization parameter C on the development set. We use Stanford CoreNLP, the HILDA parser , and jMWE <ref type="bibr" target="#b307">(Kulkarni and Finlayson, 2011)</ref>  Figure 2: Variations of our method vs several baselines on the Science QA dataset. Differences between the baselines and LSSVMs, the improvement due to negation, the improvements due to multi-task learning and joint-learning are significant (p &lt; 0.05) using the two-tailed paired T-test. Remove z2</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Remove z3</head><p>Remove z4</p><p>Remove z5</p><p>Remove K <ref type="figure" target="#fig_6">Figure 3</ref>: Ablation on MTLSSVM(Qword, JT) model 3 shows that the choice of section and alignment are important components of our model. Yet, all components are important and removing any of them will result in a loss of accuracy. Finally, in order to understand the value of external knowledge resources (K), we removed the component that induces and aligns the hypothesis with knowledge bits. This results in significant loss in performance, estabishing the efficacy of adding in external knowledge via our approach.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Conclusion</head><p>We addressed the problem of answering 8 th grade science questions using textbooks, domain specific dictionaries and semi-structured tables. We posed the task as an extension to textual entailment and proposed a solution that learns latent structures that align question answer pairs with appropriate snippets in the textbooks. Using domain specific dictionaries and semi-structured tables, we further refined the structures. The task required handling a variety of question types so we extended our technique to multi-task setting. Our technique showed improvements over a number of baselines. Finally, we also used a set of associated review questions, which were used to gain further improvements.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Representations of predicate-argument structure need to determine the span of predicates and their corresponding arguments. Surprisingly, there are no accepted NLP-standards which specify what the "right" span of an argument should be. Semantic representations typically take an inclusive (or maximal) approach: PropBank annotation , for example, marks arguments as full constituency subtrees. From an application perspective, this maximal approach ensures that all arguments are indeed embedded within the annotated span, yet it is often not trivial how to accurately recover them.</p><p>In contrast to this maximal-span approach, Open-IE systems <ref type="bibr" target="#b323">(Etzioni et al., 2008;</ref><ref type="bibr" target="#b324">Fader et al., 2011)</ref> put emphasis on extracting readable standalone propositions, typically producing shorter arguments (see examples in Section 2.1). Several recent works have exploited this property, using Open-IE extractions as an intermediate representation within a larger framework.</p><p>Angeli et al. <ref type="formula" target="#formula_0">(2015)</ref> built an Open-IE system which focuses on shorter argument spans. They hypothesize that "shorter arguments [are] more likely to be useful for downstream applications", and demonstrate this by using their system to extract facts about predefined entities in a state-ofthe-art Knowledge Base Population system.</p><p>Further, <ref type="bibr" target="#b329">Stanovsky et al. (2015)</ref> compared the performance of several off-the-shelf parsers in different semantic tasks. Most relevant to this work is the comparison between Open-IE and SRL. Specifically, they suggest that SRL's longer arguments introduce noise which hurts performance for downstream tasks. This is sustained empirically by showing that extractions from Open-IE4 1 significantly outperform ClearNLP's SRL <ref type="bibr" target="#b322">(Choi, 2012)</ref> in textual similarity, analogies, and reading comprehension tasks. <ref type="bibr">2</ref> While Open-IE extractors do provide a reduction of argument span, they lack consistency and principled rigor -there is no clear definition for the desired argument span, which is defined defacto by the different implementations. This lack of a common system-independent definition, let alone an annotation methodology, hinders the creation of gold standard argument-span annotation.</p><p>In this work we propose a concrete argument span reduction criterion and an accompanying annotation procedure, based on the recent QA-SRL paradigm . We show that this criterion can be consistently annotated with high agreement, and that it is intuitive enough to be obtained through crowd-sourcing.</p><p>As future work, we intend to apply the reduction criterion to other types of predicates (e.g., nomi-nal and adjectival predication). Subsequently, we would like to create a comprehensive annotated resource, as a benchmark for the detection of reduced argument spans.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Background</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Argument Span</head><p>As discussed in the Introduction, PropBank takes an inclusive approach to annotating arguments, by marking them as full constituency subtrees. For example, given the sentence "Obama, the newly elected president, flew to Russia", PropBank will mark "Obama, the newly elected president" as ARG0 of the predicate flew.</p><p>However, in certain applications, such as question answering or abstractive summarization, a reduced argument is preferred (i.e., "Obama"). Notably, different implementations of Open-IE provide an applicable generic way to reduce argument span. Since there are no common guidelines for this task, each Open-IE extractor produces different argument spans. We cover briefly some of the main differences in a few prominent Open-IE systems.</p><p>ReVerb <ref type="bibr" target="#b324">(Fader et al., 2011)</ref> uses part-of-speechbased regular expressions to decide whether a word should be included within an argument span. For example, they move certain light verb compliments and prepositions from the argument to the predicate slot (e.g., "gave a talk at"). OLLIE <ref type="bibr" target="#b327">(Mausam et al., 2012)</ref> learns lexical-syntactic patterns and splits extractions across certain prepositions. For example, given "I flew from Paris to Berlin", OLLIE yields (I; flew; from Paris) and (I; flew; to Berlin). More recently, <ref type="bibr" target="#b321">(Angeli et al., 2015)</ref> used natural logic to remove non-integral parts of arguments (e.g., removing the underlined non-restrictive prepositional phrase in "Heinz Fischer of Austria").</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">QA-SRL</head><p>SRL is typically perceived as answering argument role questions, such as who, what, to whom, when, or where, regarding a target predicate. For instance, PropBank's ARG0 for the predicate say answers the question "who said something?".</p><p>QA-SRL  follows this perspective, and suggests that answering explicit role questions is an intuitive means to solicit predicateargument structures from non-expert annotators. Annotators are presented with a sentence in which a target predicate 3 was marked, and are requested to annotate argument role questions (from a restricted grammar) and corresponding answers.</p><p>For example, given the previous sentence and the target predicate flew, an annotator can intuitively provide the following QA pairs: (1) Who flew somewhere? Obama, and (2) Where did someone fly? Russia.</p><p>The annotation guidelines further solicit multiple shorter answers, each typically embedded in the span of a maximal PropBank-style argument, while providing a different answer to the (same) argument role question.</p><p>In Section 4 we make use of QA-SRL's framework in order to produce annotations by our reduction argument criterion, which is defined in the next section.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Argument Reduction</head><p>In this section, we propose annotation criteria and process for obtaining minimal argument spans. Given an original, non-reduced argument, we aim to reduce it to a set of (one or more) smaller arguments, which jointly specify the same answer to the argument's role question.</p><p>Formally, given a non-reduced argument a = {w 1 , ..., w n }, along with its role question Q(a) with respect to predicate p in sentence s, we seek to find a set of minimally-scoped arguments, M (a), such that:</p><p>(1) Each m ∈ M (a) is a proper subset of a.</p><p>(2) Each m ∈ M (a) provides a different, independently interpreted answer to Q(a).</p><p>(3) M (a) is equivalent to a, in the sense that when taken jointly, M (a) specifies the same answers as a does for Q(a).</p><p>(4) Each m ∈ M (a) is minimal, meaning it cannot be further reduced without violating the equivalence criterion <ref type="bibr" target="#b471">(3)</ref>.</p><p>Note that this definition relies on human judgments, which are used to decide whether two arguments provide the same or different answers.</p><p>Generally speaking, a non-minimal argument a can be reduced in one of two ways:</p><p>(a) Removal of tokens from a, forming a smaller argument.</p><p>(b) Splitting a, yielding multiple arguments.</p><p>In our context, we would like to apply these two operations as long as they maintain the equivalence criterion <ref type="bibr" target="#b471">(3)</ref>. We empirically observe that the first case (removal) corresponds to the omission of non-restrictive modifiers, that is, modifiers for which the content of the modifier presents a separate, parenthetical unit of information about the NP <ref type="bibr" target="#b326">(Huddleston et al., 2002)</ref>. For example, revisiting the sentence: "Obama, the newly elected president, flew to Russia.", the non-reduced argument "Obama, the newly elected president" can be reduced to the minimal argument "Obama", as both specify the same answer to the role question "who flew to Russia?".</p><p>In contrast, a restrictive modifier is an integral part of the meaning of the containing NP, and hence should not be removed, as in "She wore the necklace that her mother gave her".</p><p>The second reduction operation (splitting) corresponds to decoupling distributive coordinations, that is, cases in which a predicate applies separately to all of the elements in the coordination. For example, in: "Obama and Clinton were born in America.", the non-reduced PropBank-style argument "Obama and Clinton" can be reduced to two arguments {"Obama", "Clinton"}. Each of these arguments independently answers the role question "Who was born in America?", while jointly they correspond to the longer, non-reduced argument.</p><p>Note that splitting a shorter distributive argument does not necessarily produce disjoint arguments. For example, consider: "The tall boys and girls were born in America.", in which "The tall boys and girls" would reduce to two overlapping arguments: {"The tall boys", "The tall girls"}.</p><p>In contrast, non-distributive conjuncts cannot be split. These are cases in which the predicate applies to the conjuncts taken together, while applying it separately to each element changes the interpretation of the clause. Consider for example the reciprocal structure of: "Obama and Putin met in Moscow", in which we cannot split the argument "Obama and Putin" since the predicate met implies that Obama and Putin met with each other, which will be lost if we split the argument to two independent answers.</p><p>Based on these two operations, a set of minimal arguments, M (a), can be obtained from a in a top-down manner: first apply removal, if possible; then splitting, if possible. <ref type="bibr">4</ref> Next, apply recursively to each of the smaller arguments, stopping when none of the two reduction operations can be applied. This annotation process might yield different sets of minimal arguments by different annotators, depending on their decisions regarding the reduction steps. As we show empirically in the next section, high agreement levels can be obtained, supporting the validity of our proposed criterion.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Annotation Experiment</head><p>In this section we describe the compilation and analysis of a small-scale expert annotation corpus. Creating such corpus serves 3 goals: (1) It allows us to test the applicability of the argument reducing procedure, (2) By comparing it with Propbank we can examine how often, and in which cases, we reduce arguments (Section 4.1), and <ref type="formula" target="#formula_6">(3)</ref> We can assess the plausibility of crowd-sourcing argument span annotation (Sections 4.2 and 4.3).</p><p>In order to achieve these goals, we sample 100 predicates of the Propbank corpus, which covered 260 arguments. To allow comparisons, we sample predicates which were annotated by QA-SRL and whose arguments were aligned by  with a matching Propbank argument. <ref type="bibr">5</ref> Two expert annotators used the QA-SRL's interface to re-answer the original QA-SRL annotated questions with minimally-scoped arguments, according to the procedure described in Section 3. Prior to annotating the expert dataset, the annotators discussed the process and resolved conflicts on a separate development set of 20 predicates.</p><p>Annotator agreement From an argument perspective, the annotators fully agreed on the span of 94.6% of the arguments. Looking into the word token level, we found that for a given PropBank argument a = (w 1 , ..., w n ), the respective reduced arguments always constitute a subset of a. This allows us to look at the annotation process as a list of n mapping decisions -for each w i , an annotator decides whether he (1) Maps it to one or more of the argu-ments of M (a), or (2) Deletes it. The complete annotation required each annotator to make 985 such mappings decisions. Word level agreement between the annotators was calculated as the percent of the decisions on which they agreed, and found to be 97.1%.</p><p>Overall, the annotators achieved a high level of agreement, suggesting that the reduction criterion can be consistently applied by trained annotators. An analysis of the few disagreements revealed that the deviations between the annotators stem from semantic ambiguities, where two legitimate readings of the sentence led to different span annotations. <ref type="bibr">6</ref> Finally, we compose the expert annotation dataset from 247 arguments on which both annotators fully agreed.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Comparison with Propbank</head><p>Comparing our annotation with PropBank showed that we reduced roughly 24% of the arguments: 19% of the arguments were reduced by omitting non-restrictive modifications and 5% of the arguments were split across distributive co-ordinations (see discussion on both types of reductions in Section 3).</p><p>The average reduced argument shrunk by roughly 58%. In general, these numbers suggest that our annotation scheme targets commonly recurring phenomena, and significantly deviates from PropBank's annotation of arguments.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Crowdsourcing</head><p>We created an Amazon Mechanical Turk 7 project to investigate the possible scalability of our annotation using non-trained annotators.</p><p>Similarly to the setting used by the expert annotators, turkers were presented with a sentence, followed by a list of questions regarding a target predicate. The sentences, predicates and questions were taken from the expert corpus, which aligns between QA-SRL and Propbank. <ref type="bibr">8</ref> The guidelines for annotators refined those of , soliciting answers which follow our formal criterion. In cases of multiple answers referring to the same entity, annotators are asked to provide the most specific answer, otherwise (if the answers refer to different entities), the annotators are asked to list all of the answers. Furthermore, the annotators are requested to provide the shortest answer they can, while preserving its correctness. We chose annotations which were agreed upon by at least two annotators. In cases where the three annotators gave different answers (26% of the time), we used a fourth annotator to arbitrate, and calculated agreement using the same metrics discussed above. Cases where annotators disagreed were mostly semantically ambigouos. For example, given the sentence "Our pilot simply laughed , fired up the burner and with another blast of flame lifted us , oh , a good 12 -inches above the water level ." and the question "how much did someone lift someone?", one annotator replied 12 -inches while another replied a good 12 -inches.</p><p>We found that the crowdsourcing annotations to be of high quality, reaching 89.1% argument agreement and 93.5% word agreement with our expert annotation. These results suggest that the annotation of argument span is efficiently and accurately attainable using crowd-sourcing techniques, with only subtle refinements over the original QA-SRL guidelines.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Comparison with QA-SRL</head><p>Finally, we want to compare our crowdsourcing annotation versus that of QA-SRL, with respect to argument span. Using the previously mentioned agreement metric, we find that QA-SRL agrees with our expert dataset on 80% of the arguments and 88.5% of the word-level decisions. Although it is outperformed by our crowdsourcing annota-tion project, QA-SRL still manages to capture significant amounts of the minimally-reduced arguments. This is interesting, as the QA-SRL guidelines did not address this issue specifically, but instead solicited annotators to provide "as many answers as possible". This suggests that the question answering format intuitively prompts human annotators to reduce the span of their answers.</p><p>To conclude this section, the entire comparison measurements are summarized in <ref type="table" target="#tab_10">Table 1</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Conclusion and Future Work</head><p>In this work we proposed a concrete criterion for specifying minimally-scoped arguments. While this issue was applicably addressed by previous work, it was not consistently defined or annotated. Following this definition, we created an expert annotation dataset over texts from PropBank, using the QA-SRL paradigm. This annotation achieved high levels of inter-annotator agreement, and was shown to be intuitive enough so that it can be scaled to crowdsourcing annotation. As future work, we plan to extend this annotation project to larger volumes of text, and to additional types of (non-verbal) predications, which will allow to develop learning-based methods that identify minimally-reduced argument span.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Automatic summarisation is one of the big artificial intelligence challenges in a world of information overload. Many summarisers, mostly extractive, have been developed in recent years <ref type="bibr" target="#b349">Mihalcea and Tarau, 2004;</ref><ref type="bibr" target="#b359">Wong et al., 2008;</ref><ref type="bibr" target="#b332">Celikyilmaz and Hakkani-Tür, 2011)</ref>. Research is moving beyond extraction in various directions: One could perform text manipulation such as compression as a separate step after extraction <ref type="bibr" target="#b342">(Knight and Marcu, 2000;</ref><ref type="bibr" target="#b333">Cohn and Lapata, 2008)</ref>, or alternatively, one could base a summary on an internal semantic representation such as the proposition <ref type="bibr" target="#b344">(Lehnert, 1981;</ref><ref type="bibr" target="#b348">McKeown and Radev, 1995)</ref>.</p><p>One summarisation model that allows manipulation of semantic structures of texts was proposed by <ref type="bibr">Kintsch and van Dijk (1978, henceforth KvD)</ref>. It is a model of human text processing, where the text is turned into propositions and processed incrementally, sentence by sentence. The final summary is based on those propositions whose semantic participants (arguments) are wellconnected to others in the text and hence likely to be remembered by a human reading the text, under the assumption of memory limitations. Such a deep model is attractive because it provides the theoretical possibility of performing inference and generalisation over propositions, even if current NLP technology only supports shallow versions of such manipulations. This gives it a clear theoretical advantage over nonpropositional extraction systems whose information units are individual words and their connections, e.g. centroids or random-walk models.</p><p>We present in this paper a new KvD-based summariser that is word sense-aware, unlike our earlier implementation <ref type="bibr" target="#b336">(Fang and Teufel, 2014)</ref>. §2 explains the KvD model with respect to summarisation. §3 and §4 explain why and how we use lexical chains to model argument overlap, a phenomenon which is central to KvD-style summarisation. §6 presents experimental evidence that our model of argument overlap is superior to the earlier one. Our summariser additionally beats several extractive state-of-the-art summarisers. We show that this advantage does not come from our use of lexical chains alone, but also from KvD's incremental processing.</p><p>Our second contribution concerns a new corpus of educational texts, presented in §5. Part of the reason why we prefer a genre other than news is the vexingly good performance of the lead baseline in the news genre. Traditionally, many summarisers struggled to beat this baseline <ref type="bibr" target="#b345">(Lin and Hovy, 2003)</ref>. We believe that the problem is partly due to the journalistic style, which calls for an abstract-like lead. If we want to measure the content selection ability of summarisers, alternat- ive data sets are needed. Satisfyingly, we find that on our corpus the lead baseline is surpassable by intelligent summarisers.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">The KvD Model</head><p>The KvD model is a cognitive account of human text comprehension. In our KvD-inspired model <ref type="figure" target="#fig_3">(Figure 1)</ref>, the summariser constructs a list of propositions as a meaning representation from a syntactic parse of the input text. A batch of new propositions (• in the figure) are processed for each sentence. At the beginning of a memory cycle, these new propositions are added to a coherence tree, which represents the working memory. They attach to the existing propositions on the tree with which they have the strongest overlap in arguments. At the end of a cycle, as a simulation of limited memory, only a few important propositions are carried over to the next cycle, while the others are "forgotten" (represented by ×). This selection is based on the location of propositions in the tree, using the so-called leading edge strategy; propositions that are on more recent edges, or that are attached higher, are more likely to be retained. The model attempts all future attachments using only the propositions in working memory, and allows to reuse forgotten ones only if this strategy runs into problems (when a new proposition could not otherwise be attached). KvD suggest that the decision whether a proposition should be included in the final summary depends on three factors: a) the number of cycles where it was retained in working memory, b) whether it is a generalisation, and c) whether it is a meta-statement (or macro-proposition).</p><p>For its explanatory power and simplicity, the model has been well-received not only in the fields of cognitive psychology <ref type="bibr" target="#b354">(Paivio, 1990;</ref><ref type="bibr" target="#b343">Lave, 1988)</ref> and education <ref type="bibr" target="#b338">(Gay et al., 1976)</ref>, but also in the summarisation community <ref type="bibr" target="#b352">(Moens et al., 2003;</ref><ref type="bibr" target="#b357">Uyttendaele et al., 1998;</ref><ref type="bibr" target="#b339">Hahn and Reimer, 1984)</ref>.</p><p>We presented the first computational prototype of the model that follows the proposition-centric processing closely <ref type="bibr" target="#b336">(Fang and Teufel, 2014)</ref>. Of the factors mentioned above, only the first is modelled in this summariser (called FT14). That is, we use the frequency of a proposition being retained in memory as the only indicator of its summaryworthiness. This is a simplification due to the fact that robust inference is beyond current NLP capability. Additionally, macro-propositions depend on domain-specific schema, whereas our system aims to be domain-independent. <ref type="bibr" target="#b360">Zhang et al. (2016)</ref> presented a summariser based on a later cognitive model by <ref type="bibr" target="#b341">Kintsch (1998)</ref>. Instead of modelling importance of propositions directly, their summariser computes the importance of words by spreading activation cyclically, but extracts at proposition level.</p><p>Although the summariser presented in the current paper, a newer version of FT14, is capable of sub-sentential content selection, we present its output in the form of extracted sentences that contain the most summary-worthy propositions. This is different from FT14, where we used a tokenbased extraction method. A better output would of course be an abstract based on the selected propositions, but we currently do not have a language generation module and can therefore evaluate only the content selection ability of our summariser.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Argument Overlap</head><p>The central mechanism of the KvD model is argument overlap of propositions, and it is key to successful content selection. This is because there are often multiple propositions on the tree where a new proposition could attach, of varying attractiveness. The task therefore boils down to ranking attachments, for instance by the strength of overlap, and the position in the tree. <ref type="figure" target="#fig_8">Figure 2</ref> is an example of competing attachment sites. Three subtrees in the working memory are shown, containing propositions that correspond to the text pieces 1) [fire was] a gift randomly delivered in the form of lightning, forest fire or burning lava, 2) fire-lighting was revolutionised by the discovery of the element, and 3) iron pyrites, a compound that contains sulphur, respectively. The new proposition corresponds to the text paper tipped with phosphorus. It can attach in subtree 2, because phosphorus is a kind of element; it can also attach in subtree 3, because both phosphorus and sulphur are chemicals. The definition of argument overlap is conceptually simple, namely reference of the arguments to the same concept, which can be an entity, an event, or a class of things. In KvD's manual demonstration of the algorithm, the resolution of textual expressions to concepts relies on human intelligence. A "perfect" coreference resolver is arguably all we need, but coreference as currently defined excludes generics, abstract concepts, paraphrases, bridging connections  and several other relevant linguistic phenomena. This means an insufficient number of possible overlaps are found by current coreference systems, if no further information is used. How exactly to model argument overlap for a KvD summariser is therefore open to exploration.</p><p>We use other sources of information that addresses topicality and semantic relatedness, in combination with coreference resolution. In FT14, that source was the distributional similarity of words, normalised with respect to their distractors in context to achieve numerically comparable overlap scores. In this paper, we argue that using the shared membership in lexical chains as the other source provides a better basis for ranking argument overlap.</p><p>FT14's overlap detection runs into problems in the situation above <ref type="figure" target="#fig_8">(Figure 2)</ref>. Under FT14's definition of argument overlap as distributional semantic distance, the link between paper and form is as strong as the other possibilities, which leads to the attachment of the new proposition as a child node of the root proposition of subtree 1 due to higher tree level. This attachment uses the wrong sense of the polysemous word form ("form/8 -a printed document with spaces in which to write").</p><p>In our new ranking of attachment sites, lexical chains enable us to reject the spurious attachment, as we will now explain.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Our Lexical Chain-Based System</head><p>In our new model, argument overlap is computed using lexical chains <ref type="bibr" target="#b330">(Barzilay and Elhadad, 1997)</ref>, a construct that combines the ideas of topicality and word sense clusters. A lexical chain is an equivalence class of expressions found in the text whose presumed senses in context are related to the same concept or topic. For the example in the last section, in our system form is correctly resolved to sense 2, not sense 8, and as form/2 and paper/1 are not members of the same lexical chain, the wrong attachment is prevented. Lexical chain algorithms typically use WordNet <ref type="bibr" target="#b249">(Miller, 1995)</ref> to provide the lexical relations needed, whereby each synset (synonym set) represents a concept. Hypernyms and hyponyms are related to the same topic, and they may be in a coreference relationship with the concept. To a lesser extent, the potential for coreference also holds for siblings of a concept. WordNet relations therefore give information about concept identity and topical relatedness, both of which are aspects of argument overlap.</p><p>We implemented <ref type="bibr">Galley and McKeown's (2003, henceforth GM03)</ref> chaining algorithm, which im-proves over <ref type="bibr">Barzilay and Elhadad's and Silber and McCoy's (2002)</ref> chain definition by introducing the limitation of "one sense per discourse", i.e. by enforcing that all occurrences of the same word take the same sense in one document. Initially designed to improve word sense disambiguation accuracy, GM03's method has been shown to improve summarisation quality as well <ref type="bibr" target="#b334">(Ercan and Cicekli, 2008)</ref>.</p><p>In GM03, the edge weight between possible word senses of two word occurrences depends on the lexical relation and the textual distance between them. Each word is disambiguated by choosing the sense that maximises the sum of weights of the edges leaving all its occurrences. Edges that are based on non-selected senses are then discarded. Once the entire text has been processed, each connected component of the graph represents a lexical chain.</p><p>As far as nouns 1 are concerned, we follow GM03's edge weights, but unlike GM03, we also allow verbs to enter into chains. We do this in order to model nominalised event references, and to provide a sufficient number of possible connections. <ref type="table" target="#tab_10">Table 1</ref> provides the distance of relations; weights of verb and derivation relations equal to the weights of noun relations on the same row. Instead of assigning an overlap value of 1 to all pairs of words in the same chain, the extent of overlap is given as a ∑ e∈E d e , where E is the set of edges in the shortest path between the two words in the graph of lexical relations, d e the distance of the lexical relation of e, and a an attenuation factor we set at 0.7. This models the transition from concept sameness to broader relatedness. We found empirically that the introduction of verbs and the graded overlap value using relation distance improves the performance of our KvD summariser.</p><p>Lexical coverage of this algorithm is good: WordNet covers 98.3% of all word occurrences allowed into our lexical chains in the experiment in §6, excluding those POS-tagged as proper nouns. For unknown words, the system's backoff strategy is to form overlap only if the surface strings match. The structuring of information in a memory tree and the incremental addition of information, including the concept of "forgetting", are key claims of the KvD model. But do these manipulations actually add any value beyond the information con-  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">New Corpus of Texts and Summaries</head><p>We introduce new evaluation materials, created from the reading sections of Academic Tests of the Official IELTS Practice Materials <ref type="bibr" target="#b331">(British Council et al., 2012)</ref>. The IELTS is a standardised test of English proficiency for non-native speakers. The texts cover various general topics, and resemble popular science or educational articles. They are carefully chosen to be of the same difficulty level, and understandable by people of any cultural background. Unlike news text, they also presuppose less external knowledge, such as US politics, which makes it easier to demonstrate the essence of proposition-based summarisation.</p><p>Out of all 108 texts of volumes 1-9, we randomly sampled 31. We then elicited 4 summaries summary for each, written by 14 members of our university, i.e., a total of 124 summaries. <ref type="bibr">2</ref> We asked the summarisers to create natural-sounding text, keeping the length strictly to 100 ± 2 words. They were allowed but not encouraged to paraphrase text.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Experiment</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.1">Systems and Baselines</head><p>We test 7 automatic summarisers against each other on this evaluation corpus. Our summariser (O) runs the KvD memory cycles and uses lexical chains to determine argument overlap. It is not directly comparable to FT14 due to the difference in generation method, described in §2. In order to be able to compare to FT14 nevertheless, we created a version that uses our new sentence extraction module together with an argument over-  lap module very similar to FT14 but with an even stronger model for semantic similarity, the cosine similarity of word embeddings pre-trained using word2vec  on part of the Google News dataset (∼ 100 billion words), and we call this system D.</p><p>Another variant, C, tests the hypothesis that the recurrent KvD processing is not superior than simpler network analysis. Summariser C constructs only one graph, where every two propositions are connected by an edge whose length is the reciprocal of their argument overlap, and uses betweenness centrality to determine proposition importance. We choose betweenness centrality because we found it to outperform other graph algorithms, including closeness centrality and eigenvector centrality.</p><p>We also test against the lead baseline (L) and three well-known lexical similarity-based single document summarisers: MEAD <ref type="bibr">(Radev et al., 2004, M)</ref>, TextRank <ref type="bibr">(Mihalcea and Tarau, 2004, TR)</ref>, and LexRank <ref type="bibr">(Erkan and Radev, 2004, LR)</ref>.</p><p>Because the evaluation tool we use is sensitive to text length, fair evaluation demands equal length of all summaries tested. We obtain output of exactly 100 ± 2 words from each summariser by iteratively requesting longer summaries, and unless this results in a sentence break within 2 tokens of the 100-word limit, we cut the immediately longer output to exactly 100 words.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.2">Results</head><p>For automated evaluation, we use ROUGE <ref type="bibr" target="#b346">(Lin, 2004)</ref>, which evaluates a summary by comparing it against several gold standard summaries. <ref type="table" target="#tab_5">Table 2</ref> shows our results in terms of ROUGE-1, 2, L and SU4. <ref type="bibr" target="#b471">3</ref> The metrics are based on the co-occurrence of unigrams, bigrams, longest common subsequences, and skip-bigrams (within distance of 4 and including unigrams), respectively. Our summariser outperforms all other summarisers, <ref type="bibr">4</ref> and is the only summariser that beats the lead baseline.</p><p>The fact that our summariser beats D, our KvD summariser using FT14-style distributional semantics for argument overlap, is clear evidence that our method of lexical chaining provides a superior model of argument overlap. On this genre, D performs indistinguishably from the other summarisers. This is in line with our earlier findings for FT14 on DUC <ref type="bibr" target="#b353">(Over and Liggett, 2002)</ref> news texts, where the token extraction-based summariser was comparable to extractive summarisers but was outperformed by MEAD. In a qualitative analysis, we found that a main source of error in FT14's system was that it favoured related but semantically and pragmatically incompatible terms over compatible paraphrases. This is a sideeffect of the use of co-occurrence, which relies on syntagmatic rather than paradigmatic similarities, and which is insensitive to word senses. As a result, context-unaware distributional semantics allows too many spurious overlaps.</p><p>The fact that summariser C is significantly worse than our summariser shows that the idea of incrementally maintaining a KvD-style structured memory is effective for summarisation, despite the simplifications we had to make. This naturally points to the direction of modelling incremental memory updates for summarisation, which also makes modelling with a recurrent neural network plausible in the future.</p><p>The current experiment can be seen as a demonstration of the superiority of KvD propositionbased content selection on a genre of commonsense, naturally occurring texts. This was the case even with a inferior "generation" method, namely sentence extraction. Reading through the propositions, we had the impression that they manage to capture relevant information about the text in a much shorter and more modular form than extracted sentences, although this cannot be demonstrated with a surface-based methodology such as ROUGE. Content selection is of course only the first step of summarisation; we are currently working on a grammar-based re-generation from the selected propositions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Learning to efficiently represent and reason with natural language is a fundamental yet longstanding goal in NLP. This has led to a series of efforts in broad-coverage semantic representation (or "sembanking"). Recently, AMR, a new semantic representation in standard neo-Davidsonian <ref type="bibr" target="#b366">(Davidson, 1969;</ref><ref type="bibr" target="#b378">Parsons, 1990</ref>) framework has been proposed. AMRs are rooted, labeled graphs which incorporate PropBank style semantic roles, within-sentence coreference, named entities and the notion of types, modality, negation, quantification, etc. in one framework.</p><p>In this paper, we describe an approach to use This hypothesis is AMR parsed to construct a hypothesis meaning representation graph after some post-processing ( § 2.1). Similar processing is done for each sentence in the passage as well. Then, a subset (not necessarily contiguous) of these sentence meaning representation graphs is found. These representation subgraphs are further merged using coreference information, resulting into a structure called the relevant text snippet graph. Finally, the hypothesis meaning representation graph is aligned to the snippet graph. The dashed red lines show node alignments, solid red lines show edge alignments, and thick solid black arrow shows the rhetorical structure label (elaboration).</p><p>AMR for the task of machine comprehension. Machine comprehension  evaluates a machine's understanding by posing a series of multiple choice reading comprehension tests. The tests are unique as the answer to each question can be found only in its associated texts, requiring us to go beyond simple lexical solutions. Our approach models machine comprehension as an extension to textual entailment, learning to output an answer that is best entailed by the passage. It works in two stages. First, we construct a meaning representation graph for the entire passage ( § 2.1) from the AMR graphs of comprising sentences. To do this, we account for crosssentence linguistic phenomena such as entity and event coreference, and rhetorical structures. A similar meaning representation graph is also constructed for each question-answer pair. Once we have these graphs, the comprehension task henceforth can be reduced to a graph containment problem. We posit that there is a latent subgraph of the text meaning representation graph (called snippet graph) and a latent alignment of the questionanswer graph onto this snippet graph that entails the answer (see <ref type="figure" target="#fig_3">Figure 1</ref> for an example). Then, we propose a unified max-margin approach ( § 2.2) that jointly learns the latent structure (subgraph selection and alignment) and the QA model. We evaluate our approach on the MCTest dataset and achieve competitive or better results than a number of previous proposals for this task.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">The Approach</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">The Meaning Representation Graphs</head><p>We construct the meaning representation graph using individual sentences AMR graphs and merging identical concepts (using entity and event coreference). First, for each sentence AMR, we merge nodes corresponding to multi-word expressions and nodes headed by a date entity ("date-entity"), or a named entity ("name") or a person entity ("person"). For example, the hypothesis meaning representation graph in <ref type="figure" target="#fig_3">Figure 1</ref> was achieved by merging the AMR parse shown in <ref type="figure" target="#fig_8">Figure 2</ref>.</p><p>Next, we select the subset of sentence AMRs corresponding to sentences needed to answer the question. This step uses cross-sentential phenomena such as rhetorical structures 1 and entities/event coreference. The coreferent entities/event mentions are further merged into one node resulting in a graph called the relevant text snippet graph. A similar process is also per-1 Rhetorical structure theory  tells us that sentences with discourse relations are related to each other. Previous works in QA  have shown that these relations can help us answer certain kinds of questions. As an example, the "cause" relation between sentences in the text can often give cues that can help us answer "why" or "how" questions. Hence, the passage meaning representation also remembers RST relations between sentences.</p><p>formed with the hypothesis sentences (generated by combining the question and answer candidate) as shown in <ref type="figure" target="#fig_3">Figure 1</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Max-Margin Solution</head><p>For each question q i ∈ Q, let t i be the corresponding passage text and A i = {a i1 , . . . , a im } be the set of candidate answers to the question. Our solution casts the machine comprehension task as a textual entailment task by converting each question-answer candidate pair (q i , a ij ) into a hypothesis statement h ij . We use the question matching/rewriting rules described in <ref type="bibr" target="#b365">Cucerzan and Agichtein (2005)</ref> to get the hypothesis statements. For each question q i , the machine comprehension task reduces to picking the hypothesisĥ i that has the highest likelihood of being entailed by the text t i among the set of hypotheses h i = {h i1 , . . . , h im } generated for the question q i . Let h * i ∈ h i be the hypothesis corresponding to the correct answer.</p><p>As described, we use subgraph matching to help us model the inference. We assume that the selection of sentences to generate the relevant text snippet graph and the mapping of the hypothesis meaning representation graph onto the passage meaning representation graph is latent and infer it jointly along with the answer. We treat it as a structured prediction problem of ranking the hypothesis set h i such that the correct hypothesis h * i is at the top of this ranking. We learn a scoring function S w (t, h, z) with parameter w such that the score of the correct hypothesis h * i and corresponding best latent structure z * i is higher than the score of the other hypotheses and corresponding best latent structures. In a max-margin fashion, we want that S w (t i , h * i , z * i ) &gt; S(t i , h ij , z ij ) + 1 − ξ i for all h j ∈ h \ h * for some slack ξ i . Writing the relaxed max margin formulation:</p><formula xml:id="formula_212">min ||w|| 1 2 ||w|| 2 2 + C i max z ij ,h ij ∈h i \h * i Sw(ti, hij, zij) + ∆(h * i , hij) −C i Sw(ti, h * i , z * i )<label>(1)</label></formula><p>We use 0-1 cost, i.e. ∆(h * i , h ij ) = 1(h * i = h ij ). If the scoring function is convex then this objective is in concave-convex form and hence can be solved by the concave-convex programming procedure (CCCP) . We assume the scoring function to be linear:S w (t, h, z) = w T ψ(t, h, z). Here, ψ(t, h, z) is a feature map discussed later. The CCCP algorithm essentially alternates between solving for z * i , z ij ∀j s.t. h ij ∈ h i \ h * i and w to achieve a local minima. In the absence of information regarding the latent structure z we pick the structure that gives the best score for a given hypothesis i.e. arg max z S w (t, h, z).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Scoring Function and Inference</head><p>Now, we define the scoring function S w (t, h, z). Let the hypothesis meaning representation graph be G = (V , E ). Our latent structure z decomposes into the selection (z s ) of relevant sentences that lead to the text snippet graph G, and the mapping (z m ) of every node and edge in G onto G. We define the score such that it factorizes over the nodes and edges in G . The weight vector w also has three components w s , w v and w e corresponding to the relevant sentences selection, node matches and edge matches respectively. An edge in the graph is represented as a triple (v 1 , r, v 2 ) consisting of the enpoint vertices and relation r.</p><formula xml:id="formula_213">Sw(t, h, z) = w T s f (G , G, t, h, zs) + v ∈V w T v f (v , zm(v )) + e ∈E w T e f (e , zm(e ))</formula><p>Here, t is the text corresponding to the hypothesis h, and f are parts of the feature map ψ to be described later. z(v ) maps a node v ∈ V to a node in V . Similarly, z(e ) maps an edge e ∈ E to an edge in E.</p><p>Next, we describe the inference procedure i.e. how to select the structure that gives the best score for a given hypothesis. The inference is performed in two steps: The first step selects the relevant sentences from the text. This is done by simply maximizing the first part of the score:</p><formula xml:id="formula_214">z s = arg max zs w T s f (G , G, t, h, z s ).</formula><p>Here, we only consider subsets of 1, 2 and 3 sentences as most questions can be answered by 3 sentences in the passage. The second step is formulated as an integer linear program by rewriting the scoring function. The ILP objective is:</p><formula xml:id="formula_215">v ∈V v∈V z v ,v w T v f (v , v) + e ∈E e∈E z e ,e w T e f (e , e)</formula><p>Here, with some abuse of notation, z v ,v and z e ,e are binary integers such that z v ,v = 1 iff z maps v onto v else z v ,v = 0. Similarly, z e ,e = 1 iff z maps e onto e else z e ,e = 0. Additionally, we have the following constrains to our ILP:</p><p>• Each node v ∈ V (or each edge e ∈ E ) is mapped to exactly one node v ∈ V (or one edge e ∈ E). Hence: v∈V z v ,v = 1 ∀v and e∈E z e ,e = 1 ∀e</p><p>• If an edge e ∈ E is mapped to an edge e ∈ E, then vertices (v 1 e , v 2 e ) that form the end points of e must also be aligned to vertices (v 1 e , v 2 e ) that form the end points of e. Here, we note that AMR parses also have inverse relations such as "arg0-of". Hence, we resolve this with a slight modification. If neither or both relations (corresponding to edges e and e) are inverse relations <ref type="formula" target="#formula_0">(case 1</ref> </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.4">Features</head><p>Our feature function ψ(t, h, z) decomposes into three parts, each corresponding to a part of the latent structure.</p><p>The first part corresponds to relevant sentence selection. Here, we include features for matching local neighborhoods in the sentence subset and the hypothesis: features for matching bigrams, trigrams, dependencies, semantic roles, predicateargument structure as well as the global syntactic structure: a graph kernel for matching AMR graphs of entire sentences . Before computing the graph kernel, we reverse all inverse relation edges in the AMR graph. Note that if a sentence subset contains the answer to the question, it should intuitively be similar to the question as well as to the answer. Hence, we add features that are the element-wise product of features for the subset-question match and subset-answer match. In addition to features for the exact word/phrase match of the snippet and the hypothesis, we also add features using two paraphrase databases: ParaPara <ref type="bibr" target="#b363">(Chan et al., 2011)</ref> and DIRT <ref type="bibr" target="#b373">(Lin and Pantel, 2001</ref>). These databases contain paraphrase rules of the form string 1 → string 2 . ParaPara rules were extracted through bilingual pivoting and DIRT rules were extracted using the distributional hypothesis. Whenever we have a substring in the text snippet that can be transformed into another using any of these two databases, we keep match features for the substring with a higher score (according to the current w) and ignore the other substring. Finally, we also have features corresponding to the RST  links to enable inference across sentences. RST tells us that sentences with discourse relations are related to each other and can help us answer certain kinds of questions . For example, the "cause" relation between sentences in the text can often give cues that can help us answer "why" or "how" questions. Hence, we have additional featuresconjunction of the rhetorical structure label from a RST parser and the question word as well.</p><p>The second part corresponds to node matches. Here, we have features for (a) Surface-form match (Edit-distance), and (b) Semantic word match (cosine similarity using SENNA word vectors  and "Antonymy" 'ClassInclusion' or 'Is-A' relations using Wordnet).</p><p>The third part corresponds to edge matches. Let the edges be e = (v 1 , r, v 2 ) and e = (v 1 , r , v 2 ) for notational convenience. Here, we introduce two features based on the relations -indicator that the two relations are the same or inverse of each other, indicator that the two relations are in the same relation category -categories as described in <ref type="bibr" target="#b361">Banarescu et al. (2013)</ref>. Then, we introduce a number of features based on distributional representation of the node pairs. We compute three vertex vector compositions (sum, difference and product) of the nodes for each edge proposed in recent representation learning literature in NLP <ref type="bibr" target="#b534">Mikolov et al., 2013)</ref> i.e. v 1 v 2 and v 1 v 2 for = {+, −, ×}. Then, we compute the cosine similarities of the resulting compositions producing three features. Finally we introduce features based on the structured distributional semantic representation <ref type="bibr" target="#b367">(Erk and Padó, 2008;</ref><ref type="bibr" target="#b362">Baroni and Lenci, 2010;</ref><ref type="bibr" target="#b370">Goyal et al., 2013)</ref> which takes the relations into account while performing the composition. Here, we use a large text corpora (in our experiments, the English Wikipedia) and construct a representation matrix M (r) ⊂ V × V for every relation r (V is the vocabulary) where, the ij th element M (r) ij has the value log(1+x) where x is the frequency for the i th and j th vocabulary items being in relation r in the corpora. This allows us to compose the node and relation representations and compare them. Here we compute the cosine similarity of the compositions (v 1 ) T M (r) and (v 1 ) T M (r ) , the compositions M (r) v 2 and M (r ) v 2 and their repective sums (v 1 ) T M (r) + M (r) v 2 and (v 1 ) T M (r ) + M (r ) v 2 to get three more features.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.5">Negation and Multi-task Learning</head><p>Next, we borrow two ideas from  namely, negation and multi-task learning, treating different question types in the machine comprehension setup as different tasks.</p><p>Handling negation is important for our model as facts align well with their negated versions. We use a simple heuristic. During training, if we detect negation (using a set of simple rules that test for presence of negation words ("not", "n't", etc.)), we flip the corresponding constraint, now requiring that the correct hypothesis to be ranked below all the incorrect ones. During test phase if we detect negation, we predict the answer corresponding to the hypothesis with the lowest score.</p><p>QA systems often include a question classification component that divides the questions into semantic categories based on the type of the question or answers expected. This allows the model to learn question type specific parameters when needed. We experiment with three task classifications proposed by . First is QClassification, which classifies the question, based on the question word <ref type="bibr">(what, why, what, etc.)</ref>. Next is the QAClassification scheme, which classifies questions into different semantic classes based on the possible semantic types of the answers sought. The third scheme, TaskClassification classifies the questions into one of 20 subtasks for Machine Comprehension proposed in <ref type="bibr" target="#b384">Weston et al. (2015)</ref>. We point the reader to  for details on the multi-task model.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Experiments</head><p>Datasets: We use MCTest-500 dataset , a freely available set of 500 stories (300 train, 50 dev and 150 test) and associated questions to evaluate our model. Each story in MCTest has four multiple-choice questions, each with four answer choices. Each question has exactly one correct answer. Each question is also annotated as 'single' or 'multiple'. The questions annotated 'single' require just one sentence in the passage to answer them. For 'multiple' questions it should not be possible to find the answer to the question with just one sentence of the passage. In a sense, 'multiple' questions are harder than 'single' questions as they require more complex inference. We will present the results breakdown for 'single' or 'multiple' category questions as well. Baselines: We compare our approach to the following baselines: (1-3) The first three baselines are taken from . SW and SW+D use a sliding window and match a bag of words constructed from the question and the candidate answer to the text. RTE uses textual entailment by selecting the hypothesis that has the highest likelihood of being entailed by the passage. (4) LEX++, taken from  is another lexical matching method that takes into account multiple context windows, question types and coreference. (5) JACANA uses an off the shelf aligner and aligns the hypothesis statement with the passage. (6-7) LSTM and QANTA, taken from , use neural networks (LTSMs and Recursive NNs, respectively). (8) ATTENTION, taken from <ref type="bibr">Yin et al. (2016)</ref>, uses an attention-based convolutional neural network. (9) DISCOURSE, taken from <ref type="bibr" target="#b377">Narasimhan and Barzilay (2015)</ref>, proposes a discourse based model.</p><p>(10-14) LSSVM, LSSVM+Negation, LSSVM+Negation (MultiTask), taken from  are all discourse aware latent structural svm models. LSSVM+Negation accounts for negation. LSSVM+Negation+MTL further incoporates multi-task learning based on question types. Here, we have three variants of multitask learners based on the three question classification strategies. (15) Finally, SYN+FRM+SEM, taken from  proposes a framework with features based on syntax, frame semantics, coreference and word embeddings. Results: We compare our AMR subgraph containment approach 2 where we consider our modifications for negation and multi-task learning as well in <ref type="table" target="#tab_10">Table 1</ref>. We can observe that our models have a comparable performance to all the baselines including the neural network approaches and all previous approaches proposed for this task. Further, when we incorporate multi-task learning, our approach achieves the state of the art. Also, our approaches have a considerable improvement over the baselines for 'multiple' questions. This shows the MCTest-500 dataset. The table shows accuracy on the test set of MCTest-500. All differences between the baselines (except SYN+FRM+SEM) and our approaches, and the improvements due to negation and multi-task learning are significant (p &lt; 0.05) using the two-tailed paired T-test.</p><p>the benefit of our latent structure that allows us to combine evidence from multiple sentences. The negation heuristic helps significantly, especially for 'single' questions (majority of negation cases in the MCTest dataset are for the "single" questions). The multi-task method which performs a classification based on the subtasks for machine comprehension defined in <ref type="bibr" target="#b384">Weston et al. (2015)</ref> does better than QAClassification that learns the question answer classification. QAClassification in turn performs better than QClassification that learns the question classification only. These results, together, provide validation for our approach of subgraph matching over meaning representation graphs, and the incorporation of negation and multi-task learning.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Conclusion</head><p>We proposed a solution for reading comprehension tests using AMR. Our solution builds intermediate meaning representations for passage and question-answers. Then it poses the comprehension task as a subgraph matching task by learning latent alignments from one meaning representation to another. Our approach achieves competitive or better performance than other approaches proposed for this task. Incorporation of negation and multi-task learning leads to further improvements establishing it as the new state-of-the-art.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Cross-Lingual Word Representations via Spectral Graph Embeddings</head><p>Takamasa Oshikiri, Kazuki Fukui, Hidetoshi Shimodaira Division of Mathematical Science, Graduate School of Engineering Science Osaka University, Japan 1-3 Machikaneyama-cho, Toyonaka, Osaka {oshikiri, fukui, shimo}@sigmath.es.osaka-u.ac.jp</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Abstract</head><p>Cross-lingual word embeddings are used for cross-lingual information retrieval or domain adaptations. In this paper, we extend Eigenwords, spectral monolingual word embeddings based on canonical correlation analysis (CCA), to crosslingual settings with sentence-alignment. For incorporating cross-lingual information, CCA is replaced with its generalization based on the spectral graph embeddings. The proposed method, which we refer to as Cross-Lingual Eigenwords (CL-Eigenwords), is fast and scalable for computing distributed representations of words via eigenvalue decomposition. Numerical experiments of English-Spanish word translation tasks show that CLEigenwords is competitive with stateof-the-art cross-lingual word embedding methods.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>There have been many methods proposed for word embeddings. Neural network based models are popular, and one of the most major approaches is the skip-gram model , and some extended methods have also been developed . The skip-gram model has many interesting syntactic and semantic properties, and it can be seen as the factorization of a word-context matrix whose elements represent pointwise mutual information . However, word embeddings based on neural networks (without neat implementation) can be very slow in general, and it is sometimes difficult to understand how they work. Recently, a simple spectral method, called Eigenwords, for word embeddings is proposed <ref type="bibr" target="#b388">(Dhillon et al., 2012;</ref><ref type="bibr" target="#b389">Dhillon et al., 2015)</ref>. It is based on canonical correlation analysis (CCA) for computing word vectors by maximizing correlations between words and their contexts. Eigenword algorithms are fast and scalable, yet giving good performance comparable to neural network approaches for capturing the meaning of words from their context.</p><p>The skip-gram model, originally proposed for monolingual corpora, has been extended to crosslingual settings. Given two vector representations of two languages, a linear transformation between the two spaces is trained from a set of word pairs for translation task , while other researchers use CCA for learning linear projections to a common vector space where translation pairs are strongly correlated . These methods require wordalignment in the training data, while some multilingual corpora have only coarse information such as a set of sentence pairs or paragraph pairs. Recently, extensions of the skip-gram model requiring only sentence-alignment have been developed by introducing cross-lingual losses in the objective of the original models <ref type="bibr" target="#b391">(Gouws et al., 2015;</ref><ref type="bibr" target="#b386">Coulmance et al., 2015;</ref><ref type="bibr" target="#b402">Shi et al., 2015)</ref>.</p><p>In this paper, instead of the skip-gram model, we extend Eigenwords <ref type="bibr" target="#b389">(Dhillon et al., 2015)</ref> to cross-lingual settings with sentence-alignment. Our main idea is to replace CCA, which is applicable to only two different kinds of data, with a generalized method <ref type="bibr" target="#b401">(Nori et al., 2012;</ref><ref type="bibr" target="#b403">Shimodaira, 2016)</ref> based on spectral graph embeddings <ref type="bibr" target="#b404">(Yan et al., 2007)</ref> so that the Eigenwords can deal with two or more languages for cross-lingual word embeddings. Our proposed method, referred to as Cross-Lingual Eigenwords (CL-Eigenwords), requires only sentence-alignment for capturing cross-lingual relationships. The method is very simple in mathematics as well as computation; it involves a generalized eigenvalue problem, which can be solved by fast and scalable algorithms such as the randomized eigenvalue decomposition <ref type="bibr" target="#b392">(Halko et al., 2011)</ref>. <ref type="figure" target="#fig_3">Fig. 1</ref> shows an illustrative example of crosslingual word vectors obtained by CL-Eigenwords. Although only sentence-alignment is available in the corpus, word-level translation is automatically captured in the vector representations; the same words (countries and capitals) in the two languages are placed in close proximity to each other; greece is close to grecia and rome is close to roma. In addition, the same kinds of relationships between word pairs share similar directions in the vector space; the direction from sweden to stockholm is nearly parallel to the direction from finland to helsinki.</p><p>We evaluate the word vectors obtained by our method on the English-Spanish cross-lingual translation task and compare the results with those of state-of-the-art methods, showing that our proposed method is competitive with those existing methods. We use Europarl corpus for learning the vector representation of words. Although the experiments in this paper are conducted using bilingual corpus, our method can be easily applied to three or more languages.</p><p>2 Eigenwords (One Step CCA) CCA <ref type="bibr" target="#b393">(Hotelling, 1936</ref>) is a multivariate analysis method for finding optimal projections of two sets of data vectors by maximizing the correlations. Applying CCA to pairs of raw word vector and raw context vector, Eigenword algorithms attempt to find low dimensional vector representations of words <ref type="bibr" target="#b388">(Dhillon et al., 2012)</ref>. Here we explain the simplest version of Eigenwords called One Step CCA (OSCCA).</p><p>We have monolingual corpus consisting of T tokens; (t i ) i=1,...,T , and the vocabulary consisting of V word types; {v i } i=1,...,V . Each token t i is drawn from this vocabulary. We define word matrix V ∈ {0, 1}</p><p>T ×V whose i-th row encodes token t i by 1-of-V representation; the j-th element is 1 if the word type of t i is v j , 0 otherwise. Let h be the size of context window. We define context matrix C ∈ {0, 1}</p><p>T ×2hV whose i-th row represents the surrounding context of token t i with concatenated 1-of-V encoded vectors of (t i−h , . . . , t i−1 , t i+1 , . . . , t i+h ).</p><p>We apply CCA to T pairs of row vectors of V and C. The objective function of CCA is constructed using V ⊤ V, V ⊤ C, C ⊤ C which represent occurrence and co-occurrence counts of words and contexts. In Eigenwords, however, we use</p><formula xml:id="formula_216">C V V ∈ R V ×V + , C V C ∈ R V ×2hV + , C CC ∈ R 2hV ×2hV +</formula><p>with the following preprocessing of these matrices before constructing the objective function. First, centering-process of V and C is omitted, and off-diagonal elements of C ⊤ C are ignored for simplifying the computation of inverse matrices. Second, we take the square root of the elements of these matrices for "squashing" the heavy-tailed word count distributions. Finally, we obtain vector representations of words as C</p><formula xml:id="formula_217">−1/2 V V (u 1 , . . . , u K ), where u 1 , . . . , u K ∈ R V are left singular vectors of C −1/2 V V C V C C −1/2</formula><p>CC corresponding to the K largest singular values. The computation of SVD is fast and scalable using recent idea of random projections <ref type="bibr" target="#b392">(Halko et al., 2011)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Cross-Lingual Eigenwords</head><p>In this section, we introduce Cross-Lingual Eigenwords (CL-Eigenwords), a novel method for cross-lingual word embeddings. Suppose that we have parallel corpora that contain L languages. Schematic diagrams of Eigenwords and CL-Eigenwords (with L = 2) are shown in <ref type="figure" target="#fig_8">Fig. 2</ref>.</p><p>In the same way as the monolingual Eigenwords, we denote the word matrix and the context matrix for ℓ-th language by</p><formula xml:id="formula_218">V (ℓ) ∈ R T (ℓ) ×V (ℓ) + and C (ℓ) ∈ R T (ℓ) ×2h (ℓ) V (ℓ) +</formula><p>respectively, where V (ℓ) is the size of vocabulary, T (ℓ) is the number of tokens, and h (ℓ) is the size of context window. There are D sentences (or paragraphs) in the multilingual corpora, and each token is included in one of the sentences. The sentence-alignment is represented in the matrix</p><formula xml:id="formula_219">J (ℓ) ∈ R T (ℓ) ×D + whose (i, j)- element J (ℓ)</formula><p>i,j is set to 1 if the i-th token t (ℓ) i of ℓ-th language corpus comes from the j-th sentence or 0 otherwise. We also define document matrix D whose j-th row encodes j-th sentence by 1-of-D representation; D = I D , where I D represents Ddimensional identity matrix.</p><p>The goal of CL-Eigenwords is to construct vector representations of words of two (or more) languages from multilingual corpora at the same time. This problem is formulated as an example of Cross-Domain Matching Correlation Analysis (CDMCA) <ref type="bibr" target="#b403">(Shimodaira, 2016)</ref>, which deals with many-to-many relationships between data vectors from multiple sources. CDMCA is based on the spectral graph embeddings <ref type="bibr" target="#b404">(Yan et al., 2007)</ref>, and attempts to find optimal linear projections of data vectors so that associated transformed vectors are placed in close proximity to each other. The strength of association between two vectors is specified by a nonnegative real value called matching weight. Since CDMCA includes CCA and a variant of Latent Semantic Indexing (LSI) <ref type="bibr" target="#b387">(Deerwester et al., 1990)</ref> as special cases, CLEigenwords can be interpreted as LSI-equipped Eigenwords (See Appendix).</p><p>In CL-Eigenwords, the data vectors are given as v</p><formula xml:id="formula_220">(ℓ) i , c (ℓ) i , d i , namely, the i-th row vectors of V (ℓ) , C (ℓ)</formula><p>, D, respectively. The matching weights between row vectors of V (ℓ) and C (ℓ) are specified by the identity matrix I T (ℓ) because the data vectors are in one-to-one correspondence. On the other hand, the matching weights between row vectors of V (ℓ) and D as well as those between C (ℓ) and D are specified byJ</p><formula xml:id="formula_221">(ℓ) = b (ℓ) J (ℓ)</formula><p>, the sentence-alignment matrix multiplied by a constant b (ℓ) . Then we will find linear transformation matrices A (ℓ)</p><formula xml:id="formula_222">V , A (ℓ) C , A D , (ℓ = 1, 2, . . . , L) to K- dimensional vector space by minimizing the ob- jective function L ∑ ℓ=1 T (ℓ) ∑ i=1 ∥v (ℓ) i A (ℓ) V − c (ℓ) i A (ℓ) C ∥ 2 2 + L ∑ ℓ=1 T (ℓ) ∑ i=1 D ∑ j=1J (ℓ) i,j ∥v (ℓ) i A (ℓ) V − d j A D ∥ 2 2 + L ∑ ℓ=1 T (ℓ) ∑ i=1 D ∑ j=1J (ℓ) i,j ∥c (ℓ) i A (ℓ) C − d j A D ∥ 2 2</formula><p>(1) with a scale constraint for projection matrices. Note that the first term in (1) is equivalent to that of CCA between words and contexts, namely the objective of monolingual Eigenwords, and therefore word vectors of two languages are obtained as row vectors of A (ℓ)</p><formula xml:id="formula_223">V (ℓ = 1, 2, . . . , L).</formula><p>Hereafter, we assume L = 2 for notational simplicity. A generalization to the case L &gt; 2 is straightforward; redefine X, W, A below by repeating the submatrices, such as V (ℓ) and C (ℓ) , for L times. For solving the optimization problem, we define   <ref type="table" target="#tab_10">Table 1</ref>: Computational times (in minutes) and word translation accuracies (in percent, higher is better) evaluated by Precision@n using the 1,000 test words (the 1st to 1,000th most frequent words or the 5,001st to 6,000th most frequent words). Shown are for Spanish (es) to English (en) translation and for English (en) to Spanish (es) translation. * BilBOWA is executed on 3 threads, while CL-LSI and CL-Eigenwords are executed on a single thread.</p><formula xml:id="formula_224">X =     V (1) O O O O O C (1) O O O O O V (2) O O O O O C (2) O O O O O D     , W =       O I T (1) O OJ (1) I T (1) O O OJ (1) O O O I T (2)J (2) O O I T (2) OJ (2) J (1)⊤J(1)⊤J(2)⊤J(2)⊤ O       , A ⊤ = (A (1)⊤ V , A (1)⊤ C , A (2)⊤ V , A<label>(2)</label></formula><formula xml:id="formula_225">Also define H = X ⊤ WX, G = X ⊤ MX, M = diag(W1).</formula><p>Then the optimization problem (1) is equivalent to maximizing Tr(A ⊤ HA) with a scale constraint A ⊤ GA = I K . Following the Eigenwords implementation <ref type="bibr" target="#b389">(Dhillon et al., 2015)</ref>, we replace H, G with H, G by ignoring the nondiagonal elements of G and taking the square root of elements in H, G. The optimization problem is solved as a generalized eigenvalue problem, and the word representations, as well as those for contexts and sentences, are obtained as row vectors ofÂ = G −1/2 (u 1 , . . . , u K ), where u 1 , . . . , u K are eigenvectors of (G −1/2 ) ⊤ HG −1/2 for the K largest eigenvalues. We choose K so that all the K eigenvalues are positive. As in the case of monolingual Eigenwords, we can exploit fast implementations such as the randomized eigenvalue decomposition <ref type="bibr" target="#b392">(Halko et al., 2011)</ref>; our computation in the experiments is only approximation based on the low-rank factorization with rank 2K.</p><p>For measuring similarities between two word vectors x, y ∈ R K , we use the weighted cosine similarity</p><formula xml:id="formula_226">sim(x, y) = (∥x∥ 2 · ∥y∥ 2 ) −1 K ∑ i=1 λ i x i y i ,</formula><p>where λ i is the i-th largest eigenvalue.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Experiments</head><p>The implementation of our method is available on GitHub 1 . Following the previous works <ref type="bibr" target="#b391">Gouws et al., 2015)</ref>, we use only 1 https://github.com/shimo-lab/kadingir the first 500K lines of English-Spanish sentencealigned parallel corpus of Europarl  for numerical experiments.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Word Translation Tasks</head><p>Experiments are performed in similar settings as the previous works based on the skip-gram model <ref type="bibr" target="#b391">Gouws et al., 2015)</ref>. We extract 1,000 test words with frequency rank 1-1000 or 5001-6000 from the source language, and translate these words to the target language using Google Translate, assuming they are the correct translations. Then, we evaluate the translation accuracies of each method with precision@n as the fraction of correct translations for the test words being in the top-n words of the target language returned by each method.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Baseline Systems</head><p>We compare CL-Eigenwords with the following three methods.</p><p>Edit distance Finding the nearest words measured by Levenshtein distance.</p><p>CL-LSI Cross-Language LSI (CL-LSI) <ref type="bibr" target="#b398">(Littman et al., 1998)</ref> is not originally for word embeddings. However, since this method can be used for cross-lingual information retrieval, we select it as one of our baselines. For each language, we construct the term-document matrix of size V (ℓ) × D whose (i, j)-element represents the frequency of i-th word in j-th sentence. Then LSI is applied to the concatenated matrix of size (V (1) +V (2) )×D.</p><p>BilBOWA BilBOWA <ref type="bibr" target="#b391">(Gouws et al., 2015)</ref> is one of the state-of-the-art methods for cross-lingual word embeddings based on the skip-gram model. We obtain vector representations of words using publicly available implementation. 2</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Results</head><p>In CL-Eigenwords, vocabulary size V (1) = V (2) = 10 4 , window size h (1) = h (2) = 2, the constant b (1) = b (2) = 10 3 . The dimensionality of vector representations is K = 40, 100, or 200. Similarities of two vector representations are measured by the unweighted cosine similarity in CL-LSI and BilBOWA. Our experiments were performed on a CentOS 7.2 server with Intel Xeon E5-2680 v3 CPU, 256GB of RAM and gcc 4.8.5. The computation times and the result accuracies of word translation tasks are shown in <ref type="table" target="#tab_10">Table 1</ref>. We observe that CL-Eigenwords is competitive with BilBOWA and CL-LSI. In particular, CL-Eigenwords performed very well for the most frequent words (ranks 1-1000) in this particular parameter setting. Furthermore, the computation times of CL-Eigenwords are as short as those of BilBOWA for achieving similar accuracies. Preliminary experiments also suggest that CL-Eigenwords works well for semi-supervised learning where sentence-alignment is specified only partially; the word translation accuracies are maintained well with aligned 240K lines and unaligned 260K lines.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Conclusion</head><p>We proposed CL-Eigenwords for incorporating cross-lingual information into the monolingual Eigenwords. Although our method is simple, experimental results of English-Spanish word translation tasks show that the proposed method is competitive with other state-of-the-art cross-lingual methods. Let</p><formula xml:id="formula_227">V (1) , V (2) , D, J (1) , J<label>(2</label></formula><p>) be those defined in Section 3. In CL-LSI, we consider the truncated singular value decomposition of a word-document matrix</p><formula xml:id="formula_228">B = ( V (1)⊤ J (1) V (2)⊤ J (2) ) ≈ A V Λ K A ⊤ D</formula><p>using the largest K singular values. Then row vectors of A V are the vector representations of words of CL-LSI. CL-LSI can also be interpreted as an eigenvalue decomposition of H = X ⊤ WX where</p><formula xml:id="formula_229">X = ( V (1) O O O V (2) O O O D ) , W = ( O O J (1) O O J (2) J (1)⊤ J (2)⊤ O )</formula><p>are redefined from those in Section 3 by removing submatrices related to contexts. The structure of X and W is illustrated in <ref type="figure" target="#fig_6">Fig. 3</ref>. Similarly to CL-Eigenwords of Section 3, but ignoring G, we define A = (u 1 , . . . , u K ) with the eigenvectors of H for the largest K eigenvalues λ 1 , . . . , λ K . It then follows from</p><formula xml:id="formula_230">H = ( O B B ⊤ O ) that A ⊤ = 2 −1/2 (A ⊤ V , A ⊤ D )</formula><p>with the same A V and A D obtained by the truncated singular value decomposition. The eigenvalues are the same as the singular values: diag(λ 1 , . . . , λ K ) = Λ K . Therefore CL-LSI is interpreted as a variant of CL-Eigenwords without the context information.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Collocations of the kind make [a] suggestion, attend [a] lecture, heavy rain, deep thought, strong tea, etc., are restricted lexical co-occurrences of two syntactically bound lexical elements <ref type="bibr" target="#b426">(Kilgarriff, 2006)</ref>. The central role of collocations for second language (henceforth, L2) learning has been discussed in a series of theoretical and empirical studies <ref type="bibr" target="#b422">(Hausmann, 1984;</ref><ref type="bibr" target="#b406">Bahns and Eldaw, 1993;</ref><ref type="bibr" target="#b421">Granger, 1998;</ref><ref type="bibr" target="#b427">Lewis and Conzett, 2000;</ref><ref type="bibr" target="#b434">Nesselhauf, 2005;</ref><ref type="bibr" target="#b405">Alonso Ramos et al., 2010)</ref> and is widely reflected in (especially English) learner dictionaries. In computational lexicography, several statistical measures have been used to retrieve collocations from corpora, among them, mutual information <ref type="bibr" target="#b411">(Church and Hanks, 1989;</ref><ref type="bibr" target="#b428">Lin, 1999)</ref>, entropy <ref type="bibr" target="#b426">(Kilgarriff, 2006)</ref>, pointwise mutual information <ref type="bibr" target="#b407">(Bouma, 2010)</ref>, and weighted pointwise mutual information <ref type="bibr" target="#b409">(Carlini et al., 2014)</ref>. 1 However, the needs of language learners go beyond mere lists of collocations: the cited studies reveal that language learners often build "miscollocations" (as, e.g., *give a suggestion or *have the curiosity) to express the intended meaning. In other words, they fail to observe, in Kilgarriff's terms, the "collocationality" restrictions of L2, which imply that in language production, one of the elements of a collocation (the base) is freely chosen, while the choice of the other (the collocate) depends on the base <ref type="bibr" target="#b423">(Hausmann, 1989;</ref><ref type="bibr" target="#b412">Cowie, 1994)</ref>. For instance, to express the meaning of 'do' or 'perform', the base suggestion prompts for the choice of make as collocate: make [a] suggestion, while advice prompts for give: give [an] advice; to express the meaning of 'participate in', lecture prompts for attend: attend [a] lecture, while operation prompts for assist: assist [an] operation; to express the meaning of 'intense' in connection with rain, the right collocate is heavy, while 'intense wind' is strong wind. And so on. The idiosyncrasy of collocations makes them also language-specific. Thus, in English, you take [a] walk, in Spanish you 'give' it (dar [un] paseo), and in German and French you 'make' it ([einen] Spaziergang machen, faire [une] promenade); in English, rain is heavy, while in Spanish and German it is 'strong' (fuerte lluvia/starker Regen).</p><p>In order to effectively support L2 learners, techniques are thus needed that are able not only to retrieve collocations, but also provide for a given base (or headword) and a given semantic gloss of a collocate meaning, the actual collocate lexeme. In what follows, we present such a technique, which is grounded in 's word embeddings, and which leverages the fact that semantically related words in two different vector representations are related by linear transformation . This property has been exploited for word-based translation , learning semantic hierarchies (hyponym-hypernym relations) in Chinese <ref type="bibr" target="#b417">(Fu et al., 2014)</ref>, and modeling linguistic similarities between standard (Wikipedia) and nonstandard language (Twitter) . In our task, we learn a transition matrix over a small number of collocation examples, where collocates share the same semantic gloss, to apply then this matrix to discover new collocates for any previously unseen collocation base. We discuss the outcome of the experiments with ten different collocate glosses (including 'do' / 'perform', 'increase', 'decrease', etc.), and show that for most glosses, an approach that combines a stage of the application of a gloss-specific transition matrix with a pruning stage that is based on statistical evidence outperforms approaches that exploit only one of these stages as well as a baseline that is based on collocation retrieval exploiting the embeddings property for drawing analogies, such as, e.g., x ∼ applause ≡ heavy ∼ rain (implying x=thunderous) <ref type="bibr" target="#b437">(Rodríguez-Fernández et al., 2016</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Theoretical model</head><p>The semantic glosses of collocates across collocations can be generalized into a generic semantic typology modeled, e.g., by <ref type="bibr" target="#b429">Mel'čuk (1996)</ref>'s Lexical Functions. For instance, absolute, deep, strong, heavy in absolute certainty, deep thought, strong wind, and heavy storm can all be glossed as 'intense'; make, take, give, carry out in make [a] proposal, take [a] step, give [a] hint, carry out [an] operation can be glossed as 'do'/'perform'; etc. Our goal is to capture the relation that holds between the training bases and the collocates with the same gloss, such that given a new base and a gloss, we can retrieve its corresponding collocate(s) with this gloss. Thus, given absolute certainty, deep thought, and strong wind as training examples, storm as input base and 'intense' as gloss, we aim at retrieving the collocate heavy. As already mentioned above, our approach is based on 's linear transformation model, which associates word vector representations between two analogous spaces. In Mikolov et al.'s original work, one space captures words in language L 1 and the other space words in language L 2 , such that the found relations are between translation equivalents. In our case, we define a base space B and a collocate space C in order to relate bases with their collocates that have the same meaning, in the same language. To obtain the word vector representations in B and C, we use 's word2vec. <ref type="bibr">2</ref> The linear transformation model is constructed as follows. Let T be a set of collocations whose collocates share the semantic gloss τ , and let b t i and c t i be the collocate respectively base of the collocation t i ∈ T. </p><formula xml:id="formula_231">t i , c t i } n i=1</formula><p>. Φ τ is used to learn a linear transformation matrix Ψ τ ∈ R B×C . Following the notation in , this transformation can be depicted as:</p><formula xml:id="formula_232">B τ Ψ τ = C τ</formula><p>We follow Mikolov et al.'s original approach and compute Ψ τ as follows:</p><formula xml:id="formula_233">min Ψτ |Φτ | i=1 Ψ τ b t i − c t i 2</formula><p>Hence, for any given novel base b jτ , we obtain a novel list of ranked collocates by applying Ψ τ b jτ and filtering the resulting candidates by part of speech and N P M I, an association measure that is based on the pointwise mutual information, but takes into account the asymmetry of the lexical dependencies between a base and its collocate <ref type="bibr" target="#b409">(Carlini et al., 2014)</ref>:</p><formula xml:id="formula_234">N P M I = P M I(collocate, base) −log(p(collocate))</formula><p>3 Experiments</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Setup of the Experiments</head><p>We carried out experiments with 10 of the most frequent semantic collocate glosses (listed in the first column of <ref type="table" target="#tab_10">Table 1</ref>). As is common in previous work on semantic collocation classification <ref type="bibr" target="#b433">(Moreno et al., 2013;</ref>, our training set consists of a list of manually annotated correct collocations. For this purpose, we  <ref type="table" target="#tab_10">Table 1</ref>: Semantic glosses and size of training set randomly selected nouns from the Macmillan Dictionary and manually classified their corresponding collocates with respect to the glosses. <ref type="bibr" target="#b471">3</ref> Note that there may be more than one collocate for each base. Since collocations with different collocate meanings are not evenly distributed in language (e.g., speakers use more often collocations conveying the idea of 'intense' and 'perform' than 'stop performing'), the number of instances per gloss in our training data also varies significantly (see <ref type="table" target="#tab_10">Table 1</ref>). Due to the asymmetric nature of collocations, not all corpora may be equally suitable for the derivation of word embedding representations for both bases and collocates. Thus, we may hypothesize that for modeling (nominal) bases, which keep in collocations their literal meaning, a standard register corpus with a small percentage of figurative meanings will be more adequate, while for modeling collocates, a corpus which is potentially rich in collocations is likely to be more appropriate. In order to verify this hypothesis, we carried out two different experiments. In the first experiment, we used for both bases and collocates vectors pre-trained on the Google News corpus (GoogleVecs), which is available at word2vec's website. In the second experiment, the bases were modeled by training their word vectors over a 2014 dump of the English Wikipedia, while for modeling collocates, again, GoogleVecs has been used. In other words, we assumed that Wikipedia is a standard register corpus and thus better for modeling B, while GoogleVecs is more suitable for modeling C. The figures in Section 3.2 below will give us a hint whether this assumption is correct. <ref type="bibr" target="#b471">3</ref> At this stage of our work, we considered only collocations that involve single word tokens for both the base and the collocate. In other words, we did not take into account, e.g., phrasal verb collocates such as stand up, give up or calm down. We also left aside the problem of subcategorization in collocations; cf., e.g., into in take [into] consideration.</p><p>For the calculation of N P M I during postprocessing, the British National Corpus (BNC) was used. <ref type="bibr">4</ref> </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Evaluation</head><p>The outcome of each experiment was assessed by verifying the correctness of each retrieved candidate from the top-10 candidates obtained for each test base. A total of 10 bases was evaluated for each gloss. The ground truth test set was created in a similar fashion as the training set: nouns from the Macmillan Dictionary were randomly chosen, and their collocates manually classified in terms of the different glosses, until a set of ten unseen base-collocate pairs was obtained for each gloss.</p><p>For the outcome of each experiment, we computed both precision (p) as the ratio of retrieved collocates that match the targeted glosses to the overall number of obtained collocates for each base, and Mean Reciprocal Rank (MRR), which rewards the position of the first correct result in a ranked list of outcomes:</p><formula xml:id="formula_235">MRR = 1 |Q| |Q| i=1 1 rank i</formula><p>where Q is a sample of experiment runs and rank i refers to the rank position of the first relevant outcome for the ith run. MRR is commonly used in Information Retrieval and Question Answering, but has also shown to be well suited for collocation discovery; see, e.g., <ref type="bibr" target="#b443">(Wu et al., 2010)</ref>.</p><p>We evaluated four different configurations of our technique against two baselines. The first baseline (S1) is based on the regularities in word embeddings, with the vec(king) − vec(man) + vec(woman) = vec(queen) example as paramount case. In this context, we manually selected one representative example for each semantic gloss to discover collocates for novel bases following the same schema; cf., e.g., for the gloss 'perform' vec(take) − vec(walk) + vec(suggestion) = vec(make) (where make is the collocate to be discovered); see <ref type="bibr" target="#b437">(Rodríguez-Fernández et al., 2016)</ref> for details. The second baseline (S2) is an extension of S1 in that its output <ref type="bibr">Precision (p)</ref> Mean Reciprocal Rank <ref type="table" target="#tab_5">(MRR)  Semantic gloss  S1  S2  S3  S4  S5  S6  S1  S2  S3  S4  S5  S6  '</ref>   The four configurations of our technique that we tested were: S3, which is based on the transition matrix for which GoogleVecs is used as reference vector space representation for both bases and collocates; S4, which applies POS-pattern and N P M I filters to the output of S3; S5, which is equivalent to S3, but relies on a vector space representation derived from Wikipedia for learning bases projections and on a vector space representation from GoogleVecs for collocate projections; and, finally, S6, where the S5 output is, again, filtered by POS collocation patterns and N P M I.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Discussion</head><p>The results of the experiments are displayed in <ref type="table" target="#tab_5">Table 2</ref>. In general, the configurations S3 -S6 largely outperform the baselines, with the exception of the gloss 'increase', for which S2 equals S6 as far as p is concerned. However, in this case too MRR is considerably higher for S6, which achieves the highest MMR scores for 6 and the highest precision scores for 7 out of 10 glosses 5 At the first glan ce, a state-of-the-art approach on correction of collocation errors by suggesting alternative cooccurrences, such, as, e.g., <ref type="bibr" target="#b413">(Dahlmeier and Ng, 2011;</ref><ref type="bibr" target="#b435">Park et al., 2008;</ref><ref type="bibr" target="#b418">Futagi et al., 2008)</ref>, might appear as a suitable baseline. We discarded this option given that none of them uses explicit fine-grained semantics.</p><p>(see the S6 columns in <ref type="table" target="#tab_5">Table 2</ref>). In other words, the full pipeline promotes good collocate candidates to the first positions of the ranked result lists and is also best in terms of accuracy.</p><p>Comparing S1, S3, S5 to S2, S4, and S6 , we may conclude that the inclusion of a filtering module (and, in particular, of an N P M I filtering module) contributes substantially to the overall precision in nearly all cases ('decrease' being the only exception). The comparison of the precision obtained for configurations S3 and S5 also reveals that for 7 glosses the strategy to model C and B on different corpora paid off. This is different as far as MRR is concerned. Further investigation is needed for the examination of this discrepancy.</p><p>We can observe that certain glosses seem to exhibit less linguistic variation, requiring a less populated transformation function from bases to collocates. Consider the case of 'show', which generates with only 49 training pairs the second best transition matrix, with p=0.70. It is also informative to contrast the performance on pairs of glosses with opposite meanings, such as e.g., 'begin to perform' vs. 'stop performing'; 'increase' vs. 'decrease'; 'intense' vs. 'weak'; and finally 'create, cause' vs. 'put an end'. Better performance is achieved consistently on the positive counterparts (e.g. 'begin to perform' over 'stop performing'). A closer look at the output reveals that in these 502  <ref type="table" target="#tab_42">Table 4</ref>: Precision of the coarse-grained evaluation of the S6 configuration cases positive glosses are persistently classified as negative. Further research is needed to first understand why this is the case and then to come up with an improvement of the technique in particular on the negative glosses. The fact that for some of the glosses precision is rather low may be taken as a hint that the proposed technique is not suitable for the task of semanticsoriented recognition of collocations. However, it should be also stressed that our evaluation was very strict: a retrieved collocate candidate was considered as correct only if it formed a collocation with the base, and if it belonged to the target semantic gloss. In particular the first condition might be too rigorous, given that, in some cases, there is a margin of doubt whether a combination is a free co-occurrence or a collocation; cf., e.g., huge challenge or reflect [a] concern, which were rejected as collocations in our evaluation. Since for L2 learners such co-occurrences may be also useful, we carried out a second evaluation in which all the suggested collocate candidates that belonged to a target semantic gloss were considered as correct, even if they did not form a collocation. 6 Cf. <ref type="table" target="#tab_42">Table 4</ref> for the outcome of this evaluation for the S6 configuration. Only for 'perform' the precision remained the same as before. This is because collocates assigned to this gloss are support verbs (and thus void of own lexical semantic content).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Conclusions</head><p>As already pointed out in Section 1, a substantial amount of work has been carried out to automatically retrieve collocations from corpora <ref type="bibr" target="#b410">(Choueka, 1988;</ref><ref type="bibr" target="#b411">Church and Hanks, 1989;</ref><ref type="bibr" target="#b438">Smadja, 1993;</ref><ref type="bibr"></ref> Rank-1 subspace regularization can also be motivated from the fact that word embeddings are able to capture some linguistic regularities  along certain directions in the vector space. For example, the difference vector for word pair (king, queen) is approximately aligned with the difference vector for (man,woman), encoding the gender relation. The direction of the difference vectors carries significant information for these regularities which is evident from the success of cosine similarity metrics in the word analogy problems . CTM that assumes w i + u k = w j ∀(w i , r k , w j ) ∈ R enforces an additional equal length constraint on the difference vectors, which may be rather restrictive, especially when the word vectors are also influenced by co-occurrence statistics (apart from relational knowledge). Moreover, it may face following challenges in relational modeling:</p><p>• It does not have a natural interpretation for modeling symmetric relations (e.g., synonyms, antonyms) that allow interchangeability of words in a given relation triplet (i.e., (w i , r k , w j ) ⇐⇒ (w j , r k , w i )). Having a constant translation of u k ∈ R d from the first word to the second word leads to contradiction.</p><p>• It is also not natural for modeling relations with transitive property (i.e., (w i , r k , w j ) ∧ (w j , r k , w l ) =⇒ (w i , r k , w l )), again leading to contradictions. Common examples of such relations are synonyms and hypernyms.</p><p>The proposed rank-1 subspace relation model naturally allows for modeling such relations by doing away with the constant length restriction on the difference vectors. Our empirical evaluations verify that this relaxation indeed leads to improved quality of word vectors with respect to capturing linguistic regularities.</p><p>We incorporate the proposed relational model into the learning objective for word vectors by regularizing the matrix of difference vectors towards a rank-1 matrix. We impose a nonnegativity constraint on the reconstruction coefficients α k if relation r k is asymmetric. This respects the unidirectional nature of asymmetric relations. To ensure uniqueness of solution for u k and α k , we constrain u k 2 = 1. Leaving α k completely free can end up creating spurious relations between any two words that are arbitrarily far but whose difference vector is directionally aligned with any of the relation basis vectors {u k } m k=1 . To avoid this, we further impose a upper limit of c on the absolute value of elements of α k . We minimize the following joint objective for word vectors {w i } |V | i=1 and relation parameters {u k , α k } m k=1 :</p><formula xml:id="formula_236">− 1 T T t=1 log p(w t |w t+c t−c ) + λ 2 |R| m k=1 D k − u k α k 2 F s.t. α k ≥ 0 ∀ asymmetric r k , u k 2 = 1, |(α k ) l | ≤ c.<label>(4)</label></formula><p>where D k is the matrix of difference vectors as defined earlier and λ is the regularization parameter. The first term in the objective takes into account the co-occurrence information text corpus while the second term incorporates the relational knowledge.</p><p>Optimizing for word vectors: We adopt parallel asynchronous stochastic gradient descent (SGD) with negative sampling approach of . The model parameters for optimization are input embeddings (weights connecting input and hidden layer) and output embeddings (weights connecting hidden and output layer). Input embeddings are taken as the final word embeddings. Each computing thread works with a predefined segment of the text corpus and updates parameters that are stored in a shared memory. In each gradient step of CBOW, a thread samples a target word and its local context window and updates the parameters of the neural network. It can be seen as sampling one of the f t (·), t = 1, 2, . . . , T and taking a gradient step with it. A small number of random target words are also sampled for the same context, treating them as negative examples for the gradient update. In the CBOW architecture, representations for context words are directly encoded as columns of the linear weight matrix W ∈ R d×|V | that maps input bag-of-words layer to the hidden layer. The columns of W are taken as the word embeddings for the corresponding words in the vocabulary V . The reader is referred to  for more details on the optimization procedure for CBOW. If a word appears in the set of relation triplets R, our regularization term gets activated. Since we place the regularizer only on input embeddings, the following gradient updates due to the regularization term act only on input embeddings.</p><formula xml:id="formula_237">w i ←− w i − η λ |R|   j:(w i ,r k ,w j )∈R w i − w j + u k α k ij + j:(w j ,r k ,w i )∈R w i − w j − u k α k ji   ,<label>(5)</label></formula><p>where η is the learning rate, and α k ij denotes the element of α k corresponding to the column of matrix D k which contains difference vector (w j − w i ) (and similarly for α k ji ). The modifications in the learning rate as the SGD progresses are kept same as in the original implementation of CBOW 2 . Optimization for u k and α k : Instead of having stochastic gradient updates, we adopt an asynchronous batch update strategy for relation basis {u k } m k=1 and reconstruction coefficients {α k } m k=1 . We launch one compute thread that keeps solving the batch optimization problem for {u k } m k=1 and {α k } m k=1 in an infinite loop until the optimization for word embeddings finishes. The batch optimization problem for a symmetric relation r k is:</p><formula xml:id="formula_238">min u k ,α k D k − u k α k 2 F , s.t. u k 2 = 1, |α k | ≤ c.<label>(6)</label></formula><p>where D k ∈ R d×n k is the matrix of difference vectors for all triplets corresponding to relation r k as defined in Eq. 2. Without the absolute value constraint on α k , this problem can be exactly solved by SVD. We follow an alternating optimization procedure for solving this problem. We initialize u k to the top left singular vector of D k and then alternate between solving two leastsquares sub-problems for u k and α k respectively with the corresponding constraints. For asymmetric relations, there is an additional nonnegativity constraint on α k . We use projected gradient descent to solve these constrained least-squares problems.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Empirical Observations</head><p>We report preliminary evaluations of the proposed model (termed as RELSUB) on the tasks of word analogy and knowledge base completion. We use 2 https://code.google.com/p/word2vec/  English Wikipedia for training which contains approximately 4.8 million articles and 2 billion tokens. We lowercase all the text and and tokenize using Stanford NLP tokenizer. We use two datasets for evaluating the proposed method. Google word analogy data  contains 19544 analogy relations (14 relation types -5 semantic, 9 syntactic) of the form a:b::c:d constructed from 550 unique relation triplets. We use this data only for evaluation (test phase). WordRep  contains a large collection of relation triplets (44584 triplets in total, 25 relation types -18 semantic, 7 syntactic) extracted from WordNet, Wikipedia and Dictionary. For each relation type, we randomly split the triplets in 4 : 1 ratio with larger split used for training and smaller split used for test. We make sure that there is no word overlap between training and test triplets. We also remove triplets containing words from Google Analogy data from the training set.</p><p>We compare the proposed RELSUB model with two methods: (i) CBOW , and (ii) RELCONST which is based on constant translation model for relations which was originally proposed in <ref type="bibr" target="#b446">(Bordes et al., 2013)</ref> for embedding knowledge-bases and was recently used by  <ref type="table" target="#tab_5">Table 2</ref>: Google analogy data: Accuracy on word analogy task  for learning word embeddings. Our objective for RELCONST is same as Eq. 4 except that {α k } m k=1 are set equal to the vector of all 1's and norm constraint on u k are removed. This enables us to directly test the merit of the proposed rank-1 subspace relational model over that of constant translational model in the same regularization framework. Note that this objective is similar in spirit to  in the sense that it also uses a constant translation model for relations. However, Xu et al.  employ a maximum margin objective on the relation triplets as originally proposed in <ref type="bibr" target="#b446">(Bordes et al., 2013)</ref>. It encourages the loss (measured in terms of 2 distance) for true relation triplets to be smaller than the loss for randomly corrupted relation triplets. Instead of a maximum margin objective for relational knowledge, our model uses a simpler regularization based objective. We could not obtain the implementation of RC-NET <ref type="bibr" target="#b691">(Xu et al., 2014)</ref> due to copyright issues cited by its authors. We also cannot compare with approaches that use only knowledge-base for training  since they do not learn or modify the embeddings of unseen words and our evaluation triplets do not overlap with training triplets.</p><p>We use the CBOW implementation in publicly available Word2Vec code 3 for our experiments. Our vocabulary has 400k words and we use a dimensionality of 300 for embeddings. For all other parameters, we use default values that the Word2Vec code comes with including a context window size of 5 tokens to each side, 5 negative samples per positive sample for negative sampling technique, etc. For both RELSUB and RELCONST, we set the regularization parameter to λ |R| = 1e −4 in all our experiments. We set the upper limit c in Eq. 4 to 1. The parameters were not fine tuned rigorously but these values seemed to work reasonably well for us. We do total 5 epochs of SGD over the text corpus for all methods.</p><p>In knowledge-base completion task, we want to predict the missing word of a relation triplet. For a triplet (x, r, y), we assume that x (first word) and 3 https://code.google.com/p/word2vec/ r (relation type) are observed and the task is to predict the missing word y. We restrict the search for the missing word to the most frequent 300k words (75% of the vocabulary). The missing word is predicted to be the closest word along the rank-1 subspace spanned by the relation vector (restricted by c in Eq. 4). For RELCONST, the missing word is predicted by translating the first word by the relation vector and then searching for nearest word. The accuracy results on WordRep data are shown in <ref type="table" target="#tab_10">Table 1</ref>. Relaxing the constant translation to rank-1 subspace assumption results in significant improvements on this task.</p><p>In the analogy task, we want to predict the missing word in an analogy tuple a:b::c:?. We use the Google word-analogy data  for this evaluation. We observe considerable gains with RELSUB over CBOW for semantic categories. The accuracy of knowledge regularized methods on syntactic categories is a little worse than CBOW and only slightly better than RELCONST, which is contrary to our observation on the knowledge-base completion task. This is due to the fact that analogy task uses the difference vector (b − a) instead of the learned relation vector which is assumed to be unknown.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Word embeddings are usually trained on an objective that ensures that words occurring in similar contexts have similar embeddings. This makes them useful for many tasks, but has drawbacks for others; e.g., antonyms are often interchangeable in context and thus have similar word embeddings even though they denote opposites. If we think of word embeddings as members of a (commutative or Abelian) group, then antonyms should be inverses of (as opposed to similar to) each other. In this paper, we use DENSIFIER <ref type="bibr" target="#b481">(Rothe et al., 2016)</ref> to decompose a standard embedding space into interpretable orthogonal subspaces, including a one-dimensional polarity subspace as well as concreteness, frequency and POS subspaces. We introduce a new calculus for subspaces in which antonyms are inverses, e.g., "−1 × hate = love".</p><p>The formula shows what happens in the polarity subspace; the orthogonal complement (all the remaining subspaces) is kept fixed. We show below that we can predict an entire polarity spectrum based on the subspace, e.g., the four-word spectrum hate, dislike, like, love. Similar to polarity, we explore other interpretable subspaces and do operations such as: given a concrete word like friend find the abstract word friendship (concreteness); given the frequent word friend find a less frequent synonym like comrade (frequency); and given the noun friend find the verb befriend (POS).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Word Embedding Transformation</head><p>We now give an overview of DENSIFIER; see <ref type="bibr" target="#b481">Rothe et al. (2016)</ref> for details. Let Q ∈ R d×d be an orthogonal matrix that transforms the original word embedding space into a space in which certain types of information are represented by a small number of dimensions. The orthogonality can be seen as a hard regularization of the transformation. We choose this because we do not want to add or remove any information from the original embeddings space. This ensures that the transformed word embeddings behave differently only when looking at subspaces, but behave identically when looking at the entire space. By choosing an orthogonal and thus linear transformation we also assume that the information is already encoded linearly in the original word embedding. This is a frequent assumption, as we generally use the vector addition for word embeddings.</p><p>Concretely, we learn Q such that the dimensions D p ⊂ {1, . . . , d} of the resulting space correspond to a word's polarity information and the {1, . . . , d} \ D p remaining dimensions correspond to non-polarity information. Analogously, the sets of dimensions D c , D f and D m correspond to a word's concreteness, frequency and POS (or morphological) information, respectively. In this paper, we assume that these properties do not corre- <ref type="figure" target="#fig_3">Figure 1</ref>: Illustration of the transformed embeddings. The horizontal axis is the polarity subspace. All non-polarity information, including concreteness, frequency and POS, is projected into a two dimensional subspace for visualization (gray plane). A query word (bold) specifies a line parallel to the horizontal axis. We then construct a cylinder around this line. Words in this cylinder are considered to be part of the word spectrum.</p><p>late and therefore the ultradense subspaces do not overlap. E.g., D p ∩D c = ∅. This might not be true for other settings, e.g., sentiment and semantic information. As we are using only four properties there is also a subspace which is in the orthogonal complement of all trained subspaces. This subspace includes the not classified information, e.g., genre information in our case (e.g., "clunker" is a colloquial word for "automobile").</p><p>If e v ∈ R d is the original embedding of word v, the transformed representation is u v = Qe v . We use * as a placeholder for polarity (p), concreteness (c), frequency (f ) and POS/morphology (m) and call d * = |D * | the dimensionality of the ultradense subspace of property * . For each ultradense subspace, we create P * ∈ R d * ×d , an identity matrix for the dimensions in D * . Thus, the ultradense (UD) representation u * v ∈ R d * of word v is defined as:</p><formula xml:id="formula_239">u * v := P * Qe v<label>(1)</label></formula><p>For notational simplicity, u * v will either refer to a vector in R d * or to a vector in R d where all dimensions / ∈ D * are set to zero. For training, the orthogonal transformation Q we assume we have a lexicon resource. Let L * ∼ be a set of word index pairs (v, w) with different labels, e.g., positive/negative, concrete/abstract or noun/verb. We want to maximize the distance for pairs in this group. Thus, our objective is:</p><formula xml:id="formula_240">argmin Q * ∈{p,c,f,m} (v,w)∈L * ∼ − P * Q(e v − e w )<label>(2)</label></formula><p>subject to Q being an orthogonal matrix. Another goal is to minimize the distance of two words with identical labels. Let L * ∼ be a set of word index pairs (v, w) with identical labels. In contrast to Eq. 2, we now want to minimize each distance. Thus, the objective is given by:</p><formula xml:id="formula_241">argmin Q * ∈{p,c,f,m} (v,w)∈L * ∼ P * Q(e v −e w )<label>(3)</label></formula><p>subject to Q being an orthogonal matrix. For training Eq. 2 is weighted with α * and Eq. 3 withtrix to the word embeddings gives us four subspaces for polarity, concreteness, frequency and POS. These subspaces and their orthogonal complements are the basis for an embedding calculus that supports certain operations. Here, we investigate four such operations. The first operation computes the antonym of word v:</p><formula xml:id="formula_242">antonym(v) = nn(u v − 2u p v )<label>(4)</label></formula><p>where nn : R d → V returns the word whose embedding is the nearest neighbor to the input. Thus, our hypothesis is that antonyms are usually very similar in semantics except that they differ on a single "semantic axis," the polarity axis. 1 The second operation is "neutral version of word v":</p><formula xml:id="formula_243">neutral(v) = nn(u v − u p v )<label>(5)</label></formula><p>Thus, our hypothesis is that neutral words are words with a value close to zero in the polarity subspace. The third operation produces the polarity spectrum of v:</p><formula xml:id="formula_244">spectrum(v) = {nn(u v + xu p v ) | ∀x ∈ R}<label>(</label></formula><p>6) This means that we keep the semantics of the query word fixed, while walking along the polarity axis, thus retrieving different shades of polarity. <ref type="figure" target="#fig_3">Figure 1</ref> shows two example spectra. The fourth operation is "word v with POS of word w":</p><formula xml:id="formula_245">POS w (v) = nn(u v − u m v + u m w )<label>(7)</label></formula><p>This is similar to analogies like king − man + woman, except that the analogy is inferred by the subspace relevant for the analogy. We create word spectra for some manually chosen words using the Google News corpus (W2V) and a Twitter corpus. As the transformation was orthogonal and therefore did not change the length of a dimension, we multiply the polarity dimension with 30 to give it a high weight, i.e., paying more attention to it. We then use Eq. 6 with a sufficiently small step size for x, i.e., further reducing the step size does not increase the spectrum. We also discard words that have a cosine distance of more than .6 in the non-polarity space. Table 1 shows examples. The results are highly domain dependent, with Twitter's spectrum indicating more negative views of politicians than news. While fall has negative associations, autumn's are positive -probably because autumn is of a higher register in American English.  We evaluate on Adel and Schütze (2014)'s data; the task is to decide for a pair of words whether they are antonyms or synonyms. The set has 2,337 positive and negative pairs each and is split into 80% training, 10% dev and 10% test.  collected positive/negative examples from the nearest neighbors of the word embeddings to make it hard to solve the task using word embeddings. We train an SVM (RBF kernel) on three features that are based on the intuition depicted in <ref type="figure" target="#fig_3">Figure 1</ref>: the three cosine distances in: the polarity subspace; the orthogonal complement; and the entire space.  <ref type="table" target="#tab_6">Table 3</ref>: Results for POS tagging. LSJU = Stanford. SVM = SVMTool. F=FLORS. We show three stateof-the-art taggers (lines 1-3), FLORS extended with 300-dimensional embeddings (4) and extended with UD embeddings (5). †: significantly better than the best result in the same column (α = .05, one-tailed Z-test).</p><p>this dictionary returns a list of up to 80 words of shades of meaning between two polar opposites. We look for words that are also present in Adel and Schütze (2014)'s Antonym Classification data and retrieve 35 spectra. Each word in a spectrum can be used as a query word; after intersecting the spectra with our vocabulary, we end up with 1301 test cases.</p><p>To evaluate PSC-SET, we calculate the 10 nearest neighbors of the m words in the spectrum and rank the 10m neighbors by the distance to our spectrum, i.e., the cosine distance in the orthogonal complement of the polarity subspace. We report mean average precision (MAP) and weighted MAP where each MAP is weighted by the number of words in the spectrum. As shown in <ref type="table" target="#tab_42">Table 4</ref> there is no big difference between both numbers, meaning that our algorithm does not work better or worse on smaller or larger spectra.</p><p>To evaluate PSC-ORD, we calculate Spearman's ρ of the ranks in OAWT and the values on the polarity dimension. Again, there is no significant difference between average and weighted average of ρ. Table 4 also shows that the variance of the measures is low for PSC-SET and high for PSC-ORD; thus, we do well on certain spectra and worse on others. The best one, beautiful ↔ ugly, is given as an example. The worst performing spectrum is fat ↔ skinny (ρ = .13) -presumably because both extremes are negative, contradicting our modeling assumption that spectra go from positive to negative. We test this hypothesis by separating the spectrum into two subspectra. We then report the weighted average correlation of the optimal separation. For fat ↔ skinny, this improves ρ to .67.  The previous two subspaces were onedimensional. Now we consider a POS subspace, because POS is not one-dimensional and cannot be modeled as a single scalar quantity. We create a word analogy benchmark by extracting derivational forms from WordNet <ref type="bibr" target="#b477">(Fellbaum, 1998)</ref>. We discard words with ≥2 derivational forms of the same POS and words not in the most frequent 30,000. We then randomly select 26 pairs for every POS combination for the dev set and 26 pairs for the test set. <ref type="bibr">2</ref> An example of the type of equation we solve here is prediction − predict + symbolize = symbol (from the dev set). W2V embeddings are our baseline. We can also rewrite the left side of the equation as POS(prediction) + Semantics(symbolize); note that this cannot be done using standard word embeddings. In contrast, our method can use meaningful UD embeddings and Eq. 7 with POS(v) being u m v and Semantics(v) being u v − u m v . The dev set indicates that a 8-dimensional POS subspace is optimal and  performs the baseline.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4">POS Tagging</head><p>Our final evaluation is extrinsic. We use FLORS <ref type="bibr" target="#b482">(Schnabel and Schütze, 2014)</ref>, a state-of-the-art POS tagger which was extended by  with word embeddings as additional features. W2V gives us a consistent improvement on OOVs <ref type="table" target="#tab_6">(Table 3</ref>, line 4). However, training this model requires about 500GB of RAM. When we use the 8-dimensional UD embeddings (the same as for Morphological Analogy), we outperform W2V except for a virtual tie on news <ref type="table" target="#tab_6">(Table 3</ref>, line 5). So we perform better even though we only use 8 of 300 dimensions! However, the greatest advantage of UD is that we only need 100GB of RAM, 80% less than W2V.</p><p>5 Related Work <ref type="bibr" target="#b487">Yih et al. (2012)</ref> also tackled the problem of antonyms having similar embeddings. In their model, the antonym is the inverse of the entire vector whereas in our work the antonym is only the inverse in an ultradense subspace. Our model is more intuitive since antonyms invert only part of the meaning, not the entire meaning.  present a method that switches an antonym parameter on or off (depending on whether a high antonym-synonym similarity is useful for an application) and learn multiple embedding spaces. We only need a single space, but consider different subspaces of this space. An unsupervised approach using linguistic patterns that ranks adjectives according to their intensity was presented by de <ref type="bibr" target="#b476">Melo and Bansal (2013)</ref>.  present a corpus-independent approach for the same problem. Our results (Table 1) suggest that polarity should not be considered to be corpus-independent.</p><p>There is also much work on incorporating the additional information into the original word embedding training. Examples include  and <ref type="bibr" target="#b475">(Cotterell and Schütze, 2015)</ref>. However, postprocessing has several advantages. DENSIFIER can be trained on a normal work station without access to the original training corpus. This makes the method more flexible, e.g., when new training data or desired properties are available.</p><p>On a general level, our method bears some resemblance with <ref type="bibr" target="#b485">(Weinberger and Saul, 2009</ref>) in that we perform supervised learning on a set of desired (dis)similarities and that we can think of our method as learning specialized metrics for particular subtypes of linguistic information or particular tasks. Using the method of Weinberger and Saul (2009), one could learn k metrics for k subtypes of information and then simply represent a word w as the concatenation of (i) the original embedding and (ii) k representations corresponding to the k metrics. <ref type="bibr" target="#b471">3</ref> In case of a simple one-dimensional type of information, the corresponding representation could simply be a scalar. We would expect this approach to have similar advantages for practical applications, but we view our orthogonal transformation of the original space as more elegant and it gives rise to a more compact representation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Conclusion</head><p>We presented a new word embedding calculus based on meaningful ultradense subspaces. We applied the operations of the calculus to Antonym Classification, Polarity Spectrum Creation, Morphological Analogy and POS Tagging. Our evaluation shows that our method outperforms previous work and is applicable to different types of information. We have published test sets and word embeddings at http://www.cis.lmu. de/˜sascha/Ultradense/. BOW The English sentence from <ref type="figure" target="#fig_3">Fig. 1</ref> is used as the running example for all context types. Given the target word w and the window size k, the BOW context simply comprises all 2k word pairs (w, v), where v is found in the window of k words preceding w or k words following w, e.g., BOW with k = 2 extracts the following contexts v for the word discovers from <ref type="figure" target="#fig_3">Fig. 1</ref>: Australian, scientist, stars, with. Note that BOW may miss valid longer-range contexts (e.g., telescope) while including some accidental (e.g., Australian) or uninformative ones (e.g., with).</p><p>POSIT A more informed variant of BOW is positional contexts. It includes extra information on the actual sequential position of each context word . Given the same example, POSIT with k = 2 extracts the following contexts for discovers: Australian_-2, scientist_-1, stars_+2, with_+1. This context type has not been studied systematically in relation to learning WEs. POSIT suffers from the same issues with locality as BOW, but its shallow positional annotations may capture additional shallow syntactic phenomena in the data. Therefore, POSIT may be considered a link from BOW towards DEPS. <ref type="bibr" target="#b471">3</ref> UDEPS-NAIVE Given a corpus of parsed sentences, for each target w with modifiers m 1 , . . . , m k and head h, w is paired with context elements m 1 _r 1 , . . . , m k _r k , h_r</p><formula xml:id="formula_246">−1</formula><p>h , where r is the type of the UD relation between the head and the modifier (e.g., amod), and r −1 denotes an inverse relation. A naive version of the UD-based model extracts contexts from the parsed corpus without any post-processing. The UDEPS-NAIVE contexts of discovers are now: scientist_nsubj, stars_dobj, telescope_nmod. They capture longerrange relations (e.g., telescope) and filter "accidental contexts" (e.g., Australian). In addition, the typed dependencies reveal more than POSIT and BOW about the nature of the relation in context. UDEPS-ARC However, UDEPS-NAIVE also produces uninformative context pairs such as (telescope, with_case), and it does not specify the type of e.g. the nmod relation between discovers and telescope which are linked through the preposition with. Our intuition is that a simple post-hoc intervention into the UDEPS context extraction may yield even more focused contexts. UDEPS-ARC leans on the idea of arc collapsing from prior work <ref type="bibr" target="#b512">Melamud et al., 2016)</ref> that we now adjust to the UD annotation scheme. The difference to UDEPS-NAIVE is as follows: For each pair of words linked through case (e.g., discovers and telescope), we introduce a new "pseudo-arc" which is typed by the actual case/preposition. This results in a new context for discovers: telescope_case_with and also for telescope: discovers_case_with −1 <ref type="figure" target="#fig_3">(Fig. 1)</ref>. In addition, we remove the uninformative case arc and its associated contexts: (with, telescope_case −1 ), (telescope, with_case) from the training pairs.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Experimental Setup</head><p>Evaluation Our cross-linguistic study is made possible not only thanks to the "universal NLP" initiative but also owing to the benchmarking evaluation sets for other languages beyond English (i.e., IT, DE) that have very recently become available, e.g., <ref type="bibr" target="#b504">(Leviant and Reichart, 2015)</ref>. We evaluate SGNS with different context types from sect. 2.1 across the three languages on two benchmarking tasks and datasets: (1) semantic similarity on SimLex-999  translated and re-scored by native speakers in EN, DE, and IT <ref type="bibr" target="#b504">(Leviant and Reichart, 2015)</ref>, and (2) word analogies on the Google dataset  made available in IT <ref type="bibr" target="#b493">(Berardi et al., 2015)</ref> and DE <ref type="bibr" target="#b503">(Köper et al., 2015)</ref> only recently. UPOS Tagging and UD Parsing The Wikipedia corpora were UPOS-tagged using a state-of-the art system TurboTagger . <ref type="bibr">5</ref> TurboTagger was trained using suggested settings without any further parameter fine-tuning (SVM MIRA with 20 iterations) on the TRAIN+DEV portion of the UD treebank annotated with UPOS tags. Following that, the Wikipedia data were UD-parsed 6 using the graph-based Mate parser v3.61 <ref type="bibr" target="#b495">(Bohnet, 2010)</ref>  <ref type="bibr">7</ref> and the same regime: suggested settings on the TRAIN+DEV UD treebank portion. <ref type="bibr">8</ref> The performance of the models measured on the TEST portion of the UD treebanks is reported in Tab. 1.    .</p><p>The results are consistent with prior work on the UD treebanks, e.g., <ref type="bibr" target="#b520">(Tiedemann, 2015)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Training Setup</head><p>The SGNS preprocessing scheme for English was replicated from ) and extended to the other two languages: all tokens were converted to lowercase, and words and contexts that appeared less than 100 times were filtered. Exactly the same vocabularies were used with all context types (approx. 185K distinct EN words, 163K DE words, and 83K IT words). The word2vecf SGNS was trained using standard settings: 15 epochs, 15 negative samples, global learning rate 0.025, subsampling rate 1e − 4. All WEs were trained with d = 50, 100, 300, 500, 600. BOW-based WEs were trained with k = 2 (BOW-2), proven to be the (near-)optimal choice across various semantic tasks in related work <ref type="bibr" target="#b512">Melamud et al., 2016)</ref>. The same k was used for POSIT-based WEs (POSIT-2). SimLex pairs, and 0.378 on verb pairs. 9 A comparison with UDEPS-ARC reveals only a slight drop in performance when switching to languageagnostic UDEPS (see <ref type="figure" target="#fig_3">Fig. 2(a), Q1)</ref>. <ref type="bibr">10</ref> However, the results are heavily dependent on the actual language: the claims made for English (i.e., DEPS ≥ BOW) do not extend to other languages (Q2). A comparison of results from Tab. 1 with the task evaluation also shows that excellent tagging and parsing results do not guarantee a strong task performance.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Results and Discussion</head><p>The results over the verb subset of SimLex also reveal that claims established with English are not necessarily general and true with other languages. For instance, while it has been noted that modeling verb similarity is indeed a difficult problem in English as evidenced by lower correlation scores on SimLex (see <ref type="figure" target="#fig_8">Fig. 2(a)</ref> and e.g. ), verbs are apparently easier to model in Italian <ref type="figure" target="#fig_8">(Fig. 2(c)</ref>  <ref type="table" target="#tab_6">Table 3</ref>: Rankings based on Acc 1 scores over syntactic analogy groups (from the Google dataset). A=UDEPS-ARC, N =UDEPS-NAIVE, B=BOW-2, P =POSIT-2. d = 300.</p><p>with extremely low correlation scores <ref type="figure" target="#fig_8">(Fig. 2(b)</ref>).</p><p>The results on the analogy task from Tab. 2 suggest the evident advantage of more abundant (but less informed) BOW contexts across all languages. This finding is completely in line with the analyses from prior work on English, e.g.,  report that "DEPS perform dramatically worse than BOW contexts on analogy tasks", but without providing any exact numbers.</p><p>Nonetheless, the relative ranking of context types over syntactic analogy sets as highlighted in Tab. 3 marks the evident advantage of the moreinformed POSIT and UDEPS-ARC on analogies referring to functional similarity. UDEPS-ARC in German outperforms all other context types on all syntactic analogies, except for the nationalityadjective relation. The strongest performance of UDEPS is detected with syntactic analogies where two words in the analogy pair are perfectly replaceable in the given context (e.g., past-tense: dancing-danced, sleeping-slept or opposite: sureunsure, honest-dishonest).</p><p>We can also see that POSIT displays a strong performance in detecting functional similarity across all three languages in both tasks (e.g., see the results in Tab. 3 where they outperform BOW). This finding reveals that POSIT should be included as a strong baseline in any follow-up work.</p><p>We also analysed the influence of the training data size by learning EN WEs from the EN Wikipedia comprising roughly 13M sentences (same size as the IT Wikipedia). As Tab. 4 shows, the absolute scores are naturally lower with less training data, and we observe a decrease in the performance of UDEPS. However, the decrease is small: these results demonstrate that the reduced performance of UDEPS in IT and DE cannot be attributed solely to smaller training datasets and sparsity of (word, context) pairs.</p><p>Finally, the consistent improvements of  UDEPS-ARC over UDEPS-NAIVE for all three languages on both tasks show the importance of a careful post-hoc selection of informative contexts. Future work will delve deeper into the informative context selection for the WE learning.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Conclusion and Future Work</head><p>We have presented the first comparison of different context types for learning word embeddings for multiple languages. Dependency-based contexts in different languages are for the first time extracted from "universal" parses made possible by the Universal Dependencies initiative, without any language-specific optimisation.</p><p>In sum, our comparison provides no clear answer to the question posed by the title of this paper. However, it shows conclusively that different context types yield semantic spaces with different properties, and that the optimal context type depends on the actual application and language. The usefulness of universal dependency-based contexts is evident with a simple post-parsing context extraction scheme in tasks oriented towards syntactic/functional similarity.</p><p>This first cross-linguistic analysis covering only a small set of languages from the same (IndoEuropean) phylum also reveals that training word embeddings in languages other than English is not trivial, suggesting Anglo-centric assumptions that do not extend to other languages <ref type="bibr" target="#b492">(Bender, 2011)</ref>. It is therefore essential not to generalise results on English to other languages without clear empirical evidence. Yet, a broader cross-linguistic study involving more languages from other families (with UD treebanks available) and additional experimentation is warranted in order to better guide research on "universal NLP" and languageindependent word representation learning.</p><p>The Selection Component uses a logistic regression classifier to first predict which of the candidate claims generated by the Generation Component are valid, and then to rank the valid candidates according to the classifier's score. It receives two parameters, κ and τ . If the fraction of valid candidates (according to the classifier) is less than τ , then it selects none of them. This is designed to allow the algorithm not to synthesize claims for topics where the PL does not seem to yield a substantial number of valid claims. If the number of valid candidates is at least τ , the top κ valid candidates are returned (or all of them, if there are less than κ).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Classification Features</head><p>To describe the classification features used, we need to define -given a topic -the topic's n-gram Lexicon (n-TL). This is a list of n-grams which are presumably related to the topic. Specifically, given an n-gram, we assume its appearance in Wikipedia articles follows a hyper-geometric distribution, and estimate the distribution's parameters by counting the n-gram's appearance in a large set of Wikipedia articles. With these parameters, the p-value for its appearances in topic-related articles is calculated. The n-TL is the list of n-grams with Bonferroni-corrected p-value at most 0.05. The topic-related articles were identified manually (see ).</p><p>For a candidate claim c, denote its words by w 1 , . . . , w m . Recall that c is composed of the given topic, t, and a predicate p ∈ P L. Recall also that p was extracted from a manually-detected claim c p . Denote by t p the topic for which c p was detected, and by s p the subject of the claim sentence c p . Denote by m t the number of words in t.</p><p>For example, consider the second candidate claim in <ref type="table" target="#tab_10">Table 1</ref>, c = Truth and reconciliation commissions are a source of conflict. There t = truth and reconciliation commissions and p = are a source of conflict. p was extracted from the claim c p = religion is a source of conflict in the labeled data, which is associated with the topic atheism (and the debatabase motion atheism is the only way). Hence, t p = atheism and s p = religion.</p><p>The classification features we used are of three types: One aims to identify predicates which are inherently amenable to generation of claims, that http://www.ncbi.nlm.nih.gov/books/NBK9680/ is, which state something fairly general about their subject, and which are not very specific to the topic in which the predicate was originally found (e.g., low sim(p, t p )). The second aims to find predicates which are relevant for the new topic for which claims are synthesized (e.g., high sim(p,n-TL)). Finally, we'd like the claim to be a valid and plausible sentence, and so look for the frequency of its words, and sub-phrases of it, in Wikipedia.</p><p>All in all 15 features were defined: m, the number of words in c; Number of Lucene hits for w 1 , . . . , w m (as a bag of words); Number of Wikipedia sentences containing all w 1 , . . . , w m ; Largest k, such that the k-gram w 1 . . . w k appears in Wikipedia; Number of times the 3-gram w mt w mt+1 w mt+2 appears in Wikipedia; Number of times p appears in a claim candidate labeled positive, and the number of times in one labeled negative (claim candidates generated for t are excluded, see Section 3 for labeling details); Inclusion of p's verb in a manually-crafted list of "causation verbs"; sim(p,n-TL) , for n = 1, 2, 3; sim(p, t); sim(p, t p ); sim(s p , t p ); sim(s p , t).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Experimental Setup</head><p>We generated claims for 67 topics, extracted from debatabase motions (http://idebate.org) for which we have previously annotated relevant Wikipedia articles (for the benefit of the n-TLs construction; see Section 2.1). Importantly, when generating candidate claims for a topic, predicates which originated from this topic were not used.</p><p>For each topic 28 candidate claims were generated, and in addition one manually-detected claim (as per ) and one mock claim were included for control. The mock claim was constructed by setting the topic as the subject of a sentence, and selecting a mock predicate at random from a hand-crafted list.</p><p>These 67 × 30 candidate claims were annotated using Amazon's Mechanical Turk (AMT). In each HIT (Human Intelligence Task) we presented the annotators with a debatabase motion and 10 candidate claims, and asked which of the claims is appropriate for the motion (10 annotators per HIT).</p><p>After filtering out the less reliable annotators based on mutual agreement and control questions, a reasonable agreement was apparent (average κ = 0.73). After this filtering 45 of the initial 82 annotators remained, as well as 955 of the initial 2010 annotated candidate claims (discard-</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Claim</head><p>Original Subject Label Democratization contributes to stability.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Nuclear weapons 1</head><p>Truth and reconciliation commissions are a source of conflict.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Religion 1</head><p>Graduated response lacks moral legitimacy.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>The State 1</head><p>Nuclear weapons cause lung cancer.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Smoking 0</head><p>A global language leads to great exhaustion.</p><p>Great anarchy 0 ing claims with less than 5 valid annotators, those without a clear majority decision, as well as the control claims). See <ref type="table" target="#tab_10">Table 1</ref> for some examples. We note that annotation tasks like this are inherently subjective  report κ = 0.4), so discarding candidates without a clear majority decision can be seen as discarding those for which the true label is not well defined. Nonetheless, the reason for discarding most of the candidate claims was annotator's (lack of) reliability, not ambiguity of the true label.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Experimental Results</head><p>Initially we thought to label a candidate claim as either positive or negative examples, based on the majority vote of the annotators. This lead to a seemingly 52% of the candidates being "good". However, anecdotal examination of this majority labeling suggested that the many annotators were biased toward answering "good" -even on some of the control questions which contained nonsensical sentences. This, along side relatively low mean agreement, raised the need for filtering mentioned above. After filtering, 40% of the candidate claims were taken to be positive examples. The accuracy of the Selection Component was assessed using a leave-one-out methodology, leaving out one topic at each iteration. The overall accuracy achieved by the classifier was 0.75 <ref type="table" target="#tab_5">(Table 2</ref> depicts the confusion matrix).</p><p>We also examined the trade-off between the number of selected candidate claims and the fraction of them which are valid. <ref type="figure" target="#fig_3">Figure 1</ref>   . average precision when varying the two Selection Component parameters, κ and τ . For example, at the most conservative setting, where the component outputs at most one claim per topic, and only for a topic for which at least half the candidate claims were predicted to be valid (31 of the 67 topics), the precision is 0.94. Recall that in the entire dataset, 40% of the examples are positive. We note that this precision is significantly higher than reported for claim detection , where, for example, mean precision at 5 is 0.28 (in our case it is 0.7 − 0.8). One should note, however, that this is not a fair comparison. First, we permit the algorithm to discard some topics. Second, here the definition of a valid claim is less strict than in .</p><p>Examining the impact of individual features, we first looked which of them, on their own, are most correlated with the labels. These turned out to be the number of times p appears in a claim candidate labeled positive and negative (Pearson's correlation 0.33 and -0.34 resp.). We then examined which features received the most weight in the logistic regression classifier (trained over all data; features were scaled to a [0, 1]). The top feature was the number of sentences in which all words appear, and following it were the aforementioned appearance counts in negative and positive examples.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Discussion and Work in Progress</head><p>The Generation Component can be thought of as constructing sentences by using pre-defined templates, of the form "&lt;topic-slot&gt; &lt;extracted predicate&gt;". These "generation templates" are created by "mining" a corpus of manuallydetected claims and extracting the predicate from them. They are then filled in during run-time, by inserting a new topic in that slot. There are several ways which we have started exploring to extend this paradigm -automatically identifying the grammatical position of a"topic slot" in a corpus claim rather than assuming it is the subject; using unsupervised methods for mining the predicates directly from Wikipedia; and generating candidate claims by using several variants for the subject and object, rather than just the topic and the PL entry. Initial results are promising, but more work is required to achieve reasonable accuracy.</p><p>Another interesting alternative is to construct the PL manually, rather than automatically. This can be seen as analogous to Argumentation Schemes <ref type="bibr" target="#b540">(Walton et. al, 2008)</ref>. Argumentation Schemes can be thought of as templates for modeling arguments -defining a slot for a premise or two (which may be implicit), a slot for a conclusion or claim, and some fixed connecting text. While Argumentation Schemes are used for detecting <ref type="bibr" target="#b539">(Walton, 2012)</ref> and analyzing argumentative structures, in principle they can also be used to synthesize them. In this sense, our work here can be seen as applying the same concept at finer granularityat the claim level instead of the argument.</p><p>While at the onset we presented claim synthesis as an alternative to argumentation mining for the purpose of generating arguments, it is interesting how the two augment each other. Specifically, we have started looking at whether claim synthesis can generate claims which do not appear in our corpus , and whether matching Evidence to claims <ref type="bibr" target="#b537">(Rinott et. al, 2015)</ref> can improve claim synthesis. Regarding the novelty of synthesized claims, we looked at 18 synthesized claims, labeled as valid for 3 topics -criminalization of blasphemy, building high-rise for housing and making physical education compulsory -and compared them to the 94 manually detected claims for these topics (each topic separately). Of the 18 claims, 5 appear to be novel.</p><p>A more circumvent method to assess novelty is as follows -for each candidate claim we looked for the most similar claim (for the same topic) in our annotated data. We then computed Pearson's correlation between these similarity scores and the labels of the candidate claim, getting a coefficient of 0.29 <ref type="bibr">(p-value=10 −27</ref> ). This is similar to the correlation between for the strongest classification features, suggesting again that many of the generated claims are not novel, yet similarity to annotated claims on its own is not enough to determine a candidate-claim's validity.</p><p>Similarly, we examined whether having a matching evidence in the annotated corpus (matches were determined using the algorithm of <ref type="bibr" target="#b537">(Rinott et. al, 2015)</ref>), is indicative of a candidateclaim's validity. Computing correlation (over the 51 topic for which annotated evidence was available) gave a Pearson's coefficient of 0.23. This suggests that matching Evidence can be a powerful feature in improving our current classification model.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>A growing body of evidence shows that human interpretation and production of natural language are inter-related <ref type="bibr" target="#b561">Pickering and Garrod, 2007;</ref><ref type="bibr" target="#b569">Zeevat, 2011;</ref><ref type="bibr" target="#b570">Zeevat, 2015)</ref>. In particular, evidence shows that during interpretation, listeners simulate how the utterance is produced; and during language production, speakers simulate how the utterance will be perceived. One explanation is that the human brain reasons by Bayesian inference <ref type="bibr" target="#b545">(Doya, 2007;</ref><ref type="bibr" target="#b553">Kilner et al., 2007)</ref>, which is, at the same time, a popular formulation used in language technology.</p><p>In this work, we model how humans interpret the sense of a discourse relation based on the Bayesian pragmatic framework. Discourse relations are relations between units of texts that make a document coherent. These relations are either marked by discourse connectives (DCs), such as 'but', 'as a result', or implied implicitly, as in the following examples:</p><p>1. He came late. In fact, he came at noon.</p><p>2. It is late. I will go to bed.</p><p>The explicit DC 'in fact' in Example (1) marks a Specification relation. On the other hand, a Result relation can be inferred between the two sentences in Example (2) although there are not any explicit markers. We say the two sentences (called arguments) are connected by an implicit DC.</p><p>Discourse relations have a mixture of semantic and pragmatic properties <ref type="bibr" target="#b566">(Van Dijk, 1980;</ref><ref type="bibr" target="#b556">Lewis, 2006)</ref>. For example, the sense of a discourse relation is encoded in the semantics of a DC (Example <ref type="formula" target="#formula_0">(1)</ref>), yet the interpretation of polysemic DCs (such as 'since', 'as') and implicit DCs relies on the pragmatic context (Example (2)).</p><p>This work seeks to find out if Bayesian pragmatic approaches are applicable to human comprehension of discourse relations. Our contribution includes: (i) an adaptation of the Bayesian Rational Speech Acts model to DC interpretation using a discourse-annotated corpus, the Penn Discourse Treebank; (ii) integration of the proposed model with a state-of-the-art automatic discourse parser to improve discourse sense classification.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Related work</head><p>There is increasing literature arguing that the human motor control and sensory systems make estimations based on a Bayesian perspective <ref type="bibr" target="#b545">(Doya, 2007;</ref><ref type="bibr" target="#b559">Oaksford and Chater, 2009</ref>). For example, it is proposed that the brain's mirror neuron system recognizes a perceptual input by Bayesian inference <ref type="bibr" target="#b553">(Kilner et al., 2007)</ref>. Similarly, behavioural, physiological and neurocognitive evidences support that the human brain reasons about the uncertainty in natural languages comprehension by emulating the language production processes <ref type="bibr" target="#b547">(Galantucci et al., 2006;</ref><ref type="bibr" target="#b562">Pickering and Garrod, 2013)</ref>.</p><p>Analogous to this principle of Bayesian language perception, a series of studies have developed the Grice's Maxims (Grice, 1975) based on game-theoretic approaches <ref type="bibr" target="#b551">(Jäger, 2012;</ref><ref type="bibr" target="#b546">Frank and Goodman, 2012;</ref><ref type="bibr" target="#b549">Goodman and Stuhlmüller, 2013;</ref><ref type="bibr" target="#b548">Goodman and Lassiter, 2014;</ref><ref type="bibr" target="#b542">Benz et al., 2016)</ref>. These proposals argue that the speaker and the listener cooperate in a conversation by recursively inferring the reasoning of each other in a Bayesian manner. The proposed framework successfully explains existing psycholinguistic theories and predict experimental results at various linguistic levels, such as the perception of scalar implicatures (e.g. 'some' meaning 'not all' in pragmatic usage) and the production of referring expressions <ref type="bibr" target="#b554">(Lassiter and Goodman, 2013;</ref><ref type="bibr" target="#b552">Kao et al., 2014;</ref><ref type="bibr" target="#b555">Lassiter and Goodman, 2015)</ref>. Recent efforts also acquire and evaluate the models using corpus data <ref type="bibr" target="#b560">(Orita et al., 2015;</ref><ref type="bibr" target="#b558">Monroe and Potts, 2015)</ref>.</p><p>Production and interpretation of discourse relations is also a kind of cooperative communication between speakers and listeners (or authors and readers). We hypothesize that the game-theoretic account of Bayesian pragmatics also applies to human comprehension of the meaning of a DC, which can be ambiguous or even dropped.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Method</head><p>This section explains how we model the interpretation of discourse relations by Bayesian pragmatics. The model is based on the formal framework known as Rational Speech Acts model <ref type="bibr" target="#b546">(Frank and Goodman, 2012;</ref><ref type="bibr" target="#b555">Lassiter and Goodman, 2015)</ref>. Section 3.1 explains the key elements of the RSA model, and Section 3.2 illustrates how it is adapted for discourse interpretation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">The Rational Speech Acts model</head><p>The Rational Speech Acts (RSA) model describes the speaker and listener as rational agents who cooperate towards efficient communication. It is composed of a speaker model and a listener model. In the speaker model, the utility function U defines the effectiveness for the speaker to use utterance d to express the meaning s in context C.</p><formula xml:id="formula_247">U (d; s, C) = ln P L (s|d, C) − cost(u)<label>(1)</label></formula><p>P L (s|d, C) is the probability that the listener can interpret speaker's intended meaning s. The speaker selects an utterance which, s/he thinks, is informative to the listener. The utility of d is thus defined by its informativeness towards the intended interpretation, which is quantified by negative surprisal (ln P L (s|d, C)), according to Information Theory <ref type="bibr" target="#b565">(Shannon, 1948)</ref>. The utility is modified by production cost (cost(d)), which is related to articulation and retrieval difficulties, etc.</p><p>P S (d|s, C) is the probability for the speaker to use utterance d for meaning s. It is proportional to the soft-max of the utility of d.</p><formula xml:id="formula_248">P S (d|s, C) ∝ exp(α · U (d; s, C))<label>(2)</label></formula><p>where α, the decision noise parameter, is set to 1.</p><p>On the other hand, the probability for the listener to infer meaning s from utterance d is defined by Bayes' rule.</p><formula xml:id="formula_249">P L (s|d, C) ∝ P S (d|s, C)P L (s)<label>(3)</label></formula><p>The listener infers the speaker's intended meaning by considering how likely, s/he thinks, the speaker uses that utterance (P S (d|s, C)). The inference is also related to the salience of the meaning (P L (s)), a private preference of the listener.</p><p>To summarize, the speaker and listener emulate the language processing of each other. However, instead of unlimitted iterations (i.e. the speaker thinks the listener thinks the speaker thinks..), the inference is grounded on literal interpretation of the utterance. <ref type="figure" target="#fig_3">Figure 1</ref> illustrates the direction of pragmatic inference between the speaker and listener in their minds. Our experiment compares the predictions of the literal listener (L 0 ), the pragmatic listener who reasons for one level (L 1 ), and the pragmatic listener who reasons for two levels (L 2 ). Previous works demonstrate that one level of reasoning is robust in modeling human's interpretation of scalar implicatures <ref type="bibr" target="#b554">(Lassiter and Goodman, 2013;</ref><ref type="bibr" target="#b549">Goodman and Stuhlmüller, 2013</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Applying the RSA model on discourse relation interpretation</head><p>We use the listener model of RSA to model how listeners interpret the sense a DC. Given the DC d and context C in a text, the listener's interpreted relation sense s i is the sense that maximizes P L (s|d, C). s i is specifically defined as</p><formula xml:id="formula_250">s i = arg max s∈S P L (s|d, C)<label>(4)</label></formula><p>where S is the set of defined relation senses. The literal listener, L 0 , interprets a DC directly by its most likely sense in the context. The probability is estimated by counting the co-occurrences in corpus data, the Penn Discourse Treebank, in which explicit and implicit DCs are labelled with discourse relation senses.</p><formula xml:id="formula_251">P L 0 (s|d, C) = count(s, d, C) count(d, C)<label>(5)</label></formula><p>More details about the annotation of PDTB will be explained in Section 4.1. As shown in <ref type="figure" target="#fig_3">Figure 1</ref>, the pragmatic speaker S 1 estimates the utility of a DC by emulating the comprehension of the literal listener L 0 (Eq. 1, 2). The probability for the pragmatic speaker S n to use DC d to express meaning s is estimated as:</p><formula xml:id="formula_252">P Sn (d|s, C) = exp(ln P L n−1 (s|d, C) − cost(d)) d ∈D exp(ln P L n−1 (s|d , C) − cost(d ))<label>(6)</label></formula><p>where n ≥ 1. D is the set of annotated DCs, including 'null', which stands for an implicit DC. The cost function in Equation 6, cost(d), measures the production effort of the DC. As DCs are mostly short words, we simply define the cost of producing any explicit DC by a constant positive value, which is tuned manually in the experiments. On the other hand, the production cost for an implicit DC is 0, since no word is produced .</p><p>In turn, the pragmatic listener L 1 emulates the DC production of the pragmatic speaker S 1 (Eq.</p><p>3). The probability for the pragmatic listener L n to assign meaning s to DC d is estimated as:</p><formula xml:id="formula_253">P Ln (s|d, C) = P Sn (d|s, C)P L (s) s ∈S P Sn (d|s , C)P L (s ) (7)</formula><p>where n ≥ 1 and S is the set of defined sense. The salience of a relation sense in Equation 7, P L (s), is defined by the frequency of the sense in the corpus.</p><formula xml:id="formula_254">P L (s) = count(s) s ∈S count(s )<label>(8)</label></formula><p>Lastly, we propose to define the context variable C by the the immediately previous discourse relation to resemble incremental processing. We hypothesize that certain patterns of relation transitions are more expected and predictable. Discourse context in terms of relation sense, relation form (explicit DC or not), and the sense-form pair are compared in the experiments.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Experiment</head><p>This section describes experiments that evaluate the model against discourse-annotated corpus. We seek to answer the following questions: (1) Can the proposed model explain the sense interpretation (annotation) of the DCs in the corpus? (2) Is the DC interpretation refined by the context in terms of previous discourse structure? (3) Does the proposed model help automatic discourse parsing? We first briefly introduce the corpus resource we use, the Penn Discourse Treebank.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Penn Discourse Treebank</head><p>The Penn Discourse Treebank (PDTB)  is the largest available discourseannotated resource in English. The raw text are collected from news articles of the Wall Street Journals. On the PDTB, all explicit DCs are annotated with discourse senses, while implicit discourse senses are annotated between two adjacent sentences. Other forms of discourse relations, such as 'entity relations', are also labeled. In total, there are 5 form labels and 42 distinct sense labels, some of which only occur very sparsely.</p><p>We thus use a simplified version of the annotation, which has 2 form labels (Explicit and Nonexplicit DC) and 15 sense labels (first column of <ref type="table" target="#tab_6">Table 3</ref>), following the mapping convention of the CONLL shallow discourse parsing shared task <ref type="bibr" target="#b568">(Xue et al., 2015)</ref>. Sections 2-22 are used as the training set and the rest of the corpus, Sections 0, 1, 23 and 24, are combined as the test set. Sizes of the data sets are summarized in <ref type="table" target="#tab_10">Table 1</ref>  The RSA model argues that a rational listener does not just stick to the literal meaning of an utterance. S/he should reason about how likely the speaker will use that utterance, in the current context, based on the informativeness and production effort of the utterance. If the RSA model explains DC interpretation as well, discourse sense predictions made by the pragmatic listeners should outperform predictions by the literal listener.</p><p>In this experiment, we compare the DC interpretation by the literal listener L 0 , and pragmatic listeners L 1 and L 2 . Given a DC d and the discourse context C for each test instance, the relation sense is deduced by maximizing the probability estimate P L (s|d, C). P L 0 (s|d, C) is simply based on co-occurrences in the training data (Eq. 5). P L 1 (s|d, C) and P L 2 (s|d, C) are calculated by Eq. 6 and 7, in which the salience of each sense is also extracted from the training data (Eq. 8).  <ref type="table" target="#tab_5">Table 2</ref> shows the accuracy of discourse sense prediction by listeners L 0 , L 1 and L 2 , when provided with various discourse contexts. Predictions by L 1 , when they are differ from the predictions by L 0 under 'constant' context, are more accurate than expected by chance. This provides support that the RSA framework models DC interpretation. Overall, predictions of non-implicit senses hardly differ among different models, since an implicit DC is much less informative than an explicit DC. Moreover, previous relation senses or forms do not improve the accuracy, suggesting that a more generalized formulation of contextual information is required to refine discourse understanding. It is also observed that predictions by L 2 are mostly the same as L 1 . This implies that the listener is unlikely to emulate speaker's production iteratively at deeper levels.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Insights on automatic discourse parsing</head><p>Next, we investigate if the proposed method helps automatic discourse sense classification. A full discourse parser typically consists of a pipeline of classifiers: explicit and implicit DCs are first classified and then processed separately by 2 classifiers <ref type="bibr" target="#b568">(Xue et al., 2015)</ref>. On the contrary, the pragmatic listener of the RSA model considers if the speaker would prefer a particular DC, explicit or implicit, when expressing the intended sense.</p><p>In this experiment, we integrate the output of an automatic discourse parser with the probability prediction by the pragmatic listener L 1 . We employ the winning parser of the CONLL shared task <ref type="bibr" target="#b567">(Wang and Lan, 2015)</ref>. The parser is also trained on Sections 2-22 of PDTB, and thus does not overlap with our test set. The sense classification of the parser is based on a pool of lexicosyntactic features drawn from gold standard arguments, DCs and automatic parsed trees produced by CoreNLP .</p><p>For each test sample, the parser outputs a probability estimate for each sense. We use these estimates to replace the salience measure (P L (s)) (in Eq. 8) and deduce P L 1 (s|d, C), where C is the previous relation form. P L 1 (s|d, C) = P S 1 (d|s, C)P parser (s)</p><p>s ∈S P S 1 (d|s , C)P parser (s ) (9)  Significant improvement in classification accuracy is achieved and the F1 scores for most senses are improved. This confirms the applicational potential of our model on automatic discourse parsing.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Conclusion</head><p>We propose a new framework to model the interpretation of discourse relations based on Bayesian pragmatics. Experimental results support the applicability of the model on human DC comprehension and automatic discourse parsing. As future work, we plan to deduce a more general abstraction of the context governing DC interpretation. A larger picture is to design a full, incremental discourse parsing algorithm that is motivated by the psycholinguistic reality of human discourse processing.</p><p>log-normal and vMF as hyper-prior distributions for the concentrations (κ k ) and centers of the topics (µ k ) respectively. <ref type="figure" target="#fig_3">Figure 1</ref> provides a graphical illustration of the model.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Stochastic variational inference</head><p>In the rest of the paper, we use bold symbols to denote the variables of the same kind (e.g., x d = {x dn } n , z := {z dn } d,n ). We employ stochastic variational mean-field inference (SVI) <ref type="bibr" target="#b580">(Hoffman et al., 2013)</ref> to estimate the posterior distributions of the latent variables. SVI enables us to sequentially process batches of documents which makes it appropriate in large-scale settings.</p><p>To approximate the posterior distribution of the latent variables, the mean-field approach finds the optimal parameters of the fully factorizable q (i.e., q(z, β, π, µ, κ) := q(z)q(β)q(π)q(µ)q(κ)) by maximizing the Evidence Lower Bound (ELBO),</p><formula xml:id="formula_255">L(q) = E q [log p(X, z, β, π, µ, κ)] − E q [log q]</formula><p>where E q [·] is expectation with respect to q, p(X, z, β, π, µ, κ) is the joint likelihood of the model specified by the HDP model.</p><p>The variational distributions for z, π, µ have the following parametric forms, q(z) = Mult(z|ϕ) q(π) = Dir(π|θ) q(µ) = vMF(µ|ψ, λ), where Dir denotes the Dirichlet distribution and ϕ, θ, ψ and λ are the parameters we need to optimize the ELBO. Similar to <ref type="bibr" target="#b575">(Bryant and Sudderth, 2012)</ref>, we view β as a parameter; hence, q(β) = δ β * (β). The prior distribution κ does not follow a conjugate distribution; hence, its posterior does not have a closed-form. Since κ is only one dimensional variable, we use importance sampling to approximate its posterior. For a batch size of one (i.e., processing one document at time), the update equations for the parameters are:</p><formula xml:id="formula_256">ϕ dwk ∝ exp{E q [log vMF(x dw |ψ k , λ k )] + E q [log π dk ]} θ dk ← (1 − ρ)θ dk + ρ(αβ k + D W n=1 ω wj ϕ dwk ) t ← (1 − ρ)t + ρs(x d , ϕ dk ) ψ ← t/ t 2 , λ ← t 2</formula><p>where D, ω wj , W , ρ are the total number of documents, number of word w in document j, the total number of words in the dictionary, and the step size, respectively. t is a natural parameter for vMF and s(x d , ϕ dk ) is a function computing the sufficient statistics of vMF distribution of the topic k. We use numerical gradient ascent to optimize for β * . For exact forms of E q log[vMF(x dw |ψ k , λ k )] and E q [log π dk ], see Appendix.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Experiments</head><p>Setup We perform experiments on two different text corpora: 11266 documents from 20 NEWS-GROUPS 2 and 1566 documents from the NIPS corpus <ref type="bibr" target="#b471">3</ref> . We utilize 50-dimensional word embeddings trained on text from Wikipedia using word2vec 4 . The vectors are normalized to have unit 2 -norm, which has been shown to provide superior performance ).</p><p>We evaluate our model using the measure of topic coherence <ref type="bibr" target="#b585">(Newman et al., 2010)</ref>, which has been shown to effectively correlate with human judgement . For this, we compute the Pointwise Mutual Information (PMI) using a reference corpus of 300k documents from Wikipedia. The PMI is calculated using cooccurence statistics over pairs of words (u i , u j ) in 20-word sliding windows:</p><formula xml:id="formula_257">PMI(u i , u j ) = log p(u i , u j ) p(u i ) · p(u j )</formula><p>Additionally, we also use the metric of normalized PMI (NPMI) to evaluate the models in a similar fashion:</p><formula xml:id="formula_258">NPMI(u i , u j ) = log p(u i ,u j ) p(u i )·p(u j ) − log p(u i , u j )</formula><p>We compare our model with two baselines: HDP and the Gaussian LDA model. We ran G-LDA with various number of topics (k).</p><p>Results <ref type="table" target="#tab_5">Table 2</ref> details the topic coherence averaged over all topics produced by each model. We observe that our sHDP model outperforms G-LDA by 0.08 points on 20 NEWSGROUPS and by 0.17 points in terms of PMI on the NIPS dataset. The NPMI scores also show a similar trend with sHDP obtaining the best scores on both datasets. We can also see that the individual topics inferred   by sHDP make sense qualitatively and have higher coherence scores than G-LDA <ref type="table" target="#tab_10">(Table 1)</ref>. This supports our hypothesis that using the vMF likelihood helps in producing more coherent topics. sHDP produces 16 topics for the 20 NEWSGROUPS and 92 topics on the NIPS dataset. <ref type="figure" target="#fig_8">Figure 2</ref> shows a plot of normalized loglikelihood against the runtime of sHDP and G-LDA. <ref type="bibr">5</ref> We calculate the normalized value of loglikelihood by subtracting the minimum value from it and dividing it by the difference of maximum <ref type="bibr">5</ref> Our sHDP implementation is in Python and the G-LDA code is in Java. Figure 2: Normalized log-likelihood (in percentage) over a training set of size 1566 documents from the NIPS corpus. Since the log-likelihood values are not comparable for the Gaussian LDA and the sHDP, we normalize them to demonstrate the convergence speed of the two inference schemes for these models.</p><p>and minimum values. We can see that sHDP converges faster than G-LDA, requiring only around five iterations while G-LDA takes longer to converge.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Conclusion</head><p>Classical topic models do not account for semantic regularities in language. Recently, distributional representations of words have emerged that exhibit semantic consistency over directional metrics like cosine similarity. Neither categorical nor Gaussian observational distributions used in existing topic models are appropriate to leverage such correlations. In this work, we demonstrate the use of the von Mises-Fisher distribution to model words as points over a unit sphere. We use HDP as the base topic model and propose an efficient algorithm based on Stochastic Variational Inference. Our model naturally exploits the semantic structures of word embeddings while flexibly inferring the number of topics. We show that our method outperforms three competitive approaches in terms of topic coherence on two different datasets.</p><p>Yee Whye <ref type="bibr">Teh, Michael I Jordan, Matthew J Beal, and David M Blei. 2012</ref>. Hierarchical dirichlet processes. Journal of the american statistical association.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Appendinx</head><p>Mean field update equations</p><p>In this section, we provide the mean field update equations. The SVI update equations can be derived from the mean field update <ref type="bibr" target="#b580">(Hoffman et al., 2013)</ref>. The following term is computed for the update equations:</p><formula xml:id="formula_259">E q [log vMF(x dn |µ k , κ k )] = E q [log C M (κ k )]+ E q [κ k ]x T dn E q [µ k ]</formula><p>where C M (·) is explained in Section 3. The difficulty here lies in computing E q [κ k ] and E q [C M (κ k )]. However, κ is a scalar value. Hence, to compute E q [κ k ], we divide a reasonable interval of κ k into grids and compute the weight for each grid point as suggested by <ref type="bibr" target="#b578">Gopal and Yang (2014)</ref>:</p><formula xml:id="formula_260">p(κ k |· · ·) ∝ exp (n k log C M (κ k )+ κ k D d=1 N d n=1 [ϕ dn ] k x dn , E q [µ k ] × logNormal(κ k |m, σ 2 )</formula><p>where <ref type="bibr">[a]</ref> k denotes the k'th element of vector a. After computing the normalized weights, we can compute E q [κ k ] or expectation of any other function of κ k (e.g., E q [C M (κ k )]). The rest of the terms can be computed as follows:</p><formula xml:id="formula_261">n k = D d=1 N d d=1 [ϕ dn ] k and</formula><formula xml:id="formula_262">E q [µ k ] = E q I M/2 (κ k ) I M/2−1 (κ k ) ψ k , ψ k = E q [κ k ] D d=1 N d n=1 [ϕ dn ] k x dn + C 0 µ 0 ψ k ← ψ k ψ k 2 , [E q [log(π d )]] k = Ψ([θ d ] k ) − Ψ k [θ d ] k , [ϕ dn ] k ∝ exp (E q [log vMF(x dn |µ k , κ k )] + E q [log([π d ] k )]) , [θ d ] k =α + N d n=1 [ϕ dn ] k Ψ(·)</formula><p>is the digamma function.</p><p>To find β * , similar to <ref type="bibr" target="#b581">Johnson and Willsky (2014)</ref>, we use the gradient expression of ELBO with respect to β and take a truncated gradient step on β ensuring β * ≥ 0.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Big data poses new challenges in analyzing text corpora. Topic modeling algorithms have recently grown to popularity for their ability to help discover the underlying topics in a corpus. Topic words are the words selected to represent a topic. They have been shown to be useful in the areas of machine learning, text analysis <ref type="bibr" target="#b596">(Grimmer and Stewart, 2013)</ref>, and social media analysis <ref type="bibr" target="#b607">(O'Connor et al., 2010)</ref>, among others. Topic models can be used as predictive models to classify new documents in the context of the training corpus. They are evaluated by measuring their predictive performance on a held-out set of documents. Topic models can also be inspected manually by a human to understand the themes of the underlying corpus. A widely adopted way is suggested by : it measures the quality of a topic by inspecting how far topic words are from some random words. The idea is that the quality of a topic can be measured by how far topic words are from some random words. In other words, if human evaluators can consistently separate random words from topic words, these topics are good, otherwise, they are not good. An advantage of this measure is that it can be easily implemented to deploy on a crowd-sourcing platform like Amazon's Mechanical Turk.</p><p>Assuming that random words represent random topics, we can name the above method "betweentopic" measure. In this paper, we hypothesize that this measure considers just one important aspect in assessing the quality of statistical topics. Specifically, we investigate the topic interpretability by examining the "coherence" of a topic generated by topic modeling algorithms, i.e., how close topic words are within a topic. Thus, this measure is a "within-topic" measure. Two immediate challenging questions are: (1) without knowing ground truth of topic coherence, how can we design an equally effective method like "betweentopic" measure for crowd-sourcing evaluation? and (2) how different is this "within-topic" coherence measure from the existing "between-topic" measure? We elaborate how we answer these two challenges by starting with some related work, showing how the "between-topic" measure faces difficulty in measuring coherence, and presenting our proposal of a coherence measure.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Related Work</head><p>Topic modeling is pervasive, and has been widely accepted across many communities such as machine learning and social sciences <ref type="bibr" target="#b609">(Ramage et al., 2009;</ref><ref type="bibr" target="#b610">Schmidt, 2012;</ref><ref type="bibr" target="#b613">Yang et al., 2011)</ref>. One of the reasons for the wide appreciation of these algorithms is their ability to find underlying topics in enormous sets of data . More recently topic modeling has been widely applied to social media data <ref type="bibr" target="#b600">(Kireyev et al., 2009;</ref>, e.g. <ref type="bibr" target="#b614">(Yin et al., 2011;</ref><ref type="bibr" target="#b608">Pozdnoukhov and Kaiser, 2011)</ref> focus on identifying topics in geographical Twitter datasets. In <ref type="bibr" target="#b605">Mimno et al., 2011)</ref>, the authors had to employ subjectmatter experts to assess topic quality. These manual topic labels can be supplemented with automatic labeling algorithms <ref type="bibr" target="#b603">(Maiya et al., 2013)</ref>. While these works attempt to ensure topic quality by employing domain experts, these are highly domain-specific cases. The measures we discuss going forward are more general, and can be applied to topic models trained with text data.</p><p>The most important point of comparison between our work and others lies in the Model Precision measure proposed in ). The insight of this measure is that a good topic is one whose top few words are distant, or highly separate, from randomly-selected words. Their task works by showing several human participants, or Turker, the top 5 words from a topic and one randomly-chosen, low-ranking "intruded" word. The humans are then asked to select the word that they think was intruded. The measure then estimates the topic's quality by calculating the number of times the humans correctly guessed the intruded word. While Word Intrusion provides insight into a topic's interpretability, the key assumption is that topic goodness comes only from the top words being separate from a randomly-selected word. This measure does not offer any insight about the coherence of the top words. We propose a new measure which complements Word Intrusion by measuring distance within a topic.</p><p>(Lau et al., 2014) built a machine learning algorithm to automatically detect the intruded word in a topic. Methods for evaluating topic models were proposed in <ref type="bibr" target="#b612">(Wallach et al., 2009)</ref>. We investigate the applicability of this measure in our work.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Model Precision Quandary</head><p>Model Precision works by asking the user to choose the word that does not fit within the rest of the set. We are measuring the top words in the topic by comparing them to an outlier. While this method has merit, it does not help us understand the coherence within the top words for the topic.</p><p>A diagram illustrating this phenomenon is shown in <ref type="figure" target="#fig_3">Figure 1</ref>. In <ref type="figure" target="#fig_3">Figure 1(a)</ref>, we see a coherent topic. This topic is coherent because all 5 of the top words are close together, while the intruded word is far away. In <ref type="figure" target="#fig_3">Figure 1(b)</ref> we see a topic that is less coherent because the fifth word lies at a distance from the first four. In both cases, Model Precision gives us the intruder word in the topic, as seen in <ref type="figure" target="#fig_3">Figures 1(c), and 1(d)</ref>. While this is the desired performance of Model Precision, it leaves us with no understanding of the coherence of the top words of the topic. Results are masked by the outlier, and do not give information about the intracluster distance, or coherence of the topic.</p><p>In light of this, we look for a way to separate topics not just by their distance from an outlier, but also by the distance within the top words in the topic. The next section of this paper investigates a method which can measure not just the intruder word, but also the coherence of the top words in the topic. In this way we separate topics such as those shown in <ref type="figure" target="#fig_3">Figure 1</ref> based on the coherence of their top words.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Word Intrusion Choose Two</head><p>In this section we propose a new experiment that measures the interpretability of the top words of a topic. This experiment sets up the task as before: we select the top five words from a topic, and inject one low-probability word. The key difference is that we ask the Turker to select two intruded words among the six.</p><p>The intuition behind this experiment is that the Turkers' first choice will be the intruded word, just as in Model Precision. However, their second choice is what makes the topic's quality clear. In a coherent topic the Turkers won't be able to distinguish a second word as all of the words will seem similar. A graphical representation of this phenomenon is shown in <ref type="figure" target="#fig_3">Figure 1</ref>(e). In the case of an incoherent, a strong "second-place" contender will emerge as the Turkers identify a 2nd intruder word, as in <ref type="figure" target="#fig_3">Figure 1</ref>(f).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Experimental Setup</head><p>To perform this experiment, we inject one lowprobability word for each topic, and we ask the Turkers to select two words that do not fit within the group. We show the six words to the Turker in random order with the following prompt: You will be shown six words. Four words belong together, and two of them do not. Choose two words that do not belong in the group.</p><p>Coherent topics will cause the Turkers' responses regarding the second intruded word to be unpredictable. Thus, our measure of the goodness of the topic should be the predictability of the Turkers' second choice. We propose a new measure called "Model Precision Choose Two" to measure this. Model Precision Choose Two (MPCT) measures this spread as the peakedness of the probability distribution. We define M P CT m k for topic k on model m as: </p><formula xml:id="formula_263">M P CT</formula><p>where H(·) is the Shannon entropy <ref type="bibr" target="#b595">(Cover and Thomas, 2006)</ref>, w m k is the vector of the top words in topic k generated by model m, and p turk (w m k,i ) is the probability that a Turker selects w m k,i . This measures the strength of the second-place candidate, with higher values indicating a smoother, more even distribution, and lower values indicating Turkers gravitation towards a second word.</p><p>The intuition behind choosing entropy is that it will measure the unpredictability in the Turker selections. That is, if the Turkers are confused about which second word to choose, then their answers will be scattered amongst the remaining five words. As a result, the entropy will be high. Conversely, if the second word is obvious, the Turkers will begin to congregate around that second choice, meaning that their answers will be focused. As a result, the entropy will be low. Because entropy is able to measure the confusion of the Turkers responses about the second word, we use it directly in the design of our measure.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Data</head><p>The data used in this study consists of articles from English Wikipedia. We sample 10,000 articles uniformly at random from across the dataset. We selected articles containing more than 50 words. In preprocessing we stripped case, removed punctuation, stopwords, and words consisting entirely of numbers. This process yields a corpus containing 10,000 documents, 4,200,174 tokens, and  . To build the models used in the experiments, we run LDA on the Wikipedia corpus using values of K = {10, 25, 50, 100} with the Mallet package <ref type="bibr" target="#b604">(McCallum, 2002)</ref>. This yields 4 models and 185 total topics. The model generated by each value of K is denoted by m in the equations.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Experimental Results</head><p>The results of this experiment, aggregated by model, are shown in <ref type="figure" target="#fig_8">Figure 2</ref>. We see that as the value of K increases, the median score for MPCT stays roughly the same. We compute the Spearman's ρ correlation coefficient <ref type="bibr" target="#b611">(Spearman, 1904)</ref> between the M P and M P CT measures, and find that the measures have ρ = 0.09. This lack of correlation indicates that this measure is assessing a different dimension of the topics.</p><p>To help explain these results, we provide some examples of topics that received different MPCT scores with a perfect separateness (MP) score in <ref type="table" target="#tab_10">Table 1</ref>. We see that although all of the topics have perfect scores along this dimension, their cohesiveness score varies. This is due to the Turkers' agreement about the second intruded word.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Automating Model Precision Choose Two</head><p>The crowdsourced experiments carried out in this paper provide a complementary understanding of how humans understand the topics that are generated using statistical topic models. One drawback of these methods lies in the difficulty of reproducing these experiments. This difficulty comes from two sources: 1) the monetary cost of employing the Turkers to solve the HITs, and 2) the time cost to build the surveys and to collect the results. To overcome these issues, we propose automated methods that can estimate the topics' performance along these different dimensions. These measures can be used by future researchers to automatically gauge their topics.</p><p>We test several automated measures for their ability to predict the outcome of the crowdsourced measures. To test these measures, we calculate the Spearman's ρ between the automated measure of the topic and the crowdsourced measure. The automated measures we propose are as follows:</p><p>1. Topic Size: LDA assigns a topic label to each token in the dataset. Topic size measures the number of tokens assigned to the topic by the LDA model, where more tokens indicates a larger topic. This has been tested in <ref type="bibr" target="#b605">(Mimno et al., 2011)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Topic Entropy:</head><p>The entropy of the entire probability distribution for the topic. High entropy indicates a flat distribution of probabilities, while low entropy indicates a peaked distribution around the first few words.</p><p>3. Mimno Co-Occurrence: Measures the frequency of the top words co-occurring within the same document. Proposed in <ref type="bibr" target="#b605">(Mimno et al., 2011)</ref>, and measured as: where w is the vector of the top 20 words in the topic, and D(·) returns the number of times the words co-occur in any document in the corpus.</p><formula xml:id="formula_265">M CO(w) = |w| j=2 j−1 k=1 log D(w j , w k ) + 1 D(w k ) ,<label>(2)</label></formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">No. Word Senses:</head><p>The total number of word senses, according to WordNet, of the top five words in the topic. This varies slightly from the measure proposed in , where the authors also consider the intruded word. Because the intruded word is generally far away, we exclude it from our calculation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Avg. Pairwise Jiang-Conrath Distance:</head><p>The Jiang-Conrath (Jiang and Conrath, 1997) distance (JCD) is a measure of semantic similarity, or coherence, that considers the lowest common subsumer according to WordNet. Here we compute the average JCD of all 5 2 = 10 pairs of the top five words of the topic. This approach was introduced by ), however we modify it slightly to only consider the top five words in the topic.</p><p>6. Mean-Link JCD: Using the JCD measure as before, we compute the average distance from the intruded word to each of the top 5 words from the topic.</p><p>7. Normalized Pointwise Mutual Information (NPMI): NPMI measures the association between the top words in a topic. It is normalized to yield a score of 1 in the case of perfect association. This measure was first introduced by <ref type="bibr" target="#b593">(Bouma, 2009)</ref>. We use the calculation adapted for the problem of estimating a topic's performance introduced in .</p><p>We calculate the correlation between all automated methods and MPCT, shown in <ref type="table" target="#tab_5">Table 2</ref>. MPCT is best predicted using the Avg. Pairwise JCD measure. The implications of this result are important: MPCT is best predicted by JCD, a measure that approximates the coherence of topics. Furthermore the correlations are negative, indicating that a low average distance (and thus, a high semantic similarity) indicates a high performance along this automated measure.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Conclusion and Future Work</head><p>In this work we define a new measure for the performance of statistical topic models. We show that this measure gauges a different aspect of the topics than the traditional model precision measure. Finally, we identify automated measures that can approximate the crowdsourced measures for both interpretability and coherence. This measure can be used by future researchers to complement their analysis of statistical topics. The results from our experiments indicate that Word Intrusion Choose Two is different from Word Intrusion, with almost no correlation between the two measures.</p><p>Furthermore, we propose automatic measures that can replace the crowdsourced measures. This is important as it allows for both scalability and reproducibility, as experiments using crowdsourcing are costly in terms of both time and money. We find that measures based on the interpretability of topics can best approximate the Model Precision Choose Two measure, indicating that this measure favors topics whose top words are more semantically similar, furthering our claim that this measure is assessing the coherence of the topic. Code and data to reproduce Model Precision Choose Two can be found at http://bit. ly/mpchoose2.</p><p>While model precision choose two offers a new way to understand topics, there may be others that could help to reveal other dimensions of topic quality. Future work is to find other measures for the semantic properties of topic modeling algorithms. Furthermore, the automated measures we discover to approximate the crowdsourced ones may be incorporated into a topic modeling algorithm that can better produce interpretable topics.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Persuasive essays are frequently used to assess students' understanding of subject matter and to evaluate their argumentation skills and language proficiency. For instance, the prompt for a TOEFL (Test of English as a Foreign Language) persuasive writing task is: Do you agree or disagree with the following statement? It is better to have broad knowledge of many academic subjects than to specialize in one specific subject. Use specific reasons and examples to support your answer.</p><p>Automatic essay scoring systems generally use features based on grammar usage, spelling, style, and content (e.g., topics, discourse) <ref type="bibr" target="#b615">(Attali and Burstein, 2006;</ref><ref type="bibr" target="#b617">Burstein, 2003)</ref>. However, recent work has begun to explore the impact of highlevel persuasion-related features, such as opinions and their targets, thesis clarity and argumentation schemes <ref type="bibr" target="#b620">(Farra et al., 2015;</ref><ref type="bibr" target="#b622">Ong et al., 2014;</ref><ref type="bibr" target="#b624">Persing and Ng, 2015)</ref>. In this paper, we investigate whether argumentation features derived from a coarse-grained, general argumentative structure of essays are good predictors of holistic essay scores. We use the argumentative structure proposed by <ref type="bibr" target="#b627">Stab and Gurevych (2014a)</ref>: argument components (major claims, claims, premises) and argument relations (support, attack). <ref type="figure" target="#fig_3">Figure 1(i)</ref> shows an extract from an essay written in response to the above prompt, labeled with a claim and two premises. The advantage of having a simple annotation scheme is two-fold: it allows for more reliable human annotations and it enables better performance for argumentation mining systems designed to automatically identify the argumentative structure <ref type="bibr" target="#b628">(Stab and Gurevych, 2014b)</ref>.</p><p>The paper has two main contributions. First, we introduce a set of argumentation features related to three main dimensions of argumentative structure: 1) features related to argument components such as the number of claims in an essay, number of premises, fraction of sentences containing argument components; 2) features related to argument relations such as the number and percentage of supported and unsupported claims; and 3) features related to the typology of argumentative structure such as number of chains (see <ref type="bibr">Figure 1(ii)</ref> for and example of chain) and trees (Section 3). On a dataset of 107 TOEFL essays manually annotated with the argumentative structure proposed by <ref type="bibr" target="#b627">Stab and Gurevych (2014a)</ref> (Section 2), we show that using all the argumentation features predicts essay scores that are highly correlated with human scores (Section 3). We discuss what features are correlated with high scoring es- <ref type="figure" target="#fig_3">Figure 1</ref>: (i) Essay extract showing a claim and two premises and (ii) the corresponding argumentative structure (i.e., chain). says vs. low scoring essays. Second, we show that the argumentation features extracted based on argumentative structures automatically predicted by a state-of-the-art argumentation mining system <ref type="bibr" target="#b628">(Stab and Gurevych, 2014b)</ref> are also good predictors of essays scores (Section 4). 1</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Data and Annotation</head><p>We use a set of 107 essays from TOEFL11 corpus that was proposed for the first shared task of Native Language Identification <ref type="bibr" target="#b616">(Blanchard et al., 2013)</ref>. The essays are sampled from 2 prompts: P1 (shown in the Introduction) and P3: Each essay is associated with a score: high, medium, or low. From prompt P1, we selected 25 high, 21 medium, and 16 low essays, while for prompt P3 we selected 15 essays for each of the three scores.</p><p>For annotation, we used the coarse-grained argumentative structure proposed by <ref type="bibr" target="#b627">Stab and Gurevych (2014a)</ref>: argument components (major claim, claim, premises) and argument relations (support/attack). The unit of annotation is a clause. Our annotated dataset, T OEF L arg , includes 107 major claims, 468 claims, 603 premises, and 641 number of sentences that do not contain any argument component. To measure the inter-annotator agreement we calculated P/R/F1 measures, which are used to account for fuzzy boundaries . The F1</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Argumentation Features for Predicting Essays Scores</head><p>A major contribution of this paper is a thorough analysis of the key features derived from a coarsegrained argumentative structure that are correlated with essay scores. Based on our annotations, we propose three groups of features <ref type="table" target="#tab_10">(Table 1)</ref>. The first group consists of features related to argument components (AC) such as the number of claims, number of premises, fraction of sentences containing argument components. One hypothesis is that an essay with a higher percentage of argumentative sentences will have a higher score. The second group consists of features related to argument relations (AR), such as the number and percentage of supported claims (i.e., claims that are supported by at least one premise) and the number and percentage of dangling claims (i.e., claims with no supporting premises). In low scoring essays, test takers often fail to justify their claims with proper premises and this phenomenon is captured by the dangling claims feature. In contrary, in high scoring essays, it is common to find many claims that are justified by premises. We also consider the number of attack relations and attacks against the major claim. Finally, the third group consists of features related to the typology of argument structures (TS) such as the number of argument chains (Chain), number of argument trees of height = 1 (T ree h=1 ) and the number of argument trees of height &gt; 1 (T ree h&gt;1 ). We define an argument chain when a claim is supported by a chain of premises. We define T ree h=1 as a tree structure of height 1 with more than one leaves, where the root is a claim and the leaves are premises   or claims. Finally, T ree h&gt;1 is a tree structure of height &gt; 1, where the root is a claim and the internal nodes and leaves are either supporting claims or supporting premises. <ref type="figure" target="#fig_8">Figure 2</ref> shows examples of a T ree h&gt;1 structure, a Chain structure, and a T ree h=1 structure. The dark nodes represent claims (C), lighter nodes can be either claims or premises (C/P) and white nodes are premises (P). <ref type="figure" target="#fig_3">Figure 1</ref> shows an extract from an essays and the corresponding Chain structure.</p><p>To measure the effectiveness of the above features in predicting the holistic essay scores (high/medium/low) we use Logistic Regression (LR) learners and evaluate the learners using quadratic-weighted kappa (QWK) against the human scores, a methodology generally used for essay scoring <ref type="bibr" target="#b620">(Farra et al., 2015)</ref>. QWK corrects for chance agreement between the system prediction and the human prediction, and it takes into account the extent of the disagreement between labels. <ref type="table" target="#tab_5">Table 2</ref> reports the performance for the three feature groups as well as their combination. Our baseline feature (bl) is the number of sentences in the essay, since essay length has been shown to be generally highly correlated with essay scores <ref type="bibr" target="#b619">(Chodorow and Burstein, 2004)</ref>. We found that all three feature groups individually are strongly correlated with the human scores, much better than  <ref type="table" target="#tab_5">Table 2</ref>: Correlation of LR (10 fold CV) with human scores.</p><p>the baseline feature, and the AC features have the highest correlation. We also see that although the number of claims and premises can affect the score of an essay, the argumentative structures (i.e., how the claims and premises are connected in an essay) are also important. Combining all features gives the highest QWK score (0.803).</p><p>We also looked at what features are associated with high scoring essays vs. low scoring essays. Based on the regression coefficients, we observe that the high "number and % of dangling claims" are strong features for low scoring essays, whereas the "fraction of sentences containing argument components" (AC feature), "number of supported claims" (AR feature), and "number of T ree h=1 structures" and "number of T ree h&gt;1 structures" (TS features) have the highest correlation with high scoring essays. For example, in a good persuasive essay, test takers are inclined to use multiple premises (e.g., reasons or examples) to support a claim, which is captured by the TS and AR features. In addition, we notice that attack relations are sparse, as was the case in <ref type="bibr" target="#b628">Stab and Gurevych (2014b)</ref> dataset and thus the coefficients for attack relations features (#10, #11 in <ref type="table" target="#tab_10">Table 1</ref>) are negligible.</p><p>In summary, our findings contribute to research on essay scoring, showing that argumentation features are good predictors of essay scores, besides spelling, grammar, and stylistic properties of text.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Automatic Extraction of Argumentation Features for Predicting Essay Scores</head><p>To automatically generate the argumentation features <ref type="table" target="#tab_10">(Table 1)</ref>, we first need to identify the argumentative structures: argument components (major claim, claim, and premise) and relations (support/attack). We use the approach proposed by <ref type="bibr" target="#b628">Stab and Gurevych (2014b)</ref>. 2 For argument component identification, we categorize clauses to one of the four classes (major claim (M C), claim (C), premise (P ), and N one). For argument relation identification, given a pair of argument clauses Arg 1 and Arg 2 the classifier decides whether the pair holds a support (S) or non-support (N S) relation (binary classification). For each essay, we extract all possible combinations of Arg 1 and Arg 2 from each paragraph as training data (654 S and 2503 N S instances; attack relations are few and included in N S). We do not consider relations that may span over multiple paragraphs to reduce number of non-support instances. For both tasks we use Lexical features (e.g., unigrams, bigrams, trigrams, modal verbs, adverbs, word-pairs for relation identification), Structural features (e.g., number of tokens/punctuations in argument, as well as in the sentence containing the argument, argument position in essay, paragraph position (paragraph that contains the argument)), Syntactic features (e.g., production rules from parse trees, number of clauses in the argument), and Indicators (discourse markers selected from the three top-level Penn Discourse Tree Bank (PDTB) relation senses: Comparison, Contingency, and Expansion ). We use two settings for the classification experiments using libSVM <ref type="bibr" target="#b618">(Chang and Lin, 2011)</ref> for both argument component and relation identification. In the first setting, we used the dataset of 90 high quality persuasive essays from <ref type="bibr" target="#b628">(Stab and Gurevych, 2014b</ref>) (S&amp;G) as training and use T OEF L arg for testing (out-of-domain setting). In the second setting (in-domain), we randomly split the T OEF L arg into 80% training and 20% for testing (sampled equally from each category (M C, C, P , and N one for argument components; S and N S for relations)). <ref type="table" target="#tab_6">Table 3</ref> and 4 present the classification results for identifying ar-2 In future work, we plan to use the authors' improved approach and larger dataset released after the acceptance of this paper <ref type="bibr" target="#b629">(Stab and Gurevych, 2016</ref>   <ref type="table" target="#tab_42">Table 4</ref>: F1 for argument components (in-domain setting) gument components in the first and second setting, respectively. We ran experiments for all different features groups and observe that with the exception of the P class, the F1 scores for all the other classes is comparable to the results reported by <ref type="bibr" target="#b628">Stab and Gurevych (2014b)</ref>. One explanation of having lower performance on the P (premise) category is that the S&amp;G dataset used for training has higher quality essays, while 2/3 of our T OEF L arg dataset consists of medium and low scoring essays (the writing style for providing reasons or example can differ between high and low scoring essays). When we select the top 100 features ("top100") using Information Gain <ref type="bibr" target="#b621">(Hall et al., 2009</ref>) the F1 scores for the P class improves.</p><p>The results in <ref type="table" target="#tab_42">Table 4</ref> show that when training and testing on same type of essays the results are better for all categories except for M C when using the "top100" setup. <ref type="table" target="#tab_22">Table 5</ref> shows the results for relation identification in the first setting (out-of-domain). The F1 score of identifying support relations is 84.3% (or 89% using top100), much higher than reported by <ref type="bibr" target="#b628">Stab and Gurevych (2014b)</ref>. We obtain similar results when training and testing on T OEF L arg . We observe that two specific feature groups, Structural and Lexical, individually achieve high F1 scores and when combined with other features, they assist the classifier in reaching F1 scores in high 80s%. There can be two explanations for this: 1) essays in T OEF L arg have multiple short paragraphs where the position features such as position of the arguments in the essay and paragraph (Structural group) are strong indicators for argument relations; and 2) due to short paragraphs, the percentage of N S instances are less than in the S&amp;G dataset, hence the Lexical features (i.e., word-pairs between Arg 1 and Arg 2 ) perform very well.   <ref type="table" target="#tab_23">Table 6</ref>: Correlation of LR (10 fold CV) with predicted results.</p><p>Based on the automatic identification of the argument components and relations, we generate the argumentation features to see whether they still predict essays scores that are highly correlated with human scores. Since our goal is to compare with the manual annotation setup, we use the first setting, where we train on the S&amp;G dataset and test on our T OEF L arg dataset. We select the best system setup (top100 for both tasks; <ref type="table" target="#tab_6">Table 3</ref> and 5). We ran Logistic Regression learners and evaluated their performance using QWK scores. Table 6 shows that the argumentative features related to argument relations (AR) and the typology of argument structures (TS) extracted based on the automatically predicated argumentative structure perform worse compared to the scores based on manual annotations <ref type="table" target="#tab_5">(Table 2)</ref>. Our error analysis shows that this is due to the wrong prediction of argument components, specifically wrongly labeling claims as premises <ref type="table" target="#tab_6">(Table 3)</ref>. AR and TS features rely on correctly identifying the claims, and thus a wrong prediction affects the features in these two groups, even if the accuracy of supports relations is high. This also explains why the argument components (AC) features still have a high correlation with human scores (0.669). When we extracted the argumentation features using goldstandard argument components and predicted argument relations, the correlation of AR and TS features improved to 0.576 and 0.504, respectively and the correlation of all features reached 0.769.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Related Work</head><p>Researchers have begun to study the impact of features specific to persuasive construct on student essay scores <ref type="bibr" target="#b620">(Farra et al., 2015;</ref><ref type="bibr" target="#b622">Ong et al., 2014;</ref><ref type="bibr" target="#b623">Persing and Ng, 2013;</ref><ref type="bibr" target="#b624">Persing and Ng, 2015)</ref>. <ref type="bibr" target="#b620">Farra et al. (2015)</ref> investigate the impact of opinion and target features on TOEFL essays scores. Our work looks a step further by exploring argumentation features.  show that adding features related to argumentation schemes (from manual annotation) as part of an automatic scoring system increases the correlation with human scores. We show that argumentation features are good predictors of human scores for TOEFL essays, both when the coarsegrained argumentative structure is manually annotated and automatically predicted. <ref type="bibr" target="#b624">Persing and Ng (2015)</ref> proposed a feature-rich approach for modeling argument strength in student essays, where the features are related to argument components. Our work explores features related to argument components, relations and typology of argument structures, showing that argument relation features show best correlation with human scores (based on manual annotation).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Conclusion</head><p>We show that argumentation features derived from a coarse-grained, argumentative structure of essays are helpful in predicting essays scores that have a high correlation with human scores. Our manual annotation study shows that features related to argument relations are particularly useful. Our experiments using current methods for the automatic identification of argumentative structure confirms that distinguishing between claim and premises is a particularly hard task. This led to lower performance in predicting the essays scores using automatically generate argumentation features, especially for features related to argument relations and typology of structure. As future work we plan to improve the automatic methods for identifying argument components similar to <ref type="bibr" target="#b629">Stab and Gurevych (2016)</ref>, and to use the dataset introduced by <ref type="bibr" target="#b624">Persing and Ng (2015)</ref> to investigate how our argumentation features impact the argument strength score rather than the holistic essay score. Edit tree for the inflected form abgesagt "canceled" and its lemma absagen "to cancel". The highest node contains the length of the parts before and after the LCS. The left node in the second row contains the length of the parts before and after the LCS of abge and ab. The prefix sub indicates that the node is a substitution operation.</p><p>principle be applied to any MRI system.</p><p>An edit tree e(σ, τ ) specifies a transformation from a source string σ to a target string τ <ref type="bibr" target="#b635">(Chrupała, 2008)</ref>. To compute e(σ, τ ), we first determine the longest common substring (LCS) <ref type="bibr" target="#b646">(Gusfield, 1997</ref>) between σ and τ and then recursively model the prefix and suffix pairs of the LCS. If the length of LCS is zero for (σ, τ ), then e(σ, τ ) is simply the substitution operation that replaces σ with τ . <ref type="figure" target="#fig_8">Figure 2</ref> shows an example.</p><p>Let X be a training set for MRI. For each pair (s, t) of tags, we define: E s,t = {e |∃x ∈ X : e = e(x), s = S(x), t = T (x)} where S(x) and T (x) are source and target tags of x and e(x) is e(σ(x), τ (x)), the edit tree that transforms the source form into the target form.</p><p>Let ρ be a target form predicted by the MRI system for the source form σ and let s and t be source and target tags. POET does not change ρ if e(σ, ρ) ∈ E s,t . Otherwise it replaces ρ with τ : τ := τ if e(σ, τ ) ∈ E s,t , |ρ, τ | = 1 ρ else where |ρ, τ | is the Levenshtein distance. If there are several forms τ with edit distance 1, we select the one with the most frequent edit tree. Ties are broken randomly. We observed that MED sometimes makes errors that are close to the target, but differ by one edit operation. Those errors are often not covered by edit trees that are observed in the training data whereas the correct form is. Thus, substituting a form not supported by an observed edit tree with a close one that is supported promises to reduce the error rate.</p><p>The effectiveness of POET depends on a training set that is large enough to cover the possible edit trees that can occur in reinflection in a language. Thus, if the training set is not large enough in this respect, then POET will not be beneficial.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Experiments</head><p>We compare MED with the three models of <ref type="bibr" target="#b638">Dreyer et al. (2008)</ref> as well as with two recently proposed models: (i) discriminative string transduction <ref type="bibr" target="#b640">(Durrett and DeNero, 2013;</ref><ref type="bibr" target="#b652">Nicolai et al., 2015)</ref>, the SIGMORPHON16 baseline, and (ii) 's encoder-decoder model. <ref type="bibr" target="#b471">3</ref> We call the latter MODEL*TAG as it requires training as many models as there are target tags.</p><p>We evaluate MED on two MRI tasks: CELEX and SIGMORPHON16.</p><p>CELEX. This task is based on complete inflection tables for German extracted from CELEX. For this experiment we follow <ref type="bibr" target="#b638">Dreyer et al. (2008)</ref>. We use four pairs of morphological tags and corresponding word forms from the German part of the CELEX morphological database. The 4 different transduction tasks are: 13SIA → 13SKE, 2PIE → 13PKE, 2PKE → z and rP → pA. <ref type="bibr">4</ref> An example for this task would be to produce the output gesteuert (target tag pA) for the source steuert (source tag rP). To do so, the system has to learn that the prefix ge-, which is used for many participles in German, has to be added to the beginning of the original word form.</p><p>We use the same data splits as <ref type="bibr" target="#b638">Dreyer et al. (2008)</ref>, dividing the original 2500 samples for each tag into five folds, each consisting of 500 training and 1000 development and 1000 test samples. We train a separate model for each fold and report exact match accuracy, averaged over the five folds, as our final result. SIGMORPHON16. This task covers eight languages and does not provide complete paradigms, but only a set of quadruples, each consisting of word form, source tag, target tag and target form. The main difference to CELEX is that the number of tag pairs is large, resulting in much less training data per tag pair. The number of tag pairs varies by language with Georgian being an extreme case; it has 28 tag pairs in dev that appear less than 10 times in train. For each language, we have around 12,800 training and 1600 development samples. We report exact match accuracy on the development set, as the final test data of the shared task is not publically available yet. <ref type="table" target="#tab_10">Table 1</ref> gives CELEX results. MED+POET is better than prior work on one task, close in performance on two and worse by a small amount on the third. Unlike <ref type="bibr" target="#b638">Dreyer et al. (2008)</ref>'s models, MED does not use any hand-crafted features. MED's results are weakest on 13SIA. Typical errors on this task include epenthesis (e.g., zirkle vs. zirkele) and irregular verbs (e.g., abhing vs. abhängte).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Results</head><p>For SIGMORPHON16, <ref type="table" target="#tab_5">Table 2</ref> shows that MED outperforms the baseline for all eight languages. Absolute performance and variance is probably influenced by type of morphology (e.g., templatic vs. agglutinative), regularity of the language, number of different tag pairs and other factors. MED performs well even for complex and diverse languages like Arabic, Finnish, Navajo and Turkish, suggesting that the type of attentionbased encoder-decoder we use -single-model, using an explicit morphological representation -is a good choice for MRI.  We do not compare to MODEL*TAG here because it requires training a large number of individual networks. This is a disadvantage compared to MED both in terms of the number of models that need to be trained and in terms of the effective use of the small number of training examples that are available per tag pair.</p><p>POET improves the results for all tag pairs for CELEX. However, initial experiments indicated that it is not effective for SIGMORPHON16 because its training sets are not large enough.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Analysis</head><p>The main innovation of our work is that MED learns a single model of all MRI patterns of a language and thus can transfer what it has learned from one tag pair to another tag pair. Using CELEX, we now analyze how much our design contributes to better performance by conducting two experiments in which we gradually decrease the training set in two different ways. (i) Large general training set. We only reduce the number of training examples available for a tag pair (s, t) and retain all other training examples. (ii) Small training set. We reduce the number of training examples available for all tag pairs, not just for one.</p><p>A typical example of the large general training set scenario is that familiar second person forms are rare in genres like encyclopedia and news. So a training set derived from these genres will be large, but it will have very few tag pairs whose target tag is familiar second person.</p><p>A typical example of the small training set scenario is that we are dealing with a low-resource language. In the following two experiments, we only reduce the training set and do not change the test set.</p><p>Large general training set. We iteratively halve the training data for 2PIE → 13PKE until only 6.25% or 32 samples are left. <ref type="figure" target="#fig_6">Figure 3</ref> shows that MED performs well even if only 6.25% of the training examples for the tag pair remain. In contrast, MODEL*TAG struggles to generalize correctly. This is due to the fact that we train one single model for all tags, so it can learn from other tags and transfer what it has learned to the tag pair that has a small training set.</p><p>Small training set. <ref type="figure" target="#fig_15">Figure 4</ref> shows results for reducing the training data equally for all tags. MED performs much better than the baseline for less than 50% of the training data. This can be explained by the fact that MED learns from all given data at once and thus is able to learn common patterns that apply across different tag pairs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Related Work</head><p>Earlier work on morphology includes morphological segmentation <ref type="bibr" target="#b648">(Harris, 1955;</ref><ref type="bibr" target="#b647">Hafer and Weiss, 1974;</ref><ref type="bibr" target="#b637">Déjean, 1998)</ref> and different approaches for MRI <ref type="bibr" target="#b631">(Ahlberg et al., 2014;</ref><ref type="bibr" target="#b640">Durrett and DeNero, 2013;</ref><ref type="bibr" target="#b641">Eskander et al., 2013;</ref><ref type="bibr" target="#b652">Nicolai et al., 2015)</ref>. <ref type="bibr" target="#b635">Chrupała (2008)</ref> defined edit trees and <ref type="bibr" target="#b635">Chrupała (2008)</ref> and <ref type="bibr" target="#b651">Müller et al. (2015)</ref> use them for morphological tagging and lemmatization.</p><p>In the last years, RNN encoder-decoder models and RNNs in general were applied to several NLP tasks. For example, they proved to be useful for machine translation , parsing <ref type="bibr" target="#b655">(Vinyals et al., 2015)</ref> and speech recognition <ref type="bibr" target="#b644">(Graves and Schmidhuber, 2005;</ref><ref type="bibr" target="#b645">Graves et al., 2013)</ref>.</p><p>MED bears some resemblance to 's work. However, they train one network for every tag pair; this can negatively impact performance for low-resource languages and in general when training data are limited. In contrast, we train a single model for each language. This radically reduces the amount of training data needed for the encoder-decoder because most MRI patterns occur in many tag pairs, so what is learned for one can be transferred to others. To be able to model all tag pairs of the language together, we introduce an explicit morphological representation that enables the attention mechanism of the encoder-decoder to generalize MRI patterns across tag pairs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">Conclusion and Future Work</head><p>We have presented MED, a language independent neural sequence-to-sequence mapping approach, and POET, a method based on edit trees for correcting the output of an MRI system. MED obtains results comparable to state-of-the-art systems for CELEX and establishes the state-of-the-art for SIGMORPHON16. POET improves results further for large training sets. Our analysis showed that MED outperforms a neural encoder-decoder baseline system by a large margin, especially for small training sets.</p><p>In future work, we would like to make POET less dependent on the source tag and thus increase its accuracy for small training sets. Second, we will look into ways of taking advantage of additional information sources including unlabeled corpora.</p><p>edges and POS tags from all source languages into an intermediate target graph, which is left deliberately ambiguous. In the second step, we decode the target graph by solving a constrained optimisation problem, which simultaneously resolves all ambiguities and produces a single dependency tree with a fixed set of POS tags. Below we describe both steps in more detail.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Cross-language sentence</head><p>The input to our projection algorithm is a crosslanguage sentence, a data structure that ties together a collection of aligned sentences from a parallel corpus, i.e., sentences in many different languages that are determined to be translation equivalents. One sentence of the set is designated as the target while the rest are sources. We project syntactic information from the sources to the target.</p><p>All source sentences are automatically parsed with a graph-based dependency parser and labeled with parts of speech. Instead of using the single best dependency tree output by the parser, we extract its scoring matrix, an ambiguous structure that assigns a numeric score to each potential dependency edge. The target sentence is not parsed or POS-tagged. In fact, our approach is explicitly designed to work for target languages where no such resources are available. Only unsupervised word alignments couple the target sentence with each source sentence.</p><p>More formally, a cross-language sentence may be represented as a graph G = (V, E), where each vertex is a POS-tagged token of a sentence in some language. With one target and n source languages, the total set of tagged word vertices V can be written as the union of sentence vertices: V = V 0 ∪ . . . ∪ V n . The target sentence is V t = V 0 , while source sentences are V s = V 1 ∪ . . . ∪ V n .</p><p>Two kinds of weighted edges connect the graph. Edges that go between tagged tokens of a sentence V i represent potential dependency edges. Thus, for the sentence i, the induced subgraph G[V i ] is the (ambiguous) dependency graph. Edges connecting a source vertex to target vertex represent word alignments. The set of alignment edges is A ⊆ V s × V t .</p><p>To account for POS we introduce a vertex labeling function l : V → Σ, where Σ is the POS vocabulary. The source sentences are automatically tagged, and for any source vertex the label function simply returns this tag. For the target sentence the POS labels are unknown, which is to say that every target token is ambiguous between |Σ| POS tags. We represent this ambiguity in the graph by creating a vertex for each possible combination of target word and POS. Concretely, if a source sentence i has n tokens, and the target sentence has m tokens, then |V i | = n, and |V s | = m|Σ|.</p><p>Alignments are constrained such that an alignment (u, v) ∈ V s × V t only exists if the source and target token were linked by the automatic aligner and l(u) = l(v), i.e., the POS tags match. This filters out potential source relations with dissimilar syntax, a luxury that we are allowed in a multiple source language setup.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Projecting to ambiguous target graph</head><p>The target graph G[V t ] starts out empty and is populated with edges in the following way. We go through the source sentences, looking for potential dependency edges where both endpoints are aligned to the target sentence, and transferring the edge whenever we find one. Technically, for every source sentence i and for each edge in the source graph (u s , v s ) ∈ G[V i ], we create an edge (u t , v t ) in the target iff both (u s , u t ) and (v s , v t ) ∈ A. The edge weight is the source edge score (as determined by an automatic parser) weighted by the joint alignment probability of (u s , u t ) and (v s , v t ): For clarity, d refers to weights of dependency edges, and a to alignment edge weights. Multiple source sentences may project the same edge to the target graph. When this happens we update the target edge weight only if the new weight is larger than the existing. The weight then reflects the strongest evidence found for a given syntactic relation across all source languages.</p><formula xml:id="formula_266">d(u t , v t ) = max</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Decoding the target graph</head><p>We are now ready to decode the target graph. The result of decoding is a dependency tree as well as a labeling of the target sentences with POS tags. Labeling with POS corresponds to selecting a subset of the verticesṼ ⊂ V t , such that exactly one vertex is chosen for each token. Similarly the decoded dependency tree is a subset of the projected target edges with the constraint that it must form a tree over the vertices ofṼ . The joint optimization objective is to simultaneously select a set of verticesṼ and edgesẼ to maximize the score of the decoded tree. We solve this constrained optimization problem by casting it as an integer linear programming (ILP) problem.</p><p>The full specification of the ILP model is displayed as <ref type="figure" target="#fig_3">Figure 1</ref>. The model is optimized over two types of binary decision variables mapping directly to the target graph representation discussed in the previous section, plus additional flow variables that enforce tree structure. An edge variable e i,k,j,l represents a target edge (i, j) where the POS of i is k and the POS of j is l. For instance, the variable e 2,V,1,N represents a directed edge from the second token (a verb) to the first (a noun). An active vertex variable v i,k indicates that the POS of token i is chosen as k.</p><p>Following Martins (2012), we constrain the search space to spanning trees by using a singlecommodity-flow construction. In the commodityflow analogy, we imagine the root as a factory that produces n commodities (for an n token sentence) which are distributed along the edges of the tree. Each token is a consumer that must receive and pass on all except one commodity to its dependents, i.e., the difference between incoming and outgoing flow should be 1. Since all commodities must be consumed, the outgoing flow for a leaf node will be zero. Together with the requirement that each token must have exactly one head, this ensures all tokens are connected to the root in the tree structure.</p><p>The last two constraint groups enforce edge and POS consistency, and the selection of single POS per token. Both are new to this work.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Data sources</head><p>Our projection requires parallel text, ideally spanning a large number of languages, and dependency treebanks for the sources.</p><p>Treebanks To train the source-side taggers and dependency parsers, and to evaluate the crosslingual taggers and parsers, we use the Universal Dependencies (UD) version 1.2 treebanks with the corresponding test sets. <ref type="bibr" target="#b471">3</ref> Parallel texts We exploit two sources of parallel text: the Edinburgh Multilingual Bible corpus (EBC) <ref type="bibr" target="#b660">(Christodouloupoulos and Steedman, 2014)</ref>, and our own collection of online texts published by the Wathctower Society (WTC). Above, i, j, and x are token indices, while k and l refer to POS. Quantification over these symbols in the equations are always with respect to a given target graph.</p><p>Figure 1: Specification of the ILP model. We list, in order, the decision variables, the objective, and the five groups of constraint templates.</p><p>the two collections span more than 100 languages, we focus on the subsets that overlap with the UD languages to facilitate evaluation. For EBC, that amounts to 27 languages, and 23 for WTC.</p><p>Preprocessing We use simple sentence splitting and tokenization models to segment the parallel corpora. <ref type="bibr">5</ref> To sentence-and word-align the individual language pairs, we use a Gibbs samplingbased IBM1 alignment model called efmaral <ref type="bibr">(Östling, 2015)</ref>. IBM1 has been shown to lead to more robust alignments across typologically distant language pairs <ref type="bibr">(Östling, 2015)</ref>. We modify the aligner to output alignment probabilities. All the source-side texts are POS-tagged and dependency parsed using TnT  and <ref type="bibr">TurboParser (Martins et al., 2013)</ref>. We use our own fork of the arc-factored TurboParser to output the edge weight matrices. 6</p><p>4 Experiments</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Setup</head><p>In our experiments, as in the preprocessing, we use the TnT tagger and the arc-factored TurboParser, which we train on the EBC and WTC texts with projected and decoded annotations. We randomly sample up to 20k sentences per training file in both tagging and parsing. This 20k sampling limit applies to all systems. We compare two cross-lingual projection-based parsing systems, and one baseline system. ILP The ILP-based joint projection algorithm we presented in Section 2.</p><p>DCA Our implementation of the de facto standard annotation projection algorithm of <ref type="bibr" target="#b662">Hwa et al. (2005)</ref>, as refined by . In contrast to our ILP approach, it uses heuristics to ensure dependency tree constraints on a sourcetarget sentence pair basis. We gather all the pairwise projections into a target sentence graph and then perform maximum spanning tree decoding following <ref type="bibr" target="#b672">Sagae and Lavie (2006)</ref>. DELEX The multi-source direct delexicalized transfer baseline of . Each source is represented by an approximately equal number of sentences.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Results</head><p>Table 1 provides a summary of dependency parsing scores. We report UAS scores over predicted and gold POS. The predicted tags come from our cross-lingual taggers. Our ILP approach consistently outperforms DCA on both by a large margin of 3-5 points UAS using predicted POS, and 5-10 points on gold POS. Note that DELEX is trained on gold POS and therefore has an advantage in this 6 https://github.com/andersjo/ TurboParser 8 We do not include DELEX in the comparison for the gold POS scenario only. In this particular scenario, DELEX is also trained on gold POS, and thus biased: the cross-lingual taggers do not have gold POS available for training, and the same holds for DELEX and projected POS.  In <ref type="table" target="#tab_5">Table 2</ref>, we split the scores across the test languages and parallel data sources, and we also report the POS tagging accuracies. Our WTC taggers are on average 3.5 points better than EBC taggers, yielding the top score for 16/23 languages from the overlap. Notably, on several non-IndoEuropean languages, we observe significant improvements. For example, on Indonesian, DCA improves over DELEX by 12 points UAS, while ILP adds 6 more points on top. We observe a similar pattern for Arabic and Estonian. We note that DELEX tops ILP and DCA on only 1 EBC and 3 WTC languages, and by a narrow margin.</p><p>Analysis A projected parse is allowed to be a composite of edges from many source languages. To find out to what degree this actually happens, we analyze all projections into English and German on the WTC corpus.</p><p>For German the top four source languages are Czech, Norwegian, French, and English, contributing between 16% and 7% of all edges. For English the top languages are Norwegian, Italian, Indonesian, and Swedish. Here, the top language Norwegian is responsible for 42% of the edges, while Swedish accounts for 13%. Only the language projecting the highest scoring edge is counted. On average, a German sentence has edges from 4.1 source languages. The same number for English is slightly higher, at 4.5.</p><p>Manually annotated data We annotate a small number of sentences in English from EBC and  WTC, which gives us a way to directly evaluate the projections without training parsers. On this small test set of 2 × 50 sentences, we obtain UAS scores of 68% (WTC) and 62% (EBC). The POS accuracies are 79% and 80%. All figures are comparable to the results from the indirect projection evaluation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Related work</head><p>In recent years, we note an increased interest for work in cross-lingual processing, and particularly in POS tagging and dependency parsing of lowresource languages.  proposed the idea of inducing NLP tools via parallel corpora. Their contribution started a line of work in annotation projection.  used graph-based label propagation to yield competitive POS taggers, while <ref type="bibr" target="#b662">Hwa et al. (2005)</ref> introduced the projection of dependency trees.  further improved this approach to single-source projection in the context of synthesizing dependency treebanks <ref type="bibr" target="#b674">(Tiedemann and Agić, 2016)</ref>. The current state of the art in cross-lingual dependency parsing also involves exploiting large parallel corpora <ref type="bibr" target="#b664">(Ma and Xia, 2014;</ref><ref type="bibr" target="#b671">Rasooli and Collins, 2015)</ref>.</p><p>Transferring models by training parsers without lexical features was first introduced by .  and  coupled delexicalization with contributions from multiple sources, while  were the first to leverage uniform representations of POS and syntactic dependencies in cross-lingual parsing.</p><p>Even more recently,  exposed a bias towards closely related Indo-European languages shared by most previous work on annotation projection, while introducing a bias-free projection algorithm for learning 100 POS taggers from multiple sources. Their line of work is non-trivially extended to multilingual dependency parsing by .</p><p>The work in annotation projection for crosslingual NLP invariably treats mutually dependent layers of annotation separately. Our contribution is distinct from these works by implementing the first approach to joint projection of POS and dependencies, while maintaining the outlook on processing truly low-resource languages.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Conclusion</head><p>In our contribution, we addressed tagging and parsing for low-resource languages through joint cross-lingual projection of POS tags and syntactic dependencies from multiple source languages. Our novel approach to transferring the annotations via word alignments is based on integer linear programming, more specifically on a commodityflow formalization for spanning trees.</p><p>In our experiments with 27 treebanks from the Universal Dependencies (UD) project, our approach compared very favorably to two competitive cross-lingual systems: we provided the best cross-lingual taggers and parsers for 18/27 and 20/23 languages, depending on the parallel corpora used. We made no unrealistic assumptions as to the availability of parallel texts and preprocessing tools for the target languages. Our code and data is freely available. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Experiments</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Data and Settings</head><p>We evaluate our proposed approach on three datasets, PKU, MSRA and CTB6. The PKU and MSRA data both are provided by the second International Chinese Word Segmentation Bakeoff <ref type="bibr" target="#b681">(Emerson, 2005)</ref> and CTB6 is from Chinese TreeBank 6.0 1 <ref type="bibr" target="#b693">(Xue et al., 2005)</ref>. We randomly divide the whole training data into the 90% sentences as training set and the rest 10% sentences as development set. All datasets are preprocessed by replacing the Chinese idioms and the continuous English characters. The character embeddings are pre-trained on unlabeled data, Chinese Gigaword corpus 2 . We use MSRA dataset to preprocess model weights before training on CTB6 and PKU datasets.</p><p>Following previous work and our experimental results, hyper parameters configurations are set as follows: minibatch size n = 16, window size w = 5, character embedding size d 1 = 100, amplification gate range γ = [0, 4] and margin loss discount κ = 0.2. All weight matrixes are diagonal matrixes and randomly initialized by normal distribution.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Experimental Results and Discussions</head><p>We first compare our model with baseline methods, Bi-LSTM and GRNN on three datasets. The results evaluated by F-score (F 1 score) are reported in <ref type="table" target="#tab_10">Table 1</ref>.</p><p>• Bi-LSTM. First, the output of Bi-LSTM is concatenated to a vector. Second, softmax layer takes the vector as input and generates each tag probability.  <ref type="table" target="#tab_5">Table 2</ref>: Comparisons for DGRNN and state-ofthe-art non-neural network approaches on F-score.</p><p>• GRNN. The structure of GRNN is recursive. GRNN combines adjacent word vectors to the more abstract representation in bottom-up way.</p><p>Furthermore, we conduct experiments with amplification gate on three development datasets. <ref type="figure" target="#fig_170">Figure 5</ref> shows that amplification gate significantly increases F-score on three datasets. Amplification even achieves 0.9% improvement on CTB6 dataset. It is demonstrated that amplification gate is an effective mechanism.</p><p>We compare our proposed model with previous neural approaches on PKU, MSRA and CT-B6 test datasets. Experimental results are reported in <ref type="table" target="#tab_10">Table 1</ref>  We also compare DGRNN with other state-ofthe-art non-neural networks, as shown in <ref type="table" target="#tab_5">Table 2</ref>.  implements the work of <ref type="bibr" target="#b687">Sun and Xu (2011)</ref> on CTB6 dataset and achieves 95.7% F-score. We achieve the best result on P-KU dataset only with unigram embeddings. The experimental results show that our model is a competitive model for Chinese word segmentation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Statistical Significance Tests</head><p>We use the t-test to intuitively show the improvement of DGRNN over baselines. According to the results shown in <ref type="table" target="#tab_6">Table 3</ref>, we can draw a conclusion that, by conventional criteria, this improvement is considered to be statistically significant between DGRNN with baselines, except for GRN-N approach on MSRA dataset.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Conclusions</head><p>In this work, we propose dependency-based recursive neural network to combine local features with long distance dependencies, which achieves substantial improvement over the state-of-the-art approaches. Our work indicates that long distance dependencies can improve the performance of local segmenter. In the future, we will study alternative ways of modeling long distance dependencies. O : B-SQ I-SQ I-SQ E-SQ <ref type="figure" target="#fig_3">Figure 1</ref>: Greedy parsing algorithm (3 iterations), on the sentence "Did you hear the falling bombs ?". I W , I T and O stand for input words (or composed word representations R i ), input syntactic tags (parsing or part-of-speech) and output tags (parsing), respectively. The tree produced after 3 greedy iterations can be reconstructed as the following: (SQ (VBD Did) (NP (PRP you)) (VP (VB hear) (NP (DT the) (VBG falling) (NNS bombs))) (. ?)).</p><p>fine decoding strategy. The output is then discriminatively reranked <ref type="bibr" target="#b699">(Charniak and Johnson, 2005)</ref> to select the best analysis. In contrast, the parser used in this paper constructs the parse tree in a greedy manner and relies only on word, POS tags and morphological embeddings. Several other papers have reported results for the SPMRL Shared Task 2014. <ref type="bibr" target="#b703">(Hall et al., 2014)</ref> introduced an approach where, instead of propagating contextual information from the leaves of the tree to internal nodes in order to refine the grammar, the structural complexity of the grammar is minimized. This is done by moving as much context as possible onto local surface features. This work was refined in <ref type="bibr" target="#b701">(Durrett and Klein, 2015)</ref>, taking advantage of continuous word representations. The system used in this paper also leverages words embeddings but has two major differences. First, it proceeds step-by-step in a greedy manner <ref type="bibr" target="#b701">(Durrett and Klein, 2015)</ref> by using structured inference (CKY). Second, it leverages a compositional node feature which propagates information from the leaves to internal nodes, which is exactly what is claimed not to be done. <ref type="bibr" target="#b702">(Fernández-González and Martins, 2015)</ref> proposed a procedure to turn a dependency tree into a constituency tree. They showed that encoding order information in the dependency tree make it isomorphic to the constituent tree, allowing any dependency parser to produce constituents. Like the parser we used, their parser do not need to binarize the treebank as most of the others constituency parsers. Unlike this system, we do not use the dependency structure as an intermediate representation and directly perform constituency parsing over raw words.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Recurrent greedy parsing</head><p>In this paper, we used the model presented in <ref type="bibr" target="#b705">(Legrand and Collobert, 2015)</ref>. It is a NN-based model which performs parsing in a greedy recurrent way. It follows a bottom-up iterative procedure: the tree is built starting from the terminal nodes (sentence words), as shown in <ref type="figure" target="#fig_3">Figure 1</ref>. Each step can be seen as a sequence tagging task. A BIOES 1 prefixing scheme is used to rewrite this chunk (here node) prediction problem into a word tagging problem. Each iteration of the procedure merges input constituents into new nodes by applying the following steps:</p><p>• Node tagger: a neural network sliding window is applied over the input sequence of constituents (leaves or heads of trees predicted so far). This procedure (see <ref type="figure" target="#fig_8">Figure  2</ref>) outputs for each constituent a score s i for each BIOES-prefixed parsing tag t ∈ T (T being the parsing tags ensemble).</p><p>• Dynamic programming: a coherent path of BIOES tags is retrieved by decoding over a constrained graph. This insures (for instance) that a B-A can be followed only by a I-A or a E-A (for all parsing tag A).</p><p>• Compositional procedure: new nodes are created, merging input constituents, according to the dynamic programming predictions. A neural network composition module is then used to compute vector representations for the new nodes, according to the representations of the merged constituents, as well as their corresponding tags (POS or parsing).</p><p>The procedure ends when the top node is produced.</p><p>3 Parsing Morphologically Rich Languages    A standard two-layers neural network outputs a score s i for each BIOES-prefixed parsing tag. Additional features can be easily fed to the network. Each category is assigned a new lookup table containing a vector of feature for every possible tag.</p><formula xml:id="formula_267">X i−2 X i−1 X i X i+1 X i+2</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Morphological features</head><p>Morphological features enable the augmentation of input tokens with information expressed at a word level, such as grammatical function or relation to other words. For parsing MRL, they have proven to be very helpful <ref type="bibr" target="#b700">(Cowan and Collins, 2005)</ref>. The SMPRL corpus provides a different set of morphological features associated to the  <ref type="figure" target="#fig_6">Figure 3</ref>: Recursive composition of the morphological feature gender (male (m) / female (f) / not applicable (n/a)). C gen i are the corresponding composition modules. The representation g 2 is first computed using the 3-inputs module C gen 3 . g 4 is obtained by using the 2-inputs module C gen 2 .</p><p>tree terminals (tokens) for every language. These features include morphosyntactic features such as case, number, gender, person and type, as well as specific morphological information such as verbal mood, proper/common noun distinction, lemma, grammatical function. They also include many language-specific features. For more details about the morphological features available, the reader can refer to ).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Morphological Embeddings</head><p>The parser from <ref type="bibr" target="#b705">(Legrand and Collobert, 2015)</ref> relies only on word and tag embeddings. Besides these features, our model takes advantage of additional morphological features. As illustrated in <ref type="figure" target="#fig_8">Figure 2</ref>, each additional feature m is assigned a different lookup table containing morphological feature vectors of size d m . The output vectors of the different morphological lookup-tables are simply concatenated to form the input of the next neural network layer.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Morphological composition</head><p>Morphological features are available only for leaves. To propagate morphological information to the nodes, we take advantage of a composition procedure similar to the one used in <ref type="bibr" target="#b705">(Legrand and Collobert, 2015)</ref> for words and POS. As illustrated in <ref type="figure" target="#fig_6">Figure 3</ref>, every morphological feature m is assigned a set on composition modules C m i which take as input i morphological embeddings  <ref type="table" target="#tab_10">Table 1</ref>: Results for all languages in terms of F1-score, using gold POS and morphological tags. Berkeley+POS and Berkeley RAW are the two baseline system results provided by the organizers of the shared task. Our experiments used an ensemble of 5 models, trained starting from different random initializations.</p><p>of dimension d m . Each composition module perform a matrix-vector operation followed by a nonlinearity</p><formula xml:id="formula_268">C m i (x) = h(M i m .x)</formula><p>where M i m ∈ R dm×idm is a matrix of parameters to be trained and h a pointwise non-linearity function. x = [x 1 ...x i ] is the concatenation of the corresponding input morphological embeddings. Note that given a morphological feature we have a different matrix of weight for every possible size i. In practice most tree nodes do not merge more than a few constituents and we only consider composition sizes &lt; 5.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Experiments</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Corpus</head><p>Experiments were conducted on the SPMRL corpus provided for the Shared Task 2014 . It provides sentences and tree annotations for 9 different languages (Arabic, Basque, French, German, Hebrew, Hungarian, Korean, Polish and Swedish) coming from various sources. For each language, gold part-of-speech and morphological tags are provided. Results for two baseline baseline system are provided in order to evaluate our models.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Setup</head><p>The model was trained using a stochastic gradient descent over the available training data. Hyperparameters were tuned on the provided validation sets. The word embedding size and POS/parsing tag size were set to D W = 100 and D T = 30, respectively. The morphological tag embedding size was set to 10. The window size of the tagger was set to K = 7 and its number of hidden units to 300. All parameters were initialized randomly (including the words embeddings). As suggested in <ref type="bibr" target="#b708">(Plaut and Hinton, 1987)</ref>, the learning rate was divided by the size of the input vector of each layer. We applied the same dropout regularization as in <ref type="bibr" target="#b705">(Legrand and Collobert, 2015)</ref>.   <ref type="table" target="#tab_10">Table 1</ref> compares the performance in F1-score (obtained with the provided EVALB SPMRL tool) of different systems, using the provided gold POS and morphological features. We compare our results with the two baselines provided with the task: (1) Berkeley parser with provided POS Tags (Berkeley+POS). (2) Berkeley Parser in raw mode where the parser do its own POS tagging (Berkeley RAW). We also report the results of the current state-of-the art model for this task . We included the same voting procedure as in citelegrand:2015, using 5 models trained starting from different random initializations. At  <ref type="table" target="#tab_6">Table 3</ref>: Results for all languages in terms of F1-score using predicted POS and morphological tags. Berkeley+POS and Berkeley RAW are the two baseline system results provided by the organizers of the shared task. Our experiments used an ensemble of 5 models, trained starting from different random initializations.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Results</head><p>each iteration of the greedy parsing procedure, the BIOES-tag scores are averaged and the new node representations (words+POS and morphological composition) are computed for each model by composing the sub-tree representations corresponding to the given model, using its own compositional network. One can observe that the proposed model outperforms the best model by 1.1 F1-score on average. Moreover, it yields state-ofthe art performance for 6 among the 9 available languages. Finally, <ref type="table" target="#tab_6">Table 3</ref> compares the performance of different systems for a more realistic parsing scenario where the gold POS and morphological tags are unknown. For these experiments, we use the same tags as in  2 obtained using the freely available tool MarMoT <ref type="bibr" target="#b706">(Mueller et al., 2013)</ref>. We compare our results with the same model as for the the gold tags experiences. Additionnaly, we compare our results with two recent models reporting results for the SPMRL Shared Task 2014. We see that the proposed model yields state-of-the art performance for 4 out of 9 available languages.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Conclusion</head><p>In this paper, we proposed to extend the parser introduced in <ref type="bibr" target="#b705">(Legrand and Collobert, 2015)</ref> by learning morphological embeddings. We take advantage of a recursive procedure to propagate morphological information through the tree during the parsing process. We showed that using the morphological embeddings boosts the F1-score and allows to outperform the current state-of-the-art model on the SPMRL Shared Task 2014 corpus. Moreover, our approach yields state-of-the art performance for a majority of languages.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>EARLY</head><p>First fixation duration w-1 fixation probability w-1 fixation duration First pass duration LATE Total regression-to duration n long regressions to w n refixations Re-read probability n regressions to w</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>BASIC</head><p>Total fixation duration Mean fixation duration n fixations Fixation probability REGFR. n regressions from w n long regressions from w Total regression-from duration CONTEXT w+1 fixation probability w+1 fixation duration w+2 fixation probability w+2 fixation duration w-2 fixation probability w-2 fixation probability NOGAZEB. Word length BNC log frequency w-1 BNC log frequency BNC forward transitional log probability BNC backward transitional log probability NOGAZED. Word length Dundee log frequency w-1 Dundee log frequency Dundee forward transitional log probability Dundee backward transitional log probability the Universal PoS tags . <ref type="figure" target="#fig_3">Figure 1</ref> shows a graphical representation of a secondorder hidden Markov model. Li et al. explore two aspects of type-constrained HMMs for unsupervised PoS tagging: the use of a second-order Markov model, and the use of textual features modeled by maximum entropy emissions. They find that both aspects improve tagging accuracy and report the following results for English using Universal PoS tags on the Penn Treebank: first-order HMM 85.4, first-order HMM with maxent emissions 86.1, second-order HMM 85.0, and second-order HMM with max-ent emissions 87.1. Li et al. employ a set of basic textual features for the max-ent versions, which encode word identity, presence of a hyphen, a capital letter, or a digit, and word suffixes of two to three letters.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Experiments</head><p>Features Based on the eye-movement data in the Dundee Corpus, we compute token-level values for 22 features pertaining to gaze and comple-  <ref type="table" target="#tab_5">Table 2</ref>: Tagging accuracy on the development set (token-level) for all individual feature groups, for the best combination of groups and for the best gaze-only combination of groups. ment them with another nine non-gaze features. Word length and word frequency are known to correlate and interact with gaze features. We use frequency counts from both a large corpus (the British National Corpus, BNC) and the Dundee Corpus itself. From these corpora, we also obtain forward and backward transitional probabilities, i.e., the conditional probabilities of a word given the previous or next word.</p><p>All gaze features are averaged over the ten readers and normalized linearly to a scale between 0 and 1. We divide the set of 31 features, which we list in <ref type="table" target="#tab_10">Table 1</ref>, into the following seven groups in order to examine for their individual contribution:</p><p>1. EARLY measures of processing such as firstpass fixation duration. Fixations on previous words are included in this group due to preview benefits. Early measures capture lexical access and early syntactic processing.</p><p>2. LATE measures of processing such as number of regressions to a word and re-fixation probability. These measures reflect late syntactic processing and disambiguation in general.</p><p>3. BASIC word-level features, e.g., mean fixation duration and fixation probability. These metrics do not belong explicitly to early or late processing measures.</p><p>4. REGFROM includes a small selection of measures based on regressions departing from a token. It also includes counts of long regressions <ref type="bibr" target="#b471">3</ref> . The token of departure of a regression 82.44* <ref type="table" target="#tab_6">Table 3</ref>: Tagging accuracy for the baseline, for models with no text features and for our gazeenriched models using type and token gaze features. Significant improvements over the baseline marked by * (p &lt; 10 −3 , McNemar's test).</p><p>can have syntactic relevance, e.g., in garden path sentences.</p><p>5. CONTEXT features of the surrounding tokens. This group contains features relating to the fixations of the words in near proximity of the token. The eye can only recognize words a few characters to the left, and seven to eight characters to the right of the fixation <ref type="bibr" target="#b720">(Rayner, 1998)</ref>. Therefore it is useful to know the fixation pattern around the token.</p><p>6. NOGAZEBNC includes word length and word frequency obtained from the British National Corpus, as well as forward and backward transitional probabilities. These were computed using the KenLM language modeling toolkit <ref type="bibr" target="#b716">(Heafield, 2011)</ref> with Kneser-Ney smoothing for unseen bigrams.</p><p>7. NOGAZEDUN includes the same features as NOGAZEBNC, but computed on the Dundee Corpus. They were extracted using CMUCambridge language modeling toolkit. <ref type="bibr">4</ref> Setup The Dundee Corpus does not include a standard train-development-test split, so we di- vided it into a training set containing 46,879 tokens/1,896 sentences, a development set containing 5,868 tokens/230 sentences, and a test set of 5,832 tokens/241 sentences.</p><p>To tune the number of EM iterations required for the SHMM-ME model, we ran several experiments on the development set using 1 through 50 iterations. The result is fairly consistent for both the baseline (the original model of ) and the full model (which includes all feature groups in <ref type="table" target="#tab_10">Table 1</ref>). Tagging accuracy as a function of number of iterations is graphed in <ref type="figure" target="#fig_8">Figure 2</ref>. The best number of iterations on the full model is five, which we will use for the remaining experiments.</p><p>We perform a grid search over all combinations of the seven feature groups, using five EM iterations for training, evaluating the resulting models on token-level features of the development set. We observe that the best single feature group is NOGAZEDUN, the best single group of gaze features is BASIC, the best gaze-only group combination is BASIC-LATE and the best group combination is obtained by including all seven feature groups. Using all feature groups outperforms any individual feature group on development data. The performance of all the individual groups and of the best group combinations can be seen in <ref type="table" target="#tab_5">Table 2</ref>. We run experiments on the test set and report results using the best single group (NOGAZEDUN), the best single gaze group (BASIC), the best gazeonly group combination (BASIC-LATE) and the best group combination (all features).</p><p>Following , we contrast the token-level gaze features with features ag-gregated at the type level. Type-level aggregation was used by  for supervised PoS tagging: A lexicon of word types was created and the features values were averaged over all occurrences of each type in the training data.</p><p>As our baseline, we train and evaluate the original model proposed by  on the traintest split described above, and compare it to the models that make use of eye-tracking measures.</p><p>To get an estimate of the effect of the textual features of Li et al., we train a model without these features, labeled NOTEXTFEATS. We also augment this model with the best combination of feature groups.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Results</head><p>The main results are presented in <ref type="table" target="#tab_6">Table 3</ref>. We first of all observe that both typeand token-level gaze features lead to significant improvements over , but typelevel features perform better than token-level. We observe that the best individual feature group, NOGAZEDUN, performs better than the best individual gaze feature group, BASIC and the best gaze-only feature group, BASIC+LATE. This is true on both type and token-level. Using the best combination of feature groups (All features) works best for both type-and token-level features. Also when excluding the textual feature model gaze helps and type-level features also work better than token-level here.</p><p>A feature ablation study (see <ref type="table" target="#tab_42">Table 4</ref>) supports the hierarchical ordering of the features based on the development set results (see <ref type="table" target="#tab_10">Table 1</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Related Work</head><p>The proposed approach continues the work of  by augmenting an unsupervised baseline PoS tagging model instead of a supervised model. Our work also explores the potentials of token-level features. <ref type="bibr" target="#b723">Zelenina (2014)</ref> is the only work we are aware of that uses gaze features for unsupervised PoS tagging. <ref type="bibr" target="#b723">Zelenina (2014)</ref> employs gaze features to re-rank the output of a standard unsupervised tagger. She reports a small improvement with gaze features when evaluating on the Universal PoS tagset, but finds no improvement when using the Penn Treebank tagset.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Discussion</head><p>The best individual feature group is NOGAZE-DUN, indicating that just using word length and word frequency, as well as transitional probabilities, leads to a significant improvement in tagging accuracy. However, performance increases further when we add gaze features, which supports our claim that gaze data is useful for weakly supervising PoS induction.</p><p>Type-level features work noticeably better than token-level features, suggesting that access to eyetracking data at test time is not necessary. On the contrary, our results support the more resourceefficient set-up of just having eye-tracking data available at training time. We assume that this finding is due to the fact that eye-movement data is typically quite noisy; averaging over all tokens of a type reduces the noise more than just averaging over the ten participants that read each token. Thus token-level aggregation leads to more reliable feature values.</p><p>Our finding that the best model includes all groups of gaze features, and that the best gazeonly group combination works better than the best individual gaze group suggest that different eyetracking features contain complementary information. A broad selection of eye-movement features is necessary for reliably identifying PoS classes.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">Conclusions</head><p>We presented the first study of weakly supervised part-of-speech tagging with eye-tracking data, using a type-constrained second-order hidden Markov model with max-ent emissions. We performed experiments adding a broad selection of eye-tracking features at training time (typelevel features) and at test time (token-level features). We found significant improvements over the baseline in both cases, but type averaging worked better than token-level features. Our results indicate that using traces of human cognitive processing, such as the eye-movements made during reading, can be used to augment NLP models. This could enable us to bootstrap better PoS taggers for domains and languages for which manually annotated corpora are not available, in particular once eye-trackers become widely available through smartphones or webcams <ref type="bibr" target="#b721">(Skovsgaard et al., 2013;</ref>.</p><p>balance it with F 1 -score for the "OK" class. However, the widely used weighted average of F 1 -scores for the two classes is not suitable as it will be dominated by F 1 -OK due to labels imbalance. Any reasonable MT system will nowadays generate texts where most words are correct, so the label distribution is very skewed towards the "OK" class. Therefore, we suggest instead the multiplication of F 1 -scores for individual classes: it is equal to zero if one of the components is zero, and since both are in the [0,1] range, the overall result will not exceed the value of any of the multipliers.</p><p>Phrase-level F 1 -scores. One of the features of MT errors is their phrase-level nature. Errors are not independent: one incorrect word can influence the classification of its neighbours. If several adjacent words are tagged as "BAD", they are likely to be part of an error which spans over a phrase.</p><p>Therefore, we also evaluate word-level F 1 -scores and alternative metrics which are based on correctly identified erroneous or error-free spans of words. The phrase-level F 1 -score we suggest is similar to the one used for the evaluation of named entity recognition (NER) systems <ref type="bibr" target="#b732">(Tjong Kim Sang and De Meulder, 2003)</ref>. There, precision is the percentage of named entities found by a system that are correct, recall is the percentage of named entities present in the corpus that are found by a system. For the QE task, instead of named entities we have spans of erroneous (or correct) words. Precision is the percentage of correctly identified spans among all the spans found by a system, recall is the percentage of correctly identified spans among the spans in the test data.</p><p>However, in NER the correct borders of a named entity are of big importance, because failure to identify them results in an incorrect entity. On the other hand, the actual borders of an error span in QE are not as important: the primary goal is to identify the erroneous region in the sentence, the task of finding the exact borders of an error cannot be solved unambiguously even by human annotators <ref type="bibr" target="#b733">(Wisniewski et al., 2013)</ref>. In order to take into account partially correct phrases (e.g. a 4-word "BAD" phrase where the first word was tagged as "OK" by a system and the remaining words were correctly tagged as "BAD"), we compute the number of true positives as the sum of percentages of words with correctly predicted tags for every "OK" phrase. The number of true negatives is defined analogously.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Other metrics</head><p>Matthews correlation coefficient. MCC (Powers, 2011) was used as a secondary metric in WMT14 word-level QE shared task <ref type="bibr" target="#b724">(Bojar et al., 2014)</ref>. It is determined as follows:</p><p>M CC = T P × T N + F P × F N (T P + F P )(T P + F N )(T N + F P )(T N + F N )</p><p>where T P , T N , F P and F N are true positive, true negative, false positive and false negative values, respectively. This coefficient results in values in the [-1, 1] range. If the reference and hypothesis labellings agree on the majority of the examples, the final figure is dominated by the T P × T N quantity, which gets close to the value of the denominator. The more false positives and false negatives the predictor produces, the lower the value of the numerator.</p><p>Sequence correlation. The sequence correlation score was used as a secondary evaluation metric in the QE shared task at WMT15 <ref type="bibr" target="#b725">(Bojar et al., 2015)</ref>. Analogously to the phrase-level F 1 -score, it is based on the intersection of spans of correct and incorrect words. It also weights the phrases to give them equal importance and penalises the difference in the number of phrases between the reference and the hypothesis.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Metrics comparison</head><p>One of the most reliable ways of comparing metrics is to measure their correlation with human judgements. However, for the word-level QE task, asking humans to rate a system labelling or to compare the outputs of two or more QE systems is a very expensive process. A practical way of getting the human judgements is the use of quality labels in downstream human tasks -i.e. tasks where quality labels can be used as additional information and where they can influence human accuracy or speed. One such a downstream task can be computer-assisted translation, where the user translates a sentence having automatic translation as a draft, and word-level quality labels can highlight incorrect parts in a sentence. Improvements in productivity could show the degree of usefulness of the quality labels in this case. However, such an experiment is also very expensive to be performed. Therefore, we consider indirect ways of comparing the metrics' reliability based on prelabelled gold-standard test sets.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Comparison on real systems</head><p>One of the purposes of system comparison is to identify the best-performing system. Therefore, we expect a good metric to be able to distinguish between systems as well as possible. One of the quality criteria for a metric will thus be the number of significantly different groups of systems the metric can identify. Another criterion to evaluate metrics is to compare the real systems' performance with synthetic datasets for which we know the desirable behaviour of the metrics. If a metric gives the expected scores to all artificially generated datasets, it detects some properties of the data which are relevant to us, so we can expect it to work adequately also on real datasets.</p><p>Here we compare the performance of six metrics:</p><p>• F 1 -BAD -F 1 -score for the "BAD" class.</p><p>• F 1 -mult -multiplication of F 1 -scores for "BAD" and "OK" classes.</p><p>• phr F 1 -BAD -phrase-level F 1 -score for the "BAD" class.</p><p>• phr F 1 -mult -multiplication of phraselevel F 1 -scores.</p><p>• MCC -Matthews Correlation Coefficient.</p><p>• SeqCor -Sequence Correlation.</p><p>We used these metrics to rank all systems submitted to the WMT15 QE shared task 2 (wordlevel QE). <ref type="bibr">2</ref> In addition to that, we test the performance of the metrics on a number of synthetically created labellings that should be ranked low in comparison to real system labellings:</p><p>• all-bad -all words are tagged as "BAD".</p><p>• all-good -all words are tagged as "OK".</p><p>• optimistic -98% words are tagged as "OK", with only a small number of "BAD" labels generated: this system should have high precision (0.9) and low recall (0.1) for the "BAD" label.</p><p>• pessimistic -90% words are tagged as "BAD": this system should have high recall (0.9) for the "BAD" label, but low recall (0.1) for the "OK" label.</p><p>• random -labels are drawn randomly from the label probability distribution.</p><p>We rank the systems according to all the metrics and compute the level of significance for every <ref type="bibr">2</ref> Systems that took part in the shared task are listed and described in <ref type="bibr" target="#b725">(Bojar et al., 2015)</ref>. pair of systems with randomisation tests <ref type="bibr" target="#b734">(Yeh, 2000)</ref> with Bonferroni correction <ref type="bibr">(Abdi, 2007)</ref>. In order to evaluate the metrics' performance we compute the system distinction coefficient d -the probability of two systems being significantly different, which is defined as the ratio between the number of significantly different pairs of systems and all pairs of systems. We also compute d for the top half and for the bottom half of the ranked systems list separately in order to check how well each metric can discriminate between better performing and worse performing systems. <ref type="bibr" target="#b471">3</ref> The results are shown in <ref type="table" target="#tab_10">Table 1</ref>. For every synthetic dataset we show the number of real system outputs that were rated lower than this dataset, with the rightmost column showing the sum of this figure across all the synthetic sets.</p><p>We can see that three metrics are better at distinguishing synthetic results from real systems: SeqCor and both multiplied F 1 -scores. In the case of SeqCor this result is explained by the fact that it favours longer spans of "OK" and "BAD" labels and thus penalises arbitrary labellings. The multiplications of F 1 -scores have two components which penalise different labellings and balance each other. This assumption is confirmed by the fact that F 1 -BAD scores become too pessimistic without the "OK" component: they both favour synthetic systems with prevailing "BAD" labels. Phrase-F 1 -BAD ranks these systems the highest: all-bad and pessimistic outperform 16 out of 17 systems according to this metric.</p><p>MCC is, in contrast, too 'optimistic': the optimistic dataset is rated higher than most of system outputs. In addition to that, it is not good at distinguishing different systems: its system distinction coefficient is the lowest among all metric. SeqCor and phrase-F 1 -multiplied, despite identifying artificial datasets, cannot discriminate between real systems: SeqCor fails with the top half systems, phrase-F 1 -multiplied is bad at finding differences in the bottom half of the list.</p><p>Overall, F 1 -multiplied is the only metric that performs well both in the task of distinguishing  <ref type="table" target="#tab_10">Table 1</ref>: Results for all metrics. Numbers in synthetic dataset columns denote the number of system submissions that were rated lower than the corresponding synthetic dataset.</p><p>synthetic systems from real ones and in the task of discriminating among real systems, despite the fact that its d scores are not the best. However, F 1 -BAD is not far behind: it has high values for d scores and can identify synthetic datasets quite often.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Comparison on synthetic datasets</head><p>The experiment described above has a notable drawback: we evaluated metrics on the outputs of systems which had been tuned to maximise the F 1 -BAD score. This means that the system rankings produced by other metrics may be unfairly considered inaccurate. Therefore, we suggest a more objective metric evaluation procedure which uses only synthetic datasets. We generate datasets with different proportion of errors, compute the metrics' values and their statistical significance and then compare the metrics' discriminative power. This procedure is further referred to as repeated sampling, because we sample artificial datasets multiple times.</p><p>Our goal is for the synthetic datasets to simulate real systems' output. We achieve this by using the following procedure for synthetic data generation:</p><p>• Choose the proportion of errors to introduce in the synthetic data.</p><p>• Collect all sequences that contain incorrect labels from the outputs of real systems.</p><p>• Randomly choose the sequences from this set until the overall number of errors reaches the chosen threshold.</p><p>• Take the rest of segments from the goldstandard labelling (so that they contain no errors).</p><p>Thus our artificial datasets contain a specific number of errors, and all of them come from real systems. We can generate datasets with very small differences in quality and identify metrics according to which this difference is more significant. Let us compare the discriminative power of metrics m 1 and m 2 . We choose two error thresholds e 1 and e 2 . Then we sample a relatively small number (e.g. 100) of random datasets with e 1 errors. Then -100 random datasets with e 2 errors. We compute the values for both metrics on the two sets of random samples and for each metric we test if the difference between the results for the two sets is significant (we compute the statistic significance using non-paired t-test with Bonferroni correction). Since we sampled the synthetic datasets a small number of times it is likely that the metrics will not detect any significant differences between them. In this case we repeat the process with a larger (e.g. 200) number of samples and compare the p-values for two metrics again. By gradually increasing the number of samples at some point we will find that one of the metrics recognises the differences in scores as statistically significant, while another one does not. This means that this metric has higher discriminative power: it needs less samples to determine that the systems they are different. The procedure is outlined in Algorithm 1.</p><p>In our experiments in order to make p-values more stable we repeat each sampling round (sampling of a set with e i errors 100, 200, etc. times) 1,000 times and use the average of p-values. We used fixed sets of sample numbers: <ref type="bibr">[100,</ref><ref type="bibr">200,</ref><ref type="bibr">500,</ref><ref type="bibr">1000,</ref><ref type="bibr">2000,</ref><ref type="bibr">5000,</ref><ref type="bibr">10,</ref><ref type="bibr">000]</ref>  5000 1000 500 200 SeqCor 10000 5000 5000 1000 500 500 phr F 1 -BAD 10000 10000 5000 1000 500 500 needs to observe significant differences between datasets which differ in this number of errors. Table 2 shows the results. Numbers in cells are minimum numbers of samplings. We do not show error differences greater than 0.2 because all metrics identify them well. All metrics are sorted by discriminative power from best to worst, i.e. metrics at the top of the table require less samplings to tell one synthetic dataset from another.</p><p>As in the previous experiment, here the discriminative power of the multiplication of F 1 -scores is the highest. Surprisingly, MCC performs equally well. Similarly to the experiment with real systems, the F 1 -BAD metric performs worse than the F 1 -multiply metric, but here their difference is more salient. All phrase-motivated metrics show worse results.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Conclusions</head><p>The aim of this paper was to compare evaluation metrics for word and phrase-level quality estimation and find an alternative for F 1 -BAD score, which has been used as primary metric in recent research but has a number of drawbacks, in particular tendency to overrate labellings with predominantly"BAD" instances.</p><p>We found that the multiplication of F 1 -BAD and F 1 -OK scores is more stable against "pessimistic" labellings and has bigger discriminative power when comparing synthetic datasets. However, other tested metrics, including advanced phrase-based scores, could not outperform F 1 -BAD.</p><p>This work should be seen as a proxy for real user evaluation of word-level QE metrics, which could be done on downstream tasks (e.g. computer-assisted translation).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>After the Nuremberg trials revealed the atrocities conducted in medical research by the Nazis, medical sciences established a set of rules to determine whether an experiment is ethical. This involved incorporating the principles of biomedical ethics as a lingua franca of medical ethics <ref type="bibr" target="#b742">(Beauchamp and Childress, 2001)</ref>.</p><p>These guidelines were designed to balance the potential value of conducting an experiment while preventing the exploitation of human subjects. Today, any responsible research institution uses these-or comparable-criteria to approve or reject experiments before any research can be conducted. The administrative body governing these decisions is the Institutional Review Board (IRB).</p><p>IRBs mostly pertain to experiments that directly involve human subjects, though, and so NLP and other data sciences have not employed such guidelines. Work on existing corpora is unlikely to raise any flags that would require an IRB approval. 1 Data sciences have therefore traditionally been less engaged in ethical debates of their subject, even though this seems to be shifting, see for instance <ref type="bibr" target="#b804">Wallach (2014)</ref>, <ref type="bibr" target="#b752">Galaz et al. (2015)</ref>, or O'Neil (2016). The public outcry over the "emotional contagion" experiment on Facebook <ref type="bibr" target="#b766">(Kramer et al., 2014)</ref> further suggests that data sciences now affect human subjects in real time, and that we might have to reconsider the application of ethical considerations to our research <ref type="bibr" target="#b786">(Puschmann and Bozdag, 2014)</ref>. NLP research not only involves similar data sets, but also works with their content, so it is time to start a discussion of the ethical issues specific to our field.</p><p>Much of the ethical discussion in data sciences to date, however, has centered around privacy concerns <ref type="bibr" target="#b798">(Tse et al., 2015)</ref>. We do not deny the reality and importance of those concerns, but they involve aspects of digital rights management/access control, policy making, and security, which are not specific to NLP, but need to be addressed in the data sciences community as a whole. Steps towards this have been taken by <ref type="bibr" target="#b789">Russell et al. (2015)</ref>.</p><p>Instead, we want to move beyond privacy in our ethical analysis and look at the wider social impact NLP may have. In particular, we want to explore the impact of NLP on social justice, i.e., equal opportunities for individuals and groups (such as minorities) within society to access resources, get their voice heard, and be represented in society.</p><p>Our contributions We believe ethical discussions are more constructive if led by practitioners, since the public discussion of ethical aspects of IT and data sciences is often loaded with fear of the unknown and unrealistic expectations. For example, in the public discourse about AI <ref type="bibr" target="#b759">(Hsu, 2012;</ref><ref type="bibr" target="#b748">Eadicicco, 2015;</ref><ref type="bibr" target="#b764">Khatchadourian, 2015)</ref>, people either dismiss the entire approach, or exaggerate the potential dangers (see <ref type="bibr" target="#b749">Etzioni (2014)</ref> for a practioner's view point). This paper is an attempt to take back the initiative for NLP.</p><p>At the same time, we believe that the field of ethics can contribute a more general framework, and so this paper is an interdisciplinary collaboration between NLP and ethics researchers.</p><p>To facilitate the discussion, we also provide some of the relevant terminology from the literature on ethics of technology, namely the concepts of exclusion, overgeneralization, bias confirmation, topic under-and overexposure, and dual use.</p><p>2 Does NLP need an ethics discussion?</p><p>As discussed above, the makeup of most NLP experiments so far has not obviated a need for ethical considerations, and so, while we are aware of individual discussions <ref type="bibr" target="#b795">(Strube, 2015)</ref>, there is little discourse in the community yet. A search for "ethic*" in the ACL anthology only yields three results. One of the papers <ref type="bibr" target="#b770">(McEnery, 2002)</ref> turns out to be a panel discussion, another is a book review, leaving only <ref type="bibr" target="#b746">Couillault et al. (2014)</ref>, who devote most of the discussion to legal and quality issues of data sets. We know social implications have been addressed in some NLP curricula, 2 but until now, no discipline-wide discussion seems to take place.</p><p>The most likely reason is that NLP research has not directly involved human subjects. <ref type="bibr" target="#b471">3</ref> Historically, most NLP applications focused on further enriching existing text which was not strongly linked to any particular author (newswire), was usually published publicly, and often with some temporal distance (novels). All these factors created a distance between text and author, which prevented the research from directly affecting the authors' situation.</p><p>hakaran <ref type="bibr" target="#b799">Tsur et al., 2015;</ref><ref type="bibr">Khouzami et al., 2015, inter alia)</ref>, .</p><p>The mutual relationships between language, society, and the individual are also the source for the societal impact factors of NLP: failing to recognize group membership (Section 3.1), implying the wrong group membership (see Section 3.2), and overexposure <ref type="figure" target="#fig_6">(Section 3.3)</ref>. In the following, we discuss sources of these problems in the data, modeling, and research design, and suggest possible solutions to address them.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Exclusion</head><p>As a result of the situatedness of language, any data set carries a demographic bias, i.e., latent information about the demographics in it. Overfitting to these factors can have have severe effects on the applicability of findings. In psychology, where most studies are based on western, educated, industrialized, rich, and democratic research participants (so-called WEIRD, <ref type="bibr" target="#b754">Henrich et al. (2010)</ref>), the tacit assumption that human nature is so universal that findings on this group would translate to other demographics has led to a heavily biased corpus of psychological data. In NLP, overfitting to the demographic bias in the training data is due to the i.i.d. assumption. I.e., models implicitly assume all language to be identical to the training sample. They therefore perform worse or even fail on data from other demographics.</p><p>Potential consequences are exclusion or demographic misrepresentation. This in itself already represents an ethical problem for research purposes, threatening the universality and objectivity of scientific knowledge <ref type="bibr" target="#b771">(Merton, 1973)</ref>. These problems exacerbate, though, once they are applied to products. For instance, standard language technology may be easier to use for white males from California (as these are taken into account while developing it) rather than women or citizens of Latino or Arabic descent. This will reinforce already existing demographic differences, and makes technology less user friendly for such groups, cf. authors like <ref type="bibr" target="#b743">Bourdieu and Passeron (1990)</ref> have shown how restricted language, like class specific language or scientific jargon, can hinder the expression of outsiders' voices from certain practices. A lack of awareness or decreased attention for demographic differences in research stages can therefore lead to issues of exclusion of people along the way.</p><p>Concretely, the consequences of exclusion for NLP research have recently been pointed out by  and <ref type="bibr" target="#b763">Jørgensen et al. (2015)</ref>: current state-of-the-art NLP models score a significantly lower accuracy for young people and ethnic minorities vis-à-vis the modeled demographics.</p><p>Better awareness of these mechanism in NLP research and development can help prevent problems further on. Potential counter-measures to demographic bias can be as simple as downsampling the over-represented group in the training data to even out the distribution. The work by <ref type="bibr" target="#b773">Mohammady and Culotta (2014)</ref> shows another approach, by using existing demographic statistics as supervision. In general, measures to address overfitting or imbalanced data can be used to correct for demographic bias in data.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Overgeneralization</head><p>Exclusion is a side-effect of the data. Overgeneralization is a modeling side-effect.</p><p>As an example, we consider automatic inference of user attributes, a common and interesting NLP task, whose solution also holds promise for many useful applications, such as recommendation engines and fraud or deception detection <ref type="bibr" target="#b741">Banerjee et al., 2014)</ref>.</p><p>The cost of false positives seems low: we might be puzzled or amused when receiving an email addressing us with the wrong gender, or congratulating us to our retirement on our 30th birthday.</p><p>In practice, though, relying on models that produce false positives may lead to bias confirmation and overgeneralization. Would we accept the same error rates if the system was used to predict sexual orientation or religious views, rather than age or gender? Given the right training data, this is just a matter of changing the target variable.</p><p>To address overgeneralization, the guiding question should be "would a false answer be worse than no answer?" We can use dummy variables, rather than take a tertium non datur approach to classification, and employ measures such as error weighting and model regularization, as well as confidence thresholds.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">The problem of exposure</head><p>Topic overexposure creates biases Both exclusion and overgeneralization can be addressed algo- . B shows the initial similarity network with all nodes connected. C shows the network after filtering, and D shows the network after applying the partitioning algorithm.</p><p>(2014b). As a general rule, language-specific approaches outperform language-independent ones, provided the sample size is large enough <ref type="bibr" target="#b823">(List 2014a)</ref>. Two similarity measures are used in this paper, one language-independent, and one languagespecific one. The above-mentioned SCA method for phonetic alignments <ref type="bibr" target="#b822">(List 2012b</ref><ref type="bibr" target="#b824">(List , 2014b</ref> reduces the phonetic space of sound sequences to 28 sound classes. Based on a scoring function which defines transition scores between the sound classes, phonetic sequences are aligned and similarity and distance scores can be determined. The LexStat approach <ref type="bibr" target="#b821">List (2012a</ref><ref type="bibr" target="#b824">List ( , 2014b</ref>) also uses sound classes, but instead of using a pre-defined scoring function, transition scores between sound classes are determined with help of a permutation test. In this test, words drawn from a randomized sample are repeatedly aligned with each other in order to create a distribution of sound transitions for unrelated languages. This distribution is then compared with the actual distribution retrieved from aligned words in the word list, and a language-specific scoring function is created <ref type="bibr" target="#b824">List (2014b)</ref>. SCA is very fast in computation, but LexStat has a much higher accuracy. Both approaches are freely available as part of the LingPy software package <ref type="bibr" target="#b827">(List and Forkel 2016)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Sequence Similarity Networks</head><p>Sequence similarity networks are tools for exploratory data analysis. In evolutionary biology they are used to study complex evolutionary processes <ref type="bibr" target="#b812">, Corel et al. 2016</ref>. They represent sequences as nodes and connections between nodes represent similarities which are usually determined from similarity scores exceeding a certain threshold <ref type="bibr" target="#b806">(Alvarez-Ponce et al. 2013)</ref>. Since evolutionary processes leave specific traces in the network topology, they can be identified by applying techniques for network analysis. In linguistics, sequence similarity networks have been rarely applied , although they are applicable, provided that one uses informed measures for phonetic similarity.</p><p>For the application of sequence similarity networks it is essential to decide when to draw an edge between two nodes and when not. For the new approach to partial cognate detection, three filtering criteria are applied. (1) No edges are drawn between morphemes which occur in the same word.</p><p>(2) No morpheme in one word is linked to two morphemes in another word, with the preference given to morpheme pairs with the lowest phonetic distance applying a greedy strategy. (3) Edges are only drawn when the phonetic distance between the morphemes is beyond a certain threshold. The application of the filtering criteria is illustrated in <ref type="figure" target="#fig_3">Fig. 1</ref> for the exemplary words shown in <ref type="table" target="#tab_10">Table 1</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Network Partitioning</head><p>Cognate morphemes in a similarity network can be found by partitioning the network into groups. Many algorithms are available for this purpose, as can be seen from evolutionary biology, where homology detection is frequently approached from a network perspective <ref type="bibr" target="#b841">(Vlasblom and Wodak 2009)</ref>. Three different algorithms were tested for this purpose. A flat version of the UPGMA algorithm for hierarchical clustering <ref type="bibr">(Sokal and Mich-ener 1958)</ref>, which terminates when a certain userdefined threshold is reached is originally underlying the LexStat algorithm and was therefore also included in this study. Markov Clustering (van Dongen 2000) uses techniques for matrix multiplication to inflate and expand the edge weights in a given network until weak edges have disappeared and a few clusters of connected nodes remain. Markov Clustering is very popular in biology and was shown to outperform the popular Affinity Propagation algorithm <ref type="bibr" target="#b814">(Frey and Dueck 2007)</ref> in the task of homolog detection in biology <ref type="bibr" target="#b841">(Vlasblom and Wodak 2009)</ref>. As a third method, we follow <ref type="bibr" target="#b828">List et al. (2016b)</ref> in testing Infomap <ref type="bibr" target="#b833">(Rosvall and Bergstrom 2008)</ref>, a method that was originally designed to detect communities in complex networks. Communities are groups that share more links with each other than outside the group <ref type="bibr" target="#b832">(Newman and Girvan 2004)</ref>. Infomap uses random walks to find the best partition of a network into communities. Infomap is not a classical partitioning algorithm, and we do not know of any studies which tested its suitability for the task of homolog detection in evolutionary biology, but according to <ref type="bibr" target="#b828">List et al. (2016b)</ref>, Infomap shows a better performance than UPGMA in automatic cognate detection.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">Analyses and Evaluation</head><p>All methods, be it classical or partial cognate detection, require a user-defined threshold. Since our gold standard data was too small to split it into training and tests sets, we carried out an exhaustive comparison of all methods on different thresholds varying between 0.05 and 0.95 in steps of 0.05. B-cubed scores were chosen as an evaluation measure for cognate detection <ref type="bibr" target="#b808">(Bagga and Baldwin 1998)</ref>, since they have been shown to yield sensible results <ref type="bibr" target="#b817">(Hauer and Kondrak 2011)</ref>.</p><p>With SCA and LexStat, two classical methods for cognate detection were tested <ref type="bibr" target="#b824">List (2014b)</ref>, and their underlying models for phonetic similarity (see Sec. 3.1) were used as basis for the partial cognate detection algorithm. All in all, this yielded four different methods: LexStat, LexStatPartial, SCA, and SCA-Partial. Since our new algorithms yield partial cognates, while LexStat and SCA yield``complete" cognates, it is not possible to compare them directly. In order to allow for a direct comparison, partial cognate sets were converted into``complete" cognate sets using the above-mentioned strict coding approach proposed by Ben Hamed and <ref type="bibr" target="#b842">Wang (2006)</ref>: only those words in which all morphemes are cognate were assigned to the cognate same set. With a total of three different clustering algorithms (UPGMA, Markov Clustering, and Infomap), we thus carried out twelve tests on complete cognacy (three for each of our four approaches), and six additional tests on pure partial cognate detection, in which we compared the suitability of SCA and LexStat as string similarity measures.  <ref type="table" target="#tab_6">Table 3</ref>: General performance of the algorithms on all datasets. The table shows for each of the 18 different methods the threshold (T) for which the best B-Cubed F-Score was determined, as well as the B-Cubed precision (P), recall (R), and F-score (FS). The best result in each block is shaded in gray. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.5">Implementation</head><p>The code was implemented in Python, as part of the LingPy library (Version 2.5, <ref type="bibr" target="#b827">List and Forkel (2016)</ref>, http://lingpy.org). The Igraph software package <ref type="bibr" target="#b813">(Csárdi and Nepusz 2006</ref>) is needed to apply the Infomap algorithm.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Results</head><p>The aggregated results of the test (thresholds, precision, recall, and F-scores) are given in <ref type="table" target="#tab_6">Table  3</ref>, specific results for the comparison of LexStat with LexStat-Partial are given in <ref type="table" target="#tab_6">Table 3</ref>. In general, one can clearly see that the partial cognate detection algorithms outperform their nonpartial counterparts when applying the complete cognacy measure. The differences are very striking, with LexStat-Partial outperforming its nonpartial counterpart by up to four points, and SCAPartial outperforming the classical SCA variant by almost five points. <ref type="bibr">2</ref> In contrast, we do not find strong differences in the performance of the cluster algorithms. Infomap outperforms the other cluster algorithms in almost all tests (all other aspects being equal), but the differences are not high enough to make any further conclusions at this point. When comparing the aggregated results for the true evaluation of partial cognate detection (the last two blocks in <ref type="figure" target="#fig_8">Figure 2</ref>), the scores are less high than in the complete cognate analyses. Given that we cannot detect any striking tendency, like a drastic drop of precision or recall, this suggests that the algorithms generally loose accuracy in the task of``true" partial cognate detection. This is surely not surprising, since the task of detecting exactly which morphemes in the data are historically related is much more complex than the task of detecting which words are completely cognate.</p><p>2 By one point, we mean 0.01 on the B-Cube scale.</p><p>In <ref type="figure" target="#fig_8">Figure 2</ref>, detailed analyses for the LexStat analyses with complete cognate evaluation (the first and the third block in <ref type="table" target="#tab_6">Table 3</ref>) are shown for each of the datasets, and throughout all thresholds we tested. The superior performance of the partial cognate detection variants is reflected in all datasets. That the internal diversity of the Chinese languages largely exceeds Bai and Tujia can be seen from the generally lower scores which all algorithms achieve for the datasets.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Discussion</head><p>This paper has presented a pilot approach for the detection of partial cognates in multilingual word lists. Although the results are very promising at this stage, we can think of many points where improvement is needed, and further studies are needed to fully assess the potential of the current approach. First, it should be tested on additional datasets, and ideally also on language families other than Sino-Tibetan. Second, since our approach is very general, it can easily be adjusted to employ different string similarity measures or different partitioning algorithms, and it would be interesting to see whether alternative measures can improve upon our current version.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: The improvement in labeled attachment score as a result of adding gold topological fields to the parser by dependency length.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>2 F / l Figure 1 :</head><label>2l1</label><figDesc>Figure 1: Matrix sketching algorithm by Liberty (2013). In the output, X ∈ R n×d denotes the data matrix with rows x 1 . . . x n .</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: The best-performing approaches on user engagement prediction as a function of k (number of recommendations). The ordering of methods is consistent across k.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: Performance on friend recommendation varying k.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Length distribution in experimental datasets.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: Accuracies of segments of different lengths.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Relation between log document frequency and expansion mass. One dot represents one word.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_10"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: Impact of the noise parameter p on the average accuracy for the 12 Amazon adaptation tasks. Both MDA and its extension with the regularization (MDA+TR) perform better with a high dropout-out noise. Here MDA+TR is run with fixed parameters α = 100 and λ = 1.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_12"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: The sentence is modeled with an LSTM in each direction whose input vectors at each time step are word and part-of-speech tag embeddings.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_13"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: In the 2-Layer architecture, the output of each LSTM layer is concatenated to create the positional feature vector.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_14"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: The arc-standard dependency parsing system (Nivre, 2008) (re omitted). Stack S is a list of heads, j is the start index of the queue, and s 0 and s 1 are the top two head indices on S.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_15"><head>SFigure 4 :</head><label>4</label><figDesc>Figure 4: Our shift-promote-adjoin system for constituency parsing (adj omitted).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_17"><head>Figure 6 :</head><label>6</label><figDesc>Figure 6: Recall on dependency arcs of various lengths in PTB dev set. The Bi-LSTM parser is particularly good at predicting longer arcs.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_18"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: (a) : Word alignment from EM training for Arabic (transliterated) -English sentence pair. (b): Phrase segmentations and alignments from forced decoding. (c): Phrase segmentations and alignments from oracle BLEU re-estimation. Blocks represent phrase boundaries.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_20"><head></head><label></label><figDesc>an Italian restaurant near the river.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_21"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Example DA (top) with the corresponding deep syntax tree (middle) and natural language string (bottom)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_22"><head>Figure 2 :Figure 3 :Figure 4 :</head><label>234</label><figDesc>Figure 2: Trees encoded as sequences for the seq2seq generator (top) and the reranker (bottom)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_23"><head>Figure 1 Figure 1 :</head><label>11</label><figDesc>Figure 1: D t 0 (y-axis) as a function of t 0 (x-axis), values of D t 0 (in green) and error-bars.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_24"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: Distribution of Coefficients α (top) and R 2 values (bottom) in regression of values D t 0 (w) on t 0 . The plots are histograms: y-axes are frequencies.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_25"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: An illustration of our model for event trigger extraction (here the trigger candidate is "release"). F v and B v are the output of Bi-LSTM and C 2 , C 3 are the output of CNN with convolutional filters with widths of 2 and 3.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_30"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Evaluation Interface</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_31"><head>Figure 2 :Figure 3 :</head><label>23</label><figDesc>Figure 2: Inter-annotator agreement at different stages of evaluation process</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_32"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Examples of cross-lingual projection for numeric entities.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_33"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: This FST is a small excerpt of the full grammar for TIME. Arc weights are not shown.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_34"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: (a) an example of a constituent tree with head annotations denoted by -H; (b) spinal elementary trees extracted from the parse tree (a).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_35"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: An example of parser operations: (a) sister adjunction left (b) regular adjunction right (c) insert left (d) combine right.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_36"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: A phrasal empty spine shown on the shaded region.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_37"><head>Figure 4 :</head><label>4</label><figDesc>Figure 4: Scatter plot of parsing time against sentence length, comparing with Hayashi16, Berkeley and Cai11 parsers.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_38"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Training time vs F 1 performance.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_39"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: F1 performance with varying query length.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_40"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Learning curves for the mean ranks on the training set for WordNet (left) and Freebase (right).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_42"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: The learning curve on the development set. An epoch means a complete update through the full training set. single system dev. test Moses from Cho et al. (2014) N/A 33.30</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_43"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: TBCNN-pair model. (a) Individual sentence modeling via tree-based convolution. (b) Sentence pair modeling with heuristics, after which a softmax layer is applied for output.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_44"><head></head><label></label><figDesc>://nlp.stanford.edu/projects/snli/</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_45"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: Validation accuracy versus dropout rate (full TBCNN-pair model).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_46"><head>P</head><label></label><figDesc>Blunsom, T Cohn, S Goldwater, and M Johnson. 2009. A note on the implementation of hierarch- ical Dirichlet processes. In Proceedings of the ACL- IJCNLP 2009 Conference Short Papers, pages 337- 340. Association for Computational Linguistics. C Chelba, T Mikolov, M Schuster, Q Ge, T Brants, P Koehn, and T Robinson. 2013. One billion word benchmark for measuring progress in statistical lan- guage modeling. Technical Report Google Tech Re- port 41880. JT Goodman. 2001. A bit of progress in lan- guage modeling. Computer Speech &amp; Language, 15(4):403-434. ZS Harris. 1954. Distributional structure. Word. R Kneser and H Ney. 1995. Improved backing-off for m-gram language modeling. In In Proceedings of the IEEE International Conference on Acoustics, Speech and Signal Processing, volume I, pages 181- 184, May. DJC MacKay and LCB Peto. 1995. A hierarchical Dirichlet language model. Natural language engin- eering, 1(3):289-308. N Oostdijk. 2000. The spoken Dutch corpus. Over- view and first evaluation. In LREC. R Pickhardt, T Gottron, M Körner, PG Wagner, T Speicher, and S Staab. 2014. A generalized lan- guage model as the combination of skipped n-grams and modified Kneser-Ney smoothing. arXiv pre- print arXiv:1404.3377. M Sahlgren. 2008. The distributional hypothesis. Italian Journal of Linguistics, 20(1):33-54. N Shazeer, J Pelemans, and C Chelba. 2015. Sparse non-negative matrix language modeling for skip- grams. In Proceedings of Interspeech, pages 1428- 1432. R Steinberger, B Pouliquen, A Widiger, C Ignat, T Er- javec, D Tufis, and D Varga. 2006. The JRC- Acquis: A multilingual aligned parallel corpus with 20+ languages. Proceedings of the 5th International Conference on Language Resources and Evaluation.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_48"><head></head><label></label><figDesc>: binary type-level judgments for 3,078 English phrasal verbs, from which 14% are considered idiomatic. • McCarthy et al. (2003): type-based scores on a scale from 0 to 10 provided by three experts for 116 En- glish phrasal verbs. • Reddy et al. (2011): average of 30 judgments on a scale from 0 to 5 provided by native speakers via crowdsourcing for 90 English noun compounds. • Gurrutxaga and Alegria (2013): three-way classifi- cation (idiom, collocation, free combination) pro- vided by three experts for 1,200 Basque noun-verb expressions. • Roller et al. (2013): average of around 30 judgments on a scale from 1 to 7 obtained through crowdsourc- ing for 244 German noun compounds. • Farahmand et al.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_49"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Evaluating compositionality regarding a compounds' head.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_50"><head></head><label></label><figDesc>. The largest variations are for modifiers, which may reflect their potentially accessory role in the meaning of the compound in relation to the head.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_52"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: Average compositionality for compounds, heads and modifiers.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_53"><head></head><label></label><figDesc>±0.0 5.0 ±0.0 5.0 ±0.0 tartaruga-marinha 5.0 ±0.0 5.0 ±0.0 5.0 ±0.0 vôo internacional 5.0 ±0.0 5.0 ±0.0 5.0 ±0.0</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_54"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Toy speech2sign application definition.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_55"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Token-based OOV rate as a function of the extended vocabulary size for Turkish</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_56"><head>Figure 2 :Figure 3 :</head><label>23</label><figDesc>Figure 2: Token-based OOV reduction rate for 50k word expansion as a function of type/token ratio</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_57"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Example images for several languages. classification task (Deng et al., 2009; Russakovsky et al., 2015) using Caffe (Jia et al., 2014). Each image is thus represented as a 4096-dimensional feature vector extracted from a convolutional neural network (CNN). We use two methods for computing visual similarity: (1) CNN-MAX produces a single visual vector by taking the pointwise maximum across the n image vector representations from the image set. The representation of each word w ∈ V S ∪ V T in a visual SCLVS is now a real-valued vector w vis = [f vis 1 , . . . , f vis dv ], where f vis</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_58"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Karma value distributions in the CMV dataset. Feature Category Feature Name Feature Description</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_59"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: Results using various number of comments in the thread for ranking.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_61"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Bidirectional LSTM model with Attention</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_62"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: Schematic representation of DAN. For simplicity, the prediction process is only illustrated for has_tail</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_63"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Our model.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_64"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: System architecture of the proposed regional CNN-LSTM model.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_65"><head></head><label></label><figDesc>, where |V| is the vocabulary size of a region, and d is the dimensionality of word vec- tors. For example, in Fig.1, the word vectors in the</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_66"><head></head><label></label><figDesc>and b respectively denote the weight matrix and bias, ω is the length of the filter, d is the dimen- sion of the word vector, and f is the ReLU func- tion. When a filter gradually traverses from x1:ω-1 to xN+ω-1:N, we get the output featureof filter Fl. Given varying text lengths in the regions, y l may have different dimensions for different texts. Therefore, we de- fine the maximum length of the CNN input in the corpora as the dimension N. If the input length is shorter than N, then several random vectors with a uniform distribution U(-0.25, 0.25) will be ap- pended.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_67"><head>.Figure 2 :</head><label>2</label><figDesc>Figure 2: Game state features.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_68"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Descriptions for Activision Blizzard</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_69"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: A screenshot from our annotation task.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_70"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: The performance of existing methods on our dataset. All methods are run on top of the lemma baseline. All Rules is the union of PPDB and the entailment graph. Rules + W Embs is a combination of All Rules and our word embeddings.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_71"><head></head><label></label><figDesc>Amigó et al. (2009) demonstrated the strengths of B-Cubed, and a similar version has been used in SemEval 2013 for Word Sense Induction (Jurgens and Klapaftis, 2013).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_72"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Fuzzy B-Cubed f-score using the subcategorised noun feature set (nouns-dep), across soft clustering approaches.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_73"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: Fuzzy B-Cubed f-score using NMF soft clustering, across feature sets.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_74"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: Predicting polysemy across prepositions (NMF, k = 17, nouns-dep).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_75"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Graphics for temperature data.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_76"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: Screenshot of the Extended Weather Game (Rainfall: Graphics and WMO condition).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_77"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: An example of constructing a constrained word lattice for the sentence in Figure 1. Dash-dotted lines are generated by addition and dotted lines are generated by subtraction. Constraints are specified by &lt;&gt;.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_78"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: BLEU scores of systems evaluated on sentences which fall into different ranges according to fuzzy match scores on EN-ZH and EN-FR. All scores are averaged over 3 runs.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_79"><head></head><label></label><figDesc>Simard et al. (2007a) and Simard et al. (2007b) applied SMT for post-editing, handling the repeti- tive nature of errors typically made by rule-based MT systems. Lagarda et al. (2009) used statis- tical information from the trained SMT models for post-editing of rule-based MT output. Rosa et al. (2012) and Mareček et al. (2011) applied a rule-based approach to APE on the morphologi- cal level. Denkowski (2015) developed a method for real time integration of post-edited MT output into the translation model by extracting a gram- mar for each input sentence. Recent studies have even shown that the quality of MT plus PE can exceed the quality of human translation (Fiederer and OBrien, 2009; Koehn, 2009; DePalma and Kelly, 2009) as well as the productivity (Zampieri and Vela, 2014) in some cases.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_80"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Generating the t th T L P E word y t for a given T L M T (x) by our NNAPE System.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_81"><head></head><label></label><figDesc>tic textual similarity, 1 cross-lingual textual entail- ment (Negri et al., 2013), and quality estimation (QE) for MT (Specia et al., 2009; Mehdad et al., 2012; C. de Souza et al., 2014; Turchi et al., 2014; C. de Souza et al., 2015). Also most of the previ- ous approaches to bilingual data mining/cleaning for statistical MT rely on supervised learning (Resnik and Smith, 2003; Munteanu and Marcu, 2005; Jiang et al., 2009). Unsupervised solutions, like the one proposed by Cui et al.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_82"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: BA results as a function of Z and k.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_83"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: The bag-of-words input features along with the original word features. The input vectors are projected and concatenated at the projection layer. We omit the hidden and output layers for simplification, since they remain unchanged.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_84"><head></head><label></label><figDesc>Figure 2: The change of BLEU scores on the eval11 set of the IWSLT 2013 German→English task along with the source context window size. The source windows are always symmetrical with respect to the aligned word. For instance, window size five denotes that two preceding and two succeeding words along with the aligned word are included in the window. The average sentence length of the corpus is about 18 words. The red line is the result of using a model with bag-of-words input features and a bag-of-words individual decay rate.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_85"><head></head><label></label><figDesc>x: y = y(D), x = x(D). This defines a regular language Y over strings in the target language via a projection of the sentence to be translated: Y = {y(D) : x(D) = x} (Iglesias et al., 2011; Allauzen et al., 2014). Scores are defined over derivations via a log-linear model with features {φ i } and weights λ. The decoder searches for the translation y(D) in Y with the highest derivation score S(D) (Chi- ang, 2007, Eq. 24) :</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_86"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Performance with NPLM over beam size on English-German news-test2015. A beam of 12 corresponds to row 15 in Tab. 3.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_87"><head></head><label></label><figDesc>5 .</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_88"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: More training material leads to better individual F-scores, as shown for the 10 most frequent country classes.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_89"><head></head><label></label><figDesc>(2003) connect language use with style and per- sonality, while Schler et al. (2006) automatically classified blogs text into three classes based on self-reported age using part-of-speech features. Jo- hannsen et al. (2015) uncover some consistent age patterns in part-of-speech usage across languages, while Rosenthal and McKeown (2011) studies the use of Internet specific phenomena such as slang, acronyms and capitalisation patterns. Preoţiuc- Pietro et al. (2016) study differences in paraphrase choice between older and younger Twitter users as a measure of style. Nguyen et al. (2013) ana- lyzed the relationship between language use and age, modelled as a continuous variable. They found similar language usage trends for both genders, with increasing word and tweet length with age, and an increasing tendency to write more gram- matically correct, standardized text. Such findings encourage further research in the area of measuring readability, which not only facilitates adjusting the text to the reader (Danescu-Niculescu-Mizil et al., 2011), but can also play an important role in iden- tifying authorial style (Pitler and Nenkova, 2008). Davenport and DeLine (2014) report negative cor- relation between tweet readability (i.e., simplicity) and the percentage of people with college degree in the area. Eisenstein et al. (2011) employ language use as a socio-demographic predictor.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_91"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Temporal patterns for groups of lowest (blue) and highest (orange) income users in our data set. X-axis shows the course of 24 hours in normalized time of day. Y-axis shows a normalized difference of the hourly means from the overall mean feature value. Width of a line shows the standard error.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_92"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: Predictive performance (Pearson correlation) for Income and Age. Individual points display univariate correlations (including sign) of the most predictive features.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_93"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Tweet level classification accuracy for the two-way and three-way classification problems.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_94"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: Accuracy on the user-level prediction task for different data sizes.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_95"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: Cumulative classification accuracy on the top N users sorted by Naive Bayes predicted probabilities</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_96"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: LDA.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_97"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: An example simplification tree</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_98"><head>( 3 )</head><label>3</label><figDesc>The Queen of England used the wrong name for the Republic of Ireland.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_99"><head></head><label></label><figDesc>compares the performance of our model to the figures reported in Filippova et al. (2015) for their LSTM model and McDonald's (2006) system (MIRA). For a comparison with the same judges, we repeat the evaluation with the 11 sample out- put compressions listed in Filippova et al.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_100"><head></head><label></label><figDesc>using linear-chain CRFs with syntactic features, and more recently by Filippova et al. (2015) and Klerke et al. (2016) using recur- rent neural networks with LSTM cells.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_101"><head></head><label></label><figDesc>, Woodsend and Lap- ata (2011) and Mandya et al. (2014) present joint approaches to compression and paraphrasing that are based on (quasi-) synchronous grammars, and similarly Zhu et al. (2010) take a syntax-based approach, but employ a probabilistic model of various simplification operations. Napoles et al. (2011) do not use syntactic information, but in- stead employ a character-based metric to compress and paraphrase.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_103"><head>PFigure 2 :</head><label>2</label><figDesc>Figure 2: Regular n-gram Markov chain LM (top) and conditioned LM (bottom). γ based on empirically-observed gender distribution in data</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_104"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Character-based word embedding</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_105"><head>Eneko</head><label></label><figDesc>Agirre, Daniel Cer, Mona Diab, Aitor Gonzalez- Agirre, and Weiwei Guo. 2013. sem 2013 shared task: Semantic textual similarity, including a pilot on typed-similarity. In In* SEM 2013: The Second Joint Conference on Lexical and Computational Se- mantics. Eneko Agirre, Carmen Banea, Claire Cardie, Daniel Cer, Mona Diab, Aitor Gonzalez-Agirre, Weiwei Guo, Rada Mihalcea, German Rigau, and Janyce Wiebe. 2014. Semeval-2014 task 10: Multilingual semantic textual similarity. In Proceedings of the 8th international workshop on semantic evaluation (SemEval 2014), pages 81-91. Eneko Agirre, Carmen Banea, Claire Cardie, Daniel Cer, Mona Diab, Aitor Gonzalez-Agirre, Wei- wei Guo, Inigo Lopez-Gazpioa, Montse Maritxalar, Rada Mihalcea, et al. 2015. Semeval-2015 task 2: Semantic textual similarity, english, spanish and pilot on interpretability. In Proceedings of the 9th international workshop on semantic evaluation (Se- mEval 2015), pages 252-263. Marco Baroni and Roberto Zamparelli. 2010. Nouns are vectors, adjectives are matrices: Representing adjective-noun constructions in semantic space. In Proceedings of the 2010 Conference on Empirical Methods in Natural Language Processing, pages 1183-1193. Marco Baroni, Georgiana Dinu, and Germán Kruszewski. 2014. Don't count, predict! a systematic comparison of context-counting vs. context-predicting semantic vectors. In Proceedings of the ACL. Chris Callison-Burch. 2007. Paraphrasing and Trans- lation. Ph.D. thesis, University of Edinburgh. Marine Carpuat and Dekai Wu. 2007. Improving Statistical Machine Translation using Word Sense Disambiguation. In Proceedings of the 2007 Joint Conference on Empirical Methods in Natural Lan- guage Processing and Computational Natural Lan- guage Learning (EMNLP-CoNLL 2007), pages 61- 72, Prague, June. Mona Diab. 2004. Relieving the data acquisition bot- tleneck in word sense disambiguation. In Proceed- ings of the 42nd Annual Meeting of the Association for Computational Linguistics.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_106"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: The IBC-C dataset visualised. A report is split into one or more non overlapping sections. A section is comprised of sentences which are comprised of words. Each section is linked to exactly one incident which in turn can be linked to one or more sections.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_107"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: A visualisation of the different steps taken to create the dataset.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_109"><head>Gary</head><label></label><figDesc>King and Will Lowe. 2003. An automated infor- mation extraction tool for international conflict data with performance as good as human coders: A rare events evaluation design. International Organiza- tion, 57(03):617-642. Kalev Leetaru and Philip A Schrodt. 2013. Gdelt: Global data on events, location, and tone, 1979- 2012. In ISA Annual Convention, volume 2. Cite- seer. Andrew McCallum and Wei Li. 2003. Early results for named entity recognition with conditional random fields, feature induction and web-enhanced lexicons. In Proceedings of the seventh conference on Natural language learning at HLT-NAACL 2003-Volume 4, pages 188-191. Association for Computational Lin- guistics. Grégoire Mesnil, Xiaodong He, Li Deng, and Yoshua Bengio. 2013. Investigation of recurrent-neural- network architectures and learning methods for spo- ken language understanding. In INTERSPEECH, pages 3771-3775.. 2007. Crfsuite: a fast implementa- tion of conditional random fields (crfs). (Accessed on 02/23/2016). Sean P Obrien. 2010. Crisis early warning and decision support: Contemporary approaches and thoughts on future research. International Studies Review, 12(1):87-104. Clionadh Raleigh, Andrew Linke, Håvard Hegre, and Joakim Karlsen. 2010. Introducing acled: An armed conflict location and event dataset special data feature. Journal of peace research, 47(5):651- 660. Philip A Schrodt, Omür Yilmaz, Deborah J Gerner, and Dennis Hermreck. 2008. The cameo (conflict and mediation event observations) actor coding frame- work. In 2008 Annual Meeting of the International Studies Association. Philip A Schrodt. 2001. Automated coding of interna- tional event data using sparse parsing techniques. In annual meeting of the International Studies Associ- ation, Chicago. Philip A Schrodt. 2016. Open event data alliance (oeda). (Accessed on 02/23/2016). Hristo Tanev, Jakub Piskorski, and Martin Atkinson. 2008. Real-time news event extraction for global crisis monitoring. In Natural Language and Infor- mation Systems, pages 207-218. Springer. Nicholas Weller and Kenneth McCubbins. 2014. Open event data alliance (oeda)raining on the pa- rade: Some cautions regarding the global database of events, language and tone dataset. (Accessed on 05/18/2016). GuoDong Zhou and Jian Su. 2002. Named entity recognition using an hmm-based chunk tagger. In proceedings of the 40th Annual Meeting on Associa- tion for Computational Linguistics, pages 473-480. Association for Computational Linguistics.† and Jun'ichi Tsujii ‡ § † Department of Computer Science, The University of Tokyo, Japan ‡ Artificial Intelligence Research Center, AIST, Japan § School of Computer Science, The University of Manchester, UK {hu,j-tsujii}@ms.k.u-tokyo.ac.jp,@aist.go.jp</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_110"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Projected latent concepts on the word embedding space. Concept vectors are annotated with their representative concepts in parentheses.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_112"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: Graphical representation.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_113"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: Relationship between σ 2 and AMI.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_114"><head>Figure 4 :</head><label>4</label><figDesc>Figure 4: Comparisons on clustering performance of the topic models.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_116"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Comparing performance on multiple similarity tasks, with different values of truncation. The y-axis represents the Spearman's rank correlation coefficient for word similarity datasets, and the cosine value for paraphrase (bigram) datasets (see Sec. 4.2).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_117"><head>2 :</head><label>2</label><figDesc>Comparing the training CBOW models: We set the average value of the original word2vec embeddings to be 1, and the values in the table are relative to the original embeddings baselines. "avg. (w.)" represents the average values of all word similarity datasets. "avg. (b.)" represents the average values of all bigram phrase similarity datasets. "Stoch. (16 b.)" represents the method using stochastic rounding applied to 16-bit precision. "Trunc. (8 b.)" represents the method using truncation with 8-bit auxiliary update vectors applied to 8-bit precision.to converge. Auxiliary update vectors achieve very similar results to the original vectors, and, in fact, result in almost the same vectors as produced by the original truncation method.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_118"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Intensities of the Hawkes Process for an example Ferguson rumour. Tweet occurrences over time are denoted at the bottom of the figure by different symbols. Intensity for comments is high throughout the rumour lifespan.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_119"><head>Figure 1 :Figure 2 :</head><label>12</label><figDesc>Figure 1: BLEU score as a function of the number of phrase pairs (Arabic-English).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_120"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: Moses compact phrase table size as a function of the number of phrase pairs (ArabicEnglish).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_121"><head>Yu</head><label></label><figDesc>Chen, Martin Kay, and Andreas Eisele. 2009. In- tersecting multilingual data for faster and better sta- tistical translations. In Proceedings of Human Lan- guage Technologies: The 2009 Annual Conference of the North American Chapter of the Association for Computational Linguistics (NAACL-HLT), pages 128-136. John DeNero and Dan Klein. 2008. The complex- ity of phrase alignment problems. In Proceedings of the 46th Annual Meeting of the Association for Computational Linguistics: Human Language Tech- nologies (ACL-HLT), pages 25-28. Matthias Eck, Stephan Vogel, and Alex Waibel. 2007. Translation model pruning via usage statistics for statistical machine translation. In Human Language Technologies 2007: The Conference of the North American Chapter of the Association for Computa- tional Linguistics (NAACL-HLT), pages 21-24. Howard Johnson, Joel Martin, George Foster, and Roland Kuhn. 2007. Improving translation qual-phrase redundancy and trans- lational relations for phrase table compression. The Prague Bulletin of Mathematical Linguistics, 98:63- 74. David Kempe, Jon Kleinberg, andÉva Tardos. 2003. Maximizing the spread of influence through a social network. In Proceedings of the 9th ACM SIGKDD international conference on Knowledge discovery and data mining (KDD), pages 137-146. Katrin Kirchhoff and Jeff Bilmes. 2014. Submod- ularity for data selection in machine translation. In Proceedings of the 2014 Conference on Em- pirical Methods in Natural Language Processing (EMNLP), pages 131-141. Philipp Koehn, Hieu Hoang, Alexandra Birch, Chris Callison-Burch, Marcello Federico, Nicola Bertoldi, Brooke Cowan, Wade Shen, Christine Moran, Richard Zens, Chris Dyer, Ondrej Bojar, Alexan- dra Constantin, and Evan Herbst. 2007. Moses: Open source toolkit for statistical machine transla- tion. In Proceedings of the 45th Annual Meeting of the Association for Computational Linguistics Com- panion Volume Proceedings of the Demo and Poster Sessions, pages 177-180. Jure Leskovec, Andreas Krause, Carlos Guestrin, Christos Faloutsos, Jeanne VanBriesen, and Natalie Glance. 2007. Cost-effective outbreak detection in networks. In Proceedings of the 13th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining (KDD), pages 420-429. Hui Lin and Jeff Bilmes. 2010. Multi-document sum- marization via budgeted maximization of submod- ular functions. In Human Language Technologies: The 2010 Annual Conference of the North American Chapter of the Association for Computational Lin- guistics (NAACL-HLT), pages 912-920. Hui Lin and Jeff Bilmes. 2011. A class of submodu- lar functions for document summarization. In Pro- ceedings of the 49th Annual Meeting of the Associ- ation for Computational Linguistics: Human Lan- guage Technologies (ACL-HLT), pages 510-520. Wang Ling, João Graça, Isabel Trancoso, and Alan Black. 2012. Entropy-based pruning for phrase- based machine translation. In Proceedings of the 2012 Joint Conference on Empirical Meth- ods in Natural Language Processing and Com- putational Natural Language Learning (EMNLP- CoNLL), pages 962-971. Michel Minoux. 1978. Accelerated greedy algorithms for maximizing submodular set functions. In Pro- ceedings of the 8th IFIP Conference on Optimization Techniques, pages 234-243.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_122"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Right: bi-LSTM, illustrated with b + c (bytes and characters), for w + c replace b with words w. Left: FREQBIN, our multi-task bi-LSTM that predicts at every time step the tag and the frequency class for the next token.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_123"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: Absolute improvements of bi-LSTM ( w + c) over TNT vs mean log frequency.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_124"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: Amount of training data (number of sentences) vs tagging accuracy.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_125"><head></head><label></label><figDesc>where #(w, c) is the number of times (w, c) is ob- served in the subsampled corpus. Stochastic (St): Every context window is ex- tended with k negative samples w 1...k . Iterative gradient descent of eq. (6) is then run on pairs (w, c j ), for j = 1, .., 2 * win and (w, c i ), j = 1, .., k for each window. The global loss for this</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_127"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Example with the en, es, en-es models. Dotted lines represent incorrectly-parsed dependencies. The corresponding English sentence is: 'We are working hard on putting available the best products of Spain, thank you'</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_128"><head></head><label></label><figDesc>Prime Minister Ehud Barak called his cabinet into special session late Wednesday , to discuss what he called a grave escalation of the level of violence ...</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_129"><head>Israeli</head><label></label><figDesc>Prime Minister Ehud BarakAR=1 called hisAR=14 cabinet into special session late Wednesday , to discuss what heAR=14 called a grave escalation of the level of violence ...</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_130"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: An example sentence completion question (The Princeton Review, 2007).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_131"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Contrast the syntactic complexity of a simple sentence (a) vs. a complex sentence (b). The tree depth of (a) is 4, while the value of (b) is 7. The branching factor of (a) is 1.38, while the value of (b) is 1.48</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_132"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: Sentence length (SL), tree depth (TD) and branching factor (BF) against within-topic sentence position (the relative position of a sentence from the beginning of the topic episode), grouped by speaker role, leader vs. follower. Shaded areas: bootstrapped 95% confidence intervals.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_133"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: Two normalized metrics of syntactic complexity, tree depth (NTD) (a) and branching factor (NBF) (b), vs. within-topic position of sentences in Switchboard. Shaded areas: bootstrapped 95% confidence intervals.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_134"><head>Figure 2 .</head><label>2</label><figDesc>Figure 2. The proposed User2Vec#2 framework for learning user vector representation. In this framework, the word vectors contribute directly to the user vectors, along with the microblog text vectors.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_136"><head>Figure 3 .</head><label>3</label><figDesc>Figure 3. Precision/Recall@k=100 w.r.t. vector dimension.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_137"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Illustration of the weight SA scores for the adjective target formal. The feature conception only occurs with formal and synonyms of formal, so weight SA (f ormal, conception) should return a positive value; the feature rumor only occurs with the antonym informal and with synonyms of informal, so weight SA (f ormal, rumor) should return a negative value; the feature issue occurs with both formal and informal and also with synonyms of these two adjectives, so weight SA (f ormal, issue) should return a feature score near zero.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_139"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: Differences between cosine scores for antonymous vs. synonymous word pairs.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_140"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Annotated English question from the CQA-QL corpus. Shown are the first two comments only.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_141"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: Overall architecture of the NN.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_143"><head></head><label></label><figDesc>: … Natural greenhouse gases include carbon dioxide, methane, water vapor, and ozone ... CFCs and some other man-made compounds are also greenhouse gases … Hypothesis: CO 2 , CH 4 , O 3 and CFC gases cause the greenhouse effect Q: Which of the following gases cause the greenhouse effect? ! A: CO 2 , CH 4 ,</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_144"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: The KvD-inspired incremental summarisation model.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_145"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: Possible attachments of a new proposition.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_146"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Example latent answer-entailing structure from the MCTest dataset. The question and answer candidate are combined to generate a hypothesis. This hypothesis is AMR parsed to construct a hypothesis meaning representation graph after some post-processing ( § 2.1). Similar processing is done for each sentence in the passage as well. Then, a subset (not necessarily contiguous) of these sentence meaning representation graphs is found. These representation subgraphs are further merged using coreference information, resulting into a structure called the relevant text snippet graph. Finally, the hypothesis meaning representation graph is aligned to the snippet graph. The dashed red lines show node alignments, solid red lines show edge alignments, and thick solid black arrow shows the rhetorical structure label (elaboration).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_147"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: The AMR parse for the hypothesis in Figure 1. The person nodes are merged to achieve the hypothesis meaning representation graph.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_148"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: PCA projections (PC1 and PC2) of CLEigenwords of countries (bold) and its capitals (italic) in Spanish (red) and English (blue). Word vectors of the two languages match quite well, although they are computed using sentence-level alignment without knowing word-level alignment. 100-dim word representations are used for PCA computation.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_149"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: Eigenwords are CCA-based spectral monolingual word embeddings. CL-Eigenwords are CDMCA-based spectral cross-lingual word embeddings, where the two (or more) languages are linked by sentence-alignment.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_151"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: Cross-Language Latent Semantic Indexing (CL-LSI) does not use the context information.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_153"><head>WE</head><label></label><figDesc>Induction: Data All the word representa- tions in comparison are induced from the Polyglot Wikipedia data (Al-Rfou et al., 2013). 4</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_154"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: Results in the semantic similarity task on SimLex-999 for three languages using different context types in the SGNS model. Solid lines denote the results on all words from SimLex-999, while thinner dashed lines show results on the verb portion of SimLex-999 (222 verb pairs).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_155"><head>Fig. 2</head><label>2</label><figDesc>Fig. 2(a)-2(c) show the results on SimLex-999 (Spearman's ρ) for WEs with different d-s, while Tab. 2 displays the Acc@1 scores in the anal-</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_156"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Mean Precision (micro average): Colors indicate different values of τ . In parenthesis is the number of topics for which claims were selected.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_157"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Pragmatic listeners/speakers reason for 1 or more levels, but not the literal listener/speaker.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_160"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Comparison between Model Precision, and Model Precision Choose Two for a toy topic. Circles represent the top words and triangles represent intruded words. Model Precision Choose Two can distinguish the less-coherent topic.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_162"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: Model Precision Choose Two across the four models used in this work. Higher scores are better. We see that as K increases, the median score does not improve noticeably.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_163"><head></head><label></label><figDesc>Do you agree or disagree with the following statement? Young people nowadays do not give enough time to helping their communities. Use specific reasons and examples to support your answer.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_164"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: Typology of Argumentative Structure: Examples of (i) T ree h&gt;1 ; (ii) Chain; (iii) T ree h=1</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_166"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Overview of MED</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_167"><head>Figure 3 :Figure 4 :</head><label>34</label><figDesc>Figure 3: Results for the large general training set experiment: effect of reducing the training set for only 2PIE → 13PKE on the accuracy for 2PIE → 13PKE for MED and MODEL*TAG.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_168"><head></head><label></label><figDesc>u s , v s ) a(u s , u t ) d(v s , v t ).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_169"><head></head><label></label><figDesc>://hdl.handle.net/11234/1-1548 4 https://www.jw.org/Active edges choose token POS v i,k ≥ e i,k,j,l ∀i = 0, j, k, l v i,l ≥ e i,k,j,l ∀i, j, k, l</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_170"><head>Figure 5 :</head><label>5</label><figDesc>Figure 5: Results for DGRNN with amplification gate (AG) on three development datasets.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_173"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: A constituent X i (word or node previously predicted) is tagged by considering a fixed size context window of size K (here K = 5). The concatenated output of the compositional history and constituent tags is fed as input to the tagger. A standard two-layers neural network outputs a score s i for each BIOES-prefixed parsing tag. Additional features can be easily fed to the network. Each category is assigned a new lookup table containing a vector of feature for every possible tag.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_174"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Similarity networks for partial cognate detection. A shows pairwise SCA distances computed between all morphemes of Chinese dialect words for`moon'. Values shaded in gray are excluded following filtering rules 1 and 2 (see text). B shows the initial similarity network with all nodes connected. C shows the network after filtering, and D shows the network after applying the partitioning algorithm.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_176"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: Comparing the results for the LexStat sequences similarities</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" validated="true"><head>Table 7 :</head><label>7</label><figDesc>The LAS ∆ of the parser with access to gold standard topological fields compared to the De Kok (2015) parser for the relations of Table 4.</figDesc><table>Dependency label 
LAS ∆ 
Coordinating conjunction (clausal) 11.48 
Parenthesis 
8.31 
Dependent clause 
3.49 
Conjunct 
3.38 
Sentence root 7 
2.92 
Expletive es 
2.71 
Sentence 
2.64 
Comparative 
1.87 
Separated verb prefix 
1.64 
Direct object 
1.59 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" validated="false"><head></head><label></label><figDesc>Table 1: Performance comparison between different embeddings style.</figDesc><table>w/o Embed 6B-50d 840B-300d SENT SENT+ 
alarm 
97.25 
97.68 
97.5 
97.68 
97.74 
apps 
89.16 
91.07 
92.52 
94.24 
94.3 
calendar 
91.34 
92.43 
92.32 
92.53 
92.43 
communication 
99.1 
99.13 
99.08 
99.08 
99.12 
finance 
90.44 
90.84 
90.72 
90.76 
90.82 
flights 
94.19 
92.99 
93.99 
94.59 
94.59 
games 
90.16 
91.79 
92.09 
93.08 
92.92 
hotel 
93.23 
94.21 
93.97 
94.7 
94.78 
livemovie 
90.88 
92.64 
92.8 
93.28 
93.37 
livetv 
83.14 
85.02 
84.67 
85.41 
85.86 
movies 
93.27 
94.01 
93.97 
94.75 
95.16 
music 
87.87 
90.37 
90.9 
91.75 
91.33 
mystuff 
94.2 
94.4 
94.51 
94.51 
94.95 
note 
97.62 
98.36 
98.36 
98.49 
98.52 
ondevice 
97.51 
97.77 
97.6 
97.77 
97.84 
places 
97.29 
97.68 
97.68 
98.01 
97.75 
reminder 
98.72 
98.96 
98.94 
98.96 
98.96 
sports 
76.96 
78.53 
78.38 
78.7 
79.44 
timer 
91.1 
91.79 
91.33 
92.33 
92.61 
travel 
81.58 
82.57 
82.43 
83.64 
82.81 
tv 
91.42 
94.11 
94.91 
95.19 
95.47 
weather 
97.31 
97.33 
97.4 
97.4 
97.47 
Average 
91.99 
92.89 
93.00 
93.49 
93.56 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5" validated="true"><head>Table 2 :</head><label>2</label><figDesc>Performance for selected domains as the number of unlabeled data increases.</figDesc><table>Batch Size 
X X − Y Y 2 
time 
1 
1019779.69 
100.21 
2 
1019758.22 
50.31 
4 
1019714.19 
26.50 
5 
1019713.43 
21.67 
8 
1019679.67 
14.53 
10 
1019692.67 
12.13 
16 
1019686.35 
8.53 
20 
1019709.03 
7.35 
25 
1019650.51 
6.40 
40 
1019703.24 
4.97 
50 
1019689.33 
4.48 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6" validated="false"><head>Table 3 :</head><label>3</label><figDesc>Results for corresponding batch size. Second column indicates the norm of gap between original and sketching matrix. Time represents the running time for sketching methods, measured in seconds.</figDesc><table></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_9" validated="true"><head>Table 2 :</head><label>2</label><figDesc>Macro performance for friend recommendation. Performance of NetSim-PCA and GCCA-sv are identical since the view weighting for GCCA-sv only selected solely the friend view. Thus, these methods learned identical user embeddings.</figDesc><table>Model 
age 
gender 
politics 
BOW 
0.771/0.740 
0.723/0.662 
0.934/0.975 
BOW-PCA 
0.784/0.649 
0.719/0.662 
0.908/0.900 
BOW-PCA + BOW 
0.767/0.688 
0.660/0.714 
0.937/0.9875 
GCCA 
0.725/0.740 
0.742/0.714 
0.899/0.8125 
GCCA + BOW 
0.764/0.727 
0.657/0.701 
0.940/0.9625 
GCCA-sv 
0.709/0.636 
0.699/0.714 
0.871/0.850 
GCCA-sv + BOW 
0.761/0.688 
0.647/0.675 
0.937/0.9625 
Word2Vec 
0.790/0.753 
0.777/0.766 
0.927/0.938 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_10" validated="false"><head>Table 1 :</head><label>1</label><figDesc>Statistics of pure T4 reviews.</figDesc><table>T1 
T2 
T3 
T4 
total 
192,353 
161,863 
257,831 
303,357 
ratio 
21.01% 
17.68% 
28.17% 
33.14% 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_11" validated="false"><head>Table 2 :</head><label>2</label><figDesc>Statistics of segment types.</figDesc><table></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_13" validated="true"><head>Table 3 :</head><label>3</label><figDesc>Polarity distribution in experimental datasets.</figDesc><table>(%) 
BOW 
linear 

W2V 
linear 

BOW 
RBF 

W2V 
RBF 

W2V 
CNN 
T41-test (p) 
78.55 
73.67 
81.54 
79.76 
85.04 
PT4S (p) 
77.30 
77.64 
72.01 
72.22 
67.96 
MicroAvg 
77.91 
75.69 
76.67 
75.91 
76.32 
T41-test (a) 
43.25 
41.50 
46.35 
46.13 
55.90 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_16" validated="false"><head>Table 2 :</head><label>2</label><figDesc>Accuracies of MDA and MDA+TR on 20Newsgroup adaptation tasks.</figDesc><table></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_19" validated="false"><head>Table 1 :</head><label>1</label><figDesc>Feature templates. Note that, remarkably, even though we do labeled dependency parsing, we do not include arc label as features.</figDesc><table></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_20" validated="false"><head>Table 3 Table 2 :</head><label>32</label><figDesc>indicate that both forward and backward contexts for each word are very important to obtain strong results. Using only word forms and no part-of- speech input similarly degraded performance.Layer Bi-LSTM 93.67 91.48 93.42 91.36Development and test set results for shift- reduce dependency parser on Penn Treebank using only (s 1 , s 0 , q 0 ) positional features.</figDesc><table>Parser 
Dev 
Test 
UAS LAS UAS LAS 
C &amp; M 2014 
92.0 89.7 91.8 89.6 
Dyer et al. 2015 
93.2 90.9 93.1 90.9 
Weiss et al. 2015 
-
-
93.19 91.18 
+ Percept./Beam 
-
-
93.99 92.05 
Bi-LSTM 
93.31 91.01 93.21 91.16 
2-Parser 
UAS LAS 
Bi-LSTM Hierarchical  † 93.31 91.01 
 † -Hierarchical Actions 92.94 90.96 
 † -Backward-LSTM 
91.12 88.72 
 † -Forward-LSTM 
91.85 88.39 
 † -tag embeddings 
92.46 89.81 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_22" validated="true"><head>Table 5 :</head><label>5</label><figDesc>Test F-scores for constituency parsing on Penn Treebank and CTB-5.</figDesc><table>Dependency Constituency 
Embeddings 
Word (dims) 
50 
100 
Tags (dims) 
20 
100 
Nonterminals (dims) 
-
100 
Pretrained 
No 
No 
Network details 
LSTM units (each direction) 
200 
200 
ReLU hidden units 
200 / decision 
1000 
Training 
Training epochs 
10 
10 
Minibatch size (sentences) 
10 
10 
Dropout (LSTM output only) 
0.5 
0.5 
L2 penalty (all weights) 
none 
1 × 10 −8 
ADADELTA ρ 
0.99 
0.99 
ADADELTA 
1 × 10 −7 
1 × 10 −7 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_23" validated="false"><head>Table 6 :</head><label>6</label><figDesc>Hyperparameters and training settings.</figDesc><table></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_24" validated="false"><head></head><label></label><figDesc>an additional anal-</figDesc><table>MT05 

MT06 
MT08 
MT09 
Baseline 
58.5 
47.9 
47.3 
50.1 
FD 
OB 
FD 
OB 
FD 
OB 
FD 
OB 
PTre 
57.4 (-1.1) 58.7 (+0.2) 46.3(-0.7) 47.8 (-0.1) 46.1 (-1.2) 47.4 (+0.1) 48.7 (-1.4) 50.1(0.0) 
PTin 
58.2 (-0.3) 58.8 (+0.3) 48.0(+0.1) 48.6 (+0.7) 47.5(+0.2) 47.7 (+0.4) 50.4 (+0.3) 50.7 (+0.6) 
PTin+ BiLMre 
-
59.2 (+0.7) -
48.5 (+0.6) -
47.7 (+0.4) -
50.9 (+0.8) 
PT base + BiLMre -
58.6(+0.1) -
48.2(+0.3) -
47.2 (-0.1) -
50.6(+0.5) 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_25" validated="false"><head>Table 2 :</head><label>2</label><figDesc>BLEU scores for Forced decoding and Oracle BLEU re-estimation. PT re/in = Phrase table re-estimation/interpolation/baseline, PT base = Baseline Phrase table, BiLM re = BiLM re-estimation, FD=Forced decoding, OB=oracle-BLEU.</figDesc><table>TEST 
Baseline 
51.0 
FDLO 
OB 
PTre 
50.7 (-0.3) 51.0 (0.0) 
PTin 
51.5 (+0.5) 51.5 (+0.5) 
PTin + BiLMre -
51.6 (+0.6) 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_26" validated="false"><head>Table 3 :</head><label>3</label><figDesc></figDesc><table>BLEU scores for Oracle-Bleu and Forced 
decoding with leave-one-out against concatena-
tion of MT03, MT05-MT09. 

(% of baseline) 
OB100 
5.07 
OB10 
4.16 
OB1 
3.28 
FD 
27.71 
FDLO 
7.6 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_27" validated="false"><head></head><label></label><figDesc>In Proceedings of the Conference on Empir- ical Methods in Natural Language Processing. As- sociation for Computational Linguistics.Dependency-based bilingual language models for reordering in statistical machine translation. In Proceedings of the 2014 Conference on Empir- ical Methods in Natural Language Processing (EMNLP), pages 1689-1700. Mark Hopkins and Jonathan May. 2011. Tuning as ranking. In Proceedings of the 2011 Conference on Empirical Methods in Natural Language Process- ing. Association for Computational Linguistics.Kishore Papineni, Salim Roukos, Todd Ward, and Wei- Jing Zhu. 2002. Bleu: a method for automatic eval- uation of machine translation. In Proceedings of 40th Annual Meeting of the Association for Compu- tational Linguistics. Association for Computational Linguistics.</figDesc><table>In Proceedings of the 
Conference on Empirical Methods in Natural Lan-
guage Processing. Association for Computational 
Linguistics. 

Markus Dreyer, Keith Hall, and Sanjeev Khudanpur. 
2007. Comparing reordering constraints for smt us-
ing efficient BLEU oracle computation. In Proceed-
ings of 2007 Workshop on Syntax and Structure in 
Statistical Trans-lation. 

George Foster and Roland Kuhn. 2012. Forced decod-
ing for phrase extraction. Technical report, Univer-
sity of Montreal. 

George Foster, Roland Kuhn, and Howard Johnson. 
2006. Phrasetable smoothing for statistical machine 
translation. In Proceedings of the 2006 Conference 
on Empirical Methods in Natural Language Pro-
cessing. Association for Computational Linguistics. 

Michel Galley and Christopher D. Manning. 2008. A 
simple and effective hierarchical phrase reordering 
model. Ekaterina Garmash and Christof Monz. 
2014. 
Philipp Koehn, Hieu Hoang, Alexandra Birch, Chris 
Callison-Burch, Marcello Federico, Nicola Bertoldi, 
Brooke Cowan, Wade Shen, Christine Moran, 
Richard Zens, Chris Dyer, Ondřej Bojar, Alexandra 
Constantin, and Evan Herbst. 2007. Moses: Open 
source toolkit for statistical machine translation. In 
Proceedings of the 45th Annual Meeting of the ACL 
on Interactive Poster and Demonstration Sessions. 
Association for Computational Linguistics. 

Patrik Lambert, Holger Schwenk, Christophe Ser-
van, and Sadaf Abdul-Rauf. 2011. Investigations 
on translation model adaptation using monolingual 
data. In Proceedings of the Sixth Workshop on Sta-
tistical Machine Translation. Association for Com-
putational Linguistics. 

Percy Liang, Alexandre Bouchard-Côté, Dan Klein, 
and Ben Taskar. 2006. An end-to-end discrimina-
tive approach to machine translation. In Proceed-
ings of the 21st International Conference on Com-
putational Linguistics and 44th Annual Meeting of 
the Association for Computational Linguistics. As-
sociation for Computational Linguistics, July. 

Daniel Marcu and William Wong. 2002. A phrase-
based, joint probability model for statistical ma-
chine translation. In Proceedings of the ACL-02 
Conference on Empirical Methods in Natural Lan-
guage Processing. Association for Computational 
Linguistics. 

Jan Niehues, Teresa Herrmann, Stephan Vogel, and 
Alex Waibel. 2011. Wider context by using 
bilingual language models in machine translation. 
In Proceedings of the Sixth Workshop on Statisti-
cal Machine Translation. Association for Computa-
tional Linguistics. 

Eric W. Noreen. 1989. Computer Intensive Methods 
for Testing Hypotheses. An Introduction. Wiley-
Interscience. 

Franz Josef Och and Hermann Ney. 2000. Improved 
statistical alignment models. In Proceedings of the 
38th Annual Meeting on Association for Compu-
tational Linguistics. Association for Computational 
Linguistics. 

Franz Josef Och and Hermann Ney. 2003. A sys-
tematic comparison of various statistical alignment 
models. Computational Linguistics, 29. 

Stefan Riezler and John T. Maxwell. 2005. On some 
pitfalls in automatic evaluation and significance test-
ing for MT. In Proceedings of the ACL Workshop 
on Intrinsic and Extrinsic Evaluation Measures for 
Machine Translation and/or Summarization. 

Holger Schwenk, Patrik Lambert, Loïc Barrault, 
Christophe Servan, Haithem Afli, Sadaf Abdul-
Rauf, and Kashif Shah. 2011. LIUM's SMT ma-
chine translation systems for WMT 2011. In Pro-
ceedings of the Sixth Workshop on Statistical Ma-
chine Translation. Association for Computational 
Linguistics. 

Ankit K. Srivastava, Yanjun Ma, and Andy Way. 2011. 
Oracle-based training for phrase-based statistical 
machine translation. In Proceedings of the 15th an-
nual meeting of the European Association for Ma-
chine Translation. 

Christoph Tillman. 2004. A unigram orientation 
model for statistical machine translation. In Pro-
ceedings of HLT-NAACL. Association for Computa-
tional Linguistics. 

Taro Watanabe, Jun Suzuki, Hajime Tsukada, and 
Hideki Isozaki. 2007. Online large-margin training 
for statistical machine translation. In Proceedings of 
the 2007 Joint Conference on Empirical Methods in 
Natural Language Processing and Computational Natural Language Learning (EMNLP-CoNLL). As-
sociation for Computational Linguistics. 

Guillaume Wisniewski, Alexandre Allauzen, and 
François Yvon. 2010. Assessing phrase-based 
translation models with oracle decoding. In Pro-
ceedings of the 2010 Conference on Empirical 
Methods in Natural Language Processing. Associ-
ation for Computational Linguistics. 

Joern Wuebker, Arne Mauser, and Hermann Ney. 
2010. Training phrase translation models with 
leaving-one-out. In Proceedings of the Annual 
Meeting of the Association for Computational Lin-
guistics. Association for Computational Linguistics, 
July. </table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_29" validated="false"><head></head><label></label><figDesc>).I. Konstas and M. Lapata. 2013. A Global Model for Concept-to-Text Generation. Journal of Artifi- cial Intelligence Research, 48:305-346. F. Mairesse, M. Gašić, F. Jurčíček, S. Keizer, B. Thom- son, K. Yu, and S. Young. 2010. Phrase-based sta-What to talk about and how? Selective Genera- tion using LSTMs with Coarse-to-Fine Alignment. arXiv:1509.00838 [cs], September. D. S. Paiva and R. Evans. 2005. Empirically-based control of natural language generation.In C. Cortes, N. D. Lawrence, D. D. Lee, M. Sugiyama, R. Garnett, and R. Garnett, editors, Advances in Neural Information Processing Systems 28, pages 2755-2763. M. A. Walker, O. Rambow, and M. Rogati. 2001.T.-H. Wen, M. Gasic, D. Kim, N. Mrksic, P.-H. Su, D. Vandyke, and S. Young. 2015a. Stochastic Lan- guage Generation in Dialogue using Recurrent Neu- ral Networks with Convolutional Sentence Rerank- ing. In Proceedings of the 16th Annual Meeting of the Special Interest Group on Discourse and Di-</figDesc><table>M. Abadi, A. Agarwal, P. Barham, E. Brevdo, 
Z. Chen, C. Citro, G. S. Corrado, A. Davis, 
J. Dean, M. Devin, S. Ghemawat, I. Goodfellow, 
A. Harp, G. Irving, M. Isard, Y. Jia, R. Jozefow-
icz, L. Kaiser, M. Kudlur, J. Levenberg, D. Mané, 
R. Monga, S. Moore, D. Murray, C. Olah, M. Schus-
ter, J. Shlens, B. Steiner, I. Sutskever, K. Talwar, 
P. Tucker, V. Vanhoucke, V. Vasudevan, F. Viégas, 
O. Vinyals, P. Warden, M. Wattenberg, M. Wicke, 
Y. Yu, and X. Zheng. 2015. TensorFlow: Large-
scale machine learning on heterogeneous systems. 
Software available from tensorflow.org. 

G. Angeli, P. Liang, and D. Klein. 2010. A simple 
domain-independent probabilistic approach to gen-
eration. In Proceedings of the 2010 Conference on 
Empirical Methods in Natural Language Process-
ing, pages 502-512. 

D. Bahdanau, K. Cho, and Y. Bengio. 2015. Neural 
Machine Translation by Jointly Learning to Align 
and Translate. arXiv:1409.0473. 

Y. Bengio, R. Ducharme, P. Vincent, and C. Jauvin. 
2003. A Neural Probabilistic Language Model. 
Journal of Machine Learning Research, 3:1137-
1155. 

K. Cho, B. van Merrienboer, C. Gulcehre, D. Bah-
danau, F. Bougares, H. Schwenk, and Y. Ben-
gio. 2014. Learning Phrase Representations us-
ing RNN Encoder-Decoder for Statistical Machine 
Translation. In Proceedings of the 2014 Conference 
on Empirical Methods in Natural Language Pro-
cessing (EMNLP), pages 1724-1734, Doha, Qatar. 
arXiv:1406.1078. 

N. Dethlefs, H. Hastie, H. Cuayáhuitl, and O. Lemon. 
2013. Conditional Random Fields for Responsive 
Surface Realisation using Global Features. In Pro-
ceedings of ACL, Sofia. 

G. Doddington. 2002. Automatic Evaluation of 
Machine Translation Quality Using N-gram Co-
occurrence Statistics. In Proceedings of the Sec-
ond International Conference on Human Language 
Technology Research, pages 138-145, San Fran-
cisco, CA, USA. Morgan Kaufmann Publishers Inc. 

O. Dušek and F. Jurčíček. 2015. Training a Natural 
Language Generator From Unaligned Data. In Pro-
ceedings of the 53rd Annual Meeting of the Associ-
ation for Computational Linguistics and the 7th In-
ternational Joint Conference on Natural Language 
Processing, pages 451-461, Beijing, China. Associ-
ation for Computational Linguistics. 

Ondřej Dušek, ZdeněkŽabokrtský, Martin Popel, Mar-
tin Majliš, Michal Novák, and David Mareček. 
2012. Formemes in English-Czech Deep Syntac-
tic MT. In Proceedings of the Seventh Workshop 
on Statistical Machine Translation, pages 267-274, 
Montréal, Canada. Association for Computational 
Linguistics. 

O. Dušek, L. Gomes, M. Novák, M. Popel, and 
R. Rosa. 2015. New Language Pairs in TectoMT. 
In Proceedings of the 10th Workshop on Machine 
Translation, pages 98-104, Lisbon, Portugal. Asso-
ciation for Computational Linguistics. 

A. Graves. 2013. Generating Sequences With Recur-
rent Neural Networks. arXiv:1308.0850 [cs], Au-
gust. 

S. Jean, K. Cho, R. Memisevic, and Y. Bengio. 2015. 
On Using Very Large Target Vocabulary for Neural 
Machine Translation. In Proceedings of the 53rd 
Annual Meeting of the Association for Computa-
tional Linguistics and the 7th International Joint 
Conference on Natural Language Processing (Vol-
ume 1: Long Papers), pages 1-10, Beijing, China. 
Association for Computational Linguistics. 

D. Kingma and J. Ba. 
2015. 
Adam: A 
Method for Stochastic Optimization. In Inter-
national Conference on Learning Representations. 
arXiv:1412.6980. 

P. Koehn. 2004. Statistical significance tests for 
machine translation evaluation. In Proceedings of 
EMNLP, pages 388-395. 

tistical language generation using graphical models 
and active learning. In Proceedings of the 48th An-
nual Meeting of the Association for Computational 
Linguistics, pages 1552-1561. 

H. Mei, M. Bansal, and M. R. Walter. 
2015. 
In Proceed-
ings of the 43rd Annual Meeting on Association for 
Computational Linguistics, ACL '05, pages 58-65, 
Stroudsburg, PA, USA. Association for Computa-
tional Linguistics. 

K. Papineni, S. Roukos, T. Ward, and W.-J. Zhu. 2002. 
BLEU: a method for automatic evaluation of ma-
chine translation. In Proceedings of the 40th annual 
meeting of the Association for Computational Lin-
guistics, pages 311-318. 

M. Popel and Z.Žabokrtský. 2010. TectoMT: modu-
lar NLP framework. In Proceedings of IceTAL, 7th 
International Conference on Natural Language Pro-
cessing,, pages 293-304, Reykjavík. 

M. Ranzato, S. Chopra, M. Auli, and W. Zaremba. 
2015. Sequence Level Training with Recurrent Neu-
ral Networks. arXiv:1511.06732 [cs], November. 

50 

A. Raux, B. Langner, D. Bohus, A. W. Black, and 
M. Eskenazi. 2005. Let's go public! taking a spo-
ken dialog system to the real world. In in Proc. of 
Interspeech 2005. Citeseer. 

E. Reiter and R. Dale. 2000. Building Natural Lan-
guage Generation Systems. Cambridge University 
Press, studies in natural language processing edition. 

V. Rieser, O. Lemon, and X. Liu. 2010. Optimising 
information presentation for spoken dialogue sys-
tems. In Proceedings of the 48th Annual Meeting 
of the Association for Computational Linguistics, 
pages 1009-1018. 

A. Stent, R. Prasad, and M. Walker. 2004. Trainable 
sentence planning for complex information presen-
tation in spoken dialog systems. In Proceedings of 
the 42nd Annual Meeting on Association for Com-
putational Linguistics, pages 79-86. 

I. Sutskever, O. Vinyals, and Q. VV Le. 2014. Se-
quence to sequence learning with neural networks. 
In Advances in Neural Information Processing Sys-
tems, pages 3104-3112. arXiv:1409.3215. 

O. Vinyals, Ł. Kaiser, T. Koo, S. Petrov, I. Sutskever, 
and G. Hinton. 2015. Grammar as a Foreign Lan-
guage. SPoT: a trainable sentence planner. In Proceedings 
of the second meeting of the North American Chap-
ter of the Association for Computational Linguistics 
on Language technologies, pages 1-8, Stroudsburg, 
PA, USA. Association for Computational Linguis-
tics. 

alogue, pages 275-284, Prague, Czech Republic, 
September. Association for Computational Linguis-
tics. 

T.-H. Wen, M. Gasic, N. Mrkšić, P.-H. Su, D. Vandyke, 
and S. Young. 2015b. Semantically Conditioned 
LSTM-based Natural Language Generation for Spo-
ken Dialogue Systems. In Proceedings of the 2015 
Conference on Empirical Methods in Natural Lan-
guage Processing, pages 1711-1721, Lisbon, Portu-
gal. Association for Computational Linguistics. 

Y. W. Wong and R. J. Mooney. 2007. Generation by 
inverting a semantic parser that uses statistical ma-
chine translation. In Proceedings of Human Lan-
guage Technologies: The Conference of the North 
American Chapter of the Association for Compu-
tational Linguistics (NAACL-HLT-07), pages 172-
179. 

S. Young, M. Gašić, S. Keizer, F. Mairesse, J. Schatz-
mann, B. Thomson, and K. Yu. 2010. The Hid-
den Information State model: A practical frame-
work for POMDP-based spoken dialogue manage-
ment. Computer Speech &amp; Language, 24(2):150-
174, April. </table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_31" validated="false"><head>Table 2 :</head><label>2</label><figDesc>Selected words with highest values R G(w) in COHA for the time period 1900-2000.</figDesc><table></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_33" validated="false"><head></head><label></label><figDesc>Steffen Eger, Niko Schenk, and Alexander Mehler. 2015. Towards semantic language classification: Inducing and clustering semantic association net- works from europarl. In Proceedings of the Fourth Joint Conference on Lexical and Computational Se- mantics, pages 127-136, Denver, Colorado, June. Association for Computational Linguistics.Tomas Mikolov, Ilya Sutskever, Kai Chen, Greg S Cor- rado, and Jeff Dean. 2013b. Distributed repre- sentations of words and phrases and their compo- sitionality. In C.J.C. Burges, L. Bottou, M. Welling, Z. Ghahramani, and K.Q. Weinberger, editors, Ad- vances in Neural Information Processing Systems 26, pages 3111-3119. Curran Associates, Inc.</figDesc><table>5 References 

Daron Acemoglu and Asuman Ozdaglar. 2011. Opin-
ion dynamics and learning in social networks. Dy-
namic Games and Applications, 1(1):3-49. 

Marco Baroni, Georgiana Dinu, and Germán 
Kruszewski. 2014. Don't count, predict! a 
systematic comparison of context-counting vs. 
context-predicting semantic vectors. In Proceed-
ings of the 52nd Annual Meeting of the Association 
for Computational Linguistics (Volume 1: Long 
Papers), pages 238-247, Baltimore, Maryland, 
June. Association for Computational Linguistics. 

Xinxiong Chen, Zhiyuan Liu, and Maosong Sun. 
2014. A unified model for word sense represen-
tation and disambiguation. In Proceedings of the 
2014 Conference on Empirical Methods in Natural 
Language Processing, EMNLP 2014, October 25-
29, 2014, Doha, Qatar, A meeting of SIGDAT, a Spe-
cial Interest Group of the ACL, pages 1025-1035. 

Ferdinand de Saussure. 1916. Cours de linguistique 
générale. Payot, Lausanne/Paris. 

Steffen Eger. 2016. Opinion dynamics and wisdom 
under out-group discrimination. Mathematical So-
cial Sciences, 80(C):97-107. 

Manaal Faruqui and Chris Dyer. 2014. Improving vec-
tor space word representations using multilingual 
correlation. In Proceedings of EACL. 

Benjamin Golub and Matthew O. Jackson. 2010. 
Nave learning in social networks and the wisdom 
of crowds. American Economic Journal: Microeco-
nomics, 2(1):112-49, February. 

Eric H. Huang, Richard Socher, Christopher D. Man-
ning, and Andrew Y. Ng. 2012. Improving word 
representations via global context and multiple word 
prototypes. In Proceedings of the 50th Annual 
Meeting of the Association for Computational Lin-
guistics: Long Papers -Volume 1, ACL '12, pages 
873-882, Stroudsburg, PA, USA. Association for 
Computational Linguistics. 

Adam Jatowt and Kevin Duh. 2014. A framework 
for analyzing semantic change of words across time. 
In Proceedings of the Joint JCDL/TPDL Digital Li-
braries Conference. 

Vivek Kulkarni, Rami Al-Rfou, Bryan Perozzi, and 
Steven Skiena. 2015a. Statistically significant de-
tection of linguistic change. In Proceedings of the 

24th International Conference on World Wide Web, 
WWW '15, pages 625-635, Republic and Canton 
of Geneva, Switzerland. International World Wide 
Web Conferences Steering Committee. 

Vivek Kulkarni, Bryan Perozzi, and Steven Skiena. 
2015b. Freshman or fresher? quantifying the ge-
ographic variation of internet language. CoRR, 
abs/1510.06786. 

Jey Han Lau, Paul Cook, Diana McCarthy, David New-
man, and Timothy Baldwin. 2012. Word sense in-
duction for novel sense detection. In Proceedings of 
the 13th Conference of the European Chapter of the 
Association for Computational Linguistics, EACL 
'12, pages 591-601, Stroudsburg, PA, USA. Asso-
ciation for Computational Linguistics. 

Jacques-Paul Migne, editor. 1855. Patrologiae cur-
sus completus: Series latina. 1-221. Chadwyck-
Healey, Cambridge. 

Tomas Mikolov, Quoc V. Le, and Ilya Sutskever. 
2013a. Exploiting similarities among languages for 
machine translation. CoRR, abs/1309.4168. 

Sunny Mitra, Ritwik Mitra, Martin Riedl, Chris Bie-
mann, Animesh Mukherjee, and Pawan Goyal. 
2014. That's sick dude!: Automatic identification 
of word sense change across different timescales. In 
Proceedings of the 52nd Annual Meeting of the As-
sociation for Computational Linguistics, ACL 2014, 
June 22-27, 2014, Baltimore, MD, USA, Volume 1: 
Long Papers, pages 1020-1029. 

Arvind Neelakantan, Jeevan Shankar, Alexandre Pas-
sos, and Andrew McCallum. 2014. Efficient non-
parametric estimation of multiple embeddings per 
word in vector space. In Proceedings of the 2014 
Conference on Empirical Methods in Natural Lan-
guage Processing, EMNLP 2014, October 25-29, 
2014, Doha, Qatar, A meeting of SIGDAT, a Special 
Interest Group of the ACL, pages 1059-1069. 

Christian Plitz, Thomas Bartz, Katharina Morik, and 
Angelika Strrer. 2015. Investigation of word senses 
over time using linguistic corpora. In Pavel Krl 
and Vclav Matouek, editors, Text, Speech, and Di-
alogue, volume 9302 of Lecture Notes in Com-
puter Science, pages 191-198. Springer Interna-
tional Publishing. 

Burghard B. Rieger. 2003. Semiotic cognitive in-
formation processing: Learning to understand dis-
course. A systemic model of meaning constitution. 

6 In R. Kühn, R. Menzel, W. Menzel, U. Ratsch, 
M. M. Richter, and I. O. Stamatescu, editors, Adap-
tivity and Learning. An Interdisciplinary Debate, 
pages 347-403. Springer, Berlin. 

Christian Rohrdantz, Annette Hautli, Thomas Mayer, 
Miriam Butt, Daniel A. Keim, and Frans Plank. 
2011. Towards tracking semantic change by visual 
analytics. In The 49th Annual Meeting of the Asso-
ciation for Computational Linguistics: Human Lan-
guage Technologies, Proceedings of the Conference, 
19-24 June, 2011, Portland, Oregon, USA -Short 
Papers, pages 305-310. 

Morris Swadesh. 1952. Lexico-statistic dating of pre-
historic ethnic contacts. Proceedings of the Ameri-
can Philosophical Society, 96(4):452463. 

Y. Xu and C. Kemp. 2015. A computational evalua-
tion of two laws of semantic change. In Proceedings 
of the 37th Annual Conference of the Cognitive Sci-
ence Society. 

Yating Zhang, Adam Jatowt, Sourav S. Bhowmick, and 
Katsumi Tanaka. 2015. Omnia mutantur, nihil in-
terit: Connecting past with present by finding corre-
sponding terms across time. In Proceedings of the 
53rd Annual Meeting of the Association for Compu-
tational Linguistics and the 7th International Joint 
Conference on Natural Language Processing of the 
Asian Federation of Natural Language Processing, 
ACL 2015, July 26-31, 2015, Beijing, China, Volume 
1: Long Papers, pages 645-655. 

7 

58 1 Introduction 

In learning to speak their native language, a de-
veloping infant must acquire two related pieces of 
information: a set of lexical items (along with the 
contexts in which they are likely to occur), and a 
set of phonetic categories. For instance, an English-
learning infant must learn that [i] and [I] are differ-
ent segments, differentiating between words like 
beat and bit, while for a Spanish-learning infant, 
[i] and [I]-like tokens represent realizations of the 
same category. It is clear that these two tasks are 
intimately related, and that models of language 
acquisition must solve both together-but how? 
</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_35" validated="false"><head></head><label></label><figDesc>James Hillenbrand, Laura A. Getty, Michael J. Clark, and Kimberlee Wheeler. 1995. Acoustic character- istics of American English vowels. The Journal of the Acoustical society of America, 97:3099.</figDesc><table>. A joint learning model of word 
segmentation, lexical acquisition, and phonetic vari-
ability. In Proceedings of the 2013 Conference on 
Empirical Methods in Natural Language Processing, 
pages 42-54, Seattle, Washington, USA, October. 
Association for Computational Linguistics. 

Naomi H. Feldman, Thomas L. Griffiths, Sharon Gold-
water, and James L. Morgan. 2013a. A role for the 
developing lexicon in phonetic category acquisition. 
Psychological Review, 4:751-778. 

Naomi H. Feldman, Emily B. Myers, Katherine S. 
White, Thomas L. Griffiths, and James L. Mor-
gan. 2013b. Word-level information influences 
phonetic learning in adults and infants. Cognition, 
127(3):427-438. 

Margaret M. Fleck. 2008. Lexicalized phonotac-
tic word segmentation. In Proceedings of ACL-08: 
HLT, pages 130-138, Columbus, Ohio, June. Asso-
ciation for Computational Linguistics. 

Stella Frank, Naomi Feldman, and Sharon Goldwater. 
2014. Weak semantic context helps phonetic learn-
ing in a model of infant language acquisition. In 
ACL (1), pages 1073-1083. 

Sharon Goldwater, Thomas L. Griffiths, and Mark 
Johnson. 2006. Contextual dependencies in un-
supervised word segmentation. In Proceedings of 
the 21st International Conference on Computational 
Linguistics and 44th Annual Meeting of the Associa-
tion for Computational Linguistics, pages 673-680, 
Sydney, Australia, July. Association for Computa-
tional Linguistics. 

Sharon Goldwater, Thomas L. Griffiths, and Mark 
Johnson. 2009. A Bayesian framework for word 
segmentation: Exploring the effects of context. Cog-
nition, 112(1):21-54. 

Jonathan Huggins and Frank Wood. 2014. Infi-
nite structured hidden semi-Markov models. arXiv 
preprint arXiv:1407.0044, June. 

Aren Jansen and Kenneth Church. 2011. Towards un-
supervised training of speaker independent acoustic 
models. In INTERSPEECH, pages 1693-1692. 

Mark Johnson and Sharon Goldwater. 2009. Improv-
ing nonparametric Bayesian inference: Experiments 
on unsupervised word segmentation with adaptor 
grammars. In Proceedings of Human Language 
Technologies: The 2009 Annual Conference of the 
North American Chapter of the Association for Com-
putational Linguistics, Boulder, Colorado. 

Peter Ladefoged and Keith Johnson. 2010. A course in 
phonetics. Wadsworth Publishing. 

Chia-ying Lee and James Glass. 2012. A nonparamet-
ric Bayesian approach to acoustic model discovery. 
In Proceedings of the 50th Annual Meeting of the 
Association for Computational Linguistics (Volume 
1: Long Papers), pages 40-49, Jeju Island, Korea, 
July. Association for Computational Linguistics. 

Chia-ying Lee, Timothy J O'Donnell, and James Glass. 
2015. Unsupervised lexicon discovery from acous-
tic input. Transactions of the Association for Com-
putational Linguistics, 3:389-403. 

Andrew Martin, Sharon Peperkamp, and Emmanuel 
Dupoux. 2013. Learning phonemes with a proto-
lexicon. Cognitive Science, 37:103-124. 

Don McAllaster, Lawrence Gillick, Francesco Scat-
tone, and Michael Newman. 1998. Fabricating con-
versational speech data with acoustic models: a pro-
gram to examine model-data mismatch. In ICSLP. 

Daichi Mochihashi, Takeshi Yamada, and Naonori 
Ueda. 2009. Bayesian unsupervised word segmen-
tation with nested pitman-yor language modeling. 
In Proceedings of the Joint Conference of the 47th 
Annual Meeting of the ACL and the 4th International 
Joint Conference on Natural Language Processing 
of the AFNLP, pages 100-108, Suntec, Singapore, 
August. Association for Computational Linguistics. Jurgen Van Gael, Yunus Saatci, Yee Whye Teh, and 
Zoubin Ghahramani. 2008. Beam sampling for the 
infinite Hidden Markov model. In Proceedings of 
the 25th International Conference on Machine learn-
ing, ICML '08, pages 1088-1095, New York, NY, 
USA. ACM. 

Balakrishnan Varadarajan, Sanjeev Khudanpur, and 
Emmanuel Dupoux. 2008. Unsupervised learning 
of acoustic sub-word units. In Proceedings of the As-
sociation for Computational Linguistics: Short Pa-
pers, pages 165-168. A Language-Independent Neural Network for Event Detection 

Xiaocheng Feng 
1 , Lifu Huang 
2 , Duyu Tang 
1 , Bing Qin 
1 , Heng Ji 
2 , Ting Liu 1 Introduction 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_36" validated="false"><head></head><label></label><figDesc>considered event detection as a classi- S2: The court decides Anwar 's earliest release date is April.</figDesc><table>ccomp 

det 
nsubj 

poss 

nn 
amod 
p's 
cop 

nsubj 

DT 
NN 
VBZ 
NNP 's 
JJS 
NN 
NNS VBZ NNP 

S1: The European Unit will release 20 million euros to Iraq. 

prep 

drobj 
num 
pobj 

DT 
NNP 
NNP MD 
VB 
CD 
CD 
NNS IN NNP 

det 
num 
aux 
nn 

Person 

Organization 

Transfer-
Money 

Number 

Calendar 

Release-
Parole 

clues 

clues 

nsubj 

Figure 1: Event type and syntactic parser results 
of an example sentence. 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_37" validated="false"><head></head><label></label><figDesc>. . . . . . . . . . . . . . . . . .</figDesc><table>66 

The 

European 
Unit 
will 
release 
20 
million 
euros … 

SoftMax 

LSTM B 

LSTM F 

Look up 

BV 
FV 
C3 
C2 

Concatenate 
with CNN 

LSTM 
LSTM 
LSTM 
LSTM 
LSTM 
LSTM 

LSTM 
LSTM 
LSTM 
LSTM 

Event Trigger 

LSTM 
LSTM 

LSTM 
LSTM 
LSTM 
LSTM 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_40" validated="true"><head>Table 1 :</head><label>1</label><figDesc>Hyperparameters and # of documents used in our experiments on three languages.</figDesc><table>Model 
Trigger Identification 
Trigger Classification 
P 
R 
F 
P 
R 
F 
MaxEnt 
76.2 
60.5 
67.4 
74.5 
59.1 
65.9 
Cross-Event 
N/A 
N/A 
N/A 
68.7 
68.9 
68.8 
Cross-Entity 
N/A 
N/A 
N/A 
72.9 
64.3 
68.3 
Joint Model 
76.9 
65.0 
70.4 
73.7 
62.3 
67.5 
PR 
N/A 
N/A 
N/A 
68.9 
72.0 
70.4 
CNN 
80.4 
67.7 
73.5 
75.6 
63.6 
69.1 
RNN 
73.2 
63.5 
67.4 
67.3 
59.9 
64.2 
LSTM 
78.6 
67.4 
72.6 
74.5 
60.7 
66.9 
Bi-LSTM 
80.1 
69.4 
74.3 
81.6 
62.3 
70.6 
HNN 
80.8 
71.5 
75.9 
84.6 
64.9 
73.4 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_41" validated="false"><head>Table 2 :</head><label>2</label><figDesc>Comparison of different methods on En- glish event detection.</figDesc><table></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_42" validated="false"><head>Table 4</head><label>4</label><figDesc>presents the performance of our method on the Spanish ERE corpus. The results show that</figDesc><table>69 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_43" validated="true"><head>Table 3 :</head><label>3</label><figDesc>Results on Chinese event detection.</figDesc><table>HNN approach performed better than LSTM and 
Bi-LSTM. It indicates that our proposed model 
could achieve the best performance in multiple 
languages than other neural network methods. We 
did not compare our system with other systems 
(Tanev et al., 2009), because they reported the re-
sults on a non-standard data set . 

Model 

Trigger Identification 
Trigger Classification 
P 
R 
F 
P 
R 
F 

LSTM 
62.2 
52.9 
57.2 
56.9 
32.6 
41.6 
Bi-LSTM 
76.2 
63.1 
68.7 
61.5 
42.2 
50.1 
HNN 
81.4 
65.2 
71.6 
66.3 
47.8 
55.5 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_44" validated="false"><head>Table 4 :</head><label>4</label><figDesc>Results on Spanish event detection.</figDesc><table></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_45" validated="false"><head></head><label></label><figDesc>Dzmitry Bahdanau, Kyunghyun Cho, and Yoshua Ben- gio. 2014. Neural machine translation by jointly learning to align and translate. arXiv preprint arXiv:1409.0473.Chen, V Incent Ng, and et al. 2012. Joint model- ing for chinese event extraction with rich linguistic features. In In COLING. Citeseer.Heng Ji, Ralph Grishman, and et al. 2008. Refining event extraction through cross-document inference. In ACL, pages 254-262. Yann LeCun, Yoshua Bengio, and et al. 1995. Convo- lutional networks for images, speech, and time se- ries. The handbook of brain theory and neural net- works, 3361(10). Qi Li and Heng Ji. 2014. Incremental joint extraction of entity mentions and relations. In Proceedings of the Association for Computational Linguistics.Fan Miao and Ralph Grishman. 2015. Improving event detection with active learning. In EMNLP.</figDesc><table>Chen Yubo Chen, Liheng Xu, Kang Liu, Daojian Zeng, 
and Jun Zhao. 2015. Event extraction via dy-
namic multi-pooling convolutional neural networks. 
In Proceedings of the 53rd Annual Meeting of the 
Association for Computational Linguistics and the 
7th International Joint Conference on Natural Lan-
guage Processing, volume 1, pages 167-176. 

Yu Hong, Jianfeng Zhang, Bin Ma, Jianmin Yao, 
Guodong Zhou, and Qiaoming Zhu. 2011. Us-
ing cross-entity inference to improve event extrac-
tion. In Proceedings of the 49th Annual Meeting of 
the Association for Computational Linguistics: Hu-
man Language Technologies-Volume 1, pages 1127-
1136. Association for Computational Linguistics. 

Qi Li, Heng Ji, and Liang Huang. 2013. Joint event 
extraction via structured prediction with global fea-
tures. In ACL (1), pages 73-82. 

Jiwei Li, Dan Jurafsky, and Eudard Hovy. 2015a. 
When are tree structures necessary for deep 
learning of representations? 
arXiv preprint 
arXiv:1503.00185. 

Jiwei Li, Minh-Thang Luong, and Dan Juraf-
sky. 2015b. A hierarchical neural autoencoder 
for paragraphs and documents. arXiv preprint 
arXiv:1506.01057. 

Shasha Liao, Ralph Grishman, and et al. 2010. Us-
ing document level cross-event inference to improve 
event extraction. In Proceedings of the 48th Annual 
Meeting of the Association for Computational Lin-
guistics, pages 789-797. Association for Computa-
tional Linguistics. 

Ting Liu, Wanxiang Che, and Zhenghua Li. 2011. 
Language technology platform. Journal of Chinese 
Information Processing, 25(6):53-62. 

Yang Liu, Furu Wei, Sujian Li, Heng Ji, Ming Zhou, 
and Houfeng Wang. 2015. A dependency-based 
neural network for relation classification. arXiv 
preprint arXiv:1507.04646. 

Tomas Mikolov, Martin Karafiát, Lukas Burget, Jan 
Cernockỳ, and Sanjeev Khudanpur. 2010. Recur-
rent neural network based language model. In IN-
TERSPEECH, volume 2, page 3. 

Tomas Mikolov, Ilya Sutskever, Kai Chen, Greg S Cor-
rado, and Jeff Dean. 2013. Distributed representa-
tions of words and phrases and their compositional-
ity. In Advances in neural information processing 
systems, pages 3111-3119. </table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_47" validated="true"><head>Table 1 :</head><label>1</label><figDesc>The labels for the new level in the ACC trees. #: number of occurrences.</figDesc><table>Limitations Our representation is similar to the 
representation that was suggested for ACC by 
Huddleston et al. (2002) in their comprehen-
sive linguistic description of the English gram-
mar. However, while it is capable of repre-
senting the common cases of ACC, it does not 
cover some complex and rare cases encountered 
in the PTB: (1) Argument-Cluster structures that 
include errors such as missing indexed argument 
and a wrong POS tag for the main verb; (2) ACC 
constructions where the main verb is between 
the indexed arguments such as the following: 
"([About half] 1 invested [in government bonds] 2 ) 
and ([about 10%] 1 [in cash] 2 )"; (3) Argument-
Cluster structures that include an indexed phrase 
which is not a direct child of the cluster head 
and has non-empty siblings, such as in the follow-
ing case that includes an indexed argument (8%) 
which is not directly under the conjoined VP and 
has non-empty sibling (of ): "see a raise [[of] 
[8%] N P −1 ] P P in the first year] and [7%] N P =1 
</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_49" validated="false"><head>Table 2 :</head><label>2</label><figDesc>Parsing results (EVALB) on PTB Sec- tions 22 (DEV) and 23 (TEST).</figDesc><table>PTB Trees Modified Trees 
ACC P T B 
13.0 
-
ACC OU R 
24.1 
64.8 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_51" validated="false"><head></head><label></label><figDesc>11.08] [for berries]) , ([$14.33] [for apples]) , and ([$9.31] [for peaches])</figDesc><table></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_52" validated="false"><head></head><label></label><figDesc>egorial grammars and natural language structures, pages 153-197. Springer.</figDesc><table>Kazuo Hara, Masashi Shimbo, Hideharu Okuma, and 
Yuji Matsumoto. 2009. Coordinate structure analy-
sis with global structural constraints and alignment-
based local features. In Proceedings of the Joint 
Conference of the 47th Annual Meeting of the ACL 
and the 4th International Joint Conference on Natu-
ral Language Processing of the AFNLP: Volume 2-
Volume 2, pages 967-975. Association for Compu-
tational Linguistics. 

Deirdre Hogan. 2007. Coordinate noun phrase disam-
biguation in a generative parsing model. Associa-
tion for Computational Linguistics. 

Rodney Huddleston, Geoffrey K Pullum, et al. 2002. 
The cambridge grammar of english. Language. 
Cambridge: Cambridge University Press, pages 
1273-1362. 

Mitchell P Marcus, Mary Ann Marcinkiewicz, and 
Beatrice Santorini. 1993. Building a large anno-
tated corpus of english: The penn treebank. Compu-
tational linguistics, 19(2):313-330. 

François Mouret. 2006. A phrase structure approach 
to argument cluster coordination. In Proceedings of 
the HPSG06 Conference, pages 247-267. CSLI on-
line Publications. 

Hideharu Okuma, Kazuo Hara, Masashi Shimbo, and 
Yuji Matsumoto. 2009. Bypassed alignment graph 
for learning coordination in japanese sentences. In 
Proceedings of the ACL-IJCNLP 2009 Conference 
Short Papers, pages 5-8. Association for Computa-
tional Linguistics. 

Slav Petrov, Leon Barrett, Romain Thibaux, and Dan 
Klein. 2006. Learning accurate, compact, and 
interpretable tree annotation. In Proceedings of 
the 21st International Conference on Computational 
Linguistics and the 44th annual meeting of the Asso-
ciation for Computational Linguistics, pages 433-
440. Association for Computational Linguistics. 

Masashi Shimbo and Kazuo Hara. 2007. A discrim-
inative learning model for coordinate conjunctions. 
In EMNLP-CoNLL, pages 610-619. </table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_53" validated="false"><head></head><label></label><figDesc>Kappa Diff. ref. Same ref. Source Standard .163±.01 .197±.01 0.190±.02 Weighted .330±.01 .373±.01 0.336±.</figDesc><table>02 
One-off 
.597±.01 .662±.01 0.643±.02 

Table 1: Inter-annotator agreement for different-
references (Diff. ref.), same-reference (Same ref.) 
and source-based evaluation (Source) 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_55" validated="false"><head></head><label></label><figDesc>Matteo Negri, Matt Post, Carolina Scarton, Lucia Specia, and Marco Turchi. 2015. Findings of the 2015 Workshop on Statistical Machine Translation. In Proceedings of the Tenth Workshop on Statistical Machine Translation, pages 1-46, Lisboa, Portugal.Michael Denkowski and Alon Lavie. 2010. Choos- ing the Right Evaluation for Machine Translation: an Examination of Annotator and Automatic Metric Performance on Human Judgment Tasks. In Pro- ceedings of the Ninth Biennal Conference of the As- sociation for Machine Translation in the Americas.</figDesc><table>Chris Callison-Burch, Cameron Fordyce, Philipp 
Koehn, Christof Monz, and Josh Schroeder. 2007. 
(meta-) evaluation of machine translation. In Pro-
ceedings of the Second Workshop on Statistical Ma-
chine Translation, pages 136-158. 

Jacob Cohen. 1960. A Coefficient of Agreement for 
Nominal Scales. Educational and Psychological 
Measurement, 20:37-46. 

Jacob Cohen. 1968. Weighted Kappa: Nominal Scale 
Agreement Provision for Scaled Disagreement or 
Partial Credit. Psychological bulletin, 70(4):213-
220. 

Trevor Cohn and Lucia Specia. 2013. Modelling 
Annotator Bias with Multi-task Gaussian Processes: 
An Application to Machine Translation Quality Es-
timation. In Proceedings of 51st Annual Meeting 
of the Association for Computational Linguistics, 
pages 32-42. 

Michael Denkowski and Alon Lavie. 2014. Meteor 
Universal: Language Specific Translation Evalua-
tion for Any Target Language. In Proceedings of the 
EACL 2014 Workshop on Statistical Machine Trans-
lation, pages 376-380. 

Markus Dreyer and Daniel Marcu. 2012. HyTER: 
Meaning-equivalent Semantics for Translation Eval-
uation. In Proceedings of 2012 Conference of 
the North American Chapter of the Association for 
Computational Linguistics: Human Language Tech-
nologies, pages 162-171. 

Yvette Graham, Timothy Baldwin, Alistair Moffat, 
and Justin Zobel. 2013. Continuous Measurement 
Scales in Human Evaluation of Machine Trans-
lation. 
In Proceedings 7th Linguistic Annota-
tion Workshop and Interoperability with Discourse, 
pages 33-41. 

Francisco Guzmán, Ahmed Abdelali, Irina Temnikova, 
Hassan Sajjad, and Stephan Vogel. 2015. How do 
Humans Evaluate Machine Translation. In Proceed-
ings of the Tenth Workshop on Statistical Machine 
Translation, pages 457-466. 

Xavier Llorà, Kumara Sastry, David E Goldberg, Ab-
himanyu Gupta, and Lalitha Lakshmi. 2005. Com-
bating User Fatigue in iGAs: Partial Ordering, Sup-
port Vector Machines, and Synthetic Fitness. In Pro-
ceedings of the 7th Annual Conference on Genetic 
and Evolutionary Computation, pages 1363-1370. 

Kishore Papineni, Salim Roukos, Todd Ward, and Wei-
Jing Zhu. 2002. BLEU: a Method for Automatic 
Evaluation of Machine Translation. In Proceedings 
of the 40th Annual Meeting of the ACL, pages 311-
318. 

Mark Przybocki, Kay Peterson, and Sebastian Bron-
sart. 2008. Official Results of the NIST 2008 "Met-
rics for MAchine TRanslation" Challenge (Metrics-
MATR08). In Proceedings of the AMTA-2008 Work-
shop on Metrics for Machine Translation, Honolulu, 
Hawaii, USA. 

Lucia Specia, Dhwaj Raj, and Marco Turchi. 2010. 
Machine Translation Evaluation versus Quality Es-
timation. Machine Translation, 24(1):39-50. 

John White, Theresa O'Connell, and Francis O'Mara. 
1994. The ARPA MT Evaluation Methodologies: 
Evolution, Lessons, and Future Approaches. In Pro-
ceedings of the Association for Machine Transla-
tion in the Americas Conference, pages 193-205, 
Columbia, Maryland, USA. </table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_56" validated="false"><head>Table 1 :</head><label>1</label><figDesc>NUM refers to the NUMERIC entities test set and VS refers to the VOICE-SEARCH test set.</figDesc><table>Test Set 

Utts Words % Numeric words 
NUM ID 
9,744 60,781 
19% 
NUM RU 10,988 59,933 
22% 
NUM IT 
8,685 48,195 
18% 
VS ID 
9,841 36,276 
2% 
VS RU 
12,467 49,403 
3% 
VS IT 
12,625 47,867 
2% 

text of numeric transcription. The first test set 
VOICE-SEARCH (approximately 48K words for 
Italian and Russian, and approximately 36K words 
for Indonesian) is a sample from general voice-
search traffic, and tracks any regressions that ap-
pear as a result of biasing too heavily toward the 
selected classes. The other test set NUMERIC (ap-
proximately 48K words for Italian, and approxi-
mately 60K for Russian and Indonesian) contains 
utterances we expect to benefit from class-based 
modeling of numeric entities. See Table 1 for de-
tails on these test sets. 
</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_58" validated="false"><head></head><label></label><figDesc>David Yarowsky, Grace Ngai, and Richard Wicen- towski. 2001. Inducing multilingual text analy- sis tools via robust projection across aligned cor- pora. In Proceedings of the First International Con- ference on Human Language Technology Research,</figDesc><table>. Unsupervised 
part-of-speech tagging with bilingual graph-based 
projections. In Proceedings of the 49th Annual 
Meeting of the Association for Computational Lin-
guistics: Human Language Technologies -Volume 
1, HLT '11, pages 600-609. Association for Com-
putational Linguistics. 

Fei Huang, Stephan Vogel, and Alex Waibel. 2003. 
Automatic extraction of named entity translingual 
equivalence based on multi-feature cost minimiza-
tion. In Proceedings of the ACL 2003 Workshop 
on Multilingual and Mixed-language Named Entity 
Recognition -Volume 15, MultiNER '03, pages 9-
16. Association for Computational Linguistics. 

Reinhard Knesser and Hermann Ney. 1993. Im-
proved clustering techniques for class-based statisti-
cal language modelling. In Proc. Eurospeech. ISCA 
-International Speech Communication Association, 
September. 

Philipp Koehn, Franz Josef Och, and Daniel Marcu. 
2003. Statistical phrase-based translation. In Pro-
ceedings of the 2003 Conference of the North Amer-
ican Chapter of the Association for Computational 
Linguistics on Human Language Technology, vol-
ume 1 of NAACL '03, pages 48-54. Association for 
Computational Linguistics. 

John D. Lafferty, Andrew McCallum, and Fernando 
C. N. Pereira. 2001. Conditional random fields: 
Probabilistic models for segmenting and labeling se-
quence data. In Proceedings of the Eighteenth Inter-
national Conference on Machine Learning, ICML 
'01, pages 282-289, San Francisco, CA, USA. Mor-
gan Kaufmann Publishers Inc. 

Michael Levit, Sarangarajan Parthasarathy, Shuangyu 
Chang, Andreas Stolcke, and Benoit Dumoulin. 
2014. Word-phrase-entity language models: Getting 
more mileage out of n-grams. In Proc. Interspeech. 
ISCA -International Speech Communication Asso-
ciation, September. 

Robert C. Moore. 2003. Learning translations of 
named-entity phrases from parallel corpora. In 
Proceedings of the Tenth Conference on European Chapter of the Association for Computational Lin-
guistics -Volume 1, EACL '03, pages 259-266. As-
sociation for Computational Linguistics. 

Tetsuji Nakagawa. 2015. Efficient top-down BTG 
parsing for machine translation preordering. In Pro-
ceedings of the 53rd Annual Meeting of the Associa-
tion for Computational Linguistics, ACL 2015, Vol-
ume 1: Long Papers, pages 208-218. 

Sebastian Padó and Mirella Lapata. 2009. Cross-
lingual annotation projection of semantic roles. 
Journal of Artificial Intelligence Research, 
36(1):307-340, September. 

Lucy Vasserman, Vlad Schogol, and Keith Hall. 2015. 
Sequence-based class tagging for robust transcrip-
tion in asr. In Proc. Interspeech. ISCA -Interna-
tional Speech Communication Association, Septem-
ber. 

David Yarowsky and Grace Ngai. 2001. Inducing mul-
tilingual pos taggers and np bracketers via robust 
projection across aligned corpora. In Proceedings 
of the Second Meeting of the North American Chap-
ter of the Association for Computational Linguistics 
on Language Technologies, NAACL '01, pages 1-8. 
Association for Computational Linguistics. 

HLT '01, pages 1-8. Association for Computational 
Linguistics. A Fast Approach for Semantic Similar Short Texts Retrieval 

Yanhui Gu 
1 Zhenglu Yang 
2 *  Junsheng Zhou 

1 

Weiguang Qu 
1 Jinmao Wei 
2 Xingtian Shi 

3 

1 School of Computer Science and Technology, Nanjing Normal University, China 
{gu,zhoujs,wgqu}@njnu.edu.cn 
2 CCCE&amp;CS, Nankai University, Tianjin, China 
{yangzl,weijm}@nankai.edu.cn 
3 SAP Labs China, Shanghai, China 
{xingtian.shi}@sap.com 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_59" validated="false"><head></head><label></label><figDesc>Anything after this wonderful lunch in Japan? Delicious sushi, tempura and sashimi near Okubo. Delicious sushi, tempura and sashimi near Okubo.</figDesc><table>Knowledge based Similarity Metric 
Corpus based Similarity Metric 

T2 

T3 

... 

delicious 
lunch 
Japan 

... 

top-1 result: 

word LAYER 

text LAYER 

T1 

T2 

... 

nice 

T2,... 

Very good food, but a little expensive. 

good 

wonderful 

tasty 

T2 

... 

food 

dish 

sushi 

tempura 

... 

Nippon 

sushi 

tempura 

service 

delicious 
lunch 
Japan 

T3,... 

T1,... 
... 

T2,T3 

... 

T2,... 
T2,... 

... 

... 

T2,... 

T2,... 
... 

... 

Delicious sushi, tempura and sashimi near Okubo. 

... 

word LAYER 

wonderful T1,... 

good 

nice 

tasty 

... 

sushi 

tempura 

food 

dish 

... 

Nippon 

Shinjuku 

service 

T3,... 

T2,... 
... 

... 

T2,... 

T2,... 

T2,T3 
... 

... 

... 

... 

T2,... 
... 

... 

Japan 

... 

... 

delicious T2,... 

lunch 

... 
delicious T2,... 

lunch 

... 

Japan 

... 

Okubo 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_61" validated="false"><head>Table 1 :</head><label>1</label><figDesc>Number of candidates accessed in effi- ciency evaluation</figDesc><table></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_63" validated="false"><head>Table 2 :</head><label>2</label><figDesc>Effectiveness evaluation on different strategies</figDesc><table></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_64" validated="false"><head></head><label></label><figDesc>Peng Wang, Jiaming Xu, Bo Xu, Cheng-Lin Liu, Heng Zhang, Fangyuan Wang, and Hongwei Hao. 2015. Semantic clustering and convolutional neural net- work for short text categorization. In Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing of the Asian Federation of Natural Language Pro- cessing, ACL '15, pages 352-357.</figDesc><table>Hang Cui, Renxu Sun, Keya Li, Min-Yen Kan, and Tat-
Seng Chua. 2005. Question answering passage re-
trieval using dependency relations. In Proceedings 
of the International ACM SIGIR Conference on Re-
search and Development in Information Retrieval, 
SIGIR '05, pages 400-407. 

Ronald Fagin, Amnon Lotem, and Moni Naor. 2001. 
Optimal aggregation algorithms for middleware. In 
Proceedings of the ACM SIGMOD symposium on 
Principles of Database Systems, PODS '01, pages 
102-113. 

Wen Hua, Zhongyuan Wang, Haixun Wang, Kai 
Zheng, and Xiaofang Zhou. 2015. Short text under-
standing through lexical-semantic analysis. In 31st 
IEEE International Conference on Data Engineer-
ing, ICDE'15, pages 495-506. 

Aminul Islam and Diana Inkpen. 2008. Semantic text 
similarity using corpus-based word similarity and 
string similarity. ACM Transactions on Knowledge 
Discovery from Data, 2(2):1-25. 

C. Leacock and M. Chodorow. 1998. Combining lo-
cal context and wordnet similarity for word sense 
identification. In WordNet: An Electronic Lexical 
Database, pages 305-332. In C. Fellbaum (Ed.), 
MIT Press. 

Yuhua Li, David McLean, Zuhair Bandar, James 
O'Shea, and Keeley A. Crockett. 2006. Sentence 
similarity based on semantic nets and corpus statis-
tics. IEEE Transactions on Knowledge and Data 
Engineering, 18(8):1138-1150. 

Donald Metzler, Susan T. Dumais, and Christopher 
Meek. 2007. Similarity measures for short seg-
ments of text. In Proceedings of the European Con-
ference on Information Retrieval, ECIR '07, pages 
16-27. 

Rada Mihalcea, Courtney Corley, and Carlo Strappa-
rava. 2006. Corpus-based and knowledge-based 
measures of text semantic similarity. In Proceedings 
of the AAAI Conference on Artificial Intelligence, 
AAAI'06, pages 775-780. 

Michael Mohler, Razvan C. Bunescu, and Rada Mihal-
cea. 2011. Learning to grade short answer questions 
using semantic similarity measures and dependency 
graph alignments. In Proceedings of the 49th An-
nual Meeting of the Association for Computational 
Linguistics: Human Language Technologies, Pro-
ceedings of the Conference, ACL'11, pages 752-
762. Filip Radlinski, Andrei Broder, Peter Ciccolo, Evgeniy 
Gabrilovich, Vanja Josifovski, and Lance Riedel. 
2008. Optimizing relevance and revenue in ad 
search: a query substitution approach. In Proceed-
ings of the International ACM SIGIR Conference 
on Research and Development in Information Re-
trieval, SIGIR '08, pages 403-410. 

Mehran Sahami and Timothy D. Heilman. 2006. A 
web-based kernel function for measuring the simi-
larity of short text snippets. In Proceedings of the In-
ternational Conference on World Wide Web, WWW 
'06. 

George Tsatsaronis, Iraklis Varlamis, and Michalis 
Vazirgiannis. 2010. Text relatedness based on a 
word thesaurus. Journal of Artificial Intelligence 
Research, 37:1-39. 

Kai Wang, Zhao-Yan Ming, Xia Hu, and Tat-Seng 
Chua. 2010. Segmentation of multi-sentence ques-
tions: towards effective question retrieval in cqa ser-
vices. In Proceedings of the International ACM SI-
GIR Conference on Research and Development in 
Information Retrieval, SIGIR '10, pages 387-394. 

Furu Wei, Wenjie Li, Qin Lu, and Yanxiang He. 2008. 
Query-sensitive mutual reinforcement chain and its 
application in query-oriented multi-document sum-
marization. In Proceedings of the International 
ACM SIGIR Conference on Research and Devel-
opment in Information Retrieval, SIGIR '08, pages 
283-290. 

Zhenglu Yang and Masaru Kitsuregawa. 2011. Ef-
ficient searching top-k semantic similar words. In 
Proceedings of the International Joint Conference 
on Artificial Intelligence, IJCAI'11, pages 2373-
2378. 

Shansong Yang, Weiming Lu, Dezhi Yang, Liang Yao, 
and Baogang Wei. 2015. Short text understand-
ing by leveraging knowledge into topic model. In 
The 2015 Conference of the North American Chap-
ter of the Association for Computational Linguistics: 
Human Language Technologies, NAACL/HLT'15, 
pages 1232-1237. 

Zheng Yu, Haixun Wang, Xuemin Lin, and Min Wang. 
2016. Understanding short texts through semantic 
enrichment and hashing. IEEE Trans. Knowl. Data 
Eng., 28(2):566-579. </table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_69" validated="false"><head>Table 2 :</head><label>2</label><figDesc>Result Analysis: M denotes the number of matches of system outputs (O) with the gold.</figDesc><table></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_70" validated="false"><head></head><label></label><figDesc>successfully in- tegrated empty element recovery into lattice pars- ing for latent PCFGs. Compared with PCFG pars- ing, the spinal TAG parser provides a more flexible feature representation.</figDesc><table>6 Experiments 

6.1 Experiments on the English Penn 
Treebank 

We used the Wall Street Journal (WSJ) part of the 
English Penn Treebank: Sections 02-21 were used 
for training, Section 22 for development, and Sec-
tion 23 for testing. We annotated trees with heads 
by treep (Chiang and Bikel, 2002) 3 with the appli-
cation of Collins's head rules. The 78524 lexical 
and 115 phrasal empty spine types were obtained 
from the training data 4 . The set of phrasal empty 
spines covered all phrasal empty spines extracted 
from the development data. 
We used the Stanford part-of-speech tagger to 
tag development and test data. To train the pro-
posed parsing model, we used the violation-fixing 

3 http://www3.nd.edu/˜dchiang/software/ 
treep/treep.html 
4 Excluding words from lexical spines, there were 1080 
lexical spine types. 

Typed-empty (t,i,i) 
All Brackets 
P 
R 
F1 
P 
R 
F1 

Rule 57.4 50.5 53.7 
-
-
-
Takeno15 60.4 50.6 55.1 
-
-
-

Tagger 63.1 34.7 44.8 72.9 68.6 70.7 
Lattice 64.1 52.2 57.5 73.7 70.6 72.1 
Proposed 65.3 57.6 61.2 74.3 72.8 73.6 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_71" validated="false"><head>Table 3 :</head><label>3</label><figDesc>Results on the Japanese Keyaki Treebank.</figDesc><table></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_74" validated="false"><head>Table 1</head><label>1</label><figDesc>summarizes the feature sets.</figDesc><table>Name 
Description 
#Features 
U 
orthographic unigram 
varies 
UL 
lemma unigram 
varies 
VN-Raw 
VN frames 
270 
VN-Pred 
VN predicate 
145 
VN-Role 
VN thematic role 
30 
VN-RoRe VN them. role filler 
128 
WordNet 
WN lexicographer files 
15 
Corpus 
distributional clustering 
150 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_75" validated="false"><head>Table 1 :</head><label>1</label><figDesc>Summary of feature sets. All features are binary features indicating class membership.</figDesc><table></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_76" validated="false"><head></head><label></label><figDesc>English verb lemmas. The main classification is based on syntactic frames, as enacted in VerbNet classes. We will refer to them as VN-Raw classes. An alternative classification is based on the predicative meaning of the verbs; for example, the verbs assemble and introduce are in different classes based on their syntactic beha- vior, but both have the meaning component of to- gether, marked in VerbNet as a possible value of the Predicate variable. Similarly, shiver and faint belong to different VerbNet classes in terms of syntactic behavior, but both have the meaning el- ement of describing an involuntary action. Using the different values of the Predicate variable, we created a set of VN-Pred classes. We note that the same verb lemma can occur in multiple classes, since different senses of the same lemma can have different meanings, and even a single sense can express more than one predicate. For example, the verb stew participates in the following classes ofmembers take, such as agent or benefi- ciary. Here again, verbs that differ in syntactic behavior and in the predicate they express could share thematic roles. For example, stew and prick belong to different VerbNet classes and share only the most general predicative meanings of cause and use, yet both share a thematic role of instru- ment. We create a class for each thematic role</figDesc><table>3.2 Resource-based 

VerbNet: The VerbNet database (Kipper et al., 
2006) provides a classification of verbs accord-
ing to their participation in frames -syntactic pat-
terns with semantic components, based on Levin's 
classes (Levin, 1993). Each verb class is anno-
tated with its member verb lemmas, syntactic con-
structions in which these participate (such as tran-
sitive, intransitive, diathesis alternations), seman-
tic predicates expressed by the verbs in the class 
(such as motion or contact), thematic roles (such 
as agent, patient, instrument), and restrictions on 
the fillers of these semantic roles (such as pointed 
instrument). 
VerbNet can thus be thought of as providing a 
number of different classifications over the same 
set of nearly 4,000 various degrees of granularity: cause (shared with 
2,912 other verbs), use (with 700 other verbs), ap-
ply heat (with 49 other verbs), cooked (with 49 
other verbs). 
Each VerbNet class is marked with the thematic 
roles its (VN-Role). 
Finally, VerbNet provides annotations of the re-

strictions that apply to fillers of various thematic 
roles. For example, verbs that have a thematic 
role of instrument can have the filler restricted 
to being inanimate, body part, concrete, pointy, 
solid, and others. Across the various VerbNet 
classes, there are 128 restricted roles (such as in-
strument pointy). We used those to generate VN-
RoRe classes. 
WordNet: We use lexicographer files to clas-
sify verbs into 15 classes based on their general 
meaning, such as verbs of communication, con-
sumption, weather, and so on. 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_77" validated="false"><head>Table 2 sum</head><label>2</label><figDesc></figDesc><table>-
</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_78" validated="false"><head>Table 2 :</head><label>2</label><figDesc>Summary of the data. #T = # of texts; #I = # of instances; %M = percentage of metaphors.</figDesc><table></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_80" validated="false"><head></head><label></label><figDesc>The significance of the improvement of UL+WN over SOA'15 was preserved; UL+Corpus now significantly outperformed SOA'15.</figDesc><table>Feature Set 
N 
F 
A 
C Av. 
Train 
SOA'15 
.64 .47 .71 .43 .56 
in 
UL+WN 
.68 .49 .72 .44 .58 
genre 
UL+Corpus .65 .49 .71 .43 .57 
Train 
SOA'15 
.66 .48 .74 .44 .58 
on all 
UL+WN 
.69 .50 .77 .45 .60 
genres UL+Corpus .67 .51 .76 .45 .60 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_83" validated="false"><head>Table 2</head><label>2</label><figDesc>shows the distribution of the entity categories in the data.</figDesc><table>Product Brand Model Prod. Family 
⊥ 
Train 21,688 10,417 4,394 
6,697 
47,517 
Test 
5,413 
2,659 
1,099 
1,716 
11,780 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_84" validated="false"><head>Table 2 :</head><label>2</label><figDesc>Entity category distribution.</figDesc><table></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_86" validated="false"><head>Table 3 :</head><label>3</label><figDesc>Per category performance.</figDesc><table></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_87" validated="false"><head></head><label></label><figDesc>supervised acquisition of open-domain classes and class attributes from web documents and query logs. In Proceedings of ACL-08: HLT, pages 19-27. Alexandre Passos, Vineet Kumar, and Andrew McCal- lum. 2014. Lexicon infused phrase embeddings for named entity resolution. CoRR, abs/1404.5367.</figDesc><table>Gian Fulgoni. 2014. State of the US retail economy in 
q1 2014. In Comscore, Technical Report. 

Alex Graves. 2012. Supervised Sequence Labelling 
with Recurrent Neural Networks, volume 385 of 
Studies in Computational Intelligence. Springer. 

Marti Hearst. 1992. Automatic acquisition of hy-
ponyms from large text corpora. In Proc. of the 
14th conference on Computational linguistics, pages 
539-545. 

Sepp Hochreiter and Jürgen Schmidhuber. 1997. 
Long short-term memory. Neural Computation, 
9(8):1735-1780. 

Xian-Sheng Hua, Linjun Yang, Jingdong Wang, Jing 
Wang, Ming Ye, Kuansan Wang, Yong Rui, and Jin 
Li. 2013. Clickage: Towards bridging semantic and 
intent gaps via mining click logs of search engines. 
In Proceedings of the 21st ACM International Con-
ference on Multimedia, MM '13, pages 243-252. 

Anitha Kannan, Inmar E. Givoni, Rakesh Agrawal, 
and Ariel Fuxman. 2011. Matching unstructured 
product offers to structured product specifications. 
In Proceedings of the 17th ACM SIGKDD Inter-
national Conference on Knowledge Discovery and 
Data Mining, KDD '11, pages 404-412. 

Zornitsa Kozareva and Eduard Hovy. 2010. Learning 
arguments and supertypes of semantic relations us-
ing recursive patterns. In Proceedings of the 48th 
Annual Meeting of the Association for Computa-
tional Linguistics, pages 1482-1491. 

Zornitsa Kozareva, Ellen Riloff, and Eduard Hovy. 
2008. Semantic class learning from the web with 
hyponym pattern linkage graphs. In Proceedings of 
ACL-08: HLT, pages 1048-1056. 

Zornitsa Kozareva. 2015. Everyone likes shopping! 
multi-class product categorization for e-commerce. 
In Proceedings of the 2015 Conference of the North 
American Chapter of the Association for Computa-
tional Linguistics: Human Language Technologies, 
pages 1329-1333. 

John D. Lafferty, Andrew McCallum, and Fernando 
C. N. Pereira. 2001. Conditional random fields: 
Probabilistic models for segmenting and labeling se-
quence data. In icml, pages 282-289. 

Xiao Li. 2010. Understanding the semantic struc-
ture of noun phrase queries. In Proceedings of the 
48th Annual Meeting of the Association for Compu-
tational Linguistics, pages 1337-1345. 

Mehdi Manshadi and Xiao Li. 2009. Semantic tagging 
of web search queries. In Proceedings of the Joint 
Conference of the 47th Annual Meeting of the ACL 
and the 4th International Joint Conference on Natu-
ral Language Processing of the AFNLP: Volume 2 -
Volume 2, pages 861-869. 

Grégoire Mesnil, Yann Dauphin, Kaisheng Yao, 
Yoshua Bengio, Li Deng, Dilek Z. Hakkani-Tür, 
Xiaodong He, Larry P. Heck, Gökhan Tür, Dong 
Yu, and Geoffrey Zweig. 2015. Using recurrent 
neural networks for slot filling in spoken language 
understanding. IEEE/ACM Transactions on Audio, 
Speech &amp; Language Processing, 23(3):530-539. 

Tomas Mikolov, Ilya Sutskever, Kai Chen, Greg Cor-
rado, and Jeffrey Dean. 2013. Distributed represen-
tations of words and phrases and their composition-
ality. volume abs/1310.4546, pages 3111-3119. 

Marius Paşca and Benjamin Van Durme. 
2008. 
Weakly-Duangmanee (Pew) Putthividhya and Junling Hu. 
2011. Bootstrapped named entity recognition for 
product attribute extraction. In Proceedings of the 
2011 Conference on Empirical Methods in Natural 
Language Processing, pages 1557-1567. 

Erik F. Tjong Kim Sang. 2002. Introduction to 
the conll-2002 shared task: Language-independent 
named entity recognition. 
In Proceedings of 
CoNLL-2002, pages 155-158. 

Kristina Toutanova, Dan Klein, Christopher D Man-
ning, and Yoram Singer. 2003. Feature-rich part-of-
speech tagging with a cyclic dependency network. 
In Proceedings of the 2003 Conference of the North 
American Chapter of the Association for Computa-
tional Linguistics on Human Language Technology 
-Volume 1, pages 173-180. Leveraging Lexical Resources for Learning Entity Embeddings 
in Multi-Relational Data 

Teng Long, Ryan Lowe, Jackie Chi Kit Cheung &amp; Doina Precup 
School of Computer Science 
McGill University 
teng.long@mail.mcgill.ca 
{ryan.lowe,jcheung,dprecup}@cs.mcgill.ca 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_90" validated="false"><head>Table 2 :</head><label>2</label><figDesc></figDesc><table>Sample entity descriptions from Word-
Net and Freebase. As Freebase descriptions are 
lengthy paragraphs, only the first sentence is 
shown. 

such as synonym expansion (Sinha and Mihalcea, 
2009), relation extraction (</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_92" validated="false"><head>Table 3 :</head><label>3</label><figDesc></figDesc><table>Comparison between random initialization and using the entity descriptions. 'NS' tag indicates 
stopword removal from the entity descriptions'TransE Freebase W2V init' model uses word2vec pre-
trained with the Freebase vocabulary, and thus was not tested on WN. 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_94" validated="false"><head>Table 4 :</head><label>4</label><figDesc>Sample relations from WordNet and Free- base. The relations from Freebase are clearly much more specific as they relate named entities.</figDesc><table></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_95" validated="false"><head></head><label></label><figDesc>. Incorporating both distributional and relational semantics in word rep- resentations. In In Proceedings of ICLR.</figDesc><table>Guoliang Ji, Shizhu He, Liheng Xu, Kang Liu, and Jun 
Zhao. 2015. Knowledge graph embedding via dy-
namic mapping matrix. In Proceedings of ACL. 

Nanda Kambhatla. 2004. Combining lexical, syntac-
tic, and semantic features with maximum entropy 
models for extracting relations. In Proceedings of 
ACL on Interactive Poster and Demonstration Ses-
sions. 

Igor Labutov and Hod Lipson. 2013. Re-embedding 
words. In Proceedings of ACL. 

Quoc V Le and Tomas Mikolov. 2014. Distributed 
representations of sentences and documents. In Pro-
ceedings of ICML. 

Michael Lesk. 1986. Automatic sense disambiguation 
using machine readable dictionaries: How to tell a 
pine cone from an ice cream cone. In Proceedings 
of SIGDOC. 

Yuval Marton, Saif Mohammad, and Philip Resnik. 
2009. Estimating semantic distance using soft se-
mantic constraints in knowledge-source-corpus hy-
brid models. In Proceedings of EMNLP. 

Tomas Mikolov, Kai Chen, Greg Corrado, and Jeffrey 
Dean. 2013a. Efficient estimation of word represen-
tations in vector space. In Proceedings of ICLR. 

Tomas Mikolov, Wen-tau Yih, and Geoffrey Zweig. 
2013b. Linguistic regularities in continuous space 
word representations. In Proceedings of NAACL-
HLT. 

George A Miller. 
1995. 
Wordnet: a lexical 
database for english. Communications of the ACM, 
38(11):39-41. 

Saif Mohammad. 2008. Measuring semantic distance 
using distributional profiles of concepts. Ph.D. the-
sis, University of Toronto. 

Jeffrey Pennington, Richard Socher, and Christopher D 
Manning. 2014. Glove: Global vectors for word 
representation. In Proceedings of EMNLP. 

Sascha Rothe and Hinrich Schütze. 2015. Autoex-
tend: Extending word embeddings to embeddings 
for synsets and lexemes. Proceedings of ACL. 

Ravi Sinha and Rada Mihalcea. 2009. Combining lex-
ical resources for contextual synonym expansion. In 
Proceedings of RANLP. 

Richard Socher, Danqi Chen, Christopher D Manning, 
and Andrew Ng. 2013. Reasoning with neural ten-
sor networks for knowledge base completion. In 
Proceedings of NIPS. 

Ran Tian, Naoaki Okazaki, and Kentaro Inui. 2015. 
The mechanism of additive composition. arXiv 
preprint arXiv:1511.08407. 

Kristina Toutanova and Danqi Chen. 2015. Observed 
versus latent features for knowledge base and text 
inference. In Proceedings of the 3rd Workshop on 
Continuous Vector Space Models and their Compo-
sitionality. 

John Wieting, Mohit Bansal, Kevin Gimpel, and 
Karen Livescu. 2015. Towards universal para-
phrastic sentence embeddings. 
arXiv preprint 
arXiv:1511.08198. 

Chang Xu, Yalong Bai, Jiang Bian, Bin Gao, Gang 
Wang, Xiaoguang Liu, and Tie-Yan Liu. 2014. Rc-
net: A general framework for incorporating knowl-
edge into word representations. In Proceedings of 
CIKM. 

Bishan Yang, Wen-tau Yih, Xiaodong He, Jianfeng 
Gao, and Li Deng. 2015. Embedding entities and 
relations for learning and inference in knowledge 
bases. In Proceedings of ICLR. </table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_96" validated="false"><head></head><label></label><figDesc>car is hit by another car .</figDesc><table>NMOD SBJ VC 

PMOD 

NMOD 

LGS 

u 1 /v 1 

D 1 /E 1 

Look-up 

D 2 /E 2 

u 2 /v 2 

Look-up 

Look-up 
Look-up 

u p 

Look-up 

(C) 

Figure 1: (a): The SYMDEP model. (b): The ASYMDEP model. (c): An example of how embeddings 
relate to the parse tree. In SYMDEP, the biasing of dependency is uniformly applied to all argument 
embeddings. In ASYMDEP, they are concentrated on one side of the dot product. 

FitzGerald et al., 2015). Closely related to our 
work, Woodsend and Lapata (2015) concatenate 
one hot features of dependency, POS-tag and a dis-
tributed representation for head word and project 
the concatenation onto a dense feature vector 
space. Instead of using dependency relations as 
one-hot vectors, we explicitly model the multi-
plicative compositionality between arguments and 
dependencies, and investigate two different com-
positionality configurations. 
Our model is related to </table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_99" validated="true"><head>Table 2 :</head><label>2</label><figDesc>The 8 most similar predicates to a given argument in a given dependency role.</figDesc><table>Model 
Nouns Verbs 

L&amp;G 
31.4 
27.2 
Arg2vec 
38.2 
31.4 
SYMDEP 
39.2 
36.5 
ASYMDEP 
39.7 
15.3 

ASYM1DEP 33.2 
24.2 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_100" validated="false"><head>Table 3 :</head><label>3</label><figDesc></figDesc><table>A POS-based analysis of the various em-
beddings. Numbers are the Spearman's ρ scores 
of each model on nouns and verbs of SimLex999. 

Ablation Study. We create an ablated model 
to explore the reason for ASYMDEP's perfor-
mance on verb similarity. ASYM1DEP is based 
on ASYMDEP where we force all dependency re-
lations for the predicted argument v t to use the 
same matrix D i . The aim of this experiment is to 
check the negative influence of asymmetric depen-
dency matrix to verb embedding. The results are 
shown at the bottom of </table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_102" validated="false"><head></head><label></label><figDesc>prob at time t, position j. H t is the weighted sum of encoding states. s t is the hidden state. o t is an intermediate output state. A single feedforward layer projects o t to a target vocabu- lary V o , and applies softmax to predict the proba- bility distribution over the output vocabulary.</figDesc><table>Figure 1: The attention-based NMT architecture. 
← − 
h i and 
− 
→ 
h i are bi-directional encoder states. α tj is 
the attention </table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_104" validated="false"><head>Table 2 :</head><label>2</label><figDesc></figDesc><table>Average vocabulary size for each sen-
tence or mini-batch (80 sentences). The full vo-
cabulary is 500k, all other words are UNKs. 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_105" validated="false"><head></head><label></label><figDesc>The final results on the test set are 34.20 and 34.23 separately. Those results suggest that we should use both the translation dictionary and phrases in order to get better translation quality.</figDesc><table>top n common words 

50 
200 
500 
1000 2000 10000 
BLEU on dev. 
30.61 30.65 30.70 30.70 30.72 30.69 
avg. size of </table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_108" validated="false"><head></head><label></label><figDesc>).</figDesc><table>2 Preprinted on arXiv on September 2014 
(http://arxiv.org/abs/1409.5718v1) 
3 Parsed by the Stanford parser 
(http://nlp.stanford.edu/software/lex-parser.shtml) 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_111" validated="true"><head>Table 2 :</head><label>2</label><figDesc>Statistics of the Stanford Natural Lan- guage Inference dataset where each sentence is parsed into a dependency parse tree.</figDesc><table>0 
0.1 
0.2 
0.3 
Dropout rate 

76 

78 

80 

82 

84 

Validation acc. (%) 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_113" validated="false"><head>Table 3 :</head><label>3</label><figDesc>Accuracy of the TBCNN-pair model in comparison with previous results ( b</figDesc><table></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_115" validated="false"><head>Table 4 :</head><label>4</label><figDesc></figDesc><table>Validation and test accuracies of 
TBCNN-pair variants (in percentage). 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_117" validated="false"><head></head><label></label><figDesc>). We test each model on different test sets, and we collect their intrinsic perform- ance by means of perplexity. Words in the test set</figDesc><table>1 https://github.com/redpony/cpyp 
2 http://proycon.github.io/ 
colibri-core/ 
3 https://github.com/naiaden/cococpyp 

Test ngram limited ↓% full 
↓% 

1bw 171 
141 
6 
199 
-16 
jrc 
1232 
994 
19 728 
41 
emea 1749 
1304 
25 1069 39 
wp 
724 
635 
12 542 
25 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_118" validated="true"><head>Table 1 :</head><label>1</label><figDesc>Results of the full and limited back-</figDesc><table>off systems, trained on 1bw, tested on 1bw (in-
domain), and cross-domain sets jrc, emea, and wp. 
↓% is the relative reduction in perplexity for the 
column to its left. 

Comp. ngram limited ↓% full 
↓% 

a 
1280 
1116 
13 828 35 
b 
847 
785 
7 
639 24 
c 
1501 
1272 
15 946 37 
d 
1535 
1306 
15 975 36 
f 
708 
647 
9 
572 19 
g 
479 
445 
7 
440 8 
h 
1016 
916 
10 718 29 
i 
1075 
990 
8 
783 27 
j 
469 
434 
7 
442 6 
k 
284 
253 
11 333 -17 
l 
726 
639 
12 629 13 
m 
578 
538 
7 
512 11 
n 
895 
794 
11 664 26 
o 
1017 
887 
13 833 18 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_119" validated="false"><head>Table 2 :</head><label>2</label><figDesc>Results of the full and limited backoff systems, trained on Mediargus, tested on CGN.</figDesc><table></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_121" validated="false"><head>Table 1 :</head><label>1</label><figDesc></figDesc><table>In lexical simplification, it is often necessary to re-
place single words with phrases or phrases with single words. 
The above are examples of such lexical simplifications cap-
tured by the Simple PPDB resource. 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_122" validated="false"><head>Table 2</head><label>2</label><figDesc>shows the performance of the model on cross-validation, compared to several baselines. The full model achieves 60% accuracy,</figDesc><table>Acc 

Prec. 
Random 
47.1% 
0.0% 
Simple/Regular Wiki. Ratio 49.1% 47.6% 
Length in Characters 
51.4% 47.3% 
Google Ngram Frequency 
51.4% 44.2% 
Number of Syllables 
51.5% 45.3% 
Supervised Model, W2V 
54.7% 46.3% 
Supervised Model, Full 
60.4% 52.9% 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_123" validated="false"><head>Table 4</head><label>4</label><figDesc></figDesc><table>compares the different meth-
ods in terms of how well they rank simplifying 
rules above non-simplifying rules. Simple PPDB's 
ranking of the relative simplicity achieves an av-
eraged precision of 0.72 (0.77 P@1), compared 
to 0.70 (0.69 P@1) achieved by the Horn et al. 
(2014) system-i.e. the KauchakGenerator+SVM 
Ranker. We hypothesize that the performance 
difference between these two ranking systems is 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_124" validated="false"><head>Table 5</head><label>5</label><figDesc></figDesc><table>pro-
</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_125" validated="false"><head>Table 5 :</head><label>5</label><figDesc>Examples of candidate simplifications proposed by Simple PPDB and by three other generate-and-rank methods.</figDesc><table></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_127" validated="false"><head>Table 6 :</head><label>6</label><figDesc></figDesc><table>Overall coverage of three existing lexical simplifica-
tion methods compared to the Simple PPDB resource. Glavas 
is marked as ∞ since it generates candidates based on near-
ness in vector space, and in theory could generate as many 
words/phrases as are in the vocabulary of the vector space. 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_130" validated="false"><head></head><label></label><figDesc>).Institute of Informatics, Federal University of Rio Grande do Sul (Brazil)</figDesc><table>References 

Rie Kubota Ando and Tong Zhang. 2005. A frame-
work for learning predictive structures from multiple 
tasks and unlabeled data. The Journal of Machine 
Learning Research, 6:1817-1853. 

Razvan C Bunescu and Raymond J Mooney. 2005. A 
shortest path dependency kernel for relation extrac-
tion. In Empirical Methods in Natural Language 
Processing (EMNLP), pages 724-731. 

Rich Caruana. 1997. Multitask learning. Machine 
learning, 28(1):41-75. 

Xinchi Chen, Xipeng Qiu, Chenxi Zhu, Pengfei Liu, 
and Xuanjing Huang. 2015. Long short-term mem-
ory neural networks for chinese word segmentation. 
In Empirical Methods in Natural Language Process-
ing (EMNLP). 

Colin Cherry and Hongyu Guo. 2015. The unreason-
able effectiveness of word representations for twit-
ter named entity recognition. In North America 
Chapter of Association for Computational Linguis-
tics (NAACL). 

Michael Collins and Yoram Singer. 1999. Unsuper-
vised models for named entity classification. In 
Empirical Methods in Natural Language Processing 
(EMNLP), pages 100-110. 

Ronan Collobert and Jason Weston. 2008. A unified 
architecture for natural language processing: Deep 
neural networks with multitask learning. In Inter-
national Conference on Machine Learning (ICML), 
pages 160-167. 

Mark Dredze, Paul McNamee, Delip Rao, Adam Ger-
ber, and Tim Finin. 2010. Entity disambiguation 
for knowledge base population. In Conference on 
Computational Linguistics (Coling). Huiming Duan, Zhifang Sui, Ye Tian, and Wenjie Li. 
2012. The cips-sighan clp 2012 chineseword seg-
mentation onmicroblog corpora bakeoff. In CIPS-
SIGHAN Joint Conference on Chinese Language 
Processing, pages 35-40, Tianjin, China, December. 

Tim Finin, William Murnane, Anand Karandikar, 
Nicholas Keller, Justin Martineau, and Mark 
Dredze. 2010. Annotating named entities in twit-
ter data with crowdsourcing. In NAACL Workshop 
on Creating Speech and Language Data With Me-
chanical Turk. 

Hege Fromreide, Dirk Hovy, and Anders Søgaard. 
2014. Crowdsourcing and annotating NER for Twit-
ter# drift. In Language Resources and Evaluation 
Conference (LREC). 

JinLan Fu, Jie Qiu, Yunlong Guo, and Li Li. 2015. 
Entity linking and name disambiguation using SVM 
in chinese micro-blogs. In Conference on Natural 
Computation, pages 468-472. 

Jianfeng Gao, Mu Li, Andi Wu, and Chang-Ning 
Huang. 2005. Chinese word segmentation and 
named entity recognition: A pragmatic approach. 
Computational Linguistics, 31(4):531-574, Decem-
ber. 

Zhengyan He, Houfeng Wang, and Sujian Li. 2012. 
The task 2 of cips-sighan 2012 named entity recog-
nition and disambiguation in chinese bakeoff. In 
CIPS-SIGHAN Joint Conference on Chinese Lan-
guage Processing, pages 108-114, Tianjin, China, 
December. 

Zhiheng Huang, Wei Xu, and Kai Yu. 2015. Bidirec-
tional lstm-crf models for sequence tagging. arXiv 
preprint arXiv:1508.01991. 

Guangjin Jin and Xiao Chen. 2008. The fourth inter-
national Chinese language processing bakeoff: Chi-
nese word segmentation, named entity recognition 
and Chinese pos tagging. In SIGHAN Workshop on 
Chinese Language Processing, page 69. 

Guillaume Lample, Miguel Ballesteros, Sandeep Sub-
ramanian, Kazuya Kawakami, and Chris Dyer. 
2016. Neural architectures for named entity recog-
nition. In North America Chapter of Association for 
Computational Linguistics (NAACL). 

Chenliang Li, Jianshu Weng, Qi He, Yuxia Yao, An-
witaman Datta, Aixin Sun, and Bu-Sung Lee. 2012. 
Twiner: Named entity recognition in targeted twitter 
stream. In Conference on Research and Develop-
ment in Information Retrieval (SIGIR), SIGIR '12, 
pages 721-730, New York, NY, USA. 

Xiaohua Liu, Shaodian Zhang, Furu Wei, and Ming 
Zhou. 2011. Recognizing named entities in tweets. 
In Association for Computational Linguistics (ACL), 
pages 359-367. 

Xiaohua Liu, Ming Zhou, Furu Wei, Zhongyang Fu, 
and Xiangyang Zhou. 2012a. Joint inference 
of named entity recognition and normalization for 
tweets. In Association for Computational Linguis-
tics (ACL), pages 526-535. 

Xiaohua Liu, Ming Zhou, Furu Wei, Zhongyang Fu, 
and Xiangyang Zhou. 2012b. Joint inference 
of named entity recognition and normalization for 
tweets. In Association for Computational Linguis-
tics (ACL), pages 526-535. 

Xuezhe Ma and Eduard H. Hovy. 2016. End-to-end 
sequence labeling via bi-directional lstm-cnns-crf. 
CoRR, abs/1603.01354. 

Xinnian Mao, Yuan Dong, Saike He, Sencheng Bao, 
and Haila Wang. 2008. Chinese word segmentation 
and named entity recognition based on conditional 
random fields. In International Joint Conference on 
Natural Language Processing, pages 90-93. 

Andrew McCallum and Wei Li. 2003. Early results for 
named entity recognition with conditional random 
fields, feature induction and web-enhanced lexicons. 
In North America Chapter of Association for Com-
putational Linguistics (NAACL). 

Tomas Mikolov, Ilya Sutskever, Kai Chen, Greg S Cor-
rado, and Jeff Dean. 2013. Distributed representa-
tions of words and phrases and their composition-
ality. In Neural Information Processing Systems 
(NIPS), pages 3111-3119. 

David Nadeau and Satoshi Sekine. 2007. A sur-
vey of named entity recognition and classification. 
Lingvisticae Investigationes, 30(1):3-26. 

Alexandre Passos, Vineet Kumar, and Andrew McCal-
lum. 2014. Lexicon infused phrase embeddings for 
named entity resolution. CoRR, abs/1404.5367. 

Nanyun Peng and Mark Dredze. 2015. Named en-
tity recognition for chinese social media with jointly 
trained embeddings. In Proceedings of the Con-
ference on Empirical Methods in Natural Language 
Processing (EMNLP). 

Lev Ratinov, Dan Roth, Doug Downey, and Mike An-
derson. 2011. Local and global algorithms for dis-
ambiguation to Wikipedia. In Association for Com-
putational Linguistics (ACL), pages 1375-1384. 

Alan Ritter, Sam Clark, Oren Etzioni, et al. 2011. 
Named entity recognition in tweets: an experimental 
study. In Empirical Methods in Natural Language 
Processing (EMNLP), pages 1524-1534. 

Joseph Turian, Lev Ratinov, and Yoshua Bengio. 2010. 
Word representations: a simple and general method 
for semi-supervised learning. In Association for 
Computational Linguistics (ACL), pages 384-394. 

Yi Yang and Jacob Eisenstein. 2015. Unsupervised 
multi-domain adaptation with feature embeddings. 
In North America Chapter of Association for Com-
putational Linguistics (NAACL). Zhilin Yang, Ruslan Salakhutdinov, and William Co-
hen. 2016. Multi-task cross-lingual sequence tag-
ging from scratch. CoRR, abs/1603.06270. 

Suxiang Zhang, Ying Qin, Juan Wen, and Xiaojie 
Wang. 2006. Word segmentation and named entity 
recognition for sighan bakeoff3. In SIGHAN Work-
shop on Chinese Language Processing, pages 158-
161, Sydney, Australia, July. 

Xiaoqing Zheng, Hanyang Chen, and Tianyu Xu. 
2013. Deep learning for Chinese word segmentation 
and POS tagging. In Empirical Methods in Natural 
Language Processing (EMNLP), pages 647-657. How Naked is the Naked Truth? 
A Multilingual Lexicon of Nominal Compound Compositionality 

Carlos Ramisch 
1 , Silvio Cordeiro 
1,2 , Leonardo Zilio 

2 

Marco Idiart 
3 , Aline Villavicencio 
2 , Rodrigo Wilkens 

2 

1 Aix Marseille Université, CNRS, LIF UMR 7279 (France) 
2 </table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_131" validated="false"><head>Table 1 :</head><label>1</label><figDesc>Pearson correlation r and number of cases of high standard deviation σ.</figDesc><table></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_133" validated="false"><head>Table 2 :</head><label>2</label><figDesc>Most polemic and consensual compounds in each language (average±σ score). dani et al.</figDesc><table></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_136" validated="false"><head></head><label></label><figDesc>). The platform is cur- rently in alpha testing; we plan to open it up for general use during Q3 2016. People interested in obtaining an account may do so by mailing one of the authors of this paper.Society, pages 1-11, 2015. Re- trieved from http://dx.doi.org/10. 1007/s10209-015-0408-1 (last accessed November 20, 2015).</figDesc><table>David Chiang. A hierarchical phrase-based model 
for statistical machine translation. In Proceed-
ings of the 43rd Annual Meeting on Associa-
tion for Computational Linguistics, pages 263-
270. Association for Computational Linguis-
tics, 2005. 

Stephen Cox, Michael Lincoln, Judy Tryggvason, 
Melanie Nakisa, Mark Wells, Marcus Tutt, and 
Sanja Abbott. Tessa, a system to aid communi-
cation with deaf people. In Proceedings of the 
fifth international ACM conference on Assistive 
technologies, pages 205-212. ACM, 2002. 

Sarah Ebling and John Glauert. 
Building a 
Swiss German Sign Language avatar with 
JASigning and evaluating it among the Deaf 
community. 
Universal Access in the In-
formation Eleni Efthimiou, Stavroula-Evita Fotinea, Thomas 
Hanke, John Glauert, Richard Bowden, An-
nelies Braffort, Christophe Collet, Petros Mara-
gos, and François Lefebvre-Albaret. The Dicta-
Sign Wiki: Enabling web communication for 
the Deaf. In Proceedings of the 13th Interna-
tional Conference on Computers Helping Peo-
ple with Special Needs (ICCHP), pages 205-
212, Linz, Austria, 2012. 

Ralph Elliott, John RW Glauert, JR Kennaway, 
and Ian Marshall. The development of lan-
guage processing support for the ViSiCAST 
project. In Proceedings of the fourth interna-
tional ACM conference on Assistive technolo-
gies, pages 101-108. ACM, 2000. 

Ralph Elliott, John RW Glauert, JR Kennaway, 
Ian Marshall, and Eva Safar. Linguistic mod-
elling and language-processing technologies for 
avatar-based sign language presentation. Uni-
versal Access in the Information Society, 6(4): 
375-391, 2008. 

John Glauert. Animating sign language for Deaf 
people. Lecture held at the University of Zurich, 
October 9, 2013 (unpublished), 2013. 

Thomas Hanke. ViSiCAST Deliverable D5-1: In-
terface definitions. Technical report, ViSiCAST 
project, 2001. Retrieved from http://www. 
visicast.cmp.uea.ac.uk/Papers/ 
ViSiCAST_D5-1v017rev2.pdf 
(last 
accessed November 20, 2015). 

Vince Jennings, Ralph Elliott, Richard Kennaway, 
and John Glauert. Requirements for a signing 
avatar. In Proceedings of the 4th LREC Work-
shop on the Representation and Processing of 
Sign Languages, pages 133-136, La Valetta, 
Malta, 2010. 

Hernisa Kacorri, Matt Huenerfauth, Sarah Ebling, 
Kasmira Patel, and Mackenzie Willard. Demo-
graphic and experiential factors influencing ac-
ceptance of sign language animation by Deaf 
users. In Proceedings of the 17th International 
ACM SIGACCESS Conference on Computers &amp; 
Accessibility, pages 147-154. ACM, 2015. 

Michael Kipp, Alexis Heloir, and Quan Nguyen. 
Sign language avatars: Animation and com-
prehensibility. In Proceedings of the 11th In-
ternational Conference on Intelligent Virtual 
Agents (IVA), pages 113-126, Reykjavík, Ice-
land, 2011. 

Gary Morgan and Bencie Woll. The development 
of complex sentences in British Sign Language. 
In Gary Morgan and Bencie Woll, editors, Di-
rections in Sign Language Acquisition: Trends 
in Language Acquisition Research, pages 255-
276. John Benjamins, Amsterdam, Netherlands, 
2002. 

Siegmund Prillwitz, Regina Leven, Heiko Zienert, 
Thomas Hanke, and Jan Henning. HamNoSys: 
Version 2.0: An Introductory Guide. Signum, 
Hamburg, Germany, 1989. 

Manny Rayner. 
Using the Regulus Lite 
Speech2Sign Platform. 
http://www. 
issco.unige.ch/en/research/ 
projects/Speech2SignDoc/build/ 
html/index.html, 2016. Online documen-
tation. 

J. Reilly and D. Anderson. FACES: The ac-
quisition of non-manual morphology in ASL. 
In G. Morgan and B. Woll, editors, Direc-
tions in Sign Language Acquisition, pages 159-
181. John Benjamins, Amsterdam, Netherlands, 
2002. 

Eva Sáfár and John Glauert. Computer modelling. 
In Roland Pfau, Markus Steinbach, and Bencie Woll, editors, Sign Language: An International 
Handbook, pages 1075-1101. De Gruyter Mou-
ton, Berlin, Germany, 2012. 

Rubén San-Segundo, Juan Manuel Montero, 
Javier Macías-Guarasa, R Córdoba, Javier Fer-
reiros, and José Manuel Pardo. Proposing a 
speech to gesture translation architecture for 
Spanish deaf people. Journal of Visual Lan-
guages &amp; Computing, 19(5):523-538, 2008. 

Robert Smith and Brian Nolan. Emotional fa-
cial expressions in synthesised sign language 
avatars: A manual evaluation. Universal Access 
in the Information Society, pages 1-10, 2015. 
Retrieved from http://dx.doi.org/10. 
1007/s10209-015-0410-7 (last accessed 
November 20, 2015). 

J.C. Wells. SAMPA computer readable pho-
netic alphabet. In D. Gibbon, R. Moore, and 
R. Winski, editors, Handbook of Standards and 
Resources for Spoken Language Systems. De 
Gruyter Mouton, Berlin, Germany, 1997. 

Ronnie B. Wilbur. Phonological and prosodic lay-
ering of nonmanuals in American Sign Lan-
guage. In Karen Emmorey and Harlan Lane, 
editors, The Signs of Language Revisited, pages 
215-244. Erlbaum, Mahwah, NJ, 2000. Word Alignment without NULL Words 

Philip Schulz 
P.Schulz@uva.nl 

Wilker Aziz 
W.Aziz@uva.nl 

ILLC 
University of Amsterdam 

Khalil Sima'an 
K.Simaan@uva.nl 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_138" validated="false"><head>Table 1 :</head><label>1</label><figDesc>Translation results from and into English. Alignments in the top</figDesc><table></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_140" validated="true"><head>Table 1 :</head><label>1</label><figDesc>Statistics of the datasets used in the experiments. The scripted training corpus is included.</figDesc><table>Language Training data 

Development data 
Types Tokens Types Tokens Type OOV% Token OOV% 
Assamese 
8738 
73284 
7309 
66357 
49.75 
8.36 
Bengali 
9507 
81564 
7844 
70724 
50.90 
8.56 
Pashto 
7027 115225 6174 108273 
44.91 
4.26 
Tagalog 
6370 
69791 
5614 
64506 
55.61 
8.13 
Tamil 
16284 76916 14279 70429 
65.08 
16.89 
Turkish 
12147 77310 
9944 
67171 
57.25 
12.53 
Zulu 
16008 65821 13848 57217 
68.88 
21.91 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_142" validated="false"><head>Table 2 :</head><label>2</label><figDesc></figDesc><table>Type-based OOV reduction rates for the 
50k best words </table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_143" validated="true"><head>Table 4 :</head><label>4</label><figDesc>Type-based OOV rate comparison to Kaldi</figDesc><table>Language Vocabulary size Kaldi Suggested 
Assamese 
845k 
4.3 
3.5 
Bengali 
834k 
4.6 
3.6 
Pashto 
494k 
2.4 
1.9 
Tagalog 
581k 
5.3 
4.6 
Tamil 
896k 
11.2 
9.1 
Turkish 
704k 
7.9 
6.0 
Zulu 
818k 
12.5 
11.4 

Table 5: Token-based OOV rate comparison to 
Kaldi 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_146" validated="false"><head>Table 2 :</head><label>2</label><figDesc>Mean values of demographic features and level of statistical significance in terms of p-value.</figDesc><table></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_147" validated="false"><head>Table 4 .</head><label>4</label><figDesc></figDesc><table>T1 

T2 
T3 
Significance 
Feature 
MCI control MCI control MCI control 
T1 
T2 
T3 
token # 
141.46 126.31 209.40 129.72 124.21 121.33 
0.0017 
sentence # 
8.38 
8.50 
13.42 
10.22 
8.08 
8.11 
token % 
22.40 
18.42 
20.01 
16.04 
20.19 
19.25 
0.0015 
word # 
115.54 101.53 168.65 101.39 100.27 99.36 
lemma # 
68.40 
64.31 101.19 70.86 
61.85 
61.50 
0.0017 
lemma % 
0.51 
0.54 
0.54 
0.59 
0.53 
0.53 
0.0214 
verb # 
21.71 
21.31 
36.63 
24.11 
19.56 
19.97 
0.0033 
verb % 
0.19 
0.21 
0.23 
0.25 
0.20 
0.21 
0.0009 
noun # 
23.98 
25.42 
33.23 
23.00 
21.69 
21.97 
0.0149 
noun % 
0.21 
0.25 
0.19 
0.24 
0.22 
0.22 
0.0004 0.0001 
adjective # 
6.13 
3.75 
9.50 
5.47 
4.77 
5.50 
0.0068 0.0051 
adjective % 
0.05 
0.04 
0.06 
0.05 
0.04 
0.05 
0.0067 0.0259 
pronoun # 
14.29 
10.11 
15.85 
7.67 
14.21 
13.25 0.0082 0.0001 
pronoun % 
0.12 
0.10 
0.09 
0.08 
0.14 
0.13 
0.0053 0.0227 
conjunction # 
12.69 
9.53 
18.19 
8.72 
10.81 
10.14 0.0345 0.0009 
conjunction % 
0.10 
0.09 
0.10 
0.08 
0.10 
0.10 
0.0417 
Sg1 verb # 
3.42 
2.25 
18.94 
13.36 
2.63 
2.64 
0.0341 0.0224 
punctuation # 
25.92 
24.78 
40.75 
28.33 
23.94 
21.97 
0.0062 
unknown word # 
0.31 
0.19 
0.31 
0.11 
0.08 
0.08 
unknown word % 
0.21 
0.25 
0.12 
0.10 
0.07 
0.07 
filled pause # 
3.65 
2.44 
3.92 
1.56 
2.35 
1.44 
0.0319 
pause # 
12.63 
9.11 
19.77 
9.89 
11.15 
7.28 
0.0008 0.0191 
pause after article # 
1.40 
1.08 
1.23 
0.72 
1.29 
0.81 
0.0449 
lengthened sound # 24.35 
20.39 
35.44 
19.89 
19.94 
18.22 
0.0008 
hesitation # 
17.40 
12.39 
25.92 
12.25 
14.71 
9.25 
0.0362 0.0007 0.0047 
hesitation % 
12.93 
9.32 
12.67 
10.19 
12.06 
7.55 
0.0216 
0.0010 
uncertain word # 
6.44 
4.83 
7.48 
2.81 
6.23 
5.89 
0.0003 
uncertain word % 
4.36 
3.69 
3.15 
2.07 
4.89 
4.89 
0.0087 
memory word # 
1.23 
0.69 
0.54 
0.17 
0.96 
1.14 
0.0211 0.0166 
memory word % 
0.93 
0.56 
0.28 
0.12 
0.72 
0.83 
film word 1 
10.56 
12.92 
0.21 
0.14 
4.02 
4.75 
0.0325 
film word 2 
5.75 
5.69 
0.33 
0.28 
9.10 
11.06 
0.0291 
content word % 
0.60 
0.63 
0.69 
0.72 
0.60 
0.61 
0.0441 0.0042 
function word % 
0.39 
0.37 
0.31 
0.28 
0.40 
0.39 
0.0342 0.0041 
negation # 
2.42 
1.39 
3.50 
1.47 
2.13 
2.17 
0.0305 0.0034 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_148" validated="false"><head>Table 3 :</head><label>3</label><figDesc>Mean values of features and level of statistical significance in terms of p-value. #: number, %:ratio, T: transcript.+3.4 +3.6 +16.7 +9.8 +6.9 +6.0 +6.2 +5.9</figDesc><table>184 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_149" validated="false"><head></head><label></label><figDesc>APA. 2000. DSM-IV-TR. American Psychiatric Asso- ciation. Vassilis Baldas, Charalampos Lampiris, Christos N. Capsalis, and Dimitrios Koutsouris. 2010. Early Di- agnosis of Alzheimer's Type Dementia Using Con- tinuous Speech Recognition. In James C. Lin and Konstantina S. Nikita, editors, MobiHealth, vol- ume 55 of Lecture Notes of the Institute for Com- puter Sciences, Social Informatics and Telecommu- nications Engineering, pages 105-110. Springer.Linda Boise, Margaret B Neal, and Jeffrey Kaye. 2004. Dementia assessment in primary care: Results from a study in three managed care systems. The Jour- nals of Gerontology Series A: Biological Sciences and Medical Sciences, 59(6):M621-M626. R.S. Bucks, S. Singh, J.M. Cuerden, and G.K. Wilcock. 2000. Analysis of spontaneous, conversational speech in dementia of alzheimer type: evaluation of an objective technique for analysing lexical perfor- mance. Aphasiology, 14(1):71-91. Corinna Cortes and Vladimir Vapnik. 1995. Support- vector networks. Machine Learning, 20(3):273- 297. Karen Croot, John R. Hodges, John Xuereb, and Kara- lyn Patterson. 2000. Phonological and articulatory impairment in alzheimer's disease: A case series.Kathleen Fraser, Frank Rudzicz, Naida Graham, and Elizabeth Rochon. 2013a. Automatic speech recog- nition in the diagnosis of primary progressive apha- sia. Proceedings of the Fourth Workshop on Speech and Language Processing for Assistive Technolo- gies, pages 47-54. Kathleen C. Fraser, Frank Rudzicz, and Elizabeth Ro- chon. 2013b. Using text and acoustic features to di- agnose progressive aphasia and its subtypes. In Fr- dric Bimbot, Christophe Cerisara, Ccile Fougeron, Guillaume Gravier, Lori Lamel, Franois Pellegrino, and Pascal Perrier, editors, INTERSPEECH, pages 2177-2181. ISCA. Kathleen C Fraser, Jed A Meltzer, Naida L Graham, Carol Leonard, Graeme Hirst, Sandra E Black, and Elizabeth Rochon. 2014. Automated classification of primary progressive aphasia subtypes from narra- tive speech transcripts. Cortex, 55:43-60. Peter Garrard, Lisa M Maloney, John R Hodges, and Karalyn Patterson. 2005. The effects of very early Alzheimer's disease on the characteristics of writing by a renowned author. Brain, 128(2):250-260. Mark Hall, Eibe Frank, Geoffrey Holmes, Bernhard Pfahringer, Peter Reutemann, and Ian H. Witten. 2009. The WEKA data mining software: an update. SIGKDD Explorations, 11(1):10-18. Graeme Hirst and Vanessa Wei Feng. 2012. Changes in style in authors with Alzheimer's disease. English Studies, 93(3):357-370. David I. Holmes and Sameer Singh. 1996. A stylomet- ric analysis of conversational speech of aphasic pa- tients. Literary and Linguistic Computing, 11:133- 140. William Jarrold, Bart Peintner, David Wilkins, Dimitra Vergryi, Colleen Richey, Maria L. Gorno-Tempini, and Jennifer Ogar. 2014. Aided diagnosis of dementia type through computer-based analysis of spontaneous speech. In Proceedings of the Work- shop on Computational Linguistics and Clinical Psychology: From Linguistic Signal to Clinical Re- ality, pages 27-37, Baltimore, Maryland, USA, June. Association for Computational Linguistics. János Kálmán, Magdolna Pákáski, Ildikó Hoffmann, Gergely Drótos, Gyöngyi Darvas, Krisztina Boda, Tamás Bencsik, Aliz Gyimesi, Zsófia Gulyás, Mag- dolna Bálint, Gréta Szatlóczki, and Edina Papp. 2013. Early mental test -developing a screening test for mild cognitive impairment. Ideggyógyászati szemle, 66(1-2):43-52. Xuan Le, Ian Lancashire, Graeme Hirst, and Regina Jokel. 2011. Longitudinal detection of dementia through lexical and syntactic changes in writing: a case study of three British novelists.Maider Lehr, Emily Tucker Prud'hommeaux, Izhak Shafran, and Brian Roark. 2012. Fully automated neuropsychological assessment for detecting mild cognitive impairment. In INTERSPEECH, pages 1039-1042. ISCA. Karmele Lopez-de Ipiña, Jesús B Alonso, Jordi Solé- Casals, Nora Barroso, Patricia Henriquez, Mar- cos Faundez-Zanuy, Carlos M Travieso, Miriam Ecay-Torres, Pablo Martinez-Lage, and Harkaitz Eguiraun. 2015. On automatic diagnosis of alzheimers disease based on spontaneous speech analysis and emotional temperature. Cognitive Computation, 7(1):44-55. Selam Negash, Lindsay E Petersen, Yonas E Geda, David S Knopman, Bradley F Boeve, Glenn E Smith, Robert J Ivnik, Darlene V Howard, James H Howard Jr, and Ronald C Petersen. 2007. Ef- fects of ApoE genotype and Mild Cognitive Impair- ment on implicit learning.Aharon Satt, Ron Hoory, Alexandra König, Pauline Aalten, and Philippe H. Robert. 2014. Speech- based automatic and robust detection of very early dementia. In 15th Annual Conference of the Inter- national Speech Communication Association, pages 2538-2542. Calvin Thomas, Vlado Kešelj, Nick Cercone, Kenneth Rockwood, and Elissa Asp. 2005. Automatic de- tection and rating of dementia of Alzheimer type through lexical analysis of spontaneous speech. In Mechatronics and Automation, 2005 IEEE Inter- national Conference, volume 3, pages 1569-1574. IEEE. László Tóth, Gábor Gosztolya, Veronika Vincze, Ildikó Hoffmann, Gréta Szatlóczki, Edit Biró, Fruzsina Zsura, Magdolna Pákáski, and János Kálmán. 2015. Automatic detection of mild cognitive impairment from spontaneous speech using ASR. In 16th An- nual Conference of the International Speech Com- munication Association, pages 2694-2698. Veronika Vincze. 2013. Weasels, Hedges and Pea- cocks: Discourse-level Uncertainty in Wikipedia Articles. In Proceedings of the Sixth International Joint Conference on Natural Language Processing, pages 383-391, Nagoya, Japan, October. Asian Fed- eration of Natural Language Processing. János Zsibrita, Veronika Vincze, and Richárd Farkas. 2013. magyarlanc: A toolkit for morphological and dependency parsing of Hungarian. In Proceedings of RANLP, pages 763-771.Marie-Francine Moens Department of Computer Science KU Leuven sien.moens@cs.kuleuven.be</figDesc><table>Kathryn A Bayles. 1982. Language function in senile 
dementia. Brain and Language, 16(2):265-280. 

Brain and Language, 75(2):277 -309. 

Literary and 
Linguistic Computing, 26(4):435-461. 

Neurobiology of Aging, 
28(6):885-893. 

Brian Roark, Margaret Mitchell, John-Paul Hosom, 
Kristy Hollingshead, and Jeffrey Kaye. 2011. Spo-
ken language derived measures for detecting mild 
cognitive impairment. IEEE Transactions on Au-
dio, Speech, and Language Processing, 19(7):2081-
2090. Multi-Modal Representations for Improved Bilingual Lexicon Learning 

Ivan Vulić 
Language Technology Lab, DTAL 
University of Cambridge 
iv250@cam.ac.uk 

Douwe Kiela 
Computer Laboratory 
University of Cambridge 
dk427@cam.ac.uk 

Stephen Clark 
Computer Laboratory 
University of Cambridge 
sc609@cam.ac.uk 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_150" validated="false"><head></head><label></label><figDesc>VULIC1000: constructed to measure the gen- eral performance of linguistic BLL models from comparable Wikipedia data (Vulić and Moens, 2013), this is considered a benchmarking test set for (linguistic) BLL models from comparable data (Vulić and Moens, 2016) 5 . It comprises 1, 000 nouns in ES, IT, and NL, along with their one- to-one ground-truth word translations in EN com- piled semi-automatically. Translation direction is ES/IT /N L → EN . Training Data and Setup We used standard training data and suggested settings to learn M/G/V-EMB model representations. M-EMB and G-EMB were trained on the full cleaned and tok- enized Wikipedias from the Polyglot website (Al- Rfou et al., 2013). V-EMB was trained on the full tokenized document-aligned Wikipedias from</figDesc><table>Pair: 

B: EN→ES|V: ES→EN 
B: EN→IT|V: IT→EN 
B: EN→NL|V: NL→EN 

Models 
M-EMB 
G-EMB 
V-EMB 
M-EMB 
G-EMB 
V-EMB 
M-EMB 
G-EMB 
V-EMB 

Linguistic 

d = 300 
0.71 0.77 
0.60 0.73 
0.68 0.82 
0.77 0.76 
0.63 0.71 
0.75 0.79 
0.77 0.76 
0.59 0.75 
0.74 0.79 

Visual 

CNN-Max 
0.51 0.35 
0.51 0.35 
0.51 0.35 
0.54 0.22 
0.54 0.22 
0.54 0.22 
0.56 0.33 
0.56 0.33 
0.56 0.33 
CNN-AvgMax 
0.55 0.38 
0.54 0.38 
0.54 0.38 
0.56 0.25 
0.56 0.25 
0.56 0.25 
0.60 0.34 
0.60 0.34 
0.60 0.34 

Multi-modal with global α 

Max-E-0.5 
0.76 0.79 
0.66 0.79 
0.71 0.83 
0.83 0.75 
0.72 0.70 
0.80 0.80 
0.85 0.80 
0.69 0.78 
0.80 0.81 
Max-E-0.7 
0.75 0.80 
0.62 0.76 
0.70 0.85 
0.81 0.77 
0.66 0.73 
0.78 0.82 
0.84 0.80 
0.61 0.79 
0.80 0.82 
Max-L-0.7 
0.76 0.80 
0.64 0.78 
0.71 0.85 
0.82 0.77 
0.69 0.73 
0.80 0.82 
0.85 0.82 
0.64 0.79 
0.81 0.83 

Avg-L-0.5 
0.77 0.78 
0.68 0.79 
0.73 0.83 
0.84 0.77 
0.75 0.70 
0.81 0.79 
0.86 0.80 
0.76 0.78 
0.83 0.81 
Avg-L-0.7 
0.77 0.81 
0.66 0.79 
0.72 0.85 
0.83 0.78 
0.72 0.75 
0.80 0.83 
0.86 0.83 
0.70 0.81 
0.81 0.83 

Multi-modal with image dispersion (ID) weighting 

Max-E-ID 
0.76 0.80 
0.66 0.78 
0.71 0.84 
0.81 0.77 
0.69 0.73 
0.80 0.81 
0.84 0.80 
0.64 0.79 
0.81 0.82 
Max-L-ID 
0.77 0.80 
0.66 0.78 
0.72 0.85 
0.82 0.77 
0.70 0.73 
0.80 0.81 
0.84 0.82 
0.65 0.79 
0.81 0.82 
Avg-L-ID 
0.77 0.81 
0.67 0.79 
0.73 0.84 
0.83 0.78 
0.74 0.73 
0.80 0.83 
0.85 0.82 
0.72 0.80 
0.82 0.82 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_151" validated="false"><head>Table 1 :</head><label>1</label><figDesc>Summary of the Acc 1 scores on BERGSMA500 (regular font) and VULIC1000 (italic) across all BLL runs. M/G/V-EMB denotes the BWE linguistic model. Other settings are in the form Y-Z-0.W: (1) Y denotes the visual metric, (2) Z denotes the fusion model: E is for Early-Fusion, L is for Late-Fusion, and (3) 0.W denotes the α value. Highest scores per column are in bold.</figDesc><table></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_152" validated="false"><head></head><label></label><figDesc>Lawrence W. Barsalou and Katja Wiemer-Hastings. 2005. Situating abstract concepts. In D. Pecher and R. Zwaan, editors, Grounding cognition: The role of perception and action in memory, language, and thought, pages 129-163.Sarath A.P. Chandar, Stanislas Lauly, Hugo Larochelle, Mitesh M. Khapra, Balaraman Ravindran, Vikas C. Raykar, and Amrita Saha. 2014. An autoencoder approach to learning bilingual word representations. In NIPS, pages 1853-1861. Jia Deng, Wei Dong, Richard Socher, Li-Jia Li, Kai Li, and Fei-Fei Li. 2009. ImageNet: A large-scale hierarchical image database. In CVPR, pages 248- 255. Thomas Deselaers and Vittorio Ferrari. 2011. Vi- sual and semantic similarity in ImageNet. In CVPR, pages 1777-1784. Georgiana Dinu, Angeliki Lazaridou, and Marco Ba- roni. 2015. Improving zero-shot learning by miti- gating the hubness problem. In ICLR Workshop Pa- pers. D. Elliott, S. Frank, K. Sima'an, and L. Specia. 2016. Multi30K: Multilingual English-German Image De- scriptions. CoRR, abs/1605.00459. Manaal Faruqui and Chris Dyer. 2014. Improving vector space word representations using multilingual correlation. In EACL, pages 462-471. Andrea Frome, Gregory S. Corrado, Jonathon Shlens, Samy Bengio, Jeffrey Dean, Marc'Aurelio Ranzato, and Tomas Mikolov. 2013. Devise: A deep visual- semantic embedding model. In NIPS, pages 2121- 2129. Éric Gaussier, Jean-Michel Renders, Irina Matveeva, Cyril Goutte, and Hervé Déjean. 2004. A geometric view on bilingual lexicon extraction from compara- ble corpora. In ACL, pages 526-533. Stephan Gouws, Yoshua Bengio, and Greg Corrado. 2015. BilBOWA: Fast bilingual distributed repre- sentations without word alignments. In ICML, pages 748-756. Karl Moritz Hermann and Phil Blunsom. 2014. Multi- lingual models for compositional distributed seman- tics. In ACL, pages 58-68. Yangqing Jia, Evan Shelhamer, Jeff Donahue, Sergey Karayev, Jonathan Long, Ross B. Girshick, Sergio Guadarrama, and Trevor Darrell. 2014. Caffe: Con- volutional architecture for fast feature embedding. In ACM Multimedia, pages 675-678.Douwe Kiela, Ivan Vulić, and Stephen Clark. 2015. Visual bilingual lexicon induction with transferred ConvNet features. In EMNLP, pages 148-158. Adam Kilgarriff. 1997. Putting frequencies in the dictionary. International Journal of Lexicography, 10(2):135-155. Alex Krizhevsky, Ilya Sutskever, and Geoffrey E. Hin- ton. 2012. ImageNet classification with deep con- volutional neural networks. In NIPS, pages 1106- 1114. George Lakoff and Mark Johnson. 1999. Philosophy in the flesh: The embodied mind and its challenge to Western thought. Angeliki Lazaridou, Georgiana Dinu, and Marco Ba- roni. 2015a. Hubness and pollution: Delving into cross-space mapping for zero-shot learning. In ACL, pages 270-280. Angeliki Lazaridou, Nghia The Pham, and Marco Ba- roni. 2015b. Combining language and vision with a multimodal skip-gram model. In NAACL-HLT, pages 153-163. Thang Luong, Hieu Pham, and Christopher D. Man- ning. 2015. Bilingual word representations with monolingual quality in mind. In Proceedings of the 1st Workshop on Vector Space Modeling for Natural Language Processing, pages 151-159. Tomas Mikolov, Quoc V. Le, and Ilya Sutskever. 2013. Exploiting similarities among languages for ma- chine translation. CoRR, abs/1309.4168. Jose Costa Pereira, Emanuele Coviello, Gabriel Doyle, Nikhil Rasiwasia, Gert R. G. Lanckriet, Roger Levy, and Nuno Vasconcelos. 2014. On the role of corre- lation and abstraction in cross-modal multimedia re- trieval. IEEE Transactions on Pattern Analysis and Machine Intelligence, 36(3):521-535. Janarathanan Rajendran, Mitesh M. Kapra, Sarath Chandar, and Balaraman Ravindran. 2016. Bridge correlational neural networks for multilingual multi- modal representation learning. In NAACL. Pushpendre Rastogi, Benjamin Van Durme, and Raman Arora. 2015. Multiview LSA: Representation learn- ing via generalized CCA. In NAACL, pages 556- 566. Olga Russakovsky, Jia Deng, Hao Su, Jonathan Krause, Sanjeev Satheesh, Sean Ma, Zhiheng Huang, An- drej Karpathy, Aditya Khosla, Michael S. Bernstein, Alexander C. Berg, and Fei-Fei Li. 2015. ImageNet large scale visual recognition challenge. Interna- tional Journal of Computer Vision, 115(3):211-252.Hubert Soyer, Pontus Stenetorp, and Akiko Aizawa. 2015. Leveraging monolingual data for crosslingual compositional word representations. In ICLR. Jörg Tiedemann. 2012. Parallel data, tools and inter- faces in OPUS. In LREC, pages 2214-2218. Ivan Vulić and Marie-Francine Moens. 2013. A study on bootstrapping bilingual vector spaces from non- parallel data (and nothing else). In EMNLP, pages 1613-1624. Ivan Vulić and Marie-Francine Moens. 2015. Mono- lingual and cross-lingual information retrieval mod- els based on (bilingual) word embeddings. In SI- GIR, pages 363-372. Ivan Vulić and Marie-Francine Moens. 2016. Bilingual distributed word representations from document-aligned comparable data. Journal of Arti- ficial Intelligence Research, 55:953-994. Weiran Wang, Raman Arora, Karen Livescu, and Jeff A. Bilmes. 2015. On deep multi-view repre- sentation learning. In ICML, pages 1083-1092. Is This Post Persuasive? Ranking Argumentative Comments in the Online ForumSchool of Data Science, Fudan University, Shanghai, P.R.China 2 Computer Science Department, The University of Texas at Dallas Richardson, Texas 75080, USA {zywei,yangl,yili}@hlt.utdallas.edu</figDesc><table>Shane Bergsma and Benjamin van Durme. 2011. 
Learning bilingual lexicons using the visual similar-
ity of labeled web images. In IJCAI, pages 1764-
1769. 

Elia Bruni, Nam-Khanh Tran, and Marco Baroni. 
2014. Multimodal distributional semantics. Journal 
of Artiifical Intelligence Research, 49:1-47. 

Douwe Kiela and Léon Bottou. 2014. Learning image 
embeddings using convolutional neural networks for 
improved multi-modal semantics. In EMNLP, pages 
36-45. 

Douwe Kiela, Felix Hill, Anna Korhonen, and Stephen 
Clark. 2014. Improving multi-modal representa-
tions using image dispersion: Why less is sometimes 
more. In ACL, pages 835-841. 

Carina Silberer and Mirella Lapata. 2014. Learn-
ing grounded meaning representations with autoen-
coders. In ACL, pages 721-732. 

Zhongyu Wei 
12 , Yang Liu 
2 and Yi Li 

2 

1 </table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_154" validated="false"><head>Table 1 :</head><label>1</label><figDesc>Statistics of the CMV dataset. minus the down votes is called karma, indicating the persuasiveness of the reply. Users can also give delta to a comment if it changes their orig- inal mind about the topic. The comment is then named delta awarded comment (DAC), and the thread containing a DAC is noted as delta awarded thread.</figDesc><table></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_155" validated="false"><head></head><label></label><figDesc>Argumentation Related Features connective words Number of connective words in c. modal verbs Number of modal verbs included in c. argumentative sentence Number and percentage of argumentative sentences. argument relevance Similarity with the original post and parent comment. argument originality Maximum similarity with comments published earlier.</figDesc><table></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_156" validated="false"><head>Table 2 :</head><label>2</label><figDesc>Feature list (c: the comment; rc: the root comment of c.)</figDesc><table></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_157" validated="false"><head></head><label></label><figDesc>). We then use the number and percentage of argumentative sen- 9 It is a comment that replies to the original post directly.</figDesc><table>197 

Approach 

NDCG@1 NDCG@5 NDCG@10 
random 
0.258 
0.440 
0.564 
author 
0.382 
0.567 
0.664 
entry-order 
0.460 
0.600 
0.689 
LTRtext 
0.372 
0.558 
0.658 
LTR social 
0.475 

 † 

0.650 

 † 

0.718 

 † 

LTRarg 
0.475 

 † 

0.652 

 † 

0.725 

 † 

LTR text+social 
0.494 

 † 

0.666 

 † 

0.733 

 † 

LTRtext+arg 
0.485 

 † 

0.654 

 † 

0.729 

 † 

LTR social+arg 
0.502 

 †  ‡ 

0.674 

 †  ‡ 

0.740 

 † 

LTRT +S+A 
0.508 

 †  ‡ 

0.676 

 †  ‡ 

0.743 

 †  ‡ 

LTR all 
0.521 

 †  ‡ 

0.685 

 †  ‡ 

0.752 

 †  ‡ 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_158" validated="false"><head></head><label></label><figDesc>In Proceedings of the Companion Publication of the 23rd International Conference on World Wide Web Companion, pages 615-620. Marco Guerini, GözdeÖzbal, and Carlo Strapparava. 2015. Echoes of persuasion: The effect of eu- phony in persuasive communication. arXiv preprint arXiv:1508.05817. Kazi Saidul Hasan and Vincent Ng. 2014. Why are you taking this stance? identifying and classifying reasons in ideological debates. In Proceedings of the Conference on Empirical Methods in Natural Lan- guage Processing, pages 751-762. Aaron Jaech, Vicky Zayats, Hao Fang, Mari Osten- dorf, and Hannaneh Hajishirzi. 2015. Talking to the crowd: What do people react to in online discus- sions? In Proceedings of the Conference on Empiri- cal Methods in Natural Language Processing, pages 2026-2031. Kalervo Järvelin and Jaana Kekäläinen. 2000. IR eval- uation methods for retrieving highly relevant docu- ments. In Proceedings of the 23rd annual interna- tional ACM SIGIR conference on Research and de- velopment in information retrieval, pages 41-48. Thorsten Joachims. 2002. Optimizing search en- gines using clickthrough data. In Proceedings of the Eighth ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, pages 133- 142. Annie Louis and Ani Nenkova. 2013. What makes writing great? first experiments on article quality prediction in the science journalism domain. Trans- actions of the Association for Computational Lin- guistics, 1:341-352. Christopher D. Manning, Mihai Surdeanu, John Bauer, Jenny Finkel, Steven J. Bethard, and David Mc- Closky. 2014. The Stanford CoreNLP natural lan- guage processing toolkit. In Proceedings of the Association for Computational Linguistics System Demonstrations, pages 55-60. Deokgun Park, Simranjit Sachar, Nicholas Diakopou- los, and Niklas Elmqvist. 2016. Supporting com- ment moderators in identifying high quality online news comments. In Proceedings of the 2016 CHI Conference on Human Factors in Computing Sys- tems. Sarvesh Ranade, Jayant Gupta, Vasudeva Varma, and Radhika Mamidi. 2013a. Online debate summa- rization using topic directed sentiment analysis. In Proceedings of the Second International Workshop on Issues of Sentiment Discovery and Opinion Min- ing, page 7. Sarvesh Ranade, Rajeev Sangal, and Radhika Mamidi. 2013b. Stance classification in online debates by recognizing users' intentions. In Proceedings of Special Interest Group on Discourse and Dialogue, pages 61-69. Swapna Somasundaran and Janyce Wiebe. 2010. Rec- ognizing stances in ideological on-line debates. In Proceedings of the NAACL HLT 2010 Workshop on Computational Approaches to Analysis and Genera- tion of Emotion in Text, pages 116-124.Chenhao Tan, Lillian Lee, and Bo Pang. 2014. The effect of wording on message propagation: Topic- and author-controlled natural experiments on twitter. arXiv preprint arXiv:1405.1438. Chenhao Tan, Vlad Niculae, Cristian Danescu- Niculescu-Mizil, and Lillian Lee. 2016. Winning arguments: Interaction dynamics and persuasion strategies in good-faith online discussions. arXiv preprint arXiv:1602.01103. Amine Trabelsi and Osmar R Zaıane. 2014. Finding arguing expressions of divergent viewpoints in on- line debates. In Proceedings of the 5th Workshop on Language Analysis for Social Media (LASM)@ EACL, pages 35-43.Value of Semantic Parse Labeling for Knowledge Base Question Answering Wen-tau Yih Matthew Richardson Christopher Meek Ming-Wei Chang Jina Suh Microsoft Research Redmond, WA 98052, USA {scottyih,mattri,meek,minchang,jinsuh}@microsoft.com</figDesc><table>Christian Stab and Iryna Gurevych. 2014. Identifying 
argumentative discourse structures in persuasive es-
says. In Proceedings of the Conference on Empiri-
cal Methods in Natural Language Processing, pages 
46-56. 

The </table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_159" validated="false"><head></head><label></label><figDesc>who voiced meg on family guy? Topic Entity: Meg Griffin (m.035szd) Inf. Chain: in-tv-program -actor Constraints: (1) y 0 -series -Family Guy (m.019nnl) (2) y 0 -performance-type -Voice (m.02nsjvf)</figDesc><table>Family Guy 

in-tv-program 
actor 

Meg Griffin 

x 
y 0 

Voice 

PREFIX ns: &lt;http://rdf.freebase.com/ns/&gt; 
SELECT ?x 
WHERE { 
ns:m.035szd ns:tv.tv_character.appeared_in_tv_program ?y0 . 
?y0 ns:tv.regular_tv_appearance.actor ?x ; 
ns:tv.regular_tv_appearance.series ns:m.019nnl ; 
ns:tv.regular_tv_appearance.special_performance_type 
ns:m.02nsjvf . 
} 

(a) 

(b) 

(c) 

(d) 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_160" validated="false"><head></head><label></label><figDesc>Training Signals Prec. Rec. Avg. F 1 Acc.Table 1: The results of two different model train- ing settings: answers only vs. semantic parses.</figDesc><table>Answers 
67.3 73.1 66.8 
58.8 
Sem. Parses 
70.9 80.3 71.7 
63.9 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_162" validated="false"><head>Table 2 :</head><label>2</label><figDesc>Comparing labeling methods on 50 sampled ques- tions.</figDesc><table></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_163" validated="false"><head></head><label></label><figDesc>Hannah Bast and Elmar Haussmann. 2015. More ac- curate question answering on Freebase. In Proceed- ings of the 24th ACM International on Conference on Information and Knowledge Management, pages 1431-1440. ACM. Jonathan Berant and Percy Liang. 2014. Seman- tic parsing via paraphrasing. In Proceedings of the 52nd Annual Meeting of the Association for Compu- tational Linguistics (Volume 1: Long Papers), pages 1415-1425, Baltimore, Maryland, June. Association for Computational Linguistics. Jonathan Berant, Andrew Chou, Roy Frostig, and Percy Liang. 2013. Semantic parsing on Freebase from question-answer pairs. In Proceedings of the 2013 Conference on Empirical Methods in Natural Lan- guage Processing, pages 1533-1544, Seattle, Wash- ington, USA, October. Association for Computa- tional Linguistics. Qingqing Cai and Alexander Yates. 2013. Large- scale semantic parsing via schema matching and lex- icon extension. In Proceedings of the 51st Annual Meeting of the Association for Computational Lin- guistics (Volume 1: Long Papers), pages 423-433, Sofia, Bulgaria, August. Association for Computa- tional Linguistics. James Clarke, Dan Goldwasser, Ming-Wei Chang, and Dan Roth. 2010. Driving semantic parsing from the world's response. In Proceedings of the Four- teenth Conference on Computational Natural Lan- guage Learning, pages 18-27. Association for Com- putational Linguistics. Luheng He, Mike Lewis, and Luke Zettlemoyer. 2015. Question-answer driven semantic role labeling: Us- ing natural language to annotate natural language. In Proceedings of the 2015 Conference on Empiri- cal Methods in Natural Language Processing, pages 643-653, Lisbon, Portugal, September. Association for Computational Linguistics.Siva Reddy, Mirella Lapata, and Mark Steedman. 2014. Large-scale semantic parsing without question-answer pairs. Transactions of the Associ- ation for Computational Linguistics, 2:377-392. Yuk Wah Wong and Raymond J Mooney. 2007. Learning synchronous grammars for semantic pars- ing with lambda calculus. In Annual Meeting of the Association for Computational Linguistics (ACL). Yi Yang and Ming-Wei Chang. 2015. S-MART: Novel tree-based structured learning algorithms applied to tweet entity linking. In Proceedings of the 53rd An- nual Meeting of the Association for Computational Linguistics and the 7th International Joint Confer- ence on Natural Language Processing (Volume 1: Long Papers), pages 504-513, Beijing, China, July. Association for Computational Linguistics. Wen-tau Yih, Ming-Wei Chang, Xiaodong He, and Jianfeng Gao. 2015. Semantic parsing via staged query graph generation: Question answering with knowledge base. In Proceedings of the 53rd Annual Meeting of the Association for Computational Lin- guistics and the 7th International Joint Conference on Natural Language Processing (Volume 1: Long Papers), pages 1321-1331, Beijing, China, July. As- sociation for Computational Linguistics. John Zelle and Raymond Mooney. 1996. Learning to parse database queries using inductive logic pro- gramming. In Proceedings of the National Confer- ence on Artificial Intelligence, pages 1050-1055. Luke S Zettlemoyer and Michael Collins. 2005. Learning to map sentences to logical form: Struc- tured classification with probabilistic categorial grammars. In Conference on Uncertainty in Arti- ficial Intelligence (UAI).</figDesc><table>Tom Kwiatkowski, Eunsol Choi, Yoav Artzi, and Luke 
Zettlemoyer. 2013. Scaling semantic parsers with 
on-the-fly ontology matching. In Proceedings of 
the 2013 Conference on Empirical Methods in Natu-
ral Language Processing, pages 1545-1556, Seattle, 
Washington, USA, October. Association for Compu-
tational Linguistics. 

Percy Liang, Michael I Jordan, and Dan Klein. 2013. 
Learning dependency-based compositional seman-
tics. Computational Linguistics, 39(2):389-446. 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_164" validated="false"><head></head><label></label><figDesc>). Typically, four components composite the LSTM-based recurrent neural networks: one in- put gate i t with corresponding weight matrix W xi , W hi , W ci , b i ; one forget gate f t with corre- sponding weight matrix W xf , W hf , W cf , b f ; one output gate o t with corresponding weight matrix W xo , W ho , W co , b o</figDesc><table></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_165" validated="false"><head></head><label></label><figDesc>Rink and Harabagiu, 2010) Levin classed, ProBank, FramNet, NomLex-Plus,</figDesc><table>209 

Model 

Feature Set 
F1 
SVM 
POS, prefixes, morphological, WordNet, dependency parse, 
(82.2 
Google n-gram, paraphrases, TextRunner 
CNN 
WV (Turian et al., 2010) (dim=50) 
69.7 
(Zeng et al., 2014) 
+ PF + WordNet 
82.7 
RNN 
WV (Turian et al., 2010) (dim=50) + PI 
80.0 
</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_166" validated="false"><head></head><label></label><figDesc>Table 1: Comparison with previous results. WV, PF, PI stand for word vectors, position features and position indicators respectively.</figDesc><table>PF + POS + NER + WNSYN + DEP 
84.3 
BLSTM 
WV (Turian et al., 2010) (dim=50) + PI 
80.7 
Att-BLSTM 
WV (Turian et al., 2010) (dim=50) + PI 
82.5 
BLSTM 
WV (Pennington et al., 2014) (dim=100) + PI 
82.7 
Att-BLSTM 
WV (Pennington et al., 2014) (dim=100) + PI 
84.0 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_167" validated="false"><head>Table 1</head><label>1</label><figDesc>compares our Att-BLSTM with other state-of-the-art methods of relation classification. SVM: This is the top performed system in SemEval-2010. Rink and Harabagiu (2010) lever- aged a variety of handcrafted features, and use SVM as the classifier. They achieved an F 1 -score of 82.2%. CNN: Zeng et al.</figDesc><table></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_168" validated="false"><head></head><label></label><figDesc>The effectiveness of Att- BLSTM is demonstrated by evaluating the model on SemEval-2010 relation classification task.Dzmitry Bahdanau, Kyunghyun Cho, and Yoshua Ben- gio. 2014. Neural machine translation by jointly learning to align and translate. arXiv preprint arX- iv:1409.0473. Razvan C Bunescu and Raymond J Mooney. 2005. A shortest path dependency kernel for relation extrac- tion. In Proceedings of the conference on human language technology and empirical methods in nat- ural language processing, pages 724-731. Associa- tion for Computational Linguistics. Jan K Chorowski, Dzmitry Bahdanau, Dmitriy Serdyuk, Kyunghyun Cho, and Yoshua Bengio. 2015. Attention-based models for speech recogni- tion. In Advances in Neural Information Processing Systems, pages 577-585. Alan Graves, Abdel-rahman Mohamed, and Geoffrey Hinton. 2013. Speech recognition with deep recur- rent neural networks. In Acoustics, Speech and Sig- nal Processing (ICASSP), 2013 IEEE International Conference on, pages 6645-6649. IEEE. Alex Graves. 2013. Generating sequences with recurrent neural networks. arXiv preprint arX- iv:1308.0850.Multi-way classification of semantic relation- s between pairs of nominals. In Proceedings of the Workshop on Semantic Evaluations: Recen- t Achievements and Future Directions, pages 94-99. Association for Computational Linguistics. Karl Moritz Hermann, Tomas Kocisky, Edward Grefenstette, Lasse Espeholt, Will Kay, Mustafa Su- leyman, and Phil Blunsom. 2015. Teaching ma- chines to read and comprehend. In Advances in Neu- ral Information Processing Systems, pages 1684- 1692. Geoffrey E Hinton, Nitish Srivastava, Alex Krizhevsky, Ilya Sutskever, and Ruslan R Salakhutdinov. 2012. Improving neural networks by preventing co- adaptation of feature detectors. arXiv preprint arX- iv:1207.0580. Sepp Hochreiter and Jürgen Schmidhuber. 1997. Long short-term memory. Neural computation, 9(8):1735-1780. Tomas Mikolov, Martin Karafiát, Lukas Burget, Jan Cernockỳ, and Sanjeev Khudanpur. 2010. Recur- rent neural network based language model. In IN- TERSPEECH 2010, 11th Annual Conference of the International Speech Communication Association, Makuhari, Chiba, Japan, September 26-30, 2010, pages 1045-1048. Tomas Mikolov, Ilya Sutskever, Kai Chen, Greg S Cor- rado, and Jeff Dean. 2013. Distributed representa- tions of words and phrases and their compositional- ity. In Advances in neural information processing systems, pages 3111-3119.Mike Mintz, Steven Bills, Rion Snow, and Dan Ju- rafsky. 2009. Distant supervision for relation ex- traction without labeled data. In Proceedings of the Joint Conference of the 47th Annual Meeting of the ACL and the 4th International Joint Conference on Natural Language Processing of the AFNLP: Vol- ume 2-Volume 2, pages 1003-1011. Association for Computational Linguistics. Jeffrey Pennington, Richard Socher, and Christopher D Manning. 2014. Glove: Global vectors for word representation. In EMNLP, volume 14, pages 1532- 1543. Bryan Rink and Sanda Harabagiu. 2010. Utd: Clas- sifying semantic relations by combining lexical and semantic resources. In Proceedings of the 5th Inter- national Workshop on Semantic Evaluation, pages 256-259. Association for Computational Linguistic- s. Richard Socher, Brody Huval, Christopher D Manning, and Andrew Y Ng. 2012. Semantic compositional- ity through recursive matrix-vector spaces. In Pro- ceedings of the 2012 Joint Conference on Empiri- cal Methods in Natural Language Processing and Computational Natural Language Learning, pages 1201-1211. Association for Computational Linguis- tics.Fei Wu and Daniel S Weld. 2010. Open information extraction using wikipedia. In Proceedings of the 48th Annual Meeting of the Association for Compu- tational Linguistics, pages 118-127. Association for Computational Linguistics. Kelvin Xu, Jimmy Ba, Ryan Kiros, Aaron Courville, Ruslan Salakhutdinov, Richard Zemel, and Yoshua Bengio. 2015. Show, attend and tell: Neural im- age caption generation with visual attention. arXiv preprint arXiv:1502.03044. Xu Yan, Lili Mou, Ge Li, Yunchuan Chen, Hao Peng, and Zhi Jin. 2015. Classifying relations via long short term memory networks along shortest depen- dency path. arXiv preprint arXiv:1508.03720. Xuchen Yao and Benjamin Van Durme. 2014. Infor- mation extraction over structured data: Question an- swering with freebase. In ACL (1), pages 956-966. Citeseer. Matthew D Zeiler. 2012. Adadelta: An adaptive learn- ing rate method. arXiv preprint arXiv:1212.5701. Daojian Zeng, Kang Liu, Siwei Lai, Guangyou Zhou, and Jun Zhao. 2014. Relation classification via con- volutional deep neural network. In Proceedings of COLING, pages 2335-2344. Dongxu Zhang and Dong Wang. 2015. Relation classi- fication via recurrent neural network. arXiv preprint arXiv:1508.01006. Shu Zhang, Dequan Zheng, Xinchen Hu, and Ming Yang. 2015. Bidirectional long short-term memo- ry networks for relation classification. "The red one!": On learning to refer to things based on discriminative properties Angeliki Lazaridou and Nghia The Pham and Marco Baroni University of Trento {angeliki.lazaridou|thepham.nghia|marco.baroni}@unitn.it</figDesc><table>References 

Iris Hendrickx, Su Nam Kim, Zornitsa Kozareva, 
Preslav Nakov, DiarmuidÓ Séaghdha, Sebastian 
Padó, Marco Pennacchiotti, Lorenza Romano, and 
Stan Szpakowicz. 
2009. 
Semeval-2010 task 
8: George A Miller. 
1995. 
Wordnet: a lexical 
database for english. Communications of the ACM, 
38(11):39-41. 

Joseph Turian, Lev Ratinov, and Yoshua Bengio. 2010. 
Word representations: a simple and general method 
for semi-supervised learning. In Proceedings of the 
48th annual meeting of the association for compu-
tational linguistics, pages 384-394. Association for 
Computational Linguistics. 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_169" validated="false"><head></head><label></label><figDesc>CAT, APPLE has legs, is green, ... Table 1: Example training data Our starting point is the Visual Attributes for Concepts Dataset (ViSA)</figDesc><table>referent, 

visual instances 
discriminative 
context 
attributes 

CAT, SOFA 
has tail, has cushion, 
... 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_170" validated="false"><head></head><label></label><figDesc>Test stimuli We derive our test stimuli from the VisA test split (see Section 2), containing 2000 pairs. Unlike in training, where the model was presented with specific visual instances (i.e., sin- gle images), for evaluation we use visual concepts (CAT, BED), which we derive by averaging the vectors of all images associated to an object (i.e., deriving CAT from all images of cats), due to lack</figDesc><table>Model 
Precision Recall 
F1 
DAN 
0.66 
0.49 
0.56 
attribute+sym. difference 
0.64 
0.48 
0.55 
no attribute layer 
0.63 
0.33 
0.43 
Random baseline 
0.16 
0.16 
0.16 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_171" validated="false"><head>Table 2 :</head><label>2</label><figDesc>Predicting discriminative features of gold information on per-image attributes.</figDesc><table></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_173" validated="false"><head>Table 3 :</head><label>3</label><figDesc>Predicting concept attributes 6 Evaluating Referential Success We finally ran a pilot study testing whether DAN's ability to predict discriminative attributes at the concept level translates into producing features that would be useful in constructing successful ref- erential expressions for specific object instances. Test stimuli Our starting point is the ReferIt dataset (Kazemzadeh et al., 2014), consisting of REs denoting objects (delimited by bounding boxes) in natural images. We filter out any RE, bounding box pair whose RE does not overlap with our attribute set V and annotate the remaining ones with the overlapping attribute, deriving data of the form RE, bounding box, attribute . For each intended referent of this type, we sample as context another RE, bounding box pair such that (i) the context RE does not contain the ref- erent attribute, so that the latter is a likely discriminative feature; (ii) referent and context come from different images, so that their bound- ing boxes do not accidentally overlap; (iii) there is maximum word overlap between referent and contexts REs, creating a realistic referential ambi- guity setup (e.g., two cars, two objects in similar environments). Finally we sample maximally 20 referent, context pairs per attribute, result- ing in 790 test items. For each referent and context we extract CNN visual vectors from their bound- ing boxes, and feed them to DAN to obtain their discriminative attributes. Note that we used the ViSA-trained DAN for this experiment as well.</figDesc><table></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_174" validated="false"><head></head><label></label><figDesc>Jia Deng, Wei Dong, Richard Socher, Lia-Ji Li, and Li Fei-Fei. 2009. Imagenet: A large-scale hierarchi- cal image database. In Proceedings of CVPR, pages 248-255, Miami Beach, FL. Ali Farhadi, Ian Endres, Derek Hoiem, and David Forsyth. 2009. Describing objects by their at- tributes. In Proceedings of CVPR, pages 1778- 1785, Miami Beach, FL. Vittorio Ferrari and Andrew Zisserman. 2007. Learn- ing visual attributes. In Proceedings of NIPS, pages 433-440, Vancouver, Canada. Jakob N. Foerster, Yannis M. Assael, Nando de Fre- itas, and Shimon Whiteson. 2016. Learning to communicate to solve riddles with deep dis- tributed recurrent q-networks. Technical Report arXiv:1602.02672. Dirk Geeraerts. 2009. Theories of lexical semantics. Oxford University Press, Oxford, UK. Dave Golland, Percy Liang, and Dan Klein. 2010. A game-theoretic approach to generating spatial de- scriptions. In Proceedings of the 2010 conference on empirical methods in natural language process- ing, pages 410-419. Association for Computational Linguistics. Herbert P Grice. 1975. Logic and conversation. Syn- tax and Semantics. Karl Moritz Hermann, Tomáš Kočiský, Edward Grefenstette, Lasse Espeholt, Will Kay, Mustafa Su- leyman, and Phil Blunsom. 2015. Teaching ma- chines to read and comprehend. In Advances in Neu- ral Information Processing Systems (NIPS).Hill, Antoine Bordes, Sumit Chopra, and Jason Weston. 2015. The Goldilocks principle: Read- ing children's books with explicit memory repre- sentations. http://arxiv.org/abs/1511. 02301. Sahar Kazemzadeh, Vicente Ordonez, Mark Matten, and Tamara L Berg. 2014. Referitgame: Refer- ring to objects in photographs of natural scenes. In EMNLP, pages 787-798. Emiel Krahmer and Kees Van Deemter. 2012. Compu- tational generation of referring expressions: A sur- vey. Computational Linguistics, 38(1):173-218. Tomas Mikolov, Armand Joulin, and Marco Baroni. 2015. A roadmap towards machine intelligence. arXiv preprint arXiv:1511.08130. Margaret Mitchell, Kees van Deemter, and Ehud Re- iter. 2010. Natural reference to objects in a visual domain. In Proceedings of the 6th international nat- ural language generation conference, pages 95-104. Association for Computational Linguistics. Olga Russakovsky and Li Fei-Fei. 2010. Attribute learning in large-scale datasets. In Proceedings of ECCV, pages 1-14. John R. Searle. 1969. Speech Acts: An Essay in the Philosophy of Language. Cambridge University Press. Carina Silberer, Vittorio Ferrari, and Mirella Lapata. 2013. Models of semantic representation with visual attributes. In Proceedings of ACL, pages 572-582, Sofia, Bulgaria. Karen Simonyan and Andrew Zisserman. 2014. Very deep convolutional networks for large-scale image recognition. arXiv preprint arXiv:1409.1556. Luc Steels. 2003. Social language learning. In Mario Tokoro and Luc Steels, editors, The Future of Learn- ing, pages 133-162. IOS, Amsterdam. Andrea Vedaldi and Karel Lenc. 2015. MatConvNet - Convolutional Neural Networks for MATLAB. Pro- ceeding of the ACM Int. Conf. on Multimedia. Adam Vogel, Max Bodoia, Christopher Potts, and Daniel Jurafsky. 2013. Emergence of gricean max- ims from multi-agent decision theory. In HLT- NAACL, pages 1072-1081. Don't Count, Predict! An Automatic Approach to Learning Sentiment Lexicons for Short Text Duy Tin Vo and Yue Zhang Singapore University of Technology and Design 08 Somapah Road, Singapore 487372 duytin vo@mymail.sutd.edu.sg and yue zhang@sutd.edu.sg</figDesc><table>. Content 
determination in the generation of referring expres-
sions. Computational Intelligence, 7(4):252-265. 

Robert Dale and Ehud Reiter. 1995. Computational 
interpretations of the gricean maxims in the gener-
ation of referring expressions. Cognitive science, 
19(2):233-263. 

Felix </table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_177" validated="false"><head>Table 2 :</head><label>2</label><figDesc>Statistics of the Semeval13.</figDesc><table></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_178" validated="false"><head></head><label></label><figDesc>Training data: To automatically obtain train- ing data, we use the Twitter Developers API 1 to crawl emoticon tweets 2 of English and Arabic from February 2014 to September 2014. We fol- low Go et al. (2009), removing all emoticons used to collect training data from the tweets, and Tang et al. (2014b), ignoring tweets which are less than 7 tokens. A Twitter tokenizer (Gimpel et al., 2011) is applied to preprocess all tweets. Rare words that occur less than 5 times in the vocabulary are re- moved. HTTP links and username are replaced by http and user , respectively. The statistics of training data is shown in Table 1. Sentiment classifier: We use LibLinear 3</figDesc><table>6 Experiments 

6.1 Experimental Settings 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_179" validated="false"><head></head><label></label><figDesc>1 https://dev.twitter.com/ 2 :), : ), :-), :D, =) for positive and :(, : (, :-( for negative 3 https://www.csie.ntu.edu.tw/∼cjlin/liblinear/</figDesc><table>221 

Lexicons 

Unsup 
Sup 
P 
R 
F 
Acc 

WEKA 
ED 
61 
55.9 55.4 73.8 
STS 
66.4 52.5 47.7 73.7 
HIT 
75.3 73.3 74.1 78.5 

NRC 
Hashtag 
70.3 71.4 70.8 77.4 
Emoticon 73.2 74.6 73.8 79.9 
nnLexicon 
74.4 77.3 75.3 81.3 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_180" validated="true"><head>Table 3 :</head><label>3</label><figDesc>Results on SemEval13 (English).</figDesc><table>Labels 
Balanced 
Unbalanced 
train dev test 
train 
dev 
test 
#pos 

481 
159 159 

481 
159 
159 
#neg 
1012 
336 
336 
#mix 
500 
166 
166 
#obj 
4015 1338 1338 
#Tweets 1924 636 636 
6008 1999 1999 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_181" validated="false"><head></head><label></label><figDesc>and Bravo-Marquez et al. (2015) depend on manual resources, which are</figDesc><table>Lexicons 
Balanced Unbalanced 

NRC 
Hashtag 
31.9 
63.4 
Emoticon 
31.4 
65.3 
nnLexicon 
33.3 
66.5 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_182" validated="true"><head>Table 5 :</head><label>5</label><figDesc>Results on ASTD (Arabic).</figDesc><table>Words 
nnLexicon NRC 
bad 
-1.122 
-1.295 
worse 
-1.626 
-1.417 
worst 
-2.256 
-1.875 
busy 
-0.520 
-0.003 
busier 
-0.609 
0.106 

 *  

busiest 
-1.254 
-0.712 
suitable 
0.502 
-0.040 

 *  

satisfy 
0.570 
-0.173 

 *  

lazy 
-0.462 
0.224 

 *  

scummy 
-0.852 
0.049 

 *  

old wine 
0.453 
0.552 
old meat 
-0.172 
0.014 

 *  

strong memory 
0.081 
-0.083 

 *  

strong snowstorm -0.554 
0.182 

 *  

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_183" validated="false"><head>Table 6 :</head><label>6</label><figDesc>Example sentiment scores, where * de- notes incorrect polarity. not available. As shown in</figDesc><table></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_184" validated="false"><head></head><label></label><figDesc>Apoorv Agarwal, Boyi Xie, Ilia Vovsha, Owen Ram- bow, and Rebecca Passonneau. 2011. Sentiment analysis of twitter data. In Proceedings of the Work- shop on Languages in Social Media, LSM '11, pages 30-38.Marco Baroni, Georgiana Dinu, and Germán Kruszewski. 2014. Don't count, predict! a systematic comparison of context-counting vs. context-predicting semantic vectors. In Proceedings of ACL, pages 238-247. Felipe Bravo-Marquez, Eibe Frank, and Bernhard Pfahringer. 2015. Positive, negative, or neu- tral: learning an expanded opinion lexicon from emoticon-annotated tweets. In Proceedings of IJ- CAI, pages 1229-1235. Andrea Esuli and Fabrizio Sebastiani. 2006. Senti- wordnet: A publicly available lexical resource for opinion mining. In Proceedings of LREC, volume 6, pages 417-422. Rong-En Fan, Kai-Wei Chang, Cho-Jui Hsieh, Xiang- Rui Wang, and Chih-Jen Lin. 2008. Liblinear: A library for large linear classification. The Journal of Machine Learning Research, 9:1871-1874. Kevin Gimpel, Nathan Schneider, Brendan O'Connor, Dipanjan Das, Daniel Mills, Jacob Eisenstein, Michael Heilman, Dani Yogatama, Jeffrey Flanigan, and A. Noah Smith. 2011. Part-of-speech tagging for twitter: Annotation, features, and experiments. In Proceedings of ACL-HLT, pages 42-47. Alec Go, Richa Bhayani, and Lei Huang. 2009. Twit- ter sentiment classification using distant supervision. CS224N Project Report, Stanford, 1:12. Chih-Wei Hsu, Chih-Chung Chang, Chih-Jen Lin, et al. 2003. A practical guide to support vector classifica- tion. Minqing Hu and Bing Liu. 2004. Mining and summa- rizing customer reviews. In Proceedings of KDD, KDD '04, pages 168-177. Nal Kalchbrenner, Edward Grefenstette, and Phil Blun- som. 2014. A convolutional neural network for modelling sentences. In Proceedings of ACL, pages 655-665. Svetlana Kiritchenko, Xiaodan Zhu, and Saif M. Mo- hammad. 2014. Sentiment analysis of short infor- mal texts. J. Artif. Intell. Res., 50:723-762.Saif M. Mohammad, Svetlana Kiritchenko, and Xiao- dan Zhu. 2013. Nrc-canada: Building the state-of- the-art in sentiment analysis of tweets. In Proceed- ings of SemEval-2013, June. Saif M Mohammad, Mohammad Salameh, and Svet- lana Kiritchenko. 2015. How translation alters sen- timent. Journal of Artificial Intelligence Research, 54:1-20. Mahmoud Nabil, Mohamed Aly, and Amir F Atiya. 2015. Astd: Arabic sentiment tweets dataset. In Proceedings of EMNLP, pages 2515-2519. Preslav Nakov, Sara Rosenthal, Zornitsa Kozareva, Veselin Stoyanov, Alan Ritter, and Theresa Wilson. 2013. Semeval-2013 task 2: Sentiment analysis in twitter. In Second Joint Conference on Lexical and Computational Semantics (*SEM), Volume 2: Pro- ceedings of SemEval-2013, pages 312-320. Alexander Pak and Patrick Paroubek. 2010. Twitter based system: Using twitter for disambiguating sen- timent ambiguous adjectives. In Proceedings of the 5th International Workshop on Semantic Evaluation, SemEval '10, pages 436-439. Yafeng Ren, Yue Zhang, Meishan Zhang, and Donghong Ji. 2016a. Context-sensitive twitter sen- timent classification using neural network. In Pro- ceedings of AAAI. Yafeng Ren, Yue Zhang, Meishan Zhang, and Donghong Ji. 2016b. Improving twitter sentiment classification using topic-enriched multi-prototype word embeddings. In Proceedings of AAAI. Mohammad Salameh, Saif Mohammad, and Svetlana Kiritchenko. 2015. Sentiment after translation: A case-study on arabic social media posts. In Proceed- ings of NAACL-HLT, pages 767-777, May-June.Duyu Tang, Furu Wei, Bing Qin, Ming Zhou, and Ting Liu. 2014a. Building large-scale twitter-specific sentiment lexicon : A representation learning ap- proach. In Proceedings of COLING, pages 172-182, August. Duyu Tang, Furu Wei, Nan Yang, Ming Zhou, Ting Liu, and Bing Qin. 2014b. Learning sentiment- specific word embedding for twitter sentiment clas- sification. In Proceedings of ACL, pages 1555- 1565, June. Peter Turney. 2002. Thumbs up or thumbs down? se- mantic orientation applied to unsupervised classifi- cation of reviews. In Proceedings of ACL. Duy-Tin Vo and Yue Zhang. 2015. Target-dependent twitter sentiment classification with rich automatic features. In Proceedings of IJCAI, pages 1347- 1353, July. Theresa Wilson, Janyce Wiebe, and Paul Hoffmann. 2005. Recognizing contextual polarity in phrase- level sentiment analysis. In Proceedings of HLT- EMNLP. Matthew D Zeiler. 2012. Adadelta: an adaptive learn- ing rate method. arXiv preprint arXiv:1212.5701. Xiaodan Zhu, Svetlana Kiritchenko, and Saif Moham- mad. 2014. Nrc-canada-2014: Recent improve- ments in the sentiment analysis of tweets. In Pro- ceedings of SemEval-2014, pages 443-447.</figDesc><table>Stefano Baccianella, Andrea Esuli, and Fabrizio Sebas-
tiani. 2010. Sentiwordnet 3.0: An enhanced lexical 
resource for sentiment analysis and opinion mining. 
In Proceedings of LREC, volume 10, pages 2200-
2204. 

Tomas Mikolov, Kai Chen, Greg Corrado, and Jef-
frey Dean. 2013. Efficient estimation of word 
representations in vector space. arXiv preprint 
arXiv:1301.3781. 

Maite Taboada, Julian Brooke, Milan Tofiloski, Kim-
berly Voll, and Manfred Stede. 2011. Lexicon-
based methods for sentiment analysis. Computa-
tional linguistics, 37(2):267-307. </table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_185" validated="false"><head>( r1 )</head><label>r1</label><figDesc>A few days ago I checked into a franchise hotel. (r2) The front desk service was terrible, and they didn't know much about local attrac- tions. (r3) I would not recommend this hotel to a friend.</figDesc><table></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_186" validated="false"><head></head><label></label><figDesc>* Regional CNN-LSTM vs LSTM significantly different (p&lt;0.05)</figDesc><table>Valence 
RMSE MAE 
r 
Lexicon-wAM 
2.018 
1.709 
0.350 
Lexicon-wGM 
1.985 
1.692 
0.385 
Regression-AVR 
1.856 
1.542 
0.455 
Regression-MVR 
1.868 
1.551 
0.448 
CNN 
1.489 
1.184 
0.706 
RNN 
1.976 
1.715 
0.401 
LSTM 
1.444 
1.151 
0.717 
Regional CNN-LSTM 1.341 * 0.987 * 0.778 * 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_187" validated="false"><head>Table 1 :</head><label>1</label><figDesc>Comparative results of different methods in SST.* * Regional CNN-LSTM vs LSTM significantly different (p&lt;0.05)</figDesc><table>CVAT (Chinese) 
Valence 
RMSE MAE 
r 
Lexicon -wAM 
1.884 
1.632 
0.406 
Lexicon -wGM 
1.843 
1.597 
0.418 
Regression-AVR 
1.685 
1.374 
0.476 
Regression-MVR 
1.697 
1.392 
0.468 
CNN 
1.093 
0.880 
0.645 
RNN 
1.424 
1.262 
0.493 
LSTM 
1.135 
0.939 
0.641 
Regional CNN-LSTM 1.026 * 0.842 * 0.781 * 
Arousal 
RMSE MAE 
r 
Lexicon-wAM 
1.232 
0.985 
0.268 
Lexicon-wGM 
1.243 
0.996 
0.263 
Regression-AVR 
1.154 
0.862 
0.286 
Regression-MVR 
1.128 
0.842 
0.289 
CNN 
0.991 
0.788 
0.453 
RNN 
1.024 
0.816 
0.290 
LSTM 
0.945 
0.751 
0.472 
Regional CNN-LSTM 0.874 

* 

0.689 

* 

0.557 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_188" validated="false"><head>Table 2 .</head><label>2</label><figDesc>Comparative results of different methods in CVAT.</figDesc><table></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_189" validated="false"><head></head><label></label><figDesc>Li Wei, Chung-Hsien Wu, and Jen-Chun Lin.</figDesc><table>Yoshua Bengio, Patrice Simard, and Paolo Frasconi. 
1994. Learning long-term dependencies with gra-
dient descent is difficult. IEEE Trans. Neural Net-
works, 5(21):57-166. 
Margaret M. Bradley, and Peter J. Lang. 1994. Meas-
uring emotion: the self-assessment manikin and the 

semantic differential. Journal of Behavior Therapy 
and Experimental Psychiatry, 25 (1): 49-59. 
Rafael A. Calvo and Sidney D'Mello. 2010. Affect de-
tection: An interdisciplinary re-view of models, 
methods, and their applications. IEEE Trans. Affec-
tive Computing, 1(1): 18-37. 
Paul Ekman. 1992. An argument for basic emotions. 
Cognition and Emotion, 6:169-200. 
Ronen Feldman. 2013. Techniques and applications 
for sentiment analysis. Communications of the 
ACM, 56(4):82-89. 
Alex Graves. 2012. Supervised sequence labelling 
with recurrent neural networks. Vol. 385, Springer. 
Ozan Irsoy and Claire Cardie. 2014. Opinion mining 
with deep recurrent neural networks. In Proceed-
ings of the 2014 Conference on Empirical Methods 
in Natural Language Processing (EMNLP-14), 
pages 720-728. 
Yoon Kim. 2014. Convolutional neural networks for 
sentence classification. In Proceedings of the 2014 
Conference on Empirical Methods on Natural Lan-
guage Processing (EMNLP-14), pages 1746-1751. 
Nal Kalchbrenner, Edward Grefenstette, and Phil 
Blunsom. 2014. A convolutional neural network for 
modelling sentences. In Proceedings of the 52nd 
Annual Meeting of the Association for Computa-
tional Linguistics (ACL-14), pages 655-665. 
Yann LeCun, Leon Bottou, Genevieve B. Orr and 
Klaus-Robert Muller. 2012. Efficient backprop. 
Neural networks: Tricks of the trade. Springer Ber-
lin Heidelberg, 2012. 9-48. 
Bing Liu. 2012. Sentiment Analysis and Opinion Min-
ing. Morgan &amp; Claypool, Chicago, IL. 
Pengfei Liu, Shafiq Joty and Helen Meng. 2015. Fine-
grained opinion mining with recurrent neural net-
works and word embeddings. In Proceedings of the 
2015 Conference on Empirical Methods in Natural 
Language Processing (EMNLP-15), pages 1433-
1443. 
Nikos Malandrakis, Alexandros Potamianos, Elias 
Iosif, Shrikanth Narayanan. 2011. Kernel models 
for affective lexicon creation. In Proceedings of 
INTERSPEECH, pages 2977-2980. 
Nikos Malandrakis, Alexandros Potamianos, Elias 
Iosif, Shrikanth Narayanan. 2013. Distributional 
semantic models for affective text analysis. IEEE 
Trans. Audio, Speech, and Language Processing, 
21(11): 2379-2392. 
Tomas Mikolov, Kai Chen, Greg Corrado, and Jeffrey 
Dean. 2013a. Efficient estimation of word repre-
sentations in vector space. In Proceedings of Inter-
national Conference on Learning Representations 
(ICLR-13): Workshop Track. 
Tomas Mikolov, Ilya Sutskever, Kai Chen, Greg Cor-
rado, and Jeffrey Dean. 2013b. Distributed repre-
sentations of words and phrases and their composi-
tionality. In Advances in Neural Information Pro-
cessing Systems 26, pages 3111-3119. Bo Pang and Lillian Lee. 2008. Opinion mining and 
sentiment analysis. Foundations and trends in in-
formation retrieval, 2(1-2):1-135. 
Georgios Paltoglou, Mathias Theunis, Arvid Kappas, 
and Mike Thelwall. 2013. Predicting emotional re-
sponses to long informal text. IEEE Trans. Affec-
tive Computing, 4(1):106-115. 
James A. Russell. 1980. A circumplex model of affect. 
Journal of Personality and Social Psychology, 
39(6):1161. 
Richard Socher, Alex Perelygin, Jean Y. Wu, Jason 
Chuang, Christopher D. Manning, Andrew Y. Ng 
and Christopher Potts. 2013. Recursive deep mod-
els for semantic compositionality over a sentiment 
treebank. In Proceedings of the 2013 Empirical 
Methods on Natural Language Processing 
(EMNLP-13), pages 1631-1642. 
Amy Beth Warriner, Victor Kuperman, and Marc 
Brysbaert. 2013. Norms of valence, arousal, and 
dominance for 13,915 English lemmas. Behavior 
research methods, 45(4): 1191-1207. 
Xin Wang, Yuanchao Liu, Chengjie Sun, Baoxun 
Wang and Xiaolong Wang. 2015. Predicting polari-
ties of tweets by composing word embeddings with 
long short-term memory. In Proceedings of the 
53th Annual Meeting of the Association for Com-
putational Linguistics (ACL-15), pages 1343-1353. 
Wen-2011. A regression approach to affective rating of 
Chinese words from ANEW. In Proceedings of Af-
fective Computing and Intelligent Interaction 
(ACII-11), pages 121-131. 
Liang-Chih Yu, Jin Wang, K. Robert Lai, and Xuejie 
Zhang. 2015. Predicting valence-arousal ratings of 
words using a weighted graph method. In Proceed-
ings of the 53th Annual Meeting of the Association 
for Computational Linguistics (ACL-15), pages 
788-793. 
Liang-Chih Yu, Lung-Hao Lee, Shuai Hao, Jin Wang, 
Yunchao He, Jun Hu, K. Robert Lai and Xuejie 
Zhang. 2016. Building Chinese Affective Re-
sources in Valence-Arousal Dimensions. In Pro-
ceedings of the 15th Annual Conference of the 
North American Chapter of the Association for 
Computational Linguistics: Human Language 
Technologies (NAACL/HLT-16). </table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_190" validated="false"><head></head><label></label><figDesc>See examples of the different tasks below:</figDesc><table>WORDS 
Vinken 
, 
61 
years 
old 

POS 
NNP 
, 
CD 
NNS 
JJ 
CHUNKS 
B-NP 
I-NP 
I-NP 
I-NP 
I-NP 
CCG 
N 
, 
N/N 
N 
(S[adj]\ NP)\ NP 

In-domain MTL In these experiments, POS, 
Chunking and CCG data are from the English 
Penn Treebank. We use sections 0-18 for training 
POS and CCG supertagging, 15-18 for training 
chunking, 19 for development, 20 for evaluating 
chunking, and 23 for evaluating CCG supertag-
ging. These splits were motivated by the need for 
comparability with previous results. 4 LAYERS 

DOMAINS 
CHUNKS POS BROADCAST (6) BC-NEWS (8) MAGAZINES (1) WEBLOGS (6) 

BI-LSTM 

3 
-
88.98 
91.84 
90.09 
90.36 
3 
3 
88.91 
91.84 
90.95 
90.43 
3 
1 
89.48 
92.03 
91.53 
90.78 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_191" validated="false"><head>Table 1 :</head><label>1</label><figDesc>Domain adaptation results for chunking across four domains (averages over micro-F 1 s for individual files). The number in brackets is # files per domain in OntoNotes 4.0. We use the two first files in each folder for POS supervision (for train+dev).POS+CCG), with POS being the lower-level task. We experiment three architectures: single task training for higher-level tasks (no POS layer), MTL with both tasks feeding off of the outer layer, and MTL where POS feeds off of the inner (1st) layer and the higher-level task on the outer (3rd) layer. OUr main results are below:</figDesc><table>We do MTL training for either (POS+chunking) 
or (POS CHUNKS CCG 

BI-LSTM 

-
95.28 
91.04 
3 
95.30 
92.94 
1 
95.56 
93.26 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_192" validated="false"><head>234 4 Conclusion</head><label>4</label><figDesc>MTL and sharing of intermediate representations, allowing supervision signals of different tasks to benefit each other, is an appealing idea. However, in case we suspect the existence of a hierarchy be- tween the different tasks, we show that it is worth- while to incorporate this knowledge in the MTL architecture's design, by making lower level tasks affect the lower levels of the representation.Cha Zhang and Zhengyou Zhang. 2014. Improv- ing Multiview Face Detection with Multi-Task Deep Convolutional Neural Networks. In WACV. Jerry Zhu, Timothy Rogers, and Bryan Gibson. 2009. Human Rademacher complexity. In NIPS.</figDesc><table>Yoav Goldberg. 2015. A primer on neural network 
models for natural language processing. CoRR, 
abs/1510.00726. 

Sepp Hochreiter and Juergen Schmidhuber. 1997. 
Long short-term memory. Neural Computation, 
9:1735-1780. 

Ozan Irsoy and Claire Cardie. 2014. Opinion Mining 
with Deep Recurrent Neural Networks. In Proceed-
ings of the 2014 Conference on Empirical Methods 
in Natural Language Processing (EMNLP), pages 
720-728, Doha, Qatar, October. Association for 
Computational Linguistics. 

M.-T. Luong, Q. V. Le, I. Sutskever, O. Vinyals, and 
L. Kaiser. 2015. Multi-task Sequence to Sequence 
Learning. ArXiv e-prints, November. 

Joakim Nivre, Johan Hall, Sandra Kübler, Ryan Mc-
Donald, Jens Nilsson, Sebastian Riedel, and Deniz 
Yuret. 2007. The CoNLL 2007 shared task on de-
pendency parsing. In Proceedings of the CoNLL 
Shared Task Session of EMNLP-CoNLL 2007, pages 
915-932, Prague, Czech Republic, June. Associa-
tion for Computational Linguistics. 

Erik F. Tjong Kim Sang and Sabine Buchholz. 2000. 
Introduction to the conll-2000 shared task chunk-
ing. In Fourth Conference on Computational Natu-
ral Language Learning and of the Second Learning 
Language in Logic Workshop, pages 127-132. 

M. Schuster and Kuldip K. Paliwal. 1997. Bidirec-
tional recurrent neural networks. IEEE Transactions 
on Signal Processing, 45(11):2673-2681, Novem-
ber. 

Hong Shen and Anoop Sarkar. 2005. Voting between 
multiple data representations for text chunking. In 
Proceedings of the 18th Meeting of the Canadian 
Society for Computational Intelligence. 

Jun Suzuki and Hideki Isozaki. 2008. Semi-supervised 
sequential labeling and segmentation using giga-
word scale unlabeled data. In ACL. 

Wenduan Xu, Michael Auli, and Stephen Clark. 2015. 
Ccg supertagging with a recurrent neural network. 
In ACL. 

Junho Yim, Heechul Jung, ByungIn Yoo amd 
Changkyu Choi, Dusik Park, and Junmo Kim. 2015. 
Rotating Your Face Using Multi-task Deep Neural 
Network. In CVPR. 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_193" validated="false"><head>Table 1 :</head><label>1</label><figDesc>The named entity tag set. tion game, so we can completely specify a game state by the positions of the pieces on the board and the captured pieces held by on both sides. Many matches between professional players have been recorded, and many game states have commentaries made for fans by other professional players. A game commentary corpus 1 (Mori et al., 2016) defines 21 types of NEs, which are called shogi- NEs, as listed in Table 1. The words in the com- mentary sentences in the corpus are annotated with BIO-style tags. B, I, and O stand for beginning, intermediate, and others, respectively. B or I are used for representing the beginning or intermedi- ate words of an NE as extension like Hu-B. And O is used for representing words that are not part of any NEs. Therefore there are 43 = 21 × 2 + 1 BIO tags.</figDesc><table>Tag Meaning 

Hu 

Human 

Tu 

Turn 

Po 

Position 

Pi 

Piece 

Ps 

Piece specifier 

Mc 

Move compliment 

Pa 

Piece attribute 

Pq 

Piece quantity 

Re 

Region 

Ph 

Phase 

St 

Strategy 

Ca 

Castle 

Me 

Move eval. 

Mn 

Move name 

Ee 

Eval. element 

Ev 

Evaluation 

Ti 

Time 

Ac 

Player action 

Ap 

Piece action 

Ao 

Other action 

Ot 

Other notion 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_194" validated="false"><head>Table 2 :</head><label>2</label><figDesc>Text features for DNN/CRF NER.</figDesc><table></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_196" validated="false"><head>Table 3 :</head><label>3</label><figDesc>Game commentary corpus specifications.</figDesc><table>Layer 
0 
1 
2 
3 
4 
5 
Dimension 2,282 1,000 500 200 100 50 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_197" validated="false"><head>Table 4 :</head><label>4</label><figDesc>Dimensions of the SAE layers.</figDesc><table></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_199" validated="false"><head>Table 5 :</head><label>5</label><figDesc>NER results.</figDesc><table></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_200" validated="false"><head>Table 5</head><label>5</label><figDesc>DNN+R and DNN balance them better than CRFs. CRFs recognized shogi-NEs with high pre- cision but with low recall. The NER results tell that CRFs tended to output O tags when they were not confident to classify correct shogi-NE tags. DNN+R and DNN can classify BIO tags more accurately than CRFs as can be seen in BIO ac- curacies in Table 5. As a consequence DNN+R and DNN confidently recognize more shogi-NEs, which makes their recall higher than that of CRFs.</figDesc><table>shows the results. From the F-measures 
we see that DNN is better than CRFs. This is 
consistent with many works which apply DNN 
to NLP problems. A comparison between DNN 
and DNN+R tells us that we can achieve a further 
improvement by referring to real world informa-
tion. The difference in BIO accuracies between 
them is statistically significant (McNemar's test, 
p &lt; 0.01). Therefore we can say that our method 
successfully integrates real world information into 
text information to build a better solution to the 
NER problem. 
When we take a close look at the precision and 
recall, From Table 5 we see that DNN+R is better 

than DNN. Followings are examples of shogi-NEs 
which DNN+R successfully recognized but DNN 
failed: Ot tag for "tataki," which means dropping 
a pawn in front of a piece of the opponent, and Mn 
tag for "tsumero" (threatmate). By referring to the 
game state, DNN+R was better at understanding 
the game situation and resulted better performance 
than DNN, the text-based NER. 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_201" validated="false"><head></head><label></label><figDesc>Debasis Ganguly, Johannes Leveling, and Gareth J.F. Jones. 2014. Retrieval of similar chess positions. In Proceedings of the 37th annual international ACM SIGIR conference, pages 687-696. ACM.</figDesc><table>Yoshua Bengio, Pascal Lamblin, Dan Popovici, and 
Hugo Larochelle. 2007. Greedy layer-wise train-
ing of deep networks. In B. Schölkopf, J. C. Platt, 
and T. Hoffman, editors, Advances in Neural Infor-
mation Processing Systems 19, pages 153-160. MIT 
Press. 

E. Bruni, N. K. Tran, and M. Baroni. 2014. Multi-
modal distributional semantics. Journal of Artificial 
Intelligence Research, 49:1-47. 

D. L. Chen, J. Kim, and R. J. Mooney. 2010. Training 
a multilingual sportscaster: Using perceptual con-
text to learn language. Journal of Artificial Intelli-
gence Research, 37:397-435. 

Francis Ferraro, Nasrin Mostafazadeh, Ting-Hao 
Huang, Lucy Vanderwende, Jacob Devlin, Michel 
Galley, and Margaret Mitchell. 2015. A survey of 
current datasets for vision and language research. 
In Proceedings of the 2015 Conference on Empiri-
cal Methods in Natural Language Processing, pages 
207-213. 

Abhijeet Gupta, Gemma Boleda, Marco Baroni, and 
Sebastian Padó. 2015. Distributional vectors en-
code referential attributes. In Proceedings of the 
2015 Conference on Empirical Methods in Natural 
Language Processing, pages 12-21, Lisbon, Portu-
gal, September. Association for Computational Lin-
guistics. 

James Hammerton. 2003. Named entity recognition 
with long short-term memory. In Walter Daelemans 
and Miles Osborne, editors, Proceedings of the Sev-
enth Conference on Natural Language Learning at 
HLT-NAACL 2003, pages 172-175. 

Stevan Harnad. 1990. The symbol grounding problem. 
Physica D, 42:335-346. 

Atsushi Hashimoto, Tetsuro Sasada, Yoko Yamakata, 
Shinsuke Mori, and Michihiko Minoh. 2014. Kusk 
dataset: Toward a direct understanding of recipe text 
and human cooking activity. In Proceedings of the 
SixthInternational Workshop on Cooking and Eating 
Activities. 

Aurélie Herbelot and Eva Maria Vecchi. 2015. Build-
ing a shared world: mapping distributional to model-
theoretic semantic spaces. In Proceedings of the 
2015 Conference on Empirical Methods in Natural 
Language Processing, pages 22-32, Lisbon, Portu-
gal, September. Association for Computational Lin-
guistics. 

Hirotaka Kameko, Shinsuke Mori, and Yoshimasa Tsu-
ruoka. 2015a. Can symbol grounding improve 
low-level NLP? word segmentation as a case study. 
In Proceedings of the 2015 Conference on Empiri-
cal Methods in Natural Language Processing, pages 
2298-2303, Lisbon, Portugal, September. Associa-
tion for Computational Linguistics. 

Hirotaka Kameko, Shinsuke Mori, and Yoshimasa Tsu-
ruoka. 2015b. Learning a game commentary gener-
ator with grounded move expressions. In Proceed-
ings of the 2015 IEEE Conference on Computational 
Intelligence and Games. 

Douwe Kiela and Stephen Clark. 2015. Multi-and 
cross-modal semantics beyond vision: Grounding 
in auditory perception. In Proceedings of the 2015 
Conference on Empirical Methods in Natural Lan-
guage Processing, pages 2461-2470, Lisbon, Portu-
gal, September. Association for Computational Lin-
guistics. 

Douwe Kiela, Ivan Vulić, and Stephen Clark. 2015. 
Visual bilingual lexicon induction with transferred 
convnet features. In Proceedings of the 2015 Con-
ference on Empirical Methods in Natural Language 
Processing, pages 148-158. 

John D. Lafferty, Andrew McCallum, and Fernando 
C. N. Pereira. 2001. Conditional random fields: 
Probabilistic models for segmenting and labeling se-
quence data. In Proceedings of the Eighteenth Inter-
national Conference on Machine Learning, ICML 
'01, pages 282-289, San Francisco, CA, USA. Mor-
gan Kaufmann Publishers Inc. 

Angeliki Lazaridou, Nghia The Pham, and Marco Ba-
roni. 2015. Combining language and vision with a 
multimodal skip-gram model. In Proceedings of the 
2015 Conference of the North American Chapter of 
the Association for Computational Linguistics: Hu-
man Language Technologies, pages 153-163, Den-
ver, Colorado, May-June. Association for Compu-
tational Linguistics. 

Alessandro Lopopolo and Emiel van Miltenburg. 
2015. Sound-based distributional models. In Pro-
ceedings of the 11th International Conference on 
Computational Semantics, pages 70-75, London, 
UK, April. Association for Computational Linguis-
tics. 

Andrew McCallum and Wei Li. 2003. Early results for 
named entity recognition with conditional random 
fields, feature induction and web-enhanced lexicons. 
In Proceedings of the Seventh Conference on Com-
putational Natural Language Learning. 

Tomas Mikolov, Kai Chen, Greg Corrado, and Jeffrey 
Dean. 2013a. Efficient estimation of word represen-
tations in vector space. In Proceedings of workshop 
at the International Conference on Learning Repre-
sentations (ICLR 2013). 

Tomas Mikolov, Ilya Sutskever, Kai Chen, Greg S Cor-
rado, and Jeffrey Dean. 2013b. Distributed repre-
sentations of words and phrases and their composi-tionality. Advances in Neural Information Process-
ing Systems, 26:3111-3119. 

Shinsuke Mori, John Richardson, Atsushi Ushiku, Tet-
suro Sasada, Hirotaka Kameko, and Yoshimasa Tsu-
ruoka. 2016. A Japanese chess commentary cor-
pus. In Proceedings of the Tenth International Con-
ference on Language Resources and Evaluation. 

Graham Neubig, Makoto Morishita, and Satoshi Naka-
mura. 2015. Neural reranking improves subjective 
quality of machine translation: NAIST at WAT2015. 
In Proceedings of the 2nd Workshop on Asian Trans-
lation (WAT2015), Kyoto, Japan, October. 

J. Ngiam, A. Khosla, M. Kim, J. Nam, H. Lee, and 
A. Ng. 2011. Multimodal deep learning. In Pro-
ceedings of the 28th International Conference on 
Machine Learning (ICML 2011), pages 689-696. 

Jeffrey Pennington, Richard Socher, and Christopher 
Manning. 2014. Glove: Global vectors for word 
representation. In Proceedings of the 2014 Con-
ference on Empirical Methods in Natural Language 
Processing (EMNLP), pages 1532-1543, Doha, 
Qatar, October. Association for Computational Lin-
guistics. 

Arnau Ramisa, Josiah Wang, Ying Lu, Emmanuel 
Dellandrea, Francesc Moreno-Noguer, and Robert 
Gaizauskas. 2015. Combining geometric, textual 
and visual features for predicting prepositions in im-
age descriptions. In Proceedings of the 2015 Con-
ference on Empirical Methods in Natural Language 
Processing, pages 214-220. 

Erik F. Tjong Kim Sang and Fien De Meulder. 
2003. Introduction to the conll-2003 shared task: 
Language-independent named entity recognition. In 
Proceedings of the Seventh Conference on Computa-
tional Natural Language Learning, pages 142-147. 

Tetsuro Sasada, Shinsuke Mori, Tatsuya Kawahara, and 
Yoko Yamakata. 2015. Named entity recognizer 
trainable from partially annotated data. In Proceed-
ings of the Eleventh International Conference Pa-
cific Association for Computational Linguistics. 

Burr Settles. 2004. Biomedical named entity recog-
nition using conditional random fields and rich fea-
ture sets. In Proceedings of the International 
Joint Workshop on Natural Language Processing in 
Biomedicine and its Applications, pages 33-38. 

Carina Silberer and Mirella Lapata. 2014. Learn-
ing grounded meaning representations with autoen-
coders. In Proceedings of the 52nd Annual Meet-
ing of the Association for Computational Linguis-
tics (Volume 1: Long Papers), pages 721-732, Bal-
timore, Maryland, June. Association for Computa-
tional Linguistics. 

Richard Socher, Christopher D. Manning, and An-
drew Y. Ng. 2010. Learning continuous phrase 
representations and syntactic parsing with recursive 
neural networks. In Deep Learning and Unsuper-
vised Feature Learning Workshop -NIPS 2010. 

Richard Socher, Brody Huval, Christopher D. Man-
ning, and Andrew Y. Ng. 2012. Semantic composi-
tionality through recursive matrix-vector spaces. In 
Proceedings of the 2012 Joint Conference on Empir-
ical Methods in Natural Language Processing and 
Computational Natural Language Learning, pages 
1201-1211, Jeju Island, Korea, July. Association for 
Computational Linguistics. 

Richard Socher, John Bauer, Christopher D. Manning, 
and Ng Andrew Y. 2013a. Parsing with compo-
sitional vector grammars. In Proceedings of the 
51st Annual Meeting of the Association for Compu-
tational Linguistics (Volume 1: Long Papers), pages 
455-465, Sofia, Bulgaria, August. Association for 
Computational Linguistics. 

Richard Socher, Alex Perelygin, Jean Wu, Jason 
Chuang, Christopher D. Manning, Andrew Ng, and 
Christopher Potts. 2013b. Recursive deep models 
for semantic compositionality over a sentiment tree-
bank. In Proceedings of the 2013 Conference on 
Empirical Methods in Natural Language Process-
ing, pages 1631-1642, Seattle, Washington, USA, 
October. Association for Computational Linguistics. 

Nitish Srivastava and Ruslan R Salakhutdinov. 2012. 
Multimodal learning with deep boltzmann ma-
chines. In F. Pereira, C. J. C. Burges, L. Bottou, and 
K. Q. Weinberger, editors, Advances in Neural In-
formation Processing Systems 25, pages 2222-2230. 
Curran Associates, Inc. 

Yuka Tateisi, Jin-Dong Kim, and Tomoko Ohta. 2002. 
The genia corpus: an annotated research abstract 
corpus in molecular biology domain. In Proceed-
ings of the HLT, pages 73-77. 

Yuta Tsuboi, Hisashi Kashima, Shinsuke Mori, Hiroki 
Oda, and Yuji Matsumoto. 2008. Training condi-
tional random fields using incomplete annotations. 
In Proceedings of the 22nd International Conference 
on Computational Linguistics, pages 897-904. 

Yuta Tsuboi. 2014. Neural networks leverage corpus-
wide information for part-of-speech tagging. In Pro-
ceedings of the 2014 Conference on Empirical Meth-
ods in Natural Language Processing (EMNLP), 
pages 938-950, Doha, Qatar, October. Association 
for Computational Linguistics. 

Yoshitaka Ushiku, Tatsuya Harada, and Yasuo Ku-
niyoshi. 2011. Automatic sentence generation from 
images. In Proceedings of the 19th Annual ACM In-
ternational Conference on Multimedia, pages 1533-
1536. 

Yezhou Yang, Ching Lik Teo, Hal Daumé III, and Yian-
nis Aloimonos. 2011. Corpus-guided sentence gen-
eration of natural images. In Proceedings of the 
2011 Conference on Empirical Methods in Natural 
Language Processing. </table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_203" validated="false"><head></head><label></label><figDesc>for Call of Duty, Hearthstone: Heroes of War- craft, Destiny, Skylanders and other titles. What inspires em- ployees' company spirit here Do people stand by their teams' work What impact do people have outside the organization.</figDesc><table>Hybrid: Activision Blizzard was formed in 2007 from a 
merger between Activision and Vivendi Games (as well as 
Blizzard Entertainment, which had already been a division of 
Vivendi Games.) Upon merger, Activision Blizzard's board 
of directors initially formed of eleven members: six directors 
designated by Vivendi, two Activision management directors 
and three independent directors who currently serve on Ac-
tivision's board of directors. It's comprised of Blizzard En-
tertainment, best known for blockbuster hits including World 
of Warcraft, Hearthstone: Heroes of Warcraft, and the War-
craft, StarCraft, and Diablo franchises, and Activision Pub-
lishing, whose development studios (including Infinity Ward, 
Toys for Bob, Sledgehammer Games, and Treyarch, to name 
just a few) create blockbusters like Call of Duty, Skylanders, 
Guitar Hero, and Destiny. 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_204" validated="false"><head></head><label></label><figDesc>Eugene Agichtein and Luis Gravano. 2000. Snow- ball: Extracting relations from large plain-text col- lections. In Proceedings of the fifth ACM conference on Digital libraries, pages 85-94. ACM.Michael Elhadad. 1991. FUF: The Universal Unifier User Manual ; Version 5.0. Department of Com- puter Science, Columbia University.</figDesc><table>Gabor Angeli, Percy Liang, and Dan Klein. 2010. A 
simple domain-independent probabilistic approach 
to generation. In Proceedings of the 2010 Confer-
ence on Empirical Methods in Natural Language 
Processing, EMNLP '10, pages 502-512, Strouds-
burg, PA, USA. Association for Computational Lin-
guistics. 

Or Biran and Kathleen McKeown. 2015. Discourse 
planning with an n-gram model of relations. In Pro-
ceedings of the 2015 Conference on Empirical Meth-
ods in Natural Language Processing, pages 1973-
1977, Lisbon, Portugal, September. Association for 
Computational Linguistics. 

Sasha Blair-Goldensohn, Kathleen R. McKeown, and 
And rew Hazen Schlaikjer. 2003. Defscriber: a hy-brid system for definitional qa. In SIGIR '03: Pro-
ceedings of the 26th annual international ACM SI-
GIR conference on Research and development in in-
formaion retrieval, pages 462-462. 

Nadjet Bouayad-Agha, Gerard Casamayor, and Leo 
Wanner. 2011. Content selection from an ontology-
based knowledge base for the generation of football 
summaries. In Proceedings of the 13th European 
Workshop on Natural Language Generation, ENLG 
'11, pages 72-81, Stroudsburg, PA, USA. Associa-
tion for Computational Linguistics. 

John Conroy, Judith Schlesinger, and Dianne O'Leary. 
2006. Topic-focused multi-document summariza-
tion using an approximate or acle score. In Proceed-
ings of ACL. 

Hal Daumé III and Daniel Marcu. 2005. Bayesian 
multi-document summarization at mse. In Proceed-
ings of the Workshop on Multilingual Summariza-
tion Eva luation (MSE), Ann Arbor, MI, June 29. 

Noemie Elhadad and Kathleen R. Mckeown. 2001. 
Towards generating patient specific summaries of 
medical articles. In In Proceedings of NAACL-2001 
Workshop Automatic. 

Güneş Erkan and Dragomir R. Radev. 2004. Lexrank: 
Graph-based centrality as salience in text summa-
rization. Journal of Artificial Intelligence Research 
(JAIR). 

Elena Filatova and John Prager. 2005. Tell me 
what you do and i'll tell you what you are: Learn-
ing occupation-related activities for biographies. In 
Proceedings of the Conference on Human Lan-
guage Technology and Empirical Methods in Natu-
ral Language Processing, HLT '05, pages 113-120, 
Stroudsburg, PA, USA. Association for Computa-
tional Linguistics. 

Dimitra Gkatzia, Helen F. Hastie, and Oliver Lemon. 
2014. Finding middle ground? multi-objective nat-
ural language generation from time-series data. In 
Gosse Bouma and Yannick Parmentier, editors, Pro-
ceedings of the 14th Conference of the European 
Chapter of the Association for Computational Lin-
guistics, EACL 2014, April 26-30, 2014, Gothen-
burg, Sweden, pages 210-214. The Association for 
Computer Linguistics. 

Ravi Kondadadi, Blake Howald, and Frank Schilder. 
2013. A statistical nlg framework for aggregated 
planning and realization. In ACL (1), pages 1406-
1415. The Association for Computer Linguistics. 

Alon Lavie and Abhaya Agarwal. 2007. Meteor: An 
automatic metric for mt evaluation with high levels 
of correlation with human judgments. In Proceed-
ings of the Second Workshop on Statistical Machine 
Translation, StatMT '07, pages 228-231. Associa-
tion for Computational Linguistics. 

Christian M.I.M. Matthiessen and John A. Bateman. 
1991. Text generation and systemic-functional lin-
guistics: experiences from english and japanese. 

Rada Mihalcea and Paul Tarau. 2004. Textrank: 
Bringing order into texts. In Conference on Em-
pirical Methods in Natural Language Processing, 
Barcelona, Spain. 

Jahna Otterbacher, Gunes Erkan, and Dragomir R. 
Radev. 2005. Using random walks for question-
focused sentence retrieval. In Proceedings of HLT-
EMNLP. 

Ehud Reiter and Robert Dale. 1997. Building applied 
natural language generation systems. Nat. Lang. 
Eng., 3(1):57-87, March. 

Christina Sauper and Regina Barzilay. 2009. Auto-
matically generating wikipedia articles: A structure-
aware approach. In Proceedings of the Joint Confer-
ence of the 47th Annual Meeting of the ACL and the 
4th International Joint Conference on Natural Lan-
guage Processing of the AFNLP: Volume 1 -Volume 
1, ACL '09, pages 208-216, Stroudsburg, PA, USA. 
Association for Computational Linguistics. 

B. Schiffman, Inderjeet. Mani, and K. Concepcion. 
2001. Producing biographical summaries: Combin-
ing linguistic knowledge with corpus statistics. In 
Proceedings of the 39th Annual Meeting of the Asso-
ciation for Computational Linguistics (ACL-EACL 
2001), Toulouse, France, July. 

William Yang Wang, Kapil Thadani, and Kathleen 
McKeown. 2011. Identifying event descriptions 
using co-training with online news su mmaries. 
In Proceedings of IJNLP, Chiang-Mai, Thailand, 
November. 

Ralph M. Weischedel, Jinxi Xu, and Ana Licuanan. 
2004. A hybrid approach to answering biographical 
questions. In Mark T. Maybury, editor, New Direc-
tions in Question Answering, pages 59-70. AAAI 
Press. 

Michael White. 2014. Towards surface realiza-
tion with ccgs induced from dependencies. In 
Proceedings of the 8th International Natural Lan-
guage Generation Conference (INLG), pages 147-
151, Philadelphia, Pennsylvania, U.S.A., June. As-
sociation for Computational Linguistics. Annotating Relation Inference in Context via Question Answering 

Omer Levy 
Ido Dagan 
Computer Science Department 
Bar-Ilan University 
Ramat-Gan, Israel 
{omerlevy,dagan}@cs.biu.ac.il 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_205" validated="false"><head></head><label></label><figDesc>We start by collecting factoid questions. Each question is captured as a tuple q = (q type , q rel , q arg ), for example:In addition to "Which?" questions, this template captures other WH-questions such as "Who?" (q type = person). We then collect a set of candidate answers for each question q. A candidate answer is also represented as a tuple (a answer , a rel , a arg ) or (a arg , a rel , a answer ), for example:</figDesc><table>Which 

qtype 

food 

q rel 

is included in 

qarg 

chocolate ? 

aarg 

chocolate 

a rel 

is made from 

aanswer 

the cocoa bean 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_206" validated="false"><head></head><label></label><figDesc>Oren Etzioni, and Daniel Weld. 2010. Learning first-order horn clauses from web text. In Proceedings of the 2010 Conference on Empirical Methods in Natural Language Processing, pages 1088-1098, Cambridge, MA, October. Association for Computational Linguistics. [Szpektor et al.2007] Idan Szpektor, Eyal Shnarch, and Ido Dagan. 2007. Instance-based evaluation of en- tailment rule acquisition. In Proceedings of the 45thrule evaluation. In Proceedings of the 50th Annual Meeting of the Association for Compu- tational Linguistics (Volume 2: Short Papers), pages 156-160, Jeju Island, Korea, July. Association for Computational Linguistics.</figDesc><table>[Abend et al.2014] Omri Abend, Shay B. Cohen, and 
Mark Steedman. 2014. Lexical inference over 
multi-word predicates: A distributional approach. 
In Proceedings of the 52nd Annual Meeting of the 
Association for Computational Linguistics (Volume 
1: Long Papers), pages 644-654, Baltimore, Mary-
land, June. Association for Computational Linguis-
tics. 

[Banko et al.2007] Michele Banko, Michael J. Ca-
farella, Stephen Soderland, Matthew Broadhead, 
and Oren Etzioni. 2007. Open information extrac-
tion from the web. In IJCAI 2007, Proceedings of 
the 20th International Joint Conference on Artificial Intelligence, Hyderabad, India, January 6-12, 2007, 
pages 2670-2676. 

[Beltagy et al.2013] Islam Beltagy, Cuong Chau, 
Gemma Boleda, Dan Garrette, Katrin Erk, and 
Raymond Mooney. 2013. Montague meets markov: 
Deep semantics with probabilistic logical form. In 
Second Joint Conference on Lexical and Computa-
tional Semantics (*SEM), Volume 1: Proceedings 
of the Main Conference and the Shared Task: 
Semantic Textual Similarity, pages 11-21, Atlanta, 
Georgia, USA, June. Association for Computational 
Linguistics. 

[Berant et al.2011] Jonathan Berant, Ido Dagan, and Ja-
cob Goldberger. 2011. Global learning of typed 
entailment rules. In Proceedings of the 49th An-
nual Meeting of the Association for Computational 
Linguistics: Human Language Technologies, pages 
610-619, Portland, Oregon, USA, June. Association 
for Computational Linguistics. 

[Berant et al.2013] Jonathan Berant, Andrew Chou, 
Roy Frostig, and Percy Liang. 2013. Semantic pars-
ing on Freebase from question-answer pairs. In Pro-
ceedings of the 2013 Conference on Empirical Meth-
ods in Natural Language Processing, pages 1533-
1544, Seattle, Washington, USA, October. Associa-
tion for Computational Linguistics. 

[Biemann2013] Chris Biemann. 2013. Creating a 
system for lexical substitutions from scratch using 
crowdsourcing. Language Resources and Evalua-
tion, 47(1):97-122. 

[Bird et al.2009] Steven Bird, Ewan Klein, and Edward 
Loper. 2009. Natural Language Processing with 
Python. O'Reilly Media. 

[Fader et al.2013] Anthony Fader, Luke Zettlemoyer, 
and Oren Etzioni. 2013. Paraphrase-driven learning 
for open question answering. In Proceedings of the 
51st Annual Meeting of the Association for Compu-
tational Linguistics (Volume 1: Long Papers), pages 
1608-1618, Sofia, Bulgaria, August. Association for 
Computational Linguistics. 

[Fader et al.2014] Anthony Fader, Luke Zettlemoyer, 
and Oren Etzioni. 2014. Open question answering 
over curated and extracted knowledge bases. In Pro-
ceedings of the 20th ACM SIGKDD International 
Conference on Knowledge Discovery and Data Min-
ing, pages 1156-1165. ACM. 

[Fellbaum1998] Christiane Fellbaum. 1998. WordNet. 
Wiley Online Library. 

[Goldberg and Orwant2013] Yoav Goldberg and Jon 
Orwant. 2013. A dataset of syntactic-ngrams over 
time from a very large corpus of english books. In 
Second Joint Conference on Lexical and Computa-
tional Semantics (*SEM), Volume 1: Proceedings of 
the Main Conference and the Shared Task: Semantic 
Textual Similarity, pages 241-247, Atlanta, Georgia, 
USA, June. Association for Computational Linguis-
tics. 

[Grycner and Weikum2014] Adam Grycner and Ger-
hard Weikum. 2014. Harpy: Hypernyms and align-
ment of relational paraphrases. In Proceedings of 
COLING 2014, the 25th International Conference 
on Computational Linguistics: Technical Papers, 
pages 2195-2204, Dublin, Ireland, August. Dublin 
City University and Association for Computational 
Linguistics. 

[Grycner et al.2015] Adam Grycner, Gerhard Weikum, 
Jay Pujara, James Foulds, and Lise Getoor. 2015. 
Relly: Inferring hypernym relationships between 
relational phrases. In Proceedings of the 2015 
Conference on Empirical Methods in Natural Lan-
guage Processing, pages 971-981, Lisbon, Portugal, 
September. Association for Computational Linguis-
tics. 

[Kremer et al.2014] Gerhard Kremer, Katrin Erk, Se-
bastian Padó, and Stefan Thater. 2014. What substi-
tutes tell us -analysis of an "all-words" lexical sub-
stitution corpus. In Proceedings of the 14th Confer-
ence of the European Chapter of the Association for 
Computational Linguistics, pages 540-549, Gothen-
burg, Sweden, April. Association for Computational 
Linguistics. 

[Kruszewski et al.2015] Germán Kruszewski, Denis 
Paperno, and Marco Baroni. 
2015. 
Deriv-
ing boolean structures from distributional vectors. 
Transactions of the Association for Computational 
Linguistics, 3:375-388. 

[Lesk1986] Michael Lesk. 1986. Automatic sense dis-
ambiguation using machine readable dictionaries: 
How to tell a pine cone from an ice cream cone. In 
Proceedings of the 5th Annual International Con-
ference on Systems Documentation, pages 24-26. 
ACM. 

[Levy and Goldberg2014] Omer Levy and Yoav Gold-
berg. 2014. Dependency-based word embeddings. 
In Proceedings of the 52nd Annual Meeting of the 
Association for Computational Linguistics (Volume 
2: Short Papers), pages 302-308, Baltimore, Mary-
land, June. Association for Computational Linguis-
tics. 

[Levy et al.2014] Omer Levy, Ido Dagan, and Jacob 
Goldberger. 2014. Focused entailment graphs for 
open ie propositions. In Proceedings of the Eigh-
teenth Conference on Computational Natural Lan-
guage Learning, pages 87-97, Ann Arbor, Michi-
gan, June. Association for Computational Linguis-
tics. 

[Lewis and Steedman2013] Mike Lewis and Mark 
Steedman. 2013. Combining distributional and 
logical semantics. Transactions of the Association 
for Computational Linguistics, 1:179-192. 

[Lewis2014] Mike Lewis. 2014. Combined Distribu-
tional and Logical Semantics. Ph.D. thesis, Univer-
sity of Edinburgh. [Lin and Pantel2001] Dekang Lin and Patrick Pantel. 
2001. Dirt: Discovery of inference rules from text. 
In Proceedings of the seventh ACM SIGKDD in-
ternational conference on Knowledge discovery and 
data mining, pages 323-328. ACM. 

[Marelli et al.2014] Marco Marelli, Stefano Menini, 
Marco Baroni, Luisa Bentivogli, Raffaella bernardi, 
and Roberto Zamparelli. 2014. A sick cure for the 
evaluation of compositional distributional semantic 
models. In Nicoletta Calzolari, Khalid Choukri, 
Thierry Declerck, Hrafn Loftsson, Bente Maegaard, 
Joseph Mariani, Asuncion Moreno, Jan Odijk, and 
Stelios Piperidis, editors, Proceedings of the Ninth 
International Conference on Language Resources 
and Evaluation (LREC'14), pages 216-223, Reyk-
javik, Iceland, May. European Language Resources 
Association (ELRA). ACL Anthology Identifier: 
L14-1314. 

[McCarthy and Navigli2007] Diana McCarthy and 
Roberto Navigli. 2007. Semeval-2007 task 10: 
English lexical substitution task. In Proceedings 
of the Fourth International Workshop on Seman-
tic Evaluations (SemEval-2007), pages 48-53, 
Prague, Czech Republic, June. Association for 
Computational Linguistics. 

[Melamud et al.2013] Oren Melamud, Jonathan Berant, 
Ido Dagan, Jacob Goldberger, and Idan Szpektor. 
2013. A two level model for context sensitive infer-
ence rules. In Proceedings of the 51st Annual Meet-
ing of the Association for Computational Linguis-
tics (Volume 1: Long Papers), pages 1331-1340, 
Sofia, Bulgaria, August. Association for Computa-
tional Linguistics. 

[Melamud et al.2015] Oren Melamud, Omer Levy, and 
Ido Dagan. 2015. A simple word embedding model 
for lexical substitution. In Proceedings of the 1st 
Workshop on Vector Space Modeling for Natural 
Language Processing, pages 1-7, Denver, Colorado, 
June. Association for Computational Linguistics. 

[Pavlick et al.2015a] Ellie Pavlick, Johan Bos, Malvina 
Nissim, Charley Beller, Benjamin Van Durme, and 
Chris Callison-Burch. 2015a. Adding semantics 
to data-driven paraphrasing. In Proceedings of the 
53rd Annual Meeting of the Association for Compu-
tational Linguistics and the 7th International Joint 
Conference on Natural Language Processing (Vol-
ume 1: Long Papers), pages 1512-1522, Beijing, 
China, July. Association for Computational Linguis-
tics. 

[Pavlick et al.2015b] Ellie Pavlick, Pushpendre Ras-
togi, Juri Ganitkevitch, Benjamin Van Durme, and 
Chris Callison-Burch. 2015b. Ppdb 2.0: Bet-
ter paraphrase ranking, fine-grained entailment re-
lations, word embeddings, and style classification. 
In Proceedings of the 53rd Annual Meeting of the 
Association for Computational Linguistics and the 
7th International Joint Conference on Natural Lan-
guage Processing (Volume 2: Short Papers), pages 

425-430, Beijing, China, July. Association for Com-
putational Linguistics. 

[Riedel et al.2013] Sebastian Riedel, Limin Yao, An-
drew McCallum, and Benjamin M. Marlin. 2013. 
Relation extraction with matrix factorization and 
universal schemas. In Proceedings of the 2013 Con-
ference of the North American Chapter of the Asso-
ciation for Computational Linguistics: Human Lan-
guage Technologies, pages 74-84, Atlanta, Georgia, 
June. Association for Computational Linguistics. 

[Rocktäschel et al.2015] Tim Rocktäschel, Sameer 
Singh, and Sebastian Riedel. 2015. Injecting 
logical background knowledge into embeddings 
for relation extraction. In Proceedings of the 2015 
Conference of the North American Chapter of 
the Association for Computational Linguistics: 
Human Language Technologies, pages 1119-1129, 
Denver, Colorado, May-June. Association for 
Computational Linguistics. 

[Schoenmackers et al.2010] Stefan 
Schoenmackers, 
Jesse Davis, Annual Meeting of the Association of Computational 
Linguistics, pages 456-463, Prague, Czech Repub-
lic, June. Association for Computational Linguis-
tics. 

[Voorhees and Tice2000] Ellen M Voorhees and 
Dawn M Tice. 2000. Building a question answering 
test collection. In Proceedings of the 23rd Annual 
International ACM SIGIR Conference on Research 
and Development in Information Retrieval, pages 
200-207. ACM. 

[Weisman et al.2012] Hila Weisman, Jonathan Berant, 
Idan Szpektor, and Ido Dagan. 2012. Learning 
verb inference rules from linguistically-motivated 
evidence. In Proceedings of the 2012 Joint Con-
ference on Empirical Methods in Natural Language 
Processing and Computational Natural Language 
Learning, pages 194-204, Jeju Island, Korea, July. 
Association for Computational Linguistics. 

[Zeichner et al.2012] Naomi Zeichner, Jonathan Be-
rant, and Ido Dagan. 
2012. 
Crowdsourcing 
inference-</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_207" validated="false"><head></head><label></label><figDesc>, FrameNet (Fillmore et al., 2003), VerbNet (Kip- per Schuler, 2006) and PrepNet/The Preposition Project (Litkowski and Hargraves, 2005; Saint- Dizier, 2005), as well as regarding computational classifications for nouns</figDesc><table></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_208" validated="false"><head></head><label></label><figDesc>represents our gold standard. We selected those preposition</figDesc><table>Class 

Size 
lokal 
'local' 
27 
modal 
'modal' 
24 
temporal 
'temporal' 
21 
kausal 
'causal' 
5 
distributiv 
'distributive' 
6 
final 
'final' 
4 
urheber 
'creator' 
3 
konditional 'conditional' 
3 
ersatz 
'replacement' 
2 
restriktiv 
'restrictive' 
2 
partitiv 
'partitive' 
2 
kopulativ 
'copulative' 
2 

Table 1: Preposition classes. 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_214" validated="false"><head>Table 2 :</head><label>2</label><figDesc>Average Monetary gains and Confidence scores (All Adults).</figDesc><table></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_216" validated="false"><head>Table 3 :</head><label>3</label><figDesc>Average Monetary gains and Confidence scores (Females).</figDesc><table></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_217" validated="false"><head></head><label></label><figDesc>).Albert Gatt and Ehud Reiter. 2009. SimpleNLG: A re- alisation engine for practical applications. In ENLG.Somayajulu G. Sripada, Ehud Reiter, and Lezan Haw- izy. 2005. Evaluation of an NLG system using post- edit data. In International Joint Conference on Arti- ficial Intelligence (IJCAI).</figDesc><table>Mary Ellen Foster and Jon Oberlander. 2006. Data-
driven generation of emphatic facial displays. In 
Proc. of the 11th Conference of the European Chap-
ter of the Association for Computational Linguistics 
(EACL). 

Mirta Galesic and Rocio Garcia-Retamero. 2010. 
Statistical numeracy for health: A cross-cultural 
comparison with probabilistic national samples. 
Archives of Internal Medicine, 170(462-468). 

Albert Gatt, Francois Portet, Ehud Reiter, James 
Hunter, Saad Mahamood, Wendy Moncur, and So-
mayajulu Sripada. 2009. From Data to Text in the 
Neonatal Intensive Care Unit: Using NLG Technol-
ogy for Decision Support and Information Manage-
ment. AI Communications, 22: 153-186. 

G. Gigerenzer and J. A. Muir Gray, editors. 2011. Bet-
ter doctors, better patients, better decisions: Envi-
sioning health care 2020. Cambridge MIT Press. 

Dimitra Gkatzia, Amanda Cercas Curry, Verena Rieser, 
and Oliver Lemon. 2015. A game-based setup for 
data collection and task-based evaluation of uncer-
tain information presentation. In Proceedings of 
the 15th European Workshop on Natural Language 
Generation (ENLG), pages 112-113, Brighton, UK, 
September. Association for Computational Linguis-
tics. 

Ioannis Konstas and Mirella Lapata. 2012. Un-
supervised concept-to-text generation with hyper-
graphs. In Conference of the North American Chap-
ter of the Association for Computational Linguistics 
(NAACL). 

Haleh Kootval, editor. 2008. Guidelines on Communi-
cating Forecast Uncertainty. World Meteorological 
Organisation. 

Martin Manning, Michel Petit, David Easterling, James 
Murphy, Anand Patwardhan, Hans-Holger Rogner, 
Rob Swart, and Gary Yohe. 2004. IPCC Work-
shop on Describing Scientific Uncertainties in Cli-
mate Change to Support Analysis of Risk and of Op-
tions. 

Richard Power and Sandra Williams. 2012. Generat-
ing numerical approximations. Computational Lin-
guistics, 38(1):113-134, March. 

V. Rieser and O. Lemon. 2008. Learning effective 
multimodal dialogue strategies from wizard-of-oz 
data: Bootstrapping and evaluation. Proceedings of 
ACL, pages 638-646. 

Rakesh Sarin and Alice Wieland. 2016. Risk aver-
sion for decisions under uncertainty: Are there gen-
der differences? Journal of Behavioral and Experi-
mental Economics, 60:1 -8. 

Liz Stephens, Ken Mylne, and David Spiegelhalter. 
2011. Using an online game to evaluate effective 
methods of communicating ensemble model output 
to different audiences. In American Geophysical 
Union, Fall Meeting. 

Kees van Deemter. 2009. Utility and language genera-
tion: The case of vagueness. Journal of Philosophi-
cal Logic, 38(6):607-632. 

Benjamin Weiss, Sebastian Möller, and Matthias 
Schulz. 2012. Modality preferences of different 
user groups. In The Fifth International Confer-
ence on Advances in Computer-Human Interactions 
(ACHI). 

Zheng Zhu. 2007. Gender differences in mathemati-
cal problem solving patterns: A review of literature. 
International Education Journal, 8(2):187 -203. Tweet2Vec: Character-Based Distributed 
Representations for Social Media 

Bhuwan Dhingra 
1 , Zhong Zhou 
2 , Dylan Fitzpatrick 

1,2 

Michael Muehl 
1 and William W. Cohen 

1 

1 School of Computer Science, Carnegie Mellon University, Pittsburgh, PA, USA 
2 Heinz College, Carnegie Mellon University, Pittsburgh, PA, USA 
{bdhingra,djfitzpa,mmuehl}@andrew.cmu.edu 
zhongzhou@cmu.edu wcohen@cs.cmu.edu 

Abstract 

Text from social media provides a set of 
challenges that can cause traditional NLP 
approaches to fail. Informal language, 
spelling errors, abbreviations, and special 
characters are all commonplace in these 
posts, leading to a prohibitively large vo-
cabulary size for word-level approaches. 
We propose a character composition 
model, tweet2vec, which finds vector-
space representations of whole tweets by 
learning complex, non-local dependencies 
in character sequences. The proposed 
model outperforms a word-level baseline 
at predicting user-annotated hashtags as-
sociated with the posts, doing significantly 
better when the input contains many out-
of-vocabulary words or unusual character 
sequences. Our tweet2vec encoder is pub-
licly available 1 . 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_219" validated="false"><head>Table 2 :</head><label>2</label><figDesc>Model sizes and training time/epoch</figDesc><table></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_221" validated="false"><head>Table 3 :</head><label>3</label><figDesc>Hashtag prediction results. Best numbers for each test set are in bold.</figDesc><table></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_222" validated="false"><head></head><label></label><figDesc>2 shows precision 1 of the two models as the number of parameters is increased, for each test</figDesc><table>(a) Full Test Set 

(b) Rare Words Test Set 
(c) Frequent Words Test Set 

Figure 2: Precision @1 v Number of model parameters for word model and tweet2vec. 

Dataset # Hashtags word tweet2vec 
small 
933 
28.0% 
33.1% 
medium 
2039 
24.1% 
28.4% 
large 
5114 
20.1% 
24.6% 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_223" validated="false"><head></head><label></label><figDesc>Wang Ling, Tiago Luís, Luís Marujo, Ramón Fernan- dez Astudillo, Silvio Amir, Chris Dyer, Alan W Black, and Isabel Trancoso. 2015. Finding function in form: Compositional character models for open vocabulary word representation. arXiv preprint arXiv:1508.02096.</figDesc><table>Junyoung Chung, Caglar Gulcehre, KyungHyun Cho, 
and Yoshua Bengio. 2014. Empirical evaluation of 
gated recurrent neural networks on sequence model-
ing. arXiv preprint arXiv:1412.3555. 

Fréderic Godin, Viktor Slavkovikj, Wesley De Neve, 
Benjamin Schrauwen, and Rik Van de Walle. 2013. 
Using topic models for twitter hashtag recommen-
dation. In Proceedings of the 22nd international 
conference on World Wide Web companion, pages 
593-596. International World Wide Web Confer-
ences Steering Committee. Mihajlo Grbovic, Nemanja Djuric, Vladan Radosavl-
jevic, Fabrizio Silvestri, and Narayan Bhamidipati. 
2015. Context-and content-aware embeddings for 
query rewriting in sponsored search. In Proceed-
ings of the 38th International ACM SIGIR Confer-
ence on Research and Development in Information 
Retrieval, pages 383-392. ACM. 

Sepp Hochreiter and Jürgen Schmidhuber. 1997. 
Long short-term memory. Neural computation, 
9(8):1735-1780. 

Andrej Karpathy, Justin Johnson, and Fei-Fei Li. 2015. 
Visualizing and understanding recurrent networks. 
arXiv preprint arXiv:1506.02078. 

Yoon Kim, Yacine Jernite, David Sontag, and Alexan-
der M Rush. 2015. Character-aware neural lan-
guage models. arXiv preprint arXiv:1508.06615. 

Ryan Kiros, Yukun Zhu, Ruslan Salakhutdinov, 
Richard S Zemel, Antonio Torralba, Raquel Urta-
sun, and Sanja Fidler. 2015. Skip-thought vectors. 
arXiv preprint arXiv:1506.06726. 

Quoc V Le and Tomas Mikolov. 2014. Distributed 
representations of sentences and documents. arXiv 
preprint arXiv:1405.4053. 

Thang Luong, Richard Socher, and Christopher D 
Manning. 2013. Better word representations 
with recursive neural networks for morphology. In 
CoNLL, pages 104-113. Citeseer. 

Tomas Mikolov, Kai Chen, Greg Corrado, and Jef-
frey Dean. 2013. Efficient estimation of word 
representations in vector space. arXiv preprint 
arXiv:1301.3781. 

Li-Qiang Niu and Xin-Yu Dai. 2015. Topic2vec: 
Learning distributed representations of topics. arXiv 
preprint arXiv:1506.08422. 

Cicero Nogueira dos Santos and Victor Guimarães. 
2015. Boosting named entity recognition with 
neural character embeddings. 
arXiv preprint 
arXiv:1505.05008. 

Cicero D Santos and Bianca Zadrozny. 2014. Learning 
character-level representations for part-of-speech 
tagging. In Proceedings of the 31st International 
Conference on Machine Learning (ICML-14), pages 
1818-1826. 

Alessio Signorini, Alberto Maria Segre, and Philip M 
Polgreen. 2011. The use of twitter to track lev-
els of disease activity and public concern in the us 
during the influenza a h1n1 pandemic. PloS one, 
6(5):e19467. 

Jason Weston, Sumit Chopra, and Keith Adams. 2014. 
tagspace: Semantic embeddings from hashtags. 
In Proceedings of the 2014 Conference on Em-
pirical Methods in Natural Language Processing 
(EMNLP), pages 1822-1827. 

Xiang Zhang, Junbo Zhao, and Yann LeCun. 2015. 
Character-level convolutional networks for text clas-
sification. In Advances in Neural Information Pro-
cessing Systems, pages 649-657. Phrase-Level Combination of SMT and TM 
Using Constrained Word Lattice 

Liangyou Li and Andy Way and Qun Liu 
ADAPT Centre, School of Computing 
Dublin City University 
Dublin 9, Ireland 
{liangyouli,away,qliu}@computing.dcu.ie 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_227" validated="false"><head>Table 3 :</head><label>3</label><figDesc>Composition of test subsets based on fuzzy match scores on English-Chinese and English-French data.</figDesc><table></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_228" validated="false"><head></head><label></label><figDesc>German Research Center for Artificial Intelligence (DFKI), Germany 3 Jadavpur University, Kolkata, India {santanu.pal, josef.vangenabith}@uni-saarland.de sudip.naskar@cse.jdvu.ac.in, m.vela@mx.uni-saarland.de</figDesc><table>Christopher Dyer, Smaranda Muresan, and Philip 
Resnik. 2008. Generalizing Word Lattice Trans-
lation. In Proceedings of the 46th Annual Meeting 
of the Association for Computational Linguistics: 
Human Language Technologies, Columbus, Ohio, 
June. 

Yifan He, Yanjun Ma, Josef van Genabith, and Andy 
Way. 2010. Bridging SMT and TM with Translation 
Recommendation. In Proceedings of the 48th An-
nual Meeting of the Association for Computational 
Linguistics, pages 622-630, Uppsala, Sweden, July. 

Philipp Koehn and Jean Senellart. 2010. Conver-
gence of Translation Memory and Statistical Ma-
chine Translation. In Proceedings of AMTA Work-
shop on MT Research and the Translation Industry, 
pages 21-31, Denver, Colorado, USA, November. 

Philipp Koehn, Franz Josef Och, and Daniel Marcu. 
2003. Statistical Phrase-based Translation. In Pro-
ceedings of the 2003 Conference of the North Amer-
ican Chapter of the Association for Computational 
Linguistics on Human Language Technology -Vol-
ume 1, pages 48-54, Edmonton, Canada. 

Philipp Koehn, Hieu Hoang, Alexandra Birch, Chris 
Callison-Burch, Marcello Federico, Nicola Bertoldi, 
Brooke Cowan, Wade Shen, Christine Moran, 
Richard Zens, Chris Dyer, Ondřej Bojar, Alexan-
dra Constantin, and Evan Herbst. 2007. Moses: 
Open Source Toolkit for Statistical Machine Trans-
lation. In Proceedings of the 45th Annual Meeting 
of the ACL on Interactive Poster and Demonstration 
Sessions, pages 177-180, Prague, Czech Republic, 
June. 

Vladimir Iosifovich Levenshtein. 1966. Binary Codes 
Capable of Correcting Deletions, Insertions and Re-
versals. Soviet Physics Doklady, 10:707. 

Liangyou Li, Andy Way, and Qun Liu. 2014. A 
Discriminative Framework of Integrating Transla-
tion Memory Features into SMT. In Proceedings of 
the 11th Conference of the Association for Machine 
Translation in the Americas, Vol. 1: MT Researchers 
Track, pages 249-260, Vancouver, BC, Canada, Oc-
tober. 

Yanjun Ma, Yifan He, Andy Way, and Josef van Gen-
abith. 2011. Consistent Translation using Discrim-
inative Learning -A Translation Memory-Inspired 
Approach. In Proceedings of the 49th Annual Meet-
ing of the Association for Computational Linguis-
tics: Human Language Technologies, pages 1239-
1248, Portland, Oregon, USA, June. 

Franz Josef Och and Hermann Ney. 2002. Discrimi-
native Training and Maximum Entropy Models for 
Statistical Machine Translation. In Proceedings of 
the 40th Annual Meeting on Association for Com-
putational Linguistics, pages 295-302, Philadelphia, 
Pennsylvania, July. 

Franz Josef Och and Hermann Ney. 2003. A System-
atic Comparison of Various Statistical Alignment 
Models. Computational Linguistics, 29(1):19-51, 
March. 

Franz Josef Och and Hermann Ney. 2004. The 
Alignment Template Approach to Statistical Ma-
chine Translation. Compututational Linguistics, 
30(4):417-449, December. 

Kishore Papineni, Salim Roukos, Todd Ward, and Wei-
Jing Zhu. 2002. BLEU: A Method for Automatic 
Evaluation of Machine Translation. In Proceedings 
of the 40th Annual Meeting on Association for Com-
putational Linguistics, pages 311-318, Philadelphia, 
Pennsylvania, July. 

M. Snover, B. Dorr, R. Schwartz, L. Micciulla, and 
J. Makhoul. 2006. A Study of Translation Edit Rate 
with Targeted Human Annotation. In Proceedings 
of Association for Machine Translation in the Amer-
icas, pages 223-231, Cambridge, Massachusetts, 
USA, August. 

Andreas Stolcke. 2002. SRILM-an Extensible Lan-
guage Modeling Toolkit. In Proceedings of the 7th 
International Conference on Spoken Language Pro-
cessing, pages 257-286, Denver, Colorado, USA, 
November. 

Kun Wang, Chengqing Zong, and Keh-Yih Su. 2013. 
Integrating Translation Memory into Phrase-Based 
Machine Translation during Decoding. In Proceed-
ings of the 51st Annual Meeting of the Association 
for Computational Linguistics (Volume 1: Long Pa-
pers), pages 11-21, Sofia, Bulgaria, August. A Neural Network based Approach to Automatic Post-Editing 

Santanu Pal 
1 , Sudip Kumar Naskar 
3 , Mihaela Vela 
1 , Josef van Genabith 

1,2 

1 Saarland University, Saarbrücken, Germany 
2 </table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_230" validated="false"><head>Table 1 :</head><label>1</label><figDesc>Automatic evaluation.</figDesc><table></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_231" validated="false"><head></head><label></label><figDesc>this correlation coefficient can be interpreted as fair.</figDesc><table>Cohen's κ 

T1 
T2 
T3 
T4 
T1 
-
0.141 0.424 0.398 
T2 
0.141 
-
0.232 0.540 
T3 
0.424 0.232 
-
0.248 
T4 
0.398 0.540 0.248 
-

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_232" validated="false"><head></head><label></label><figDesc>Union's Framework Programme (FP7/2007-2013) under REA grant agreement no 317471.Dzmitry Bahdanau, Kyunghyun Cho, and Yoshua Ben- gio. 2014. Neural Machine Translation by Jointly Learning to Align and Translate. arXiv preprint arXiv:1409.0473.Chris Dyer, Ondřej Bojar, Alexandra Constantin, and Evan Herbst. 2007. Moses: Open Source Toolkit for Statistical Machine Translation. In Proceedings of the 45th Annual Meeting of the ACL on Interactive Poster and Demonstration Ses- sions, pages 177-180.An Unsupervised Method for Automatic Translation Memory Cleaning</figDesc><table>References 

Yoshua Bengio, Patrice Simard, and Paolo Frasconi. 
1994. Learning Long-Term Dependencies with Gra-
dient Descent is Difficult. IEEE Transactions on 
Neural Networks, 5(2):157-166. 

Colin Cherry and George Foster. 2012. Batch Tun-
ing Strategies for Statistical Machine Translation. In 
Proceedings of the 2012 Conference of the North 
American Chapter of the Association for Computa-
tional Linguistics: Human Language Technologies, 
pages 427-436. 

KyungHyun Cho, Bart van Merrienboer, Dzmitry Bah-
danau, and Yoshua Bengio. 2014a. On the Prop-
erties of Neural Machine Translation: Encoder-
Decoder Approaches. CoRR, abs/1409.1259. 

Kyunghyun Cho, Bart Van Merriënboer, Ç alar 
Gülçehre, Dzmitry Bahdanau, Fethi Bougares, Hol-
ger Schwenk, and Yoshua Bengio. 2014b. Learn-
ing Phrase Representations using RNN Encoder-
Decoder for Statistical Machine Translation. In Pro-
ceedings of the 2014 Conference on Empirical Meth-
ods in Natural Language Processing (EMNLP), 
pages 1724-1734. 

Junyoung Chung, Ç alar Gülçehre, Kyunghyun Cho, 
and Yoshua Bengio. 2014. Empirical Evalua-
tion of Gated Recurrent Neural Networks on Se-
quence Modeling. Technical Report Arxiv report 
1412.3555, Université de Montréal. 

Jacob Cohen. 1960. A Coefficient of Agreement for 
Nominal Scales. Educational and Psychological 
Measurement, 20(1):37-46, April. 

Michael Denkowski and Alon Lavie. 2011. Meteor 
1.3: Automatic Metric for Reliable Optimization 
and Evaluation of Machine Translation Systems. In 
Proceedings of the EMNLP 2011 Workshop on Sta-
tistical Machine Translation, pages 85-91. 

Michael Denkowski. 2015. Machine Translation for 
Human Translators. Ph.D. thesis, Carnegie Mellon 
University. 

Donald A. DePalma and Nataly Kelly. 2009. Project 
Management for Crowdsourced Translation: How 
User-Translated Content Projects Work in Real Life. 
Translation and Localization Project Management: 
The Art of the Possible, pages 379-408. 

Rebecca Fiederer and Sharon OBrien. 2009. Qual-
ity and Machine Translation: a Realistic Objective. 
Journal of Specialised Translation, 11:52-74. Ian J Goodfellow, David Warde-Farley, Mehdi Mirza, 
Aaron Courville, and Yoshua Bengio. 2013. Max-
out networks. arXiv preprint arXiv:1302.4389. 

Kenneth Heafield. 2011. KenLM: Faster and Smaller 
Language Model Queries. In Proceedings of the 
Sixth Workshop on Statistical Machine Translation, 
pages 187-197. 

Sepp Hochreiter and Jürgen Schmidhuber. 1997. Long 
Short-Term Memory. Neural Comput., 9(8):1735-
1780, November. 

Rafal Józefowicz, Wojciech Zaremba, and Ilya 
Sutskever. 2015. An Empirical Exploration of 
Recurrent Network Architectures. In Proceedings 
of the 32nd International Conference on Machine 
Learning, pages 2342-2350. 

Nal Kalchbrenner and Phil Blunsom. 2013. Recurrent 
Continuous Translation Models. In Proceedings of 
the 2013 Conference on Empirical Methods in Nat-
ural Language Processing, pages 1700-1709. 

Philipp Koehn, Hieu Hoang, Alexandra Birch, Chris 
Callison-Burch, Marcello Federico, Nicola Bertoldi, 
Brooke Cowan, Wade Shen, Christine Moran, 
Richard Zens, Philipp Koehn. 2009. A Process Study of Computer-
aided Translation. Machine Translation, 23(4):241-
263. 

Antonio Lagarda, Vicent Alabau, Francisco Casacu-
berta, Roberto Silva, and Enrique Díaz-de Liaño. 
2009. Statistical post-editing of a rule-based ma-
chine translation system. In Proceedings of Human 
Language Technologies: The 2009 Annual Confer-
ence of the North American Chapter of the Associa-
tion for Computational Linguistics, Companion Vol-
ume: Short Papers, NAACL-Short '09, pages 217-
220. 

J. Richard Landis and Gary G. Koch. 1977. The 
Measurement of Observer Agreement for Categor-
ical Data. Biometrics, 33(1):159-74. 

Anne-Marie Loffler-Laurian. 1985. Traduction Au-
tomatique et Style. Babel, 31(2):70-76. 

David Mareček, Rudolf Rosa, Petra Galuščáková, and 
Ondřej Bojar. 2011. Two-step Translation with 
Grammatical Post-processing. In Proceedings of the 
Sixth Workshop on Statistical Machine Translation, 
pages 426-432. 

Franz Josef Och. 2003. Minimum Error Rate Training 
in Statistical Machine Translation. In Proceedings 
of the 41st Annual Meeting on Association for Com-
putational Linguistics -Volume 1, pages 160-167. 

Santanu Pal, Mihaela Vela, Sudip Kumar Naskar, and 
Josef van Genabith. 2015. USAAR-SAPE: An 
English-Spanish Statistical Automatic Post-Editing 
System. In Proceedings of the Tenth Workshop on 
Statistical Machine Translation, pages 216-221. 

Santanu Pal. 2015. Statistical Automatic Post Editing. 
In The Proceedings of the EXPERT Scientific and 
Technological workshop. 

Kishore Papineni, Salim Roukos, Todd Ward, and Wei-
Jing Zhu. 2002. BLEU: A Method for Automatic 
Evaluation of Machine Translation. In Proceedings 
of the 40th Annual Meeting on Association for Com-
putational Linguistics, ACL '02, pages 311-318. 

Rudolf Rosa, David Mareček, and Ondřej Dušek. 
2012. DEPFIX: A System for Automatic Correc-
tion of Czech MT Outputs. In Proceedings of the 
Seventh Workshop on Statistical Machine Transla-
tion, pages 362-368. 

Nakatani Shuyo. 2010. Language Detection Library 
for Java. 

Michel Simard, Cyril Goutte, and Pierre Isabelle. 
2007a. Statistical Phrase-Based Post-Editing. In 
Human Language Technologies 2007: The Confer-
ence of the North American Chapter of the Associa-
tion for Computational Linguistics; Proceedings of 
the Main Conference, pages 508-515. 

Michel Simard, Nicola Ueffing, Pierre Isabelle, and 
Roland Kuhn. 2007b. Rule-Based Translation with 
Statistical Phrase-Based Post-Editing. In Proceed-
ings of the Second Workshop on Statistical Machine 
Translation, pages 203-206. 

Matthew Snover, Bonnie Dorr, Richard Schwartz, Lin-
nea Micciulla, and John Makhoul. 2006. A study 
of Translation Edit Rate with Targeted Human An-
notation. In Proceedings of association for machine 
translation in the Americas, pages 223-231. 

TAUS Report. 2010. Post editing in practice. Techni-
cal report, TAUS. 

Tony Veale and Andy Way. 1997. Gaijin: A Bootstrap-
ping, Template-driven Approach to Example-based 
MT. In Proceedings of the Recent Advances in Nat-
ural Language Processing. 

Marcos Zampieri and Mihaela Vela. 2014. Quantify-
ing the Influence of MT Output in the Translators 
Performance: A Case Study in Technical Transla-
tion. In Proceedings of the EACL Workshop on Hu-
mans and Computer-assisted Translation (HaCat), 
pages 93-98. 

Matthew D. Zeiler. 2012. ADADELTA: An Adaptive 
Learning Rate Method. arXiv:1212.5701 [cs.LG]. Masoud Jalili Sabet 
(1) , Matteo Negri 
(2) , Marco Turchi 
(2) , Eduard Barbu 

(3) 

(1) School of Electrical and Computer Engineering, University of Tehran, Iran 
(2) Fondazione Bruno Kessler, Trento, Italy 
(3) Translated srl, Rome, Italy 
jalili.masoud@ut.ac.ir 
{negri,turchi}@fbk.eu 
eduard@translated.net 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_233" validated="false"><head></head><label></label><figDesc>Examples of problematic translation units mined from the English-Italian version of MyMemory.</figDesc><table>ENGLISH 

ITALIAN 
(EN translation) 

a traditional costumes of Iceland 
costumi tradizionali dell'islanda 
(traditional costumes of iceland) 

b Active substances: per dose of 2 ml: 
Principi attivi Per ogni dose da 2 ml: 
(Active substances Per dose of 2 ml:) 

c The length of time of ... 
La durata delperiodo di ... 
(The length oftime of ...) 

d ... 4 weeks after administration ... 
... 4 settimane dopo la somministarzione ... 
(... 4 weeks after somministarzione ...) 

e 5. ensure the organization of ... 
5. 
5. 

f 
Read package leaflet 
Per lo smaltimento leggere il foglio illustrativo 
For disposal read the package leaflet 

g beef chuck roast 
chuck carne assada 
?chuck meat ?assada 

h is an integral part of the contract 
risultato della stagione 
(result of the season) 
Table 1: </table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_234" validated="false"><head></head><label></label><figDesc>Eduard Barbu. 2015. Spotting False Translation Segments in Translation Memories. In Proceed- ings of the Workshop Natural Language Processing for Translation Memories, pages 9-16, Hissar, Bul- garia, September.Matthew Snover, Bonnie Dorr, Richard Schwartz, Lin- nea Micciulla, and John Makhoul. 2006. A Study of Translation Edit Rate with Targeted Human An- notation. In Proceedings of Association for Machine Translation in the Americas, pages 223-231, Cam- bridge, Massachusetts, USA, August.</figDesc><table>Kay Henning Brodersen, Cheng Soon Ong, Klaas Enno 
Stephan, and Joachim M. Buhmann. 2010. The Bal-
anced Accuracy and Its Posterior Distribution. In 
Proceedings of the 2010 20th International Confer-
ence on Pattern Recognition, ICPR '10, pages 3121-
3124, Istanbul, Turkey, August. 

José G. C. de Souza, Jesús González-Rubio, Chris-
tian Buck, Marco Turchi, and Matteo Negri. 2014. 
FBK-UPV-UEdin participation in the WMT14 
Quality Estimation shared-task. In Proceedings of 
the Ninth Workshop on Statistical Machine Trans-
lation, pages 322-328, Baltimore, Maryland, USA, 
June. 

José G. C. de Souza, Matteo Negri, Elisa Ricci, and 
Marco Turchi. 2015. Online Multitask Learning 
for Machine Translation Quality Estimation. In Pro-
ceedings of the 53rd Annual Meeting of the Associa-
tion for Computational Linguistics (Volume 1: Long 
Papers), pages 219-228, Beijing, China, July. 

José Guilherme Camargo de Souza, Christian Buck, 
Marco Turchi, and Matteo Negri. 2013. FBK-
UEdin Participation to the WMT13 Quality Esti-
mation Shared Task. In Proceedings of the Eighth 
Workshop on Statistical Machine Translation, pages 
352-358, Sofia, Bulgaria, August. 

Lei Cui, Dongdong Zhang, Shujie Liu, Mu Li, and 
Ming Zhou. 2013. Bilingual data cleaning for 
smt using graph-based random walk. In Proceed-
ings of the 51st Annual Meeting of the Association 
for Computational Linguistics (Volume 2: Short Pa-
pers), pages 340-345, Sofia, Bulgaria, August. 

Qin Gao and Stephan Vogel. 2008. Parallel implemen-
tations of word alignment tool. In In Proceedings 
of the ACL 2008 Software Engineering, Testing, and 
Quality Assurance Workshop, pages 49-57, Colum-
bus, Ohio, USA, June. 

Pierre Geurts, Damien Ernst, and Louis Wehenkel. 
2006. Extremely randomized trees. Machine learn-
ing, 63(1):3-42. 

Long Jiang, Shiquan Yang, Ming Zhou, Xiaohua Liu, 
and Qingsheng Zhu. 2009. Mining bilingual data 
from the web with adaptively learnt patterns. In Pro-
ceedings of the Joint Conference of the 47th Annual 
Meeting of the ACL and the 4th International Joint 
Conference on Natural Language Processing of the 
AFNLP, pages 870-878, Suntec, Singapore, August. 

Marco Lui and Timothy Baldwin. 2012. langid.py: An 
Off-the-shelf Language Identification Tool. In Pro-
ceedings of the ACL 2012 System Demonstrations, 
pages 25-30, Jeju Island, Korea, July. 

Yashar Mehdad, Matteo Negri, and Marcello Fed-
erico. 2012. Match without a Referee: Eval-
uating MT Adequacy without Reference Transla-
tions. In Proceedings of the Machine Translation 
Workshop (WMT2012), pages 171-180, Montréal, 
Canada, June. 

Dragos Stefan Munteanu and Daniel Marcu. 2005. Im-
proving machine translation performance by exploit-
ing non-parallel corpora. Computational Linguis-
tics, 31(4):477-504, December. 

Matteo Negri, Alessandro Marchetti, Yashar Mehdad, 
Luisa Bentivogli, and Danilo Giampiccolo. 2013. 
Semeval-2013 Task 8: Crosslingual Textual Entail-
ment for Content Synchronization. In Proceedings 
of the 7th International Workshop on Semantic Eval-
uation (SemEval 2013), pages 25-33, Atlanta, Geor-
gia, USA, June. 

Erik W. Noreen. 1989. Computer-intensive methods 
for testing hypotheses: an introduction. Wiley Inter-
science. 

Philip Resnik and Noah A. Smith. 2003. The web 
as a parallel corpus. Computational Linguistics, 
29(3):349-380. 

Anders Søgaard,Željko Agić, Héctor Martínez Alonso, 
Barbara Plank, Bernd Bohnet, and Anders Jo-
hannsen. 2015. Inverted indexing for cross-lingual 
NLP. In Proceedings of the 53rd Annual Meet-
ing of the Association for Computational Linguistics 
and the 7th International Joint Conference on Natu-
ral Language Processing (Volume 1: Long Papers), 
pages 1713-1722, Beijing, China, July. 

Lucia Specia, Nicola Cancedda, Marc Dymetman, 
Marco Turchi, and Nello Cristianini. 2009. Estimat-
ing the Sentence-level Quality of Machine Trans-
lation Systems. In Proceedings of the 13th An-
nual Conference of the European Association for 
Machine Translation (EAMT-2009), pages 28-35, 
Barcelona, Spain. 

Marco Turchi, Matteo Negri, and Marcello Federico. 
2013. Coping with the Subjectivity of Human 
Judgements in MT Quality Estimation. In Proceed-
ings of the Eighth Workshop on Statistical Machine 
Translation, pages 240-251, Sofia, Bulgaria, Au-
gust. 

Marco Turchi, Antonios Anastasopoulos, José G. C. de 
Souza, and Matteo Negri. 2014. Adaptive Qual-
ity Estimation for Machine Translation. In Proceed-
ings of the 52nd Annual Meeting of the Association 
for Computational Linguistics (Volume 1: Long Pa-
pers), pages 710-720, Baltimore, Maryland, USA, 
June. </table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_236" validated="false"><head>Table 1</head><label>1</label><figDesc>illustrates the experimental results of the neural network translation model with ex- ponentially decaying bag-of-words input features on IWSLT 2013 German→English, WMT 2015 German→English and BOLT Chinese→EnglishTER [%] BLEU [%] TER [%]</figDesc><table>IWSLT 

WMT 
BOLT 
test 
eval11 
newstest2013 
test 
BLEU [%] BLEU [%] TER [%] 
BLEU [%] TER [%] 
Baseline + NNTM 
31.9 
47.5 
36.7 
43.0 
28.8 
53.8 
17.4 
67.1 
+ BoW Features 
32.0 
47.3 
36.9 
42.9 
28.8 
53.5  *  
17.5 
67.0 
+ Fixed DR (0.9) 
32.2  *  
47.3 
37.0  *  
42.6  *  † 
29.0 
53.5  *  
17.7  *  
66.8  *  
+ Corpus DR 
32.1 
47.3 
36.9 
42.7  *  
29.1  *  † 
53.5  *  
17.7  *  
66.7  *  † 
+ BoW DR 
32.4  *  † 
47.0  *  † 37.2  *  † 
42.4  *  † 
29.2  *  † 
53.2  *  † 
17.9  *  † 
66.6  *  † 
+ Word DR 
32.3  *  † 
47.0  *  
37.1  *  
42.7  *  
29.1  *  † 
53.4  *  
17.8  *  † 
66.7  *  † 
Baseline + LSTM 
32.2  *  
47.4 
37.1  *  
42.5  *  † 
29.0 
53.3  *  
17.6 
66.8  *  

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_240" validated="true"><head>Table 2 :</head><label>2</label><figDesc>BLEU scores on news-test2014 calculated with multi-bleu.perl. NMT-LV refers to the RNNSEARCH-LV model from (Jean et al., 2015a) for large output vocabularies.</figDesc><table>Search 
Vocab. NMT Grammar KN-LM NPLM 
# of node exp-
BLEU 
BLEU 
space 
scores 
scores 
scores 
scores 
ansions per sen. 
(single) (ensemble) 

1 

Lattice 
Hiero 
-
21.1 (Hiero) 

2 

Lattice 
Hiero 
-
21.7 (Hiero) 
3 Unrestricted 
NMT 
254.8 
19.5 
21.8 

4 

100-best 
Hiero 
2,233.6 
(DFS: 832.1) 

22.8 
23.3 

5 

100-best 
Hiero 
22.9 
23.4 

6 

100-best 
Hiero 
22.9 
23.3 

7 

1000-best 
Hiero 
21,686.2 
(DFS: 6,221.8) 

23.3 
23.8 

8 

1000-best 
Hiero 
23.4 
23.9 

9 

1000-best 
Hiero 
23.5 
24.0 

10 

Lattice 
NMT 
243.3 
20.3 
21.4 

11 

Lattice 
Hiero 
243.3 
23.0 
24.2 

12 

Lattice 
Hiero 
243.3 
23.0 
24.2 

13 

Lattice 
Hiero 
240.5 
23.4 
24.5 

14 

Lattice 
Hiero 
243.9 
23.4 
24.4 

15 

Lattice 
Hiero 
244.3 
24.0 
24.4 
16 Neural MT -UMontreal-MILA (Jean et al., 2015b) 
22.8 
25.2 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_242" validated="false"><head>Table 4 :</head><label>4</label><figDesc>Time for lattice preprocessing operations on English-German news-test2015.</figDesc><table></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_244" validated="false"><head></head><label></label><figDesc>Wolfgang Macherey, Franz Josef Och, Ignacio Thayer, and Jakob Uszkoreit. 2008. Lattice-based minimum error rate training for statistical machine translation. In EMNLP, pages 725-734.Rico Sennrich, Barry Haddow, and Alexandra Birch. 2015. Neural machine translation of rare words with subword units. arXiv preprint arXiv:1508.07909.</figDesc><table>Minh-Thang Luong, Ilya Sutskever, Quoc V Le, Oriol 
Vinyals, and Wojciech Zaremba. 2015. Addressing 
the rare word problem in neural machine translation. 
In ACL. 

Yuval Marton and Philip Resnik. 2008. Soft syntac-
tic constraints for hierarchical phrased-based trans-
lation. In ACL, pages 1003-1011. 

Mehryar Mohri and Michael Riley. 2001. A weight 
pushing algorithm for large vocabulary speech 
recognition. In Interspeech, pages 1603-1606. 

Mehryar Mohri, Fernando Pereira, and Michael Ri-
ley. 2002. Weighted finite-state transducers in 
speech recognition. Computer Speech and Lan-
guage, 16(1). 

Graham Neubig, Makoto Morishita, and Satoshi Naka-
mura. 2015. Neural reranking improves subjective 
quality of machine translation: NAIST at WAT2015. 
In Workshop on Asian Translation, pages 35-41. 

Holger Schwenk. 
2014. 
Universit du Maine. 
http://www-lium.univ-lemans.fr/ 
schwenk/nnmt-shared-task/. 
[Online; 
accessed 1-March-2016]. 

Nakatani Shuyo. 2010. Language detection li-
brary for Java. http://code.google.com/ 
p/language-detection/. [Online; accessed 
1-March-2016]. Ilya Sutskever, Oriol Vinyals, and Quoc V Le. 2014. 
Sequence to sequence learning with neural net-
works. In Advances in Neural Information Process-
ing Systems, pages 3104-3112. 

Zhaopeng Tu, Zhengdong Lu, Yang Liu, Xiaohua Liu, 
and Hang Li. 2016. Coverage-based neural machine 
translation. arXiv preprint arXiv:1601.04811. 

Bart van Merriënboer, Dzmitry Bahdanau, Vincent Du-
moulin, Dmitriy Serdyuk, David Warde-Farley, Jan 
Chorowski, and Yoshua Bengio. 2015. Blocks and 
fuel: Frameworks for deep learning. arXiv preprint 
arXiv:1506.00619. 

Ashish Vaswani, Yinggong Zhao, Victoria Fossum, and 
David Chiang. 2013. Decoding with large-scale 
neural language models improves translation. In 
EMNLP, pages 1387-1392. 

Ashish Venugopal, Andreas Zollmann, Noah A. Smith, 
and Stephan Vogel. 2009. Preference grammars: 
Softening syntactic constraints to improve statistical 
machine translation. In NAACL-HLT, pages 236-
244. </table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_245" validated="false"><head></head><label></label><figDesc>AH Nijmegen, The Netherlands {i.croijmans,asifa.majid,a.vandenbosch}@let.ru.nl</figDesc><table>Iris Hendrickx 

1 

1 Centre for Language Studies 
Radboud University, P.O. Box 9103 
NL6500 HD Nijmegen, Netherlands 
i.hendrickx@let.ru.nl 

Els Lefever 

2 

2 Language and Translation Technology Team 
Dep. of Translation, Interpreting and 
Communication, Ghent University, Belgium 
els.lefever@ugent.be 

Ilja Croijmans 
1 , Asifa Majid 
1,3 and Antal van den Bosch 

1 

3 Max Planck Institute for 
Psycholinguistics, P.O. Box 310, 
6500 </table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_246" validated="false"><head>2 Vivino :</head><label>Vivino</label><figDesc>http://www.vivino.com 3 Delectable: http://www.delectable.com</figDesc><table></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_248" validated="true"><head>Table 2 :</head><label>2</label><figDesc>Top 10 features based on Chi-Square measures on the training set.</figDesc><table>class #number prec recall f-score 
red 
9296 
97.7 99.0 
98.4 
white 
4582 
97.6 97.1 
97.4 
rose 
335 
94.5 66.3 
77.9 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_249" validated="false"><head></head><label></label><figDesc>Ilja Croijmans and Asifa Majid. 2016. Not all flavor expertise is equal: The language of wine and coffee experts. PLoS ONE.//mallet.cs.umass.edu. Elin McCoy. 2006. The Emperor of Wine: The Rise of Robert M. Parker, Jr., and the Reign of American Taste. Harper Perennial. Tomas Mikolov, ILya Sutskever, Kai Chen, Greg Cor- rado, and Jeff Dean. 2013. Distributed representa- tions of words and phrases and their composition- ality. Advances in Neural Information Processing Systems 26, pages 3111-3119.</figDesc><table>Frédéric Brochet and Denis Dubourdieu. 2001. Wine 
descriptive language supports cognitive specificity 
of chemical senses. Brain and Language, 77:187-
196. 

Rosario Caballero and Ernesto Suárez-Toste. 2010. A 
genre approach to imagery in winespeak: Issues and 
prospects. Researching and applying metaphor in 
the real world, 26:265-288. 

William S Cain. 1979. To know with the nose: keys to 
odor identification. Science, 203(4379):467-470. 

Chih-Chung Chang and Chih-Jen Lin. 2011. LIB-
SVM: A library for support vector machines. ACM 
Transactions on Intelligent Systems and Technol-
ogy, 2:27:1-27:27. Software available at http:// 
www.csie.ntu.edu.tw/˜cjlin/libsvm. 

Deng-feng Chen, Qi-chun Ji, Liang Zhao, and Hong-
cai Zhang. 2009. The classification of wine based 
on pca and ann. In Bingyuan Cao, Tai-Fu Li, 
and Cheng-Yi Zhang, editors, Fuzzy Information 
and Engineering Volume 2, volume 62 of Advances 
in Intelligent and Soft Computing, pages 647-655. 
Springer Berlin Heidelberg. 

Paulo Cortez, António Cerdeira, Fernando Almeida, 
Telmo Matos, and José Reis. 2009. Modeling wine 
preferences by data mining from physicochemical 
properties. Decision Support Systems, 47(4):547-
553. 

Richard Gawel and Peter Godden. 2008. Evaluation of 
the consistency of wine quality assessments from ex-
pert wine tasters. Australian Journal of Grape and 
Wine Research, 14(1):1-8. 

Robin Goldstein, Johan Almenberg, Anna Dreber, 
John W Emerson, Alexis Herschkowitsch, and Ja-
cob Katz. 2008. Do more expensive wines taste 
better? evidence from a large sample of blind tast-
ings. Journal of Wine Economics, 3(01):1-9. 

Helene Hopfer and Hildegarde Heymann. 2014. Judg-
ing wine quality: Do we need experts, consumers 
or trained panelists? Food Quality and Preference, 
32:221-233. 

Øyvind Horverak. 2009. Wine journalism-marketing 
or consumers' guide? 
Marketing Science, 
28(3):573-579. 

Matt Kusner, Yu Sun, Nicholas Kolkin, and Kilian Q 
Weinberger. 2015. From word embeddings to docu-
ment distances. In Proceedings of the 32nd Interna-
tional Conference on Machine Learning (ICML-15), 
pages 957-966. 

Harry T Lawless. 1984. Flavor description of white 
wine by "expert" and nonexpert wine consumers. 
Journal of Food Science, 49(1):120-123. 

Sébastien Lecocq and Michael Visser. 2006. What de-
termines wine prices: Objective vs. sensory charac-
teristics. Journal of Wine Economics, 1(01):42-56. 

Stephen C Levinson and Asifa Majid. 2014. Differen-
tial ineffability and the senses. Mind &amp; Language, 
29(4):407-427. 

Asifa Majid and Niclas Burenhult. 2014. Odors are ex-
pressible in language, as long as you speak the right 
language. Cognition, 130(2):266-270. 

Christopher D. Manning, Mihai Surdeanu, John Bauer, 
Jenny Finkel, Steven J. Bethard, and David Mc-
Closky. 2014. The Stanford CoreNLP natural lan-
guage processing toolkit. In Association for Compu-
tational Linguistics (ACL) System Demonstrations, 
pages 55-60. 

Andrew McCallum. 
2002. 
MALLET: A 
machine 
learning 
for 
language 
toolkit. 
http:Edward Oczkowski and Hristos Doucouliagos. 2014. 
Wine prices and quality ratings: A meta-regression 
analysis. American Journal of Agricultural Eco-
nomics, page aau057. 

Jonas K Olofsson and Jay A Gottfried. 2015. The 
muted sense: neurocognitive limitations of olfactory 
language. Trends in cognitive sciences, 19(6):314-
321. 

Carita Paradis and Mats Eeg-Olofsson. 2013. Describ-
ing sensory experience: The genre of wine reviews. 
Metaphor and Symbol, 28(1):22-40. 

Wendy V Parr, David Heatherbell, and K Geoffrey 
White. 2002. Demystifying wine expertise: olfac-
tory threshold, perceptual skill and semantic mem-
ory in expert and novice wine judges. Chemical 
Senses, 27(8):747-755. 

Caroline Sezille, Arnaud Fournel, Catherine Rouby, 
Fanny Rinck, and Moustafa Bensafi. 2014. Hedo-
nic appreciation and verbal description of pleasant 
and unpleasant odors in untrained, trainee cooks, fla-
vorists, and perfumers. Front. Psychol, 5:12. 

Michael Silverstein. 2006. Old wine, new ethno-
graphic lexicography. Annual Review of Anthropol-
ogy, 35:481-496. 

Ernesto Suárez Toste. 2007. Metaphor inside the wine 
cellar: On the ubiquity of personification schemas in 
winespeak. Metaphorik. de, 12(1):53-64. Debbie Vigar-Ellis, Leyland Pitt, and Albert Caruana. 
2015. Knowledge effects on the exploratory acquisi-
tion of wine. International Journal of Wine Business 
Research, 27(2):84-102. 

Gesualdo M. Zucco, Aurelio Carassai, Maria Rosa 
Baroni, and Richard J. Stevenson. 2011. Label-
ing, identification, and recognition of wine-relevant 
odorants in expert sommeliers, intermediates, and 
untrained wine drinkers. Perception, 40(5):598-
607. </table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_252" validated="false"><head></head><label></label><figDesc>Daniel Preoţiuc-Pietro, Svitlana Volkova, Vasileios Lampos, Yoram Bachrach, and Nikolaos Aletras. 2015b. Studying user income through language, be- haviour and affect in social media. PLoS ONE.</figDesc><table>. 
The Readability of Tweets and their Geographic 
Correlation with Education. 
arXiv preprint 
arXiv:1401.6058. 

Munmun De Choudhury, Michael Gamon, Scott 
Counts, and Eric Horvitz. 2013. Predicting Depres-
sion via Social Media. In Proceedings of the Seventh 
International AAAI Conference on Weblogs and So-
cial Media, ICWSM. 

Jacob Eisenstein, Brendan O'Connor, Noah A. Smith, 
and Eric P. Xing. 2010. A latent variable model for 
geographic lexical variation. In Proceedings of the 
Conference on Empirical Methods in Natural Lan-
guage Processing, EMNLP. 

Jacob Eisenstein, Noah A Smith, and Eric P Xing. 
2011. Discovering Sociolinguistic Associations 
with Structured Sparsity. In Proceedings of the 
49th annual meeting of the Association for Computa-
tional Linguistics: Human Language Technologies, 
NAACL. 

Lijun Feng, Noémie Elhadad, and Matt Huenerfauth. 
2009. Cognitively Motivated Features for Readabil-
ity Assessment. In Proceedings of the 12th Confer-
ence of the European Chapter of the Association for 
Computational Linguistics, EACL. 

Jenny Rose Finkel, Trond Grenager, and Christopher 
Manning. 2005. Incorporating Non-Local Informa-
tion into Information extraction Systems by Gibbs 
Sampling. In Proceedings of the 43rd Annual Meet-
ing of the Association for Computational Linguistics, 
ACL. J.W. Pennebaker, Matthias R. Mehl, and K.G. Nieder-
hoffer. 2003. Psychological Aspects of Natural Lan-
guage Use: Our Words, Our Selves. Annual Review 
of Psychology, 54(1). 

Slav Petrov, Dipanjan Das, and Ryan T. McDonald. 
2012. A Universal Part-of-Speech Tagset. In Pro-
ceedings of the Eighth International Conference on 
Language Resources and Evaluation, LREC. 

Emily Pitler and Ani Nenkova. 2008. Revisiting Read-
ability: A Unified Framework for Predicting Text 
Quality. In Proceedings of the Conference on Em-
pirical Methods in Natural Language Processing, 
EMNLP. 

Daniel Preoţiuc-Pietro, Sina Samangooei, Trevor Cohn, 
Nick Gibbins, and Mahesan Niranjan. 2012. Trend-
miner: An Architecture for Real Time Analysis of 
Social Media Text. In Workshop on Real-Time Anal-
ysis and Mining of Social Streams, ICWSM, pages 
38-42. 

Daniel Preoţiuc-Pietro, Vasileios Lampos, and Niko-
laos Aletras. 2015a. An Analysis of the User Occu-
pational Class through Twitter Content. In Proceed-
ings of the 53rd Annual Meeting of the Association 
for Computational Linguistics, ACL. 

Daniel Preoţiuc-Pietro, Wei Xu, and Lyle Ungar. 2016. 
Discovering User Attribute Stylistic Differences via 
Paraphrasing. In Proceedings of the Thirtieth AAAI 
Conference on Artificial Intelligence, AAAI. 

Daniel Preotiuc-Pietro, Johannes Eichstaedt, Gregory 
Park, Maarten Sap, Laura Smith, Victoria Tobolsky, 
H Andrew Schwartz, and Lyle H Ungar. 2015. The 
Role of Personality, Age and Gender in Tweeting 
about Mental Illnesses. In Proceedings of the Work-
shop on Computational Linguistics and Clinical Psy-
chology: From Linguistic Signal to Clinical Reality, 
NAACL. 

Francisco Rangel, Paolo Rosso, Irina Chugur, Martin 
Potthast, Martin Trenkmann, Benno Stein, Ben Ver-
hoeven, and Walter Daelemans. 2014. Overview 
of the 2nd Author Profiling Task at PAN 2014. In 
Proceedings of the Conference and Labs of the Eval-
uation Forum (Working Notes), CLEF. 

Delip Rao, David Yarowsky, Abhishek Shreevats, and 
Manaswi Gupta. 2010. Classifying Latent User At-
tributes in Twitter. In Proceedings of the 2nd In-
ternational Workshop on Search and Mining User-
generated Contents, SMUC. 

Sara Rosenthal and Kathleen McKeown. 2011. Age 
Prediction in Blogs: A Study of Style, Content, and 
Online Behavior in Pre-and Post-Social Media Gen-
erations. In Proceedings of the 53rd Annual Meet-
ing of the Association for Computational Linguistics, 
ACL. 

Maarten Sap, Gregory Park, Johannes Eichstaedt, Mar-
garet Kern, David Stillwell, Michal Kosinski, Lyle 
Ungar, and H Andrew Schwartz. 2014. Develop-
ing Age and Gender Predictive Lexica over Social 
Media. In Proceedings of the 2014 Conference on 
Empirical Methods in Natural Language Processing, 
EMNLP. 

Jonathan Schler, Moshe Koppel, Shlomo Argamon, 
and James Pennebaker. 2006. Effects of Age and 
Gender on Blogging. In Proceedings of 2006 AAAI 
Spring Symposium on Computational Approaches 
for Analyzing Weblogs. 

H Andrew Schwartz, Johannes C Eichstaedt, Mar-
garet L Kern, Lukasz Dziurzynski, Stephanie M 
Ramones, Megha Agrawal, Achal Shah, Michal 
Kosinski, David Stillwell, Martin EP Seligman, and 
Lyle H Ungar. 2013. Personality, Gender, and 
Age in the Language of Social Media: The Open-
Vocabulary Approach. PLoS ONE. 

R.J. Senter and E.A. Smith. 1967. Automated Read-
ability Index. Aerospace Medical Research Labora-
tories. 

SanjaŠtajner, Richard Evans, Constantin Orasan, and 
Ruslan Mitkov. 2012. What can readability mea-
sures really tell us about text complexity. In NLP 
for Improving Textual Accessibility workshop, pages 
14-22. 

Kristina Toutanova, Dan Klein, Christopher D. Man-
ning, and Yoram Singer. 2003. Feature-rich Part-of-
Speech Tagging with a Cyclic Dependency Network. 
In Proceedings of the 2003 Conference of the North 
American Chapter of the Association for Computa-
tional Linguistics, NAACL. 

Vladimir N Vapnik. 1998. Statistical learning theory. 
Wiley. 

Svitlana Volkova and Yoram Bachrach. 2015. On 
predicting socio-demographic traits and emotions 
in social networks and implications to online self-
disclosure. Cyberpsychology, behavior and social 
networking, 18(12):726-736. 

Hui Zou and Trevor Hastie. 2005. Regularization and 
Variable Selection via the Elastic Net. Journal of the 
Royal Statistical Society, Series B, 67. Finding Optimists and Pessimists on Twitter 

Xianzhi Ruan, Steven R. Wilson, and Rada Mihalcea 
University of Michigan 
Ann Arbor, MI 
{rxianzhi, steverw, mihalcea}@umich.edu 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_253" validated="true"><head>Table 1 .</head><label>1</label><figDesc>Interestingly the opti- mists have more followers and are following more</figDesc><table>2 The 2007 version of LIWC was used 

321 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_255" validated="false"><head>Table 3 :</head><label>3</label><figDesc>Predicted optimism &amp; pessimism in three major cities</figDesc><table></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_257" validated="false"><head>Table 4 :</head><label>4</label><figDesc>Predicted optimism &amp; pessimism of those following some of the candidates for the 2016 Presidential election.</figDesc><table></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_259" validated="false"><head></head><label></label><figDesc>. 2: Use MDA with noise level p to estimate W * = min W ||U − WŨ|| 2 . 3: Get the denoised class predictions for x t asLabel x t with c * = argmax c {y t c |y t }. 5: return Labels for X t .</figDesc><table>y t = W  *  
[1:N,d+1:d+C] · f s (x t ). 
4: </table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_260" validated="true"><head>Table 1 :</head><label>1</label><figDesc>TPA results on the AMT dataset.</figDesc><table>S → T 
MDA 

 *  

f 
s (X 
t ) 
TPA 
TPAe 
d → b 
84.59 
81.36 
82.61 83.19 
e → b 
78.07 
73.87 
75.93 79.95 
k → b 
78.75 
73.50 
75.02 78.39 
b → d 
85.07 
82.54 
83.56 84.32 
e → d 
79.99 
76.46 
77.67 81.60 
k → d 
80.76 
77.58 
79.16 81.92 
b → e 
80.32 
76.44 
78.54 81.81 
d → e 
83.70 
78.65 
80.75 82.89 
k → e 
89.05 
87.55 
88.38 88.50 
b → k 
84.00 
79.46 
81.44 85.21 
d → k 
86.08 
80.83 
83.15 86.14 
e → k 
90.76 
89.97 
91.10 90.86 
Avg 
83.4 
79.85 
81.44 83.73 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_261" validated="true"><head>Table 2 :</head><label>2</label><figDesc>TPA results on the 20Newsgroup dataset.</figDesc><table>class pair 
f 
s (X 
t ) 
TPA 
TPAe 
'comp vs sci' 
71.06 
80.24 80.43 
65.4 
71.6 
71.98 
'rec vs talk' 
65.66 
68.01 70.18 
69.93 
75.84 
77.2 
'rec vs sci' 
76.02 
85.97 86.42 
74.17 
81.14 82.71 
'sci vs talk' 
76.1 
80.22 
81.3 
74.92 
80.07 80.19 
'comp vs rec' 
86.63 
91.56 92.06 
86.97 
92.67 93.34 
Avg 
74.69 
80.73 81.58 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_264" validated="false"><head>335</head><label></label><figDesc>Jihie Kim, Jaebong Yoo, Ho Lim, Huida Qiu, Zornitsa Kozareva, and Aram Galstyan. 2013. Sentiment prediction using collaborative filtering. In ICWSM.Ajit P. Singh and Geoffrey J. Gordon. 2008. Relational learning via collective matrix factorization. In KDD.</figDesc><table>Charles F Manski. 1975. Maximum score estimation 
of the stochastic utility model of choice. Journal of 
Econometrics, 3(3):205-228. 

Daniel McFadden. 1974. Conditional logit analysis of 
qualitative choice behavior. In Frontiers in Econo-
metrics, pages 105-142. 

Sanjay Purushotham, Yan Liu, and C.-C. Jay Kuo. 
2012. Collaborative topic regression with social 
matrix factorization for recommendation systems. 
CoRR. 

Ruslan Salakhutdinov and Andriy Mnih. 
2008. 
Bayesian probabilistic matrix factorization using 
markov chain monte carlo. In ICML. 

Chong Wang and David M. Blei. 2011. Collaborative 
topic modeling for recommending scientific articles. 
In KDD. 

Dawei Yin, Liangjie Hong, and Brian D Davison. 
2011. Structural link analysis and prediction in mi-
croblogs. In CIKM. 

Yunhong Zhou, Dennis Wilkinson, Robert Schreiber, 
and Rong Pan. 2008. Large-scale parallel collabo-
rative filtering for the netflix prize. In AAIM. </table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_267" validated="false"><head>Table 2 :</head><label>2</label><figDesc></figDesc><table>Compression ratios and automatic read-
ability scores for the Google compression data set, 
compared to the system output. Readability is in-
dicated by a high Flesh Reading Ease score and a 
low Dale-Chall score. * indicates differences com-
pared to the original sentences that are significant 
at p &lt; 10 −3 . 

System 
Readability Informativeness 
MIRA 
4.31 
3.55 
LSTM 
4.51 
3.78 
TL 
4.14 
4.01 

RT (11) 
3.09 
4.12 
LSTM (11) 
4.23 
3.42 
TL (11) 
4.21 
4.15 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_268" validated="false"><head>Table 3 :</head><label>3</label><figDesc></figDesc><table>Mean readability and informativeness rat-
ings for the first 200 sentences in the Google data 
(upper) and for the 11 sample sentences listed in 
Filippova et al. (2015) (lower). 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_269" validated="false"><head></head><label></label><figDesc>Siobhan Lucy Devlin. 1999. Simplifying natural lan- guage for aphasic readers. Ph.D. thesis, University of Sunderland.</figDesc><table>Arendse Bernth. 1998. EasyEnglish: Preprocessing 
for MT. In Proceedings of the Second Interna-
tional Workshop on Controlled Language Applica-
tions, pages 30-41. 

John Carroll, Guido Minnen, Darren Pearce, Yvonne 
Canning, Siobhan Devlin, and John Tait. 1999. 
Simplifying text for language-impaired readers. In 
Proceedings of EACL, volume 99, pages 269-270. 

James Clarke and Mirella Lapata. 2008. Global in-
ference for sentence compression: An integer linear 
programming approach. Journal of Artificial Intelli-
gence Research, pages 399-429. 

Trevor Cohn and Mirella Lapata. 2008. Sentence 
compression beyond word deletion. In Proceedings 
of the 22nd International Conference on Computa-
tional Linguistics-Volume 1, pages 137-144. Asso-
ciation for Computational Linguistics. 

Trevor Cohn and Mirella Lapata. 2009. Sentence com-
pression as tree transduction. Journal of Artificial 
Intelligence Research, pages 637-674. 

Edgar Dale and Jeanne S Chall. 1948. A formula for 
predicting readability: Instructions. Educational re-
search bulletin, pages 37-54. 

Jakob Elming, Anders Johannsen, Sigrid Klerke, 
Emanuele Lapponi, Hector Martinez Alonso, and 
Anders Søgaard. 2013. Down-stream effects of 
tree-to-dependency conversions. In HLT-NAACL, 
pages 617-626. 

Katja Filippova and Michael Strube. 2008. Depen-
dency tree based sentence compression. In Proceed-
ings of the Fifth International Natural Language 
Generation Conference, pages 25-32. Association 
for Computational Linguistics. 

Katja Filippova, Enrique Alfonseca, Carlos A Col-
menares, Lukasz Kaiser, and Oriol Vinyals. 2015. 
Sentence compression by deletion with lstms. In 
Proceedings of the 2015 Conference on Empirical 
Methods in Natural Language Processing, pages 
360-368. 

Rudolph Flesch. 1948. A new readability yardstick. 
Journal of applied psychology, 32(3):221. 

Juri Ganitkevitch, Benjamin Van Durme, and Chris 
Callison-Burch. 2013. PPDB: The paraphrase 
database. In Proceedings of NAACL-HLT, pages 
758-764, Atlanta, Georgia, June. Association for 
Computational Linguistics. 

Kentaro Inui, Atsushi Fujita, Tetsuro Takahashi, Ryu 
Iida, and Tomoya Iwakura. 2003. Text simplifica-
tion for reading assistance: a project note. In Pro-
ceedings of the second international workshop on 
Paraphrasing-Volume 16, pages 9-16. Association 
for Computational Linguistics. 

Sigrid Klerke, Yoav Goldberg, and Anders Søgaard. 
2016. Improving sentence compression by learning 
to predict gaze. In Proceedings of ACL 2016 (short). 

Kevin Knight and Daniel Marcu. 2002. Summariza-
tion beyond sentence extraction: A probabilistic ap-
proach to sentence compression. Artificial Intelli-
gence, 139(1):91-107. 

Angrosh A. Mandya, Tadashi Nomoto, and Advaith 
Siddharthan. 2014. Lexico-syntactic text simplifi-
cation and compression with typed dependencies. In 
COLING, pages 1996-2006. 

Christopher D. Manning, Mihai Surdeanu, John Bauer, 
Jenny Finkel, Steven J. Bethard, and David Mc-
Closky. 2014. The Stanford CoreNLP natural lan-
guage processing toolkit. In Proceedings of 52nd 
Annual Meeting of the Association for Computa-
tional Linguistics: System Demonstrations, pages 
55-60. 

Ryan T McDonald. 2006. Discriminative sentence 
compression with soft syntactic evidence. In EACL. 

Thomas Mueller, Helmut Schmid, and Hinrich 
Schütze. 2013. Efficient higher-order CRFs for 
morphological tagging. In Proceedings of the 2013 
Conference on Empirical Methods in Natural Lan-
guage Processing, pages 322-332, Seattle, Wash-
ington, USA, October. Association for Computa-
tional Linguistics. 

Courtney Napoles, Chris Callison-Burch, Juri Ganitke-
vitch, and Benjamin Van Durme. 2011. Paraphras-
tic sentence compression with a character-based 
metric: Tightening without deletion. In Proceed-
ings of the Workshop on Monolingual Text-To-Text 
Generation, pages 84-90. Association for Computa-
tional Linguistics. 

Shashi Narayan and Claire Gardent. 2014. Hybrid 
simplification using deep semantics and machine 
translation. In the 52nd Annual Meeting of the As-
sociation for Computational Linguistics, pages 435-
445. 

Tadashi Nomoto. 2007. Discriminative sentence com-
pression with conditional random fields. Informa-
tion Processing and Management: an International 
Journal, 43(6):1571-1587. 

Emily Pitler. 2010. Methods for sentence compres-
sion. Technical report, Department of Computer and 
Information Science, University of Pennsylvania. 

Luz Rello, Ricardo Baeza-Yates, Laura Dempere-
Marco, and Horacio Saggion. 2013. Frequent words 
improve readability and short words improve under-
standability for people with dyslexia. In Human-
Computer Interaction-INTERACT 2013, pages 203-
219. Springer. 

Stefan Riezler, Tracy H King, Richard Crouch, and An-
nie Zaenen. 2003. Statistical sentence condensa-
tion using ambiguity packing and stochastic disam-
biguation methods for lexical-functional grammar. In Proceedings of the 2003 Conference of the North 
American Chapter of the Association for Computa-
tional Linguistics on Human Language Technology-
Volume 1, pages 118-125. Association for Compu-
tational Linguistics. 

Jenine Turner and Eugene Charniak. 2005. Super-
vised and unsupervised learning for sentence com-
pression. In Proceedings of the 43rd Annual Meet-
ing on Association for Computational Linguistics, 
pages 290-297. Association for Computational Lin-
guistics. 

Willian Massami Watanabe, Arnaldo Candido Junior, 
Vinícius Rodriguez Uzêda, Renata Pontin de Mat-
tos Fortes, Thiago Alexandre Salgueiro Pardo, and 
Sandra Maria Aluísio. 2009. Facilita: reading as-
sistance for low-literacy readers. In Proceedings of 
the 27th ACM international conference on Design of 
communication, pages 29-36. ACM. 

Kristian Woodsend and Mirella Lapata. 2011. Learn-
ing to simplify sentences with quasi-synchronous 
grammar and integer programming. In Proceedings 
of the conference on empirical methods in natural 
language processing, pages 409-420. Association 
for Computational Linguistics. 

Zhemin Zhu, Delphine Bernhard, and Iryna Gurevych. 
2010. A monolingual tree-based translation model 
for sentence simplification. In Proceedings of the 
23rd international conference on computational lin-
guistics, pages 1353-1361. Association for Compu-
tational Linguistics. </table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_272" validated="true"><head>Table 2 :</head><label>2</label><figDesc>Performance of NER systems</figDesc><table>distribution for the main annotation was 66.9% 
PERSON, 10.2% LOCATION, 19.0% OTHER, 2.4% 
UNCERTAIN, and 1.5% segmentation error. For 
the main evaluation, we excluded both UNCER-
TAIN examples and segmentation errors, but had 
our annotator provide correct segmentation for the 
15 segmentation errors and carried out a separate 
comparison on these. 
</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_273" validated="false"><head></head><label></label><figDesc>6 https://crowdflower.com 16% FAKE JUDGE COND. LM REG. LM p &lt; 0.01</figDesc><table>words only 
88.27 
87.89 
no 
+meta-info 
88.92 
92.42 
yes 

p &lt; 0.01 
yes 
yes 

50% FAKE 

words only 
75.52 
72.78 
yes 
+meta-info 
77.40 
88.43 
yes 

p &lt; 0.01 
yes 
yes 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_274" validated="false"><head>Table 2 :</head><label>2</label><figDesc></figDesc><table>Model performance (F1) with different 
amounts of information on reviews generated by 
regular or conditional model under two conditions 

mance. This effect is especially pronounced in 
the regular LMs, since the detection model is able 
to pick up on the mismatch between category and 
text content. 
</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_276" validated="false"><head></head><label></label><figDesc>Character-based Neural Machine Translation Marta R. Costa-jussà and José A. R. Fonollosa TALP Research Center Universitat Politècnica de Catalunya, Barcelona {marta.ruiz,jose.fonollosa}@upc.eduNeural Machine Translation (MT) has reached state-of-the-art results. However, one of the main challenges that neural MT still faces is dealing with very large vo- cabularies and morphologically rich lan- guages.</figDesc><table>Dirk Hovy and Shannon L. Spruit. 2016. Beyond Pri-
vacy: The Social Impact of Natural Language Pro-
cessing. In Proceedings of the 54th Annual Meet-
ing of the Association for Computational Linguis-
tics. ACL, Association for Computational Linguis-
tics. 

Dirk Hovy, Taylor Berg-Kirkpatrick, Ashish Vaswani, 
and Eduard Hovy. 2013. Learning whom to trust 
with MACE. In Proceedings of NAACL. 

Dirk Hovy, Anders Johannsen, and Anders Søgaard. 
2015. User review-sites as a source for large-scale 
sociolinguistic studies. In Proceedings of WWW. 

Dirk Hovy. 2015. Demographic factors improve clas-
sification performance. In Proceedings of the 53rd 
annual meeting of the ACL. 

Nitin Jindal and Bing Liu. 2007. Review spam de-
tection. In Proceedings of the 16th international 
conference on World Wide Web, pages 1189-1190. 
ACM. 

Nitin Jindal, Bing Liu, and Ee-Peng Lim. 2010. Find-
ing unusual review patterns using unexpected rules. 
In Proceedings of the 19th ACM international con-
ference on Information and knowledge management, 
pages 1549-1552. ACM. 

Dan Jurafsky, Victor Chahuneau, Bryan R Routledge, 
and Noah A Smith. 2014. Narrative framing of con-
sumer sentiment in online restaurant reviews. First 
Monday, 19(4). 

Theodoros Lappas. 2012. Fake reviews: The mali-
cious perspective. In Natural Language Processing 
and Information Systems, pages 23-34. Springer. 

Ee-Peng Lim, Viet-An Nguyen, Nitin Jindal, Bing Liu, 
and Hady Wirawan Lauw. 2010. Detecting prod-
uct review spammers using rating behaviors. In Pro-
ceedings of the 19th ACM international conference 
on Information and knowledge management, pages 
939-948. ACM. 

Michael Luca and Georgios Zervas. 2015. Fake it till 
you make it: Reputation, competition, and yelp re-
view fraud. Harvard Business School NOM Unit 
Working Paper, (14-006). 

Jo Mackiewicz. 2008. Reviewer motivations, bias, and 
credibility in online reviews. Handbook of research 
on computer mediated communication, 1:252-266. 

Julian McAuley, Jure Leskovec, and Dan Jurafsky. 
2012. Learning attitudes and attributes from multi-
aspect reviews. In Data Mining (ICDM), 2012 IEEE 
12th International Conference on, pages 1020-
1025. IEEE. 

Myle Ott, Yejin Choi, Claire Cardie, and Jeffrey T 
Hancock. 2011. Finding deceptive opinion spam 
by any stretch of the imagination. In Proceed-
ings of the 49th Annual Meeting of the Association 
for Computational Linguistics: Human Language 

Technologies-Volume 1, pages 309-319. Association 
for Computational Linguistics. 

Kevin Reschke, Adam Vogel, and Dan Jurafsky. 2013. 
Generating recommendation dialogs by extracting 
information from user reviews. In Proceedings of 
the 51st annual meeting of the ACL, pages 499-504. 

Jeff John Roberts. 2012. Amazon sues people who 
charge $5 for fake reviews. Fortune, October 19. 
http://fortune.com/2015/10/19/ 
amazon-fake-reviews/ Retrieved Feb 27, 
2016. 

Noah Smith. 2012. Adversarial evaluation for models 
of natural language. http://arxiv.org/abs/1207.0245. 

David Streitfeld. 2012. The Best Book Reviews 
Money Can Buy. The New York Times, August 25. 
http://www.nytimes.com/2012/08/26/ 
business/book-reviewers-for-hire-
meet-a-demand-for-online-raves.html 
Retrieved Feb 27, 2016. 

Svitlana Volkova, Theresa Wilson, and David 
Yarowsky. 2013. Exploring demographic language 
variations to improve multilingual sentiment anal-
ysis in social media. In Proceedings of EMNLP, 
pages 1815-1827. Abstract 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_277" validated="false"><head></head><label></label><figDesc>1 http://www.statmt.org/wmt15/translation-task.html other than German or English. Statistics are shown in Table 1.</figDesc><table>L 
Set 
S 
W 
V 
OOV 
De Train 3.5M 77.7M 1.6M 
-
Dev 
3k 
63.1k 13.6k 1.7k 
Test 
2.2k 44.1k 
9.8k 
1.3k 
En Train 3.5M 81.2M 0.8M 
-
Dev 
3k 
67.6k 10.1k 0.8k 
Test 
2.2k 46.8k 
7.8k 
0.6k 

Table 1: Corpus details. Number of sentences (S), 
words (W), vocabulary (V) and out-of-vocabulary-
words (OOV) per set and language (L). M standing 
for millions, k standing for thousands. 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_278" validated="false"><head></head><label></label><figDesc>India , in addition to a contract for the defence cooperation between the two nations . NN according to reports , India also hopes to establish a contract for the UNK between the two nations . CHAR according to reports , India hopes to see a Treaty of Defence Cooperation between the two nations . REF India is also reportedly hoping for a deal on defence collaboration between the two nations .</figDesc><table>1 

SRC 
Berichten zufolge hofft Indien darber hinaus auf einen Vertrag zur Verteidigungszusammenarbeit zwischen den beiden Nationen . 
Phrase 
reportedly hopes 2 
SRC 
der durchtrainierte Mainzer sagt von sich , dass er ein " ambitionierter Rennradler " ist . 
Phrase 
the will of Mainz says that he a more ambitious . 
NN 
the UNK Mainz says that he is a " ambitious , . " 
CHAR 
the UNK in Mainz says that he is a ' ambitious racer ' . 
REF 
the well-conditioned man from Mainz said he was an " ambitious racing cyclist . " 
3 
SRC 
die GDL habe jedoch nicht gesagt , wo sie streiken wolle , so dass es schwer sei , die Folgen konkret vorherzusehen . 
Phrase 
the GDL have , however , not to say , where they strike , so that it is difficult to predict the consequences of concrete . 
NN 
however , the UNK did not tell which they wanted to UNK , so it is difficult to predict the consequences . 
CHAR 
however , the UNK did not say where they wanted to strike , so it is difficult to predict the consequences . 
REF 
the GDL have not said , however , where they will strike , making it difficult to predict exactly what the consequences will be . 
4 
SRC 
die Premierminister Indiens und Japans trafen sich in Tokio . 
Phrase 
the Prime Minister of India and Japan in Tokyo . 
NN 
the Prime Minister of India and Japan met in Tokyo 
CHAR 
the Prime Ministers of India and Japan met in Tokyo 
REF 
India and Japan prime ministers meet in Tokyo 
5 
SRC 
wo die Beamten es aus den Augen verloren . 
Phrase 
where the officials lost sight of 
NN 
where the officials lost it out of the eyes 
CHAR 
where officials lose sight of it 
REF 
causing the officers to lose sight of it 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_279" validated="true"><head>Table 2 :</head><label>2</label><figDesc>Translation examples.</figDesc><table>De-&gt;En En-&gt;De 
Phrase 
20.99 
17.04 
NN 
18.83 
16.47 
NN+Src 
20.64 
17.15 
CHAR 
21.40 
19.53 
CHAR+Src 
22.10 
20.22 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_280" validated="false"><head>Table 3 :</head><label>3</label><figDesc>De-En BLEU results.</figDesc><table></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_281" validated="false"><head></head><label></label><figDesc>USA elgohary@cs.umd.edu, marine@cs.umd.eduBilingual models that capture the seman- tics of sentences are typically only eval- uated on cross-lingual transfer tasks such as cross-lingual document categorization or machine translation. In this work, we evaluate the quality of the monolingual representations learned with a variant of the bilingual compositional model of Her- mann and Blunsom</figDesc><table>Learning Monolingual Compositional Representations 
via Bilingual Supervision 

Ahmed Elgohary and Marine Carpuat 
Department of Computer Science 
University of Maryland 
College Park, MD 20742, Abstract 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_282" validated="false"><head>Table 1 :</head><label>1</label><figDesc>Positive and negative examples for each of the 3 types of supervision considered Bilingual Sentences + thus, in fact, we might say that he hurried ahead of the decision by our fellow member.</figDesc><table>as que podramos decir 
, de hecho, que se adelant a 
la decisin de nuestro colega. 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_283" validated="true"><head>Table 2 :</head><label>2</label><figDesc>Training conditions: three types of semantic equivalence for composed representations.</figDesc><table>Condition 
# examples Avg. length Provenance 
Bilingual Sentences 
1.9M 
28 Europarl-v7 (Koehn, 2005) 
Bilingual phrases 
3M 
5 + Moses phrase extraction (Koehn et al., 2007) 
Monolingual phrases 
</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_284" validated="false"><head></head><label></label><figDesc>).</figDesc><table>Monolingual Phrases Bilingual Phrases Bilingual Sentences 
Reference Results 
J bi 
Jpa 
J bi 
Jpa 
J bi 
Jpa 
Paragram GloVe 

MSRpar 
0.28 
0.42 
0.54 
0.38 
0.54 
0.36 
0.44 
0.47 
MSRvid 
0.33 
0.55 
0.71 
0.38 
0.71 
0.19 
0.77 
0.64 
SMT-eur 
0.39 
0.41 
0.49 
0.46 
0.47 
0.47 
0.48 
0.46 
SMT-news 0.40 
0.50 
0.59 
0.40 
0.58 
0.38 
0.63 
0.50 
OnWN 
0.52 
0.57 
0.64 
0.62 
0.46 
0.62 
0.71 
0.55 
2012 Avg 
0.39 
0.49 
0.59 
0.45 
0.54 
0.41 
0.61 
0.53 
headline 
0.56 
0.66 
0.70 
0.58 
0.66 
0.61 
0.74 
0.64 
OnWN 
0.55 
0.53 
0.75 
0.34 
0.48 
0.25 
0.72 
0.63 
FNWN 
0.35 
0.29 
0.41 
0.32 
0.25 
0.16 
0.47 
0.34 
2013 Avg 
0.49 
0.49 
0.62 
0.41 
0.46 
0.34 
0.58 
0.42 
deft forum 
0.35 
0.47 
0.51 
0.36 
0.36 
0.33 
0.53 
0.27 
deft news 
0.59 
0.68 
0.77 
0.59 
0.76 
0.58 
0.75 
0.68 
headline 
0.56 
0.63 
0.73 
0.58 
0.67 
0.58 
0.72 
0.60 
images 
0.58 
0.73 
0.73 
0.59 
0.66 
0.49 
0.80 
0.61 
OnWN 
0.65 
0.62 
0.80 
0.55 
0.55 
0.47 
0.81 
0.58 
tweet news 0.59 
0.66 
0.73 
0.64 
0.56 
0.69 
0.77 
0.51 
2014 Avg 
0.55 
0.63 
0.71 
0.55 
0.59 
0.52 
0.73 
0.54 
forums 
0.35 
0.42 
0.55 
0.48 
0.50 
0.45 
0.66 
0.31 
students 
0.66 
0.66 
0.73 
0.73 
0.65 
0.69 
0.77 
0.63 
headline 
0.64 
0.60 
0.79 
0.64 
0.73 
0.66 
0.76 
0.62 
belief 
0.46 
0.71 
0.68 
0.67 
0.48 
0.61 
0.77 
0.41 
images 
0.52 
0.71 
0.75 
0.62 
0.67 
0.56 
0.82 
0.68 
2015 Avg 
0.53 
0.63 
0.70 
0.63 
0.59 
0.60 
0.76 
0.53 
SICK 
0.53 
0.62 
0.66 
0.57 
0.63 
0.54 
0.72 
0.66 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_285" validated="false"><head>Table 4 :</head><label>4</label><figDesc></figDesc><table>Undertrained word ratios (tokens seen 
fewer than 100 times during training) are uncor-
related with performance in Table 3. 

Dataset 
Monolingual 
Phrases 

Bilingual 
Phrases 

Bilingual 
Sentences 

2012 Avg 
0.15 
0.17 
0.09 
2013 Avg 
0.16 
0.17 
0.11 
2014 Avg 
0.19 
0.22 
0.11 
2015 Avg 
0.15 
0.19 
0.11 
SICK 
0.2 
0.25 
0.15 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_286" validated="false"><head>Table 5 :</head><label>5</label><figDesc>Impact of memorization: Pearson corre- lation scores on SICK with training sets with and without filtering out training pairs that contain any bigrams that appear in SICK. Number of training pairs (# Pairs) is shown in millions.</figDesc><table>Not Filtered 
Filtered 
# Pairs Score # Pairs Score 

Monoling. Phrases 
3M 
0.52 
2.3M 
0.54 
Bilingual Phrases 
3M 
0.67 
2.1M 
0.65 
Bilingual Sentences 
1.9M 
0.66 
0.47M 
0.58 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_287" validated="true"><head>Table 6 :</head><label>6</label><figDesc>Impact of training set size: Average Pear- son correlation per test set with different numbers (in millions) of bilingual phrase pairs, compared to the full set of bilingual sentences and monolin- gually pretrained GloVe.</figDesc><table>Bilingual Phrases 
Sent. 
0.5M 
1M 
1.9M 
3M 
1.9M GloVe 

2012 
0.55 
0.58 
0.59 
0.59 
0.54 
0.53 
2013 
0.59 
0.61 
0.61 
0.62 
0.46 
0.42 
2014 
0.69 
0.71 
0.71 
0.71 
0.59 
0.54 
2016 
0.68 
0.69 
0.70 
0.70 
0.61 
0.53 
SICK 
0.62 
0.64 
0.65 
0.66 
0.63 
0.66 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_291" validated="false"><head>Table 3 :</head><label>3</label><figDesc>Performance of FBRNN compared with reported top results in TAC competition (Mita- mura et al., 2015) on Rich ERE 2015.</figDesc><table></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_292" validated="false"><head></head><label></label><figDesc>IBC-C: A Dataset for Armed Conflict Event Analysis AndrejŽukov-Gregorič and Bartal Veyhe and Zhiyuan Luo</figDesc><table>Yubo Chen, Liheng Xu, Kang Liu, Daojian Zeng, and 
Jun Zhao. 2015. Event Extraction via Dynamic 
Multi-Pooling Convolutional Neural Networks. As-
sociation for Computational Linguistics, 1:167-176. 

Kyunghyun Cho, Bart van Merrienboer, Ç aglar 
Gülçehre, Dzmitry Bahdanau, Fethi Bougares, Hol-
ger Schwenk, and Yoshua Bengio. 2014. Learn-
ing Phrase Representations using RNN Encoder-
Decoder for Statistical Machine Translation. Em-
pirical Methods in Natural Language Processing, 
pages 1724-1734. 

Ronan Collobert and Jason Weston. 2008. A unified 
architecture for natural language processing: deep 
neural networks with multitask learning. ICML, 
pages 160-167. 

James Cross and Liang Huang. 2016. Incremental 
Parsing with Minimal Features Using Bi-Directional 
LSTM. Association for Computational Linguistics. 

John Duchi, Elad Hazan, and Yoram Singer. 2011. 
Adaptive subgradient methods for online learning 
and stochastic optimization. The Journal of Ma-
chine Learning Research, 12:2121-2159. 

Geoffrey E. Hinton, Nitish Srivastava, Alex 
Krizhevsky, Ilya Sutskever, and Ruslan Salakhut-
dinov. 2012. Improving neural networks by 
preventing co-adaptation of feature detectors. 
CoRR, abs/1207.0580. 

Sepp Hochreiter and Jürgen Schmidhuber. 1997. 
Long Short-Term Memory. Neural Computation, 
9(8):1735-1780. 

Ruihong Huang and Ellen Riloff. 2012. Modeling 
Textual Cohesion for Event Extraction. AAAI. 

Heng Ji and Ralph Grishman. 2008. Refining Event 
Extraction through Cross-Document Inference. As-
sociation for Computational Linguistics, pages 254-
262. 

Diederik Kingma and Jimmy Ba. 
2015. 
Adam: A method for stochastic optimization. 
arXiv:1412.6980. 

Peifeng Li, Qiaoming Zhu, and Guodong Zhou. 2013a. 
Argument Inference from Relevant Event Mentions 
in Chinese Argument Extraction. Association for 
Computational Linguistics, 1:1477-1487. 

Qi Li, Heng Ji, and Liang Huang. 2013b. Joint Event 
Extraction via Structured Prediction with Global 
Features. Association for Computational Linguis-
tics, 1:73-82. 

Qi Li, Heng Ji, Yu Hong, and Sujian Li. 2014. Con-
structing Information Networks Using One Single 
Model. Empirical Methods in Natural Language 
Processing, pages 1846-1851. 

Shasha Liao and Ralph Grishman. 2010. Using Docu-
ment Level Cross-Event Inference to Improve Event 
Extraction. Association for Computational Linguis-
tics, pages 789-797. 

David McClosky, Mihai Surdeanu, and Christopher D. 
Manning. 2011. Event Extraction as Dependency 
Parsing. Association for Computational Linguistics, 
pages 1626-1635. 

Tomas Mikolov, Ilya Sutskever, Kai Chen, Gregory S. 
Corrado, and Jeffrey Dean. 2013. Distributed Rep-
resentations of Words and Phrases and their Compo-
sitionality. Neural Information Processing Systems, 
pages 3111-3119. 

Teruko Mitamura, Zhengzhong Liu, and Eduard Hovy. 
2015. Overview of TAC KBP 2015 Event Nugget 
Track. Text Analysis Conference. 

Thien Huu Nguyen and Ralph Grishman. 2015. Event 
Detection and Domain Adaptation with Convolu-
tional Neural Networks. Association for Computa-
tional Linguistics, 2:365-371. 

Siddharth Patwardhan and Ellen Riloff. 2009. A Uni-
fied Model of Phrasal and Sentential Evidence for 
Information Extraction. Empirical Methods in Nat-
ural Language Processing, pages 151-160. 

Romain Paulus, Richard Socher, and Christopher D. 
Manning. 2014. Global Belief Recursive Neural 
Networks. Neural Information Processing Systems, 
pages 2888-2896. 

Richard Socher, Andrej Karpathy, Quoc V. Le, Christo-
pher D. Manning, and Andrew Y. Ng. 2014. 
Grounded Compositional Semantics for Finding and 
Describing Images with Sentences. Transactions 
of the Association for Computational Linguistics, 
2:207-218. 

Nitish Srivastava, Geoffrey E. Hinton, Alex 
Krizhevsky, Ilya Sutskever, and Ruslan Salakhutdi-
nov. 2014. Dropout: a simple way to prevent neural 
networks from overfitting. Journal of Machine 
Learning Research, 15(1):1929-1958. 

Kai Sheng Tai, Richard Socher, and Christopher D. 
Manning. 2015. Improved Semantic Representa-
tions From Tree-Structured Long Short-Term Mem-
ory Networks. Association for Computational Lin-
guistics, 1:1556-1566. 

Matthew D Zeiler. 
2012. 
ADADELTA: an 
adaptive learning rate method. 
arXiv preprint 
arXiv:1212.5701. Department of Computer Science 
Royal Holloway, University of London 
Egham TW20 0EX 
{andrej.zukovgregoric.2010, bartal.veyhe.2014}@live.rhul.ac.uk 
zhiyuan@cs.rhul.ac.uk 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_294" validated="false"><head>Table 1 :</head><label>1</label><figDesc></figDesc><table>Dataset statistics. Fully capitalised words 
indicate named entity tags. 

datasets created by hand. These include IBC (IBC, 
2016), ACLED (Raleigh et al., 2010), EDACS 
</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_296" validated="false"><head>Table 2 :</head><label>2</label><figDesc></figDesc><table>An example of an incident hand coded 
by IBC staff. Min and max values represent the 
minimum and maximum figures quoted in report 
sections linked to the incident. 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_299" validated="false"><head>Table 4 :</head><label>4</label><figDesc>Results for various models</figDesc><table></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_301" validated="true"><head>Table 2</head><label>2</label><figDesc>shows the propor- tion of OOV words and classification accuracy 2 See http://scikit-learn.org/stable/.</figDesc><table>Training Set 
400short 800short 1561short 
OOV prop 
0.348 
0.253 
0.181 
Method 
Classification Accuracy 
LCTM 
0.302 
0.367 
0.416 
LCTM-UNK 0.262 
0.340 
0.406 
LFLDA 
0.253 
0.333 
0.410 
nI-cLDA 
0.261 
0.333 
0.412 
LDA 
0.215 
0.293 
0.382 
GLDA 
0.0527 
0.0529 
0.0529 
Chance Rate 0.0539 
0.0539 
0.0539 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_303" validated="true"><head>Table 1 :</head><label>1</label><figDesc>The detailed average results for word similarity and paraphrases of Fig. 1.</figDesc><table>Average 
CBOW 
Skipgram 
Original Binary 
4-bits 
6-bits 
8-bits 
Original Binary 
4-bits 
6-bits 
8-bits 
wordsim (25) 
0.5331 
0.4534 0.5223 0.5235 0.5242 
0.4894 
0.4128 0.4333 0.4877 0.4906 
wordsim (200) 
0.5818 
0.5598 0.4542 0.5805 0.5825 
0.5642 
0.5588 0.4681 0.5621 0.5637 
bigram (25) 
0.3023 
0.2553 0.3164 0.3160 0.3153 
0.3110 
0.2146 0.2498 0.3050 0.3082 
bigram (200) 
0.3864 
0.3614 0.2954 0.3802 0.3858 
0.3565 
0.3562 0.2868 0.3529 0.3548 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_304" validated="false"><head>Table</head><label></label><figDesc></figDesc><table></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_305" validated="true"><head>Table 3 :</head><label>3</label><figDesc>Evaluation results for dependency parsing (in LAS).</figDesc><table>Bits 
CBOW Skipgram 
Original 88.58% 88.15% 
Binary 89.25% 88.41% 
4-bits 
87.56% 86.46% 
6-bits 
88.62% 87.98% 
8-bits 
88.63% 88.16% 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_308" validated="false"><head>Table 2 :</head><label>2</label><figDesc>Accuracy and F 1 scores for different methods across datasets. HP Approx. is the best method according to accuracy, whereas Language model and GP are both strong methods according to F 1 .</figDesc><table></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_311" validated="false"><head>Table 2 :</head><label>2</label><figDesc>Comments selected for experiments.</figDesc><table></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_314" validated="false"><head>Table 6 :</head><label>6</label><figDesc>Paid troll vs. non-troll comments. Re- sults for individual feature groups.</figDesc><table>5 
10 
15 
20 
Acc 80.70 81.08 
83.41 
85.59 
Diff +8.46 +18.51 +30.81 +32.26 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_318" validated="false"><head>Table 2 :</head><label>2</label><figDesc></figDesc><table>Tagging accuracies on UD 1.2 test sets. w: words, c: characters, b: bytes. Bold/ †: best 
accuracy/representation; +POLYGLOT: using pre-trained embeddings. FREQBIN: our multi-task model. 
OOV ACC: accuracies on OOVs. BTS: best results in Gillick et al. (2016) (not strictly comparable). 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_319" validated="false"><head>Table 3 :</head><label>3</label><figDesc></figDesc><table>Comparison POS accuracy on WSJ; bi-
LSTM: 30 epochs, σ=0.3, no POLYGLOT. 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_322" validated="false"><head></head><label></label><figDesc>).</figDesc><table>Method 

WSim WRel MEN MTurk RW SimLex-999 MC 
RG 
SCWS 
PPMI-SVD 
.731 
.617 
.731 
.627 
.427 
.303 
.770 .756 
.615 
GloVe 
.719 
.607 
.736 
.643 
.400 
.338 
.725 .774 
.573 
SGNS 
.770 
.670 
.763 
.675 
.465 
.339 
.823 .793 
.643 
LexVec + MB + W SP P M I + (W +W ) 
.770 
.671 
.755 
.650 
.455 
.322 
.824 .830 
.623 
LexVec + St. + W SP P M I + (W +W ) 
.763 
.671 
.760 
.655 
.458 
.336 
.816 .827 
.630 
LexVec + MB + W SP P M I + W 
.748 
.635 
.741 
.636 
.456 
.320 
.827 .820 
.632 
LexVec + St. + W SP P M I + W 
.741 
.622 
.733 
.628 
.457 
.338 
.820 .808 
.638 
LexVec + MB + W SSGNS + (W +W ) 
.768 
.675 
.755 
.654 
.448 
.312 
.824 .827 
.626 
LexVec + St. + W SSGNS + (W +W ) 
.775 
.673 
.762 
.654 
.468 
.339 
.838 .848 
.628 
LexVec + MB + W SSGNS + W 
.745 
.640 
.734 
.645 
.447 
.311 
.814 .802 
.624 
LexVec + St. + W SSGNS + W 
.740 
.628 
.728 
.640 
.459 
.339 
.821 .818 
.638 

Table 1: Spearman rank correlation on word similarity tasks. 

Method 
GSem 
3CosAdd / 3CosMul 

GSyn 
3CosAdd / 3CosMul 

MSR 
3CosAdd / 3CosMul 
PPMI-SVD 
.460 / .498 
.445 / .455 
.303 / .313 
GloVe 
.818 / .813 
.630 / .626 
.539 / .547 
SGNS 
.773 / .777 
.642 / .644 
.481 / .505 
LexVec + MB + W SP P M I + (W +W ) 
.775 / .792 
.520 / .539 
.371 / .413 
LexVec + St + W SP P M I + (W +W ) 
.794 / .807 
.543 / .555 
.378 / .408 
LexVec + MB + W SP P M I + W 
.800 / .805 
.584 / .597 
.421 / .457 
LexVec + St. + W SP P M I + W 
.787 / .782 
.597 / .613 
.445 / .475 
LexVec + MB + W SSGNS + (W +W ) 
.762 / .785 
.520 / .534 
.349 / .386 
LexVec + St. + W SSGNS + (W +W ) 
.792 / .809 
.536 / .553 
.362 / .396 
LexVec + MB + W SSGNS + W 
.798 / .807 
.573 / .580 
.399 / .435 
LexVec + St. + W SSGNS + W 
.779 / .778 
.600 / .614 
.434 / .463 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_325" validated="false"><head>Table 2 :</head><label>2</label><figDesc>Performance on the Universal Dependency Treebanks test sets using the gold CPOSTAG information. The table is laid out like Table 1.</figDesc><table></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_327" validated="false"><head>Table 4 :</head><label>4</label><figDesc></figDesc><table>Performance on a code-switching treebank com-

posed of 10 sentences. 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_328" validated="false"><head></head><label></label><figDesc>Thierry Declerck, Mehmet Uǧur Doǧan, Bente Maegaard, Joseph Mariani, Asuncion Moreno, Jan Odijk, and Stelios Piperidis, editors, Proceedings of the Eight International Conference on Language Resources and Evaluation (LREC'12), Istanbul, Turkey, May. European Language Resources Asso- ciation (ELRA).</figDesc><table></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_330" validated="false"><head>Table 1 :</head><label>1</label><figDesc></figDesc><table>Accessibility rank values used in our ex-
periments, with their base distribution over ex-
tracted NPs. 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_331" validated="false"><head>Table 2 :</head><label>2</label><figDesc>Accessibility transitions (&gt;0.05) CoNLL-2012 DEV.</figDesc><table></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_332" validated="false"><head></head><label></label><figDesc>).</figDesc><table>Gold 

Auto 

MUC 

B 

3 

CEAFE 

CoNLL 

MUC 

B 

3 

CEAFE 

CoNLL 
Fernandes et al. (2012) 
72.18 59.17 
55.72 
62.36 
70.51 57.58 
53.86 
60.65 
Björkelund and Kuhn (2014) 
73.80 62.00 
59.06 
64.95 
70.72 58.58 
55.61 
61.63 
LIMERIC Baseline 
74.07 60.91 
58.57 
64.52 
70.36 56.60 
54.42 
60.46 
+ Fine-Grained Specialisation 74.73 61.72 
59.43 
65.29 
70.72 57.40 
55.26 
61.13 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_333" validated="false"><head>Table 4 :</head><label>4</label><figDesc>Performance on CoNLL-2012 TEST evaluated with gold and automatic annotations and system extracted mentions.</figDesc><table></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_337" validated="true"><head>Table 1 :</head><label>1</label><figDesc>β coefficients of the fixed effect (within-topic position) of the linear mixed models.</figDesc><table>group 
SL 
TD 
BF 

Switchboard leader 
0.363*** 
-0.129*** 
−1.82 × 10 −3 *** 
Switchboard follower 0.188*** 
0.104*** 
2.141 × 10 −3 *** 
BNC leader 
-0.166*** 
-0.030*** 
−1.88 × 10 −3 *** 
BNC follower 
0.012 
9.45 × 10 −3 *** 5.51 × 10 −4 *** 

*** p &lt; 0.001 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_340" validated="false"><head>Table 1 .</head><label>1</label><figDesc>Overview of results.</figDesc><table></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_342" validated="false"><head></head><label></label><figDesc>SA + SVD 0.36 * * * 0.76 * * * 0.40 * 0.66 * 0.38 * * * 0.70 * * * Table 1: AP evaluation on DSMs.</figDesc><table>2 χ 
2 , 
 *  *  *  p &lt; .001, 
 *  *  p &lt; .005, 
 *  p &lt; .05 Adjectives 

Nouns 
Verbs 
ANT 
SYN 
ANT SYN ANT 
SYN 
LMI 
0.46 
0.56 
0.42 
0.60 
0.42 
0.62 
weight SA 
0.36  *  *  
0.75  *  *  
0.40 
0.66 
0.38  *  
0.71  *  
LMI + SVD 
0.46 
0.55 
0.46 
0.55 
0.44 
0.58 
weight </table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_343" validated="true"><head>Table 2 :</head><label>2</label><figDesc>Spearman's ρ on SimLex-999.</figDesc><table>Adjectives Nouns Verbs 
SGNS 
0.64 
0.66 
0.65 
mLCM 
0.85 
0.69 
0.71 
dLCE 
0.90 
0.72 
0.81 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_344" validated="false"><head>Table 3 :</head><label>3</label><figDesc>AUC scores for identifying antonyms.</figDesc><table></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_349" validated="false"><head>Table 3 :</head><label>3</label><figDesc></figDesc><table>Comparative results with the best 
SemEval-2016 Task 3, subtask A systems. 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_350" validated="false"><head></head><label></label><figDesc>When athletes begin to exercise, their heart rates and res- piration rates increase. At what level of organization does the human body coordinate these functions?</figDesc><table>Question Category 
Example 

Questions without 
context: 
Which example describes a learned behavior in a dog? 

Questions 
with 
context: 

Negation 
Ques-
tions: 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_351" validated="false"><head>Table 1 :</head><label>1</label><figDesc>Example questions for Qtype classification</figDesc><table></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_352" validated="false"><head></head><label></label><figDesc>for linguistic preprocessing 6 We found that the accuracy over test questions tagged by our heuristic as negation questions went up from 33.64 percent to 42.52 percent and the accuracy over test questions not tagged as negation did not decrease significantly</figDesc><table>40.04 

31.6 
32.56 

37.84 

32.42 
31.86 

27.74 
29.32 
31.26 

41.38 
43.18 
44.82 
45.44 
46.09 
46.66 
46.86 
47.68 
47.84 

25 

30 

35 

40 

45 

50 

Accuracy 

Lucene 
PMI 
SW 
SW+D 
RTE 
Jacana 
RNNLM 
LSTM 
QANTA 
Lucene+LSSVM Alignment 
LSSVM 
LSSVM(NegaJon) 
LSSVM(JT) 
LSSVM(JT, NegaJon) 
MTLSSVM(Qword) 
MTLSSVM(Qtype) 
MTLSSVM(Qword, JT) 
MTLSSVM(Qtype, JT) 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_355" validated="false"><head></head><label></label><figDesc>1 Following Silber and McCoy (2002), we create an addi- tional chain for each named entity, in addition to those chains defined by WordNet synsets.</figDesc><table>Distance 
Noun 
Verb 
Derivation 
0 
synonymy 
1 
hypernymy 
synonymy 
noun-to-verb 
2 
sibling 
hypernymy 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_356" validated="false"><head>Table 1 :</head><label>1</label><figDesc>Distance of lexical relations. tained in a global network representing all connec- tions between all propositions in the text? In such a network without forgetting or discourse struc- ture, standard graph algorithms could be used to determine central propositions. This hypothesis is tested in §6.</figDesc><table></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_357" validated="false"><head></head><label></label><figDesc>.122 .094 .088 .092 .100 .094 .100 L .345 .320 .318 .308 .314 .309 .314 SU4 .154 .131 .129 .128 .132 .130 .132</figDesc><table>O 

D 
C 
M 
LR 
TR 
L 
1 
.376 .349 .351 .343 .341 .343 .341 
2 
</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_358" validated="false"><head>Table 2 :</head><label>2</label><figDesc>ROUGE F-scores by four metrics.</figDesc><table></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_359" validated="false"><head></head><label></label><figDesc>), we en- force that v 1 e align with v 1 e and v 2 e align with v 2 e . If exactly one of the relations is an in- verse relation (case 2), we enforce that v 1align with v 2 e and v 2 e align with v 1 e . Hence, we introduce the following constraints: z e e ≤ z v 1and z e e ≤ z v 2∀e .e in case 1 z e e ≤ z v 1and z e e ≤ z v 2 e v 1 e ∀e .e in case 2</figDesc><table>e 

e 

v 1 

e 

e 

v 2 

e 

e 

v 2 

e 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_360" validated="false"><head></head><label></label><figDesc>Table 1: Comparison of variations of our method against several baselines on</figDesc><table>Single Multiple 
All 

AMR 

Subgraph 
67.28 
65.24 
66.16 
Subgraph+Negation 
69.48 
66.46 
67.83 
+MTL 
QClassification 
70.59 
67.99 
69.17 
QAClassification 
71.32 
68.29 
69.67 
TaskClassification 
72.05 
68.90 
70.33 

Baselines 

SW 
54.56 
54.04 
54.28 
SW+D 
62.99 
58.00 
60.26 
RTE 
69.85 
42.71 
55.01 
LEX++ 
69.12 
63.34 
65.96 
JACANA Aligner 
58.82 
54.88 
56.67 
LSTM 
62.13 
58.84 
60.33 
QANTA 
63.23 
59.45 
61.00 
ATTENTION 
54.20 
51.70 
52.90 
DISCOURSE 
68.38 
59.90 
63.75 
LSSVM 
61.12 
66.67 
64.15 
LSSVM+Negation 
63.24 
66.15 
64.83 
+MTL 
QClassification 
64.34 
66.46 
65.50 
QAClassification 
66.18 
67.37 
66.83 
TaskClassification 
67.65 
67.99 
67.83 
SYN+FRM+SEM 
72.05 
67.94 
69.94 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_362" validated="false"><head></head><label></label><figDesc>The base matrix B τ = [b t 1 , b t 2 . . . b tn ] and the collocate matrix C τ = [c t 1 , c t 2 . . . c tn ] are given by their corresponding vector representations. Together, they constitute a set of training examples Φ τ , composed by vector pairs {b</figDesc><table></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_364" validated="true"><head>Table 2 :</head><label>2</label><figDesc>Precision and MRR</figDesc><table>Semantic gloss 
Base 
Retrieved candidates 
'intense' 
caution 
extreme 
'weak' 
change 
slight, little, modest, minor, noticeable, minimal, sharp, definite, small, big 
'perform' 
calculation produce, carry 
'begin to perform' cold 
catch, get, run, keep 
'stop performing' 
career 
abandon, destroy, ruin, terminate, threaten, interrupt 
'increase' 
capability 
enhance, increase, strengthen, maintain, extend, develop, upgrade, build, provide 
'decrease' 
congestion 
reduce, relieve, cut, ease, combat 
'create', 'cause' 
challenge 
pose 
'put an end' 
ceasefire 
break 
'show' 
complexity 
demonstrate, reveal, illustrate, indicate, reflect, highlight, recognize, explain 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_365" validated="false"><head>Table 3 :</head><label>3</label><figDesc>Examples of retrieved collocations is filtered with respect to the valid POS-patterns of targeted collocations and N P M I. 5</figDesc><table></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_368" validated="false"><head>Table 1 :</head><label>1</label><figDesc>WordRep data: Accuracy on knowledge- base completion</figDesc><table></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_370" validated="false"><head></head><label></label><figDesc>1 See discussion/experiments below for exceptions Corpus, Type Spectrum News, Polarity hypocrite, politician, legislator, busi- nessman, reformer, statesman, thinker fall, winter, summer, spring, autumn drunks, booze, liquor, lager, beer, beers, wine, beverages, wines, tastings Twitter, Polarity corrupt, coward, politician, journalist, citizen, musician, representative stalker, neighbour, gf, bf, cousin, frnd,imperialist, conflict, war, Iraq, Vietnam War, battlefields, soldiers love, friendship, dear friend, friends, friend, girlfriend News, Frequency redesigned, newer, revamped, new intellect, insights, familiarity, skills, knowledge, experience Table 1: Example word spectra for polarity, con- creteness and frequency on two different corpora. Queries are bold.Adel, 2014 .79 .65 .72 .75 .58 .66 our work .81 .90 .85 .76 .88 .82</figDesc><table>friend, mentor 
#stupid, 
#problems, 
#homework, 
#mylife, #reality, #life, #happiness 
News, 
Concreteness 

dev set 
test set 
P 
R F 1 
P 
R F 1 
</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_371" validated="false"><head>Table 2 :</head><label>2</label><figDesc>Results for Antonym Classification</figDesc><table>4 Evaluation 

4.1 Antonym Classification. 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_372" validated="false"><head>Table 2</head><label>2</label><figDesc>shows that improve- ment of precision is minor (.76 vs. .75), but recall and F 1 improve by a lot (+.30 and +.16). 4.2 Polarity Spectrum Creation consists of two subtasks. PSC-SET: Given a query word how well can we predict a spectrum? PSC- ORD: How good is the order in the spectrum? Our gold standard is Word Spectrum, included in the Oxford American Writer's Thesaurus (OAWT) and therefore also in MacOS. For each query wordOOV ALL OOV ALL OOV ALL OOV ALL OOV ALL OOV 1 LSJU 89.11 † 56.02 † 91.43 † 58.66 † 94.15 † 77.13 † 88.92 † 49.30 † 88.68 † 58.42 † 96.83 90.25 2 SVM 89.14 † 53.82 † 91.30 † 54.20 † 94.21 † 76.44 † 88.96 † 47.25 † 88.64 † 56.37 † 96.63 87.96 † 3 F 90.86 66.42 † 92.95 75.29 † 94.71 83.64 † 90.30 62.15 † 89.44 62.61 † 96.59 90.37 4 F+W2V 90.51 72.26 92.46 † 78.03 94.70 86.05 90.34 65.16 89.26 63.70 † 96.44 91.36 5 F+UD 90.79 72.20 92.84 78.80 94.84 86.47 90.60 65.48 89.68 66.24 96.61 92.36</figDesc><table>newsgroups 

reviews 
weblogs 
answers 
emails 
wsj 
ALL </table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_373" validated="false"><head></head><label></label><figDesc>PSC-SET: MAP PSC-ORD: ρ avg(ρ1, ρ2)</figDesc><table>average .48 
.59 
.70 
weighted avg. .47 
.59 
.70 
variance .004 
.048 
.014 
beautiful/ugly .48 
.84 
.84 
fat/skinny .56 
.13 
.67 
absent/present .43 
.72 
.76 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_374" validated="false"><head>Table 4 :</head><label>4</label><figDesc>Results for Polarity Spectrum Creation: MAP, Spearman's ρ (one spectrum) and average ρ (two subspectra) 4.3 Morphological Analogy.</figDesc><table></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_375" validated="false"><head>Table 5</head><label>5</label><figDesc>shows that this method out-W2V UD A→B B→A A→B B→A noun-verb 35.69 6.62 59.69 † 50.46 † adj-noun 30.77 27.38 53.85 † 43.85 † adj-verb 20.62 3.08 32.15 † 24.77 † adj-adverb 45.38 35.54 46.46 † 43.08 †</figDesc><table>all 
25.63 
44.29  † 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_376" validated="false"><head>Table 5 :</head><label>5</label><figDesc>Accuracy @1 on test for Morphological Analogy. †: significantly better than the corre- sponding result in the same row (α = .05, one- tailed Z-test).</figDesc><table></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_377" validated="false"><head></head><label></label><figDesc>Australian scientist discovers stars with telescopeFigure 1: An example of extracting dependency- based contexts from UD parses (UDEPS) in En- glish and Italian. Top: the example sentence in English taken from (Levy and Goldberg, 2014a), now UD-parsed. Middle: the same sentence in Italian, UD-parsed. Note the very similar struc- ture of the two parses. Bottom: the intuition behind UDEPS-ARC. The uninformative short- range case arc between with and telescope is re- moved, and another "pseudo-arc" now specifying the exact link type (i.e., case_with) between dis- covers and telescope is added. tion of word2vec which is capable of learning from arbitrary (word, context) pairs. 2 Keeping the representation model fixed across experiments and varying only the context type allows us to at- tribute any differences in results to a sole factor: the context type.</figDesc><table>amod 
nsubj 
dobj 
case 

nmod 

Scienziato australiano scopre stelle con telescopio 

amod 

nsubj 

dobj 
case 

nmod 

Australian scientist discovers stars with telescope 

amod 
nsubj 
dobj 
case 

nmod 

case with 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_379" validated="false"><head>Table 1 :</head><label>1</label><figDesc>Universal POS tagging accuracy scores and labeled (LAS) vs unlabeled (UAS) attachment scores of universal dependency parsing.</figDesc><table></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_381" validated="false"><head>Table 2 :</head><label>2</label><figDesc>Acc@1 scores in the analogy solving task over semantic (SEM), syntactic (SYN) and all analo- gies (TOT). SGNS with d = 300 for all context types. Similar trends are observed with other d-s. DEPS-LEVY refers to pre-trained 300-dimensional EN WEs from</figDesc><table></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_382" validated="false"><head></head><label></label><figDesc>), and a real challenge in German,</figDesc><table>Syntactic Relation 

English 
German 
Italian 

gram1-adjective-to-adverb 
P&gt;B&gt;A&gt;N 
-
P&gt;B&gt;A&gt;N 
gram2-opposite 
A&gt;N&gt;P&gt;B 
A&gt;B&gt;P&gt;N 
A&gt;B&gt;P&gt;N 
gram3-comparative 
P&gt;B&gt;A&gt;N 
A&gt;B&gt;P&gt;N 
P&gt;A&gt;N&gt;B 
gram4-superlative 
P&gt;B&gt;A&gt;N 
A&gt;N&gt;B&gt;P 
P&gt;B&gt;A&gt;N 
gram5-present-participle 
P&gt;A&gt;B&gt;N 
A&gt;N&gt;P&gt;B 
P&gt;B&gt;A&gt;N 
gram6-nationality-adjective 
B&gt;P&gt;A&gt;N 
B&gt;P&gt;A&gt;N 
B&gt;P&gt;A&gt;N 
gram7-past-tense 
A&gt;P&gt;N&gt;B 
A&gt;B&gt;N&gt;P 
A&gt;B&gt;P&gt;N 
gram8-plural 
B&gt;P&gt;A&gt;N 
A&gt;B&gt;P&gt;N 
A&gt;P&gt;N&gt;B 
gram9-plural-verbs 
P&gt;A&gt;B&gt;N 
A&gt;N&gt;B&gt;P 
A&gt;N&gt;P&gt;B 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_384" validated="false"><head>Table 4 :</head><label>4</label><figDesc>Results on SimLex in English with SGNS trained on a reduced EN training set containing the same number of sentences as the entire IT training set (≈ 13M sentences). d = 300.</figDesc><table></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_385" validated="false"><head>Table 1 :</head><label>1</label><figDesc>Examples of candidate claims (top- ics in italics, predicates in bold), the subject of the claim sentence which originated their predicate, and their label.</figDesc><table></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_387" validated="false"><head>Table 2 :</head><label>2</label><figDesc>Confusion Matrix: Number of claim candidates according to AMT annota- tion (x-axis) and predicted label (y-axis)</figDesc><table></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_388" validated="false"><head></head><label></label><figDesc>.</figDesc><table>Train 
Test 
Total 
Explicit 
15,402 3,057 18,459 
Non-Exp 18,569 3,318 21,887 
Total 
33,971 6,375 40,346 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_389" validated="false"><head>Table 1 :</head><label>1</label><figDesc>Sample count per data set 4.2 Does RSA explain DC interpretation?</figDesc><table></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_390" validated="true"><head>Table 2 :</head><label>2</label><figDesc>Accuracy of prediction by L 0 , L 1 and L 2 . Improvements above the baseline are bolded. * means significant at p &lt; 0.02 by McNemar Test.</figDesc><table>context C 
Explicit Non-Explicit 
L 0 constant (BL) .8767 
.2616 
prev. form 
.8754 
.2616 
prev. sense 
.8727 
.2507 
form-sense 
.8684 
.2692 
L 1 constant 
.8853* 
.2616 
prev. form 
.8830 
.2616 
prev. sense 
.8671 
.2698* 
form-sense 
.8621 
.2671 
L 2 constant 
.8853* 
.2616 
prev. form 
.8830 
.2616 
prev. sense 
.8671 
.2616 
form-sense 
.8621 
.2616 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_391" validated="false"><head>Table 3</head><label>3</label><figDesc>compares the performance of the origi- nal parser output and the prediction based on P L 1 .</figDesc><table>discourse 

parser P L 1 
test 
relation sense tags output output counts 
Conjunction 
.7022 .7079 1479 
Contrast 
.7382 .7152 1152 
Entity 
.5174 .5249 862 
Reason 
.4844 .5105 661 
Restatement 
.2773 .2871 567 
Result 
.4019 .4150 405 
Instantiation 
.4346 .4357 282 
Synchrony 
.6553 .7007 264 
Condition 
.9087 .9302 238 
Succession 
.7022 .7210 204 
Precedence 
.7523 .7762 200 
Concession 
.3048 .4382 146 
Chosen alternative .5000 .5200 36 
Alternative 
.8421 .8929 28 
Exception 
1.00 
1.00 
1 
Accuracy / Total 
.5833 .5916 6525 1 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_392" validated="false"><head>Table 3 :</head><label>3</label><figDesc>F1 scores of original parser output vs parser output modified with P L 1 . Higher scores are bolded. The improvement in accuracy is sig- nificant at p &lt; 0.05 by McNemar Test.</figDesc><table></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_393" validated="false"><head></head><label></label><figDesc>Table 1: Examples of top words for the most coherent topics (column-wise) inferred on the NIPS dataset by Gaussian LDA (k=40) and Spherical HDP. The last row for each model is the topic coherence (PMI) computed using Wikipedia documents as reference.</figDesc><table>Gaussian LDA 
vector 
shows 
network 
hidden 
performance 
net 
figure 
size 
image 
feature 
learning 
term 
work 
references 
shown 
average 
gaussian 
show 
model 
rule 
press 
introduction 
neurons 
present 
equation 
motion 
neural 
word 
tion 
statistical 
point 
family 
generalization 
action 
input 
means 
ing 
related 
large 
versus 
images 
spike 
data 
words 
eq 
comparison 
neuron 
spread 
gradient 
series 
function 
approximate 
performed 
source 
small 
median 
theory 
final 
time 
derived 
em 
statistics 
fig 
physiology 
dimensional 
robot 
set 
describe 
vol 
free 
cells 
children 
1.16 
0.4 
0.35 
0.29 
0.25 
0.25 
0.21 
0.2 
Spherical HDP 
neural 
function 
analysis 
press 
pattern 
problem 
noise 
algorithm 
layer 
linear 
theory 
cambridge 
fig 
process 
gradient 
error 
neurons 
functions 
computational 
journal 
temporal 
method 
propagation parameters 
neuron 
vector 
statistical 
vol 
shape 
optimal 
signals 
computation 
activation 
random 
field 
eds 
smooth 
solution 
frequency 
algorithms 
brain 
probability 
simulations 
trans 
surface 
complexity 
feedback 
compute 
cells 
parameter 
simulation 
springer 
horizontal 
estimation 
electrical 
binary 
cell 
dimensional 
nonlinear 
volume 
vertical 
prediction 
filter 
mapping 
synaptic 
equation 
dynamics 
review 
posterior 
solve 
detection 
optimization 
1.87 
1.73 
1.51 
1.44 
1.41 
1.19 
1.12 
1.03 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_394" validated="false"><head>Table 2 :</head><label>2</label><figDesc>Average topic coherence for various base- lines (HDP, Gaussian LDA (G-LDA)) and sHDP. k=number of topics. Best scores are shown in bold.</figDesc><table></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_395" validated="true"><head>Table 1 :</head><label>1</label><figDesc>Example topics showing the variance of M P CT when M P = 1.0.</figDesc><table>MPCT Top Five Words 
Intruded Word 

0.202 
canada, canadian, north, ontario, http 
shipping 
0.373 
language, century, word, english, greek drew 
0.407 
river, highway, road, north, route 
berea 
0.569 
born, children, family, life, father 
boatsman 
0.795 
design, engine, model, power, system 
resynthesized 
0.946 
railway, station, road, line, route 
anagarika 
1.000 
film, series, show, television, films 
bubblegrunge 

196,219 types. 
The topic modeling algorithm used is latent 
Dirichlet allocation (LDA) </table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_396" validated="true"><head>Table 2 :</head><label>2</label><figDesc>Performance of automated measures in approximating the crowdsourced experiments. All values are Spearman's ρ correlation coefficients with the crowdsourced measure.</figDesc><table>Automated Measure MPCT 

1. Topic Size 
-0.572 
2. Topic Entropy 
-0.539 
3. Mimno 
-0.438 
4. No. Word Senses 
-0.456 
5. Avg. Pairwise JCD 
-0.844 
6. Mean-Link JCD 
-0.434 
7. NPMI 
-0.582 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_398" validated="false"><head>Table 1 :</head><label>1</label><figDesc>Argumentation Features</figDesc><table></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_400" validated="false"><head></head><label></label><figDesc>).</figDesc><table>Feature Type 
M C 
C 
P 
N one 
All features 
50.0 44.3 48.6 
97.7 
top100 
60.8 36.2 54.1 
97.7 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_401" validated="false"><head>Table 3 :</head><label>3</label><figDesc>F1 for argument components (out-of- domain setting)</figDesc><table>Feature Type 
M C 
C 
P 
N one 
All features 
78.6 53.2 64.0 
96.1 
top100 
53.8 64.5 69.2 
96.2 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_402" validated="true"><head>Table 5 :</head><label>5</label><figDesc>F1 for argument relations (out-of-domain setting)</figDesc><table>Features 
Correlations 
AC 
0.669 
AR 
0.460 
TS 
0.311 
AC + AR + TS 
0.728 
All features 
0.737 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_403" validated="false"><head></head><label></label><figDesc>Table 1: Exact match accuracy of MRI on CELEX. Re- sults of (Dreyer et al., 2008)'s model are from their pa- per; backoff: ngrams+x model; lat-class: ngrams+x+latent class model; lat-region: ngrams+x+latent class+latent re- gion model; baseline: SIGMORPHON16 baseline.</figDesc><table>model 

13SIA 
2PIE 
2PKE 

rP 

Dreyer 

backoff 
82.8 88.7 74.7 69.9 
lat-class 
84.8 93.6 75.7 81.8 
lat-region 
87.5 93.4 87.4 84.9 
baseline 
77.6 95.1 82.5 69.6 
MODEL*TAG 76.4 92.1 83.4 81.8 
MED 
82.3 94.4 86.8 83.9 
MED+POET 
83.9 95.0 87.6 84.0 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_405" validated="false"><head>Table 2 :</head><label>2</label><figDesc>Exact match accuracy of MRI on SIG- MORPHON16; baseline: SIGMORPHON16 baseline; MED/average: average of five MED models (standard devia- tion in parentheses); MED/ensemble: majority voting of five MED models.</figDesc><table></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_406" validated="false"><head></head><label></label><figDesc>Approach Predicted POS ILP DCA DELEX EBC 51.62 (18) 48.39 (8) 42.44 (1) WTC 53.58 (20) 48.40 (0) 47.35 (3)</figDesc><table>Gold POS 
EBC 65.43 (25) 59.94 (2) 64.13 (-) 
WTC 66.51 (23) 55.73 (0) 66.68 (-) 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_407" validated="false"><head>Table 1 :</head><label>1</label><figDesc>Macro-averaged UAS scores summariz- ing our evaluation. EBC: Edinburgh Bible corpus, WTC: Watchtower corpus. Numbers of languages with top performance per system are reported in brackets. All parsers use their respective EBC or WTC taggers. 8 setting. Relying on predicted POS and WTC data, our ILP approach beats DCA for all the test lan- guages. With EBC, we outperform DCA on 19 out of 27 languages.</figDesc><table></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_408" validated="false"><head></head><label></label><figDesc>Language EBC WTC ILP DCA DELEX ILP DCA DELEX Arabic 39.54 53.91 36.59 37.70 13.17 37.41 32.14 21.15Bulgarian 76.45 68.27 50.6 60.03 57.83 49.68 37.18 48.37 Croatian 72.83 76.18 54.19 45.08 42.34 55.16 50.56 45.49 Czech 70.81 78.49 52.67 41.44 40.99 53.09 44.36 47.99 Danish 76.43 86.36 61.14 53.22 49.65 61.78 58.64 55.96 English 71.90 79.2 55.76 50.64 48.04 58.70 57.12 53.87 * Estonian 75.55 73.98 62.9 56.95 49.32 63.85 58.41 48.48 Farsi 64.94 25.67 23.53 42.37 28.93 20.34 12.26 19.48 Finnish 70.41 67.44 43.66 44.51 41.18 42.59 35.6 41.52 French 74.25 79.23 53.52 53.11 48.97 55.69 51.47 51.53 German 74.36 68.36 45.02 50.21 49.36 43.99 36.7 45.79 * Greek 56.52 75.75 62.59 37.73 37.11 62.43 52.95 54.90Hindi 59.99 48.86 18.26 35.59 21.03 15.95 10.77 21.04 * Hungarian 71.57 71.42 49.74 44.97 43.07 44.17 42.33 46.Portuguese 78.41 83.67 63.75 60.45 52.91 64.62 63.16 56.99 * Romanian 71.56 76.34 57.74 56.73 45.73 58.76 54.78 51.23Swedish 78.26 84.80 65.24 55.21 50.85 66.15 62.45 57.48 Average 69.40 73.05 51.62 48.39 42.44 53.58 48.40 47.35</figDesc><table>Dependency parsing 

POS tagging 
EBC 
WTC 

Basque 43.43 
-
22.77 17.38 27.85 
-
-
-
Hebrew 43.65 
-
30.25 39.76 19.06 
-
-
-
66 
Indonesian 63.30 75.61 51.99 23.53 31.18 58.01 52.29 39.67 
Italian 79.28 83.82 63.13 58.66 53.94 64.88 63.57 58.06 
* Latin 83.41 
-
68.65 68.45 41.42 
-
-
-
Norwegian 77.00 85.31 65.04 58.32 53.46 66.54 64.37 60.11 
Polish 73.36 73.68 62.94 59.27 53.33 63.74 55.4 
54.87 
* Serbian 74.07 
-
49.15 49.38 47.06 
-
-
-
Slovene 75.68 78.11 59.17 53.66 50.55 59.79 54.8 
52.53 
Spanish 76.72 85.69 63.63 52.20 
47.6 
64.93 61.90 55.87 
Best for 
7 
16 
18 
8 
1 
20 
0 
3 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_409" validated="false"><head>Table 2 :</head><label>2</label><figDesc>Tagging and parsing (UAS) accuracy. Scores are macro-averaged, and all parsers use predicted POS from respective EBC or WTC tag- gers. *: True target languages, not used as sources.</figDesc><table></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_410" validated="false"><head></head><label></label><figDesc>1 https://catalog.ldc.upenn.edu/LDC2007T36 2 https://catalog.ldc.upenn.edu/LDC2003T09Table 1: Comparisons for DGRNN and other neu- ral approaches based on traditional unigram em- beddings.</figDesc><table>Model (Unigram) PKU MSRA CTB6 
Bi-LSTM 
95.0 
95.8 
95.2 
GRNN 
95.8 
96.2 
95.5 
Pei et al. (2014) 
94.0 
94.9 
* 
Chen et al. (2015) 96.1 
96.2 
95.6 
DGRNN 
96.1 
96.3 
95.8 

Model 
PKU MSRA CTB6 
Zhang et al. (2006) 95.1 
97.1 
* 
Zhang et al. (2007) 94.5 
97.2 
* 
Sun et al. (2009) 
95.2 
97.3 
* 
Sun et al. (2012) 
95.4 
97.4 
* 
Zhang et al. (2013) 96.1 
97.4 
* 
DGRNN 
96.1 
96.3 
95.8 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_411" validated="false"><head></head><label></label><figDesc>. It can be clearly seen that our approach achieves the best results compared withLSTM t = 5.94, p &lt; 1 × 10 −4 GRNN t = 1.22, p = 0.22 PKU Bi-LSTM t = 15.54, p &lt; 1 × 10 −4 GRNN t = 4.43, p &lt; 1 × 10 −4CTB6 Bi-LSTM t = 5.01, p &lt; 1 × 10 −4 GRNN t = 2.55, p = 2.48 × 10 −2</figDesc><table>Dataset 

Model 
Result 

MSRA 
Bi-</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_412" validated="false"><head>Table 3 :</head><label>3</label><figDesc>The t-test results for DGRNN and base- lines. other neural networks on traditional unigram em- beddings. It is possible that bigram embeddings may achieve better results. With the help of bi- gram embeddings, Pei et al. (2014) can achieve 95.2% and 97.2% F-scores on PKU and MSRA datasets and Chen et al. (2015) can achieve 96.4%, 97.6% and 95.8% F-scores on PKU, MSRA and CTB6 datasets. However, performance varies a- mong these bigram models since they have dif- ferent ways of involving bigram embeddings. Be- sides, the training speed would be very slow after adding bigram embeddings. Therefore, we only compare our model on traditional unigram embed- dings.</figDesc><table></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_413" validated="false"><head></head><label></label><figDesc>IW : Did you hear the falling bombs ? (a) IT : VBD PRP VB DT VBG NNS . O : O S-NP O B-NP I-NP E-NP O IW : Did R1 hear R2 . (b) IT : VBD NP VB NP .</figDesc><table>Did 

you 
hear 
the 
falling bombs ? 
VBD 
PRP 
VB 
DT 
VBG 
NNS . 

NP 
NP 
(R1) 
(R2) 

(a) 

Did 
R1 
hear 
R2 
? 
VBD 
NP 
VB 
NP 
. 

VP (R3) 

(b) 

Did 
R1 
R3 
? 
VBD 
NP 
VP 
. 

SQ 

(c) 

O : O 

O 
B-VP E-VP 
. 

IW : Did R1 R3 
? 

(c) IT : VDB NP VP 

. 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_414" validated="false"><head></head><label></label><figDesc>. . . . . . . . . . . . . . .</figDesc><table>Additional 
features 

Word 
embeddings 

. 
. POS tags 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_415" validated="false"><head>C gen3 C gen2 . . .</head><label>gen3gen2.</label><figDesc>hear n/a ...</figDesc><table>the 

f 

... 

falling f 

... 

bombs f 

g 2 

g 4 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_416" validated="false"><head></head><label></label><figDesc>Model Ara. Bas. Fre. Ger. Heb. Hun. Kor. Pol. Swe. AVGBjörkelund et al., 2014) 82.2 90.0 84.0 82.1 91.6 92.6 86.5 88.6 85.1 87.0 Proposed approach 84.1 91.0 85.7 84.6 91.7 91.2 87.8 94.1 82.5 88.1</figDesc><table>Berkeley+POS 
80.8 76.2 81.8 80.3 92.2 87.6 82.9 88.1 82.9 83.7 
Berkeley RAW 
79.1 69.8 80.4 79.0 87.3 81.4 73.3 79.5 78.9 78.7 
(</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_417" validated="true"><head>Table 2</head><label>2</label><figDesc>presents the influence of adding morpho- logical features to the model. We observe signif- icant improvement for every languages except for Hebrew. On average, morphological features al- lowed to overcome the original model by 2 F1- score.</figDesc><table>language Words + POS + morph 
Arabic 
80.7 
82.9 
Basque 
82.7 
90.6 
French 
81.1 
85.0 
German 
81.5 
83.1 
Hebrew 
91.6 
91.5 
Hungarian 
89.6 
90.3 
Korean 
86.1 
86.7 
Polish 
93.2 
93.7 
Swedish 
81.1 
81.5 
AVG 
85.3 
87.3 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_418" validated="false"><head>Table 2 :</head><label>2</label><figDesc>Influence of the additional morphological embeddings in terms of F1-score</figDesc><table></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_419" validated="false"><head></head><label></label><figDesc>Model Ara. Bas. Fre. Ger. Heb. Hun. Kor. Pol. Swe. AVGFernández and Martins, 2015) n/a 85.9 78.7 78.7 89.0 88.2 79.3 91.2 82.8 84.2 (Björkelund et al., 2014) 81.3 87.9 81.8 81.3 89.5 91.8 84.3 87.5 84.0 85.5 Proposed approach 80.4 87.5 80.8 82.0 91.6 90.0 84.8 93.0 80.5 85.6</figDesc><table>Berkeley+POS 
78.7 74.7 79.8 78.3 85.4 85.2 78.6 86.7 80.6 80.9 
Berkeley RAW 
79.2 70.5 80.4 78.3 87.0 81.6 71.4 79.2 79.2 78.5 
(Durrett and Klein, 2015) 
80.2 85.4 81.2 80.9 88.6 90.7 82.2 93.0 83.4 85.1 
(</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_420" validated="false"><head>Table 1 :</head><label>1</label><figDesc>Features in feature selection groups.</figDesc><table></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_421" validated="false"><head></head><label></label><figDesc>Best Gaze-Only Comb (BASIC-LATE) 80.45</figDesc><table>Features 
TA 

NOGAZEDUN 
81.03 
NOGAZEBNC 
80.69 
BASIC 
80.30 
EARLY 
79.96 
LATE 
79.87 
REGFROM 
79.62 
CONTEXT 
79.53 

Best Group Comb (All) 
81.37 
</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_422" validated="false"><head></head><label></label><figDesc>NoTextFeats + Best Group Comb (token) 79.56 NoTextFeats + Best Group Comb (type) 81.94* Token-level features Best Gaze Group (BASIC) 80.42* Best Gaze-Only Comb (BASIC+LATE) 80.45* Best Single Group (NOGAZEDUN)</figDesc><table>System 

TA 

Baseline (Li et al., 2012) 
79.77 

NoTextFeats 
74.61 
80.61* 
Best Group Comb (All) 
81.00* 

Type-averaged features 

Best Gaze Group (BASIC) 
81.28* 
Best Gaze-Only Comb (BASIC+LATE) 81.38* 
Best Group (NOGAZEDUN) 
81.52* 
Best Group Comb (All) 
</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_423" validated="false"><head></head><label></label><figDesc>4 http://www.speech.cs.cmu.edu/SLM/toolkit.htmlTable 4: Results of an ablation study over fea- ture groups on the test set on token-level features. Significant differences with previous model are marked by * (p &lt; 0.05, McNemar's test).</figDesc><table>Feature groups 
Accuracy 
∆ 

All groups 
81.00 
−NOGAZEBNC 
80.80 
−0.20 
−NOGAZEDUN 
80.28 
−0.52* 
−BASIC 
80.20 
−0.08 
−EARLY 
79.78 
−0.42* 
−LATE 
79.53 
−0.25 
−REGFROM 
79.24 
−0.29* 
−CONTEXT (Baseline) 
79.77 
+0.53* 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_424" validated="false"><head>d d</head><label>d</label><figDesc>top d bottom all-bad all-good optimistic pessimistic random total F</figDesc><table>1 -BAD 
0.79 0.61 
0.81 
4 
-
1 
4 
1 
10 
F 1 -mult 
0.81 0.57 
0.75 
-
-
2 
-
2 
4 
phr F 1 -BAD 0.86 0.61 
0.78 
16 
-
1 
16 
-
33 
phr F 1 -mult 0.75 0.54 
0.47 
-
-
1 
-
-
1 
MCC 
0.63 0.61 
0.34 
-
-
15 
-
-
15 
SeqCor 
0.77 0.39 
0.75 
-
-
1 
1 
2 
4 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_425" validated="false"><head></head><label></label><figDesc>and error thresholds: [30%, 30.01%, 30.05%, 30.1%, 30.2%]. The sig- nificance level α is 0.05. Since we compare all six metrics on five er- ror thresholds, we have 10 p-values for each met- ric at every sampling round. We analyse the re- sults in the following way: for every difference in the percentage of errors (e.g. thresholds of 30% and 30.01% give 0.01% difference, thresholds of 30% and 30.2% -0.2% difference), we define the minimum number of samplings that a metric</figDesc><table>588 

0.01 

0.04 
0.05 0.1 
0.15 0.2 
F 1 -mult 
10000 2000 
2000 500 
200 100 
MCC 
10000 2000 
2000 500 
200 100 
F 1 -BAD 
10000 5000 
2000 1000 500 200 
phr F 1 -mult 10000 5000 
</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_426" validated="false"><head>Table 2 :</head><label>2</label><figDesc>Repeated sampling: the minimum number of samplings required to discriminate between sam- ples with a different proportions of errors. Result: m x ∈ {m 1 , m 2 }, where m x -metric with the highest discriminative power on error thresholds e 1 and e 2 N ← 100 α ← significance level while p-val m 1 α and p-val m 2 α do s 1 ← N random samples with e 1 errors s 2 ← N random samples with e 2 errors p-val m 1 ← t-test(m 1 (s 1 ), m 1 (s 2 )) p-val m 2 ← t-test(m 2 (s 1 ), m 2 (s 2 )) if p-val m 1 &lt; α and p-val m 2 α then return m 1 else if p-val m 1 α and p-val m 2 &lt; α then return m 2 else N ← N + 100 end Algorithm 1: Repeated sampling for metrics m 1 , m 2 and error thresholds e 1 , e 2 .</figDesc><table></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2">335 in the TüBa-D/Z treebank. 3 Dependency relations that connect two clauses are excluded.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4">The software is available from: https://github. com/danieldk/toponn 5 Using paired approximate randomization tests (Noreen, 1989).</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1">Between layers, in general, a non linear function such as tanh or ReLU is applied.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2">In contrast to (Chen et al., 2012), we do not add a bias feature so that the domain and MDA have the same dimensionality. Experiments shown no impact on the performance.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3">The derivation is not included due to space limitation. 4 α ∈ [.1, 1, 50, 100, 150, 200, 300], λ ∈ [.01, .1, 1, 10].</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot">Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics, pages 32-37, Berlin, Germany, August 7-12, 2016. c 2016 Association for Computational Linguistics</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1">The greedy accuracies for Mi and Huang (2015) are from Haitao Mi, and greedy results for Zhu et al. (2013) come from duplicating experiments with code provided by those authors. 2 The parser of Vinyals et al. (2015) does not use an explicit transition system, but is similar in spirit since generating a right bracket can be viewed as a reduce action.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1">We use the implementation in the TensorFlow framework (Abadi et al., 2015).</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="11">The difference is statistically significant at 99% level according to pairwise bootstrap resampling test (Koehn, 2004). 12 The BLEU/NIST differences are statistically significant.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3">http://corpus.byu.edu/coha/. 4 Each time period contains texts that were written in that decade. 5 http://www.sueddeutsche.de/</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="6">The top ten words with the lowest values R G(w) are one, write, have, who, come, only, even, know, hat, fact.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1">Feldman et al. (2013a) assumes a more complex distribution over consonants, while Goldwater et al. (2009) assumes uniformity over all sounds.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4">Word segmentation scores from Lee et al. (2015), learning directly on acoustics, range between 16 and 20.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot">Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics, pages 66-71, Berlin, Germany, August 7-12, 2016. c 2016 Association for Computational Linguistics</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2">The same trend holds also if we exclude the 12 modified trees from the evaluation sets. 3 http://allenai.org/content/data/Regents.zip</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4">This measurement is relevant only when parsing based on our proposed annotation, and cannot be measured for parse trees based the original PTB annotation.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1">In MT evaluation, agreement is usually computed using standard k both for ranking different translations and for scoring translations on an interval-level scale. We note, however, that weighted k is more appropriate for scoring, since it allows the use of weights to describe the closeness of the agreement between categories (Artstein and Poesio, 2008).</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2">Literally: "However these all totally beyond the control of you."</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot">Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics, pages 89-94, Berlin, Germany, August 7-12, 2016. c 2016 Association for Computational Linguistics</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1">After adjunctions, the result forms a phrase consisting of several spines. If a phrasal spine is also used in adjunction operations as Figure 2 (b), we treat it as a lexical spine by referring to its head spine.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2">To construct a full parse tree from A, our actual implementation attaches index i to spine s after shift transition.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="5">http://www.cs.bgu.ac.il/˜yoavg/ software/blatt/ 6 http://www3.nd.edu/˜dchiang/software/ eevalb.py</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot">Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics, pages 101-106, Berlin, Germany, August 7-12, 2016. c 2016 Association for Computational Linguistics</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1">available at http://metaphorlab.org/metcor/search/ 2 Data and features will be made available at https://github.com/EducationalTestingService/metaphor.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3">Removing verbs of weather propelled the correlations with Conversation to a moderate range, r = 0.25-0.45 across genres.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4">We used McNemar's test of significance of difference between correlated proportions (McNemar, 1947), 2-tailed. We combined data from all genres into on a 2X2 matrix: both SOA'15 and UL+WN correct in (1,1), both wrong (0,0), SOA'15 correct UL+WN wrong (0,1), UL+WN correct SOA'15 wrong (1,0)).</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot">Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics, pages 107-111, Berlin, Germany, August 7-12, 2016. c 2016 Association for Computational Linguistics Recognizing Salient Entities in Shopping Queries</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4">cnts.ua.ac.be/conll2000/chunking/ conlleval.txt</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot">Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics, pages 112-117, Berlin, Germany, August 7-12, 2016. c 2016 Association for Computational Linguistics</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2">This means that word2vec was trained in the usual way on a large textual corpus, but the vocabulary was truncated to include as many entities from Freebase as possible. Indeed, this is the reason for the small overlap between W2V, GloVe, and the relational databases: after training the word embeddings, the vocabulary must be truncated to a reasonable size, which leaves out many entities from these datasets.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3">Note that we use h, l, t ∈ R k to denote both the entities and relations, in addition to the vector representations of the entities and relations</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1">To be precise, the embeddings are indexed by the arguments, which are then indexed by their positions, like u w(t) . Here we omit w. The same convention applies to dependency matrices, which are indexed by the dependency label first.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2">Resulted embeddings can be downloaded from https: //bitbucket.org/luanyi/unsupervised-srl.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot">Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics, pages 124-129, Berlin, Germany, August 7-12, 2016. c 2016 Association for Computational Linguistics</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2">Two code bases share the same architecture, initial states, and hyper-parameters. We simulate Jean et al. (2015)'s work with our code base in the both training and test procedures, the final results of our simulation are 29.99 and 34.16 on dev. and test sets respectively. Those scores are very close to Jean et al. (2015).</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot">Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics, pages 130-136, Berlin, Germany, August 7-12, 2016. c 2016 Association for Computational Linguistics</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1">Code is released on: https://sites.google.com/site/tbcnninference/</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="5">We applied collapsed dependency trees, where prepositions and conjunctions are annotated on the dependency relations, but these auxiliary words themselves are removed.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot">Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics, pages 137-142, Berlin, Germany, August 7-12, 2016. c 2016 Association for Computational Linguistics</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot">Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics, pages 143-148, Berlin, Germany, August 7-12, 2016. c 2016 Association for Computational Linguistics</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1">http://www.seas.upenn.edu/˜nlp/ resources/simple-ppdb.tgz</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2">http://paraphrase.org/#/download</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3">We do not compute the difference f (e1) − f (e2) for sparse features, i.e. character ngrams and POS tags. 4 http://scikit-learn.org/</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="5">Heuristically, we define "high quality" as ≥3.5 for words and ≥4 for phrases.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="6">http://www.seas.upenn.edu/˜nlp/ resources/simple-ppdb.tgz</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot">Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics, pages 149-155, Berlin, Germany, August 7-12, 2016. c 2016 Association for Computational Linguistics</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1">Chen et al. (2015) preprocessed the data specifically for Chinese word segmentation, such as replacing English characters, symbols, dates and Chinese idioms as special symbols. Our implementation discarded all these preprocessing steps, which while it achieved nearly identical results on development data (as inferred from their published figure), it lagged in test accuracy by 2.4%. However, we found that while these preprocessing steps improved segmentation, they hurt NER results as they resulted in a mis-match between the segmentation and NER input data. Since our focus is on improving NER, we do not use their preprocessing steps in this paper.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2">The same functionality as Aij in the model of Chen et al. (2015).</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3">This reduces to the multi-task setting of Yang et al. (2016). and learning.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot">Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics, pages 156-161, Berlin, Germany, August 7-12, 2016. c 2016 Association for Computational Linguistics</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3">Institute of Physics, Federal University of Rio Grande do Sul (Brazil) silvioricardoc@gmail.com carlos.ramisch@lif.univ-mrs.fr lzilio@inf.ufrgs.br marco.idiart@gmail.com avillavicencio@inf.ufrgs.br rswilkens@inf.ufrgs.br Abstract We introduce a new multilingual resource containing judgments about nominal compound compositionality in English, French and Portuguese. It covers 3 × 180 noun-noun and adjective-noun compounds for which we provide numerical compositionality scores for the head word, for the modifier and for the compound as a whole, along with possible paraphrases. This resource was constructed by native speakers via crowdsourcing. It can serve as basis for evaluating tasks such as lexical substitution and compositionality prediction.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1">We have not attempted to select equivalent compounds for all three languages. A compound in a given language may correspond to a single word in the other languages. Even when it does translate as a compound, its POS pattern and level of compositionality may be widely different.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2">We include the 90 compounds from Reddy et al. (2011), which are compatible with the new dataset.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3">http://pageperso.lif.univ-mrs. fr/~carlos.ramisch/?page=downloads/ compounds</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot">Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics, pages 162-168, Berlin, Germany, August 7-12, 2016. c 2016 Association for Computational Linguistics</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot">manual and non-manual components, is rendered using the JASigning avatar system. The platform is designed to make the component technologies readily accessible to sign language experts who are not necessarily computer scientists. Translation grammars are written in a version of Synchronous Context-Free Grammar adapted to the peculiarities of sign language. All processing is carried out on a remote server, with content uploaded and accessed through a web interface. Initial experiences show that simple translation grammars can be implemented on a time-scale of a few hours to a few days and produce signed output readily comprehensible to Deaf informants. Overall, the platform drastically lowers the barrier to entry for researchers interested in building applications that generate high-quality signed language.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1">We follow the widely recognized convention of using the upper-cased word Deaf to describe members of the linguistic community of sign language users and, in contrast, the lower-cased word deaf to describe the audiological state of a hearing loss (Morgan and Woll, 2002). 162</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2">Sign languages make use of a communication form known as the manual alphabet (or, finger alphabet), in which the letters of a spoken language word are fingerspelled, i.e., dedicated signs are used for each letter of the word.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3">Any recognition language supported by Nuance Recognizer 10.2 can potentially be used as a source language; the current version of the platform is loaded with language packs for English, French, German, Italian, Japanese and Slovenian. 4 GrXML is an open standard for writing speech recognition grammars.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot">Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics, pages 169-174, Berlin, Germany, August 7-12, 2016. c 2016 Association for Computational Linguistics</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1">The target side is often identified with English and the source side is usually taken to be French.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2">Crucially, this vocabulary includes a NULL word. 3 We denote realisations of random variables by the corresponding lower case letters.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4">We use a bigram LM to avoid conditioning Z on longer (n − 1)-grams.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="6">http://statmt.org/wmt14/ translation-task.html</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot">Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics, pages 175-180, Berlin, Germany, August 7-12, 2016. c 2016 Association for Computational Linguistics</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot">Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics, pages 181-187, Berlin, Germany, August 7-12, 2016. c 2016 Association for Computational Linguistics</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1">Our experiments conform to all operative rules and restrictions on data collection, anonymization and publication according to the requirements in the European Union.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2">This words seem to have a lot in common with weasel and hedge words, which refer to uncertainty (Vincze, 2013).</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot">Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics, pages 188-194, Berlin, Germany, August 7-12, 2016. c 2016 Association for Computational Linguistics</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2">Methodology 2.1 Linguistic Representations We use three representative linguistic BWE models. Given a source and target vocabulary V S and V T , BWE models learn a representation of each word w ∈ V S ∪ V T as a real-valued vec-</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1">Setting γ = 0 reduces the model to the bilingual models trained solely on parallel data (Hermann and Blunsom, 2014; Chandar et al., 2014). γ = 1 results in the models from Gouws et al. (2015) and Soyer et al. (2015). Although they use the same data sources, all G-EMB models differ in the choice of monolingual and cross-lingual objectives.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2">https://github.com/gouwsmeister/bilbowa</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3">Under the assumption of having the centered and L2-normalized feature vectors, and cos as SF, Early-Fusion may be transformed into Late-Fusion with adapted weighting: α 2 × cos(w ling , v ling ) + (1 − α) 2 × cos(wvis, vvis) 4 http://www.clsp.jhu.edu/~sbergsma/LexImg/ 5 http://www.cl.cam.ac.uk/~dk427/bli.html</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="8">Similar rankings of different models are also visible with more lenient Acc10 scores, not reported for brevity. 9 The average image dispersion value (Kiela et al., 2014), which indicates abstractness, on VULIC1000 is 0.711 compared to 0.642 on BERGSMA500.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot">Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics, pages 195-200, Berlin, Germany, August 7-12, 2016. c 2016 Association for Computational Linguistics</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3">https://www.reddit.com 4 https://www.reddit.com/r/changemyview</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="5">The data was shared with us by researchers at the University of Washington. 6 Please contact authors about sharing the data set. 7 This is the number of deltas the author has received.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="8">Stanford CoreNLP (Manning et al., 2014) was used to preprocess the text (i.e., comment splitting, sentence tokenization, POS tagging and NER recognition.).</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="10">We constructed a list of connective words including 55 entries (e.g., because, therefore etc.).</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot">Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics, pages 201-206, Berlin, Germany, August 7-12, 2016. c 2016 Association for Computational Linguistics</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2">Screenshots are included in the supplementary material. 3 We manually edited the SPARQL queries for about 3.1% of the questions in WEBQUESTIONS that are not expressible by our UI.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4">The average F1 score of the original STAGG's output to these 1,639 questions is 60.3%, evaluated using WEB-QUESTIONS. Note that the number is not directly comparable to what we report in Table 1 because many of the labeled answers in WEBQUESTIONS are either incorrect or incomplete.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="5">We considered a label to be correct only if the derived/labeled answer set is completely accurate.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot">Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics, pages 213-218, Berlin, Germany, August 7-12, 2016. c 2016 Association for Computational Linguistics</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot">Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics, pages 219-224, Berlin, Germany, August 7-12, 2016. c 2016 Association for Computational Linguistics</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4">http://saifmohammad.com/WebPages/Abstracts/NRCSentimentAnalysis.htm 5 http://ir.hit.edu.cn/∼dytang/ 6 http://www.cs.waikato.ac.nz/∼fjb11/ 7 http://saifmohammad.com/WebPages/ArabicSA.html</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot">Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics, pages 225-230, Berlin, Germany, August 7-12, 2016. c 2016 Association for Computational Linguistics</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1">http://www.github.com/clab/cnn 2 http://ronan.collobert.com/senna/ 3 http://polyglot.readthedocs.org 4 In CCG supertagging, we follow common practice and only evaluate performance with respect to the 425 most frequent labels. For this reason, we also do not calculate any loss from not predicting the other labels during training (but we do suffer a loss for tokens tagged with a different label during evaluation).</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2">In the target language in the experiments, Japanese, the types are hiragana, katakana, kanji, number, symbol, and combinations of them.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3">Tsuboi et al. (2008) extended conditional random fields to be trained from partially annotated data. One can extend sequence labeling DNN (RNN or LSTM) in a similar way. This is, however, clearly out of the scope of this paper.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1">We use a threshold on the cosine similarity of the texts to determine whether they match. 2 We excluded Wikipedia results to better simulate the case of companies which do not have a Wikipedia page</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot">Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics, pages 249-255, Berlin, Germany, August 7-12, 2016. c 2016 Association for Computational Linguistics</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4">This is the only part in our process that might introduce some bias. However, this bias is independent of existing relation inference methods such as DIRT. 5 See supplementary material for a detailed description. 6 Several additional filters were applied to prune nongrammatical assertions (see supplementary material).</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="8">This harsh filtering process is mainly a result of poor annotator quality. See supplementary material for a detailed description of the steps we took to improve annotator quality. 9 To recreate the embeddings, see supplementary material.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot">Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics, pages 256-263, Berlin, Germany, August 7-12, 2016. c 2016 Association for Computational Linguistics</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3">k-Means/prep directly provides binary membership.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot">Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics, pages 264-268, Berlin, Germany, August 7-12, 2016. c 2016 Association for Computational Linguistics</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1">Women made up 44.5% of the subjects.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot">Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics, pages 269-274, Berlin, Germany, August 7-12, 2016. c 2016 Association for Computational Linguistics</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2">https://twitter.com/</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot">Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics, pages 275-280, Berlin, Germany, August 7-12, 2016. c 2016 Association for Computational Linguistics</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1">In this paper, edge weights are set to 1. 2 Addition means that constraints are added from a TM target to an input, while subtraction means that some constraints are removed from the TM target.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4">http://ipsc.jrc.ec.europa.eu/index. php?id=198</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="5">In this paper, we use a lexical fuzzy match score (Koehn and Senellart, 2010) based on Levenshtein distance to find the best match.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot">Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics, pages 281-286, Berlin, Germany, August 7-12, 2016. c 2016 Association for Computational Linguistics</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1">https://www.matecat.com/</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot">Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics, pages 287-292, Berlin, Germany, August 7-12, 2016. c 2016 Association for Computational Linguistics</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4">Implemented in TMop: https://github.com/hlt-mt/TMOP 5 Being these feature very sparse, we collapsed them into a single one, which is set to 1 if any feature has value 1.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot">Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics, pages 299-305, Berlin, Germany, August 7-12, 2016. c 2016 Association for Computational Linguistics</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1">http://ucam-smt.github.io/sgnmt/html/ 2 https://pyfst.github.io/</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3">http://matrix.statmt.org/matrix/systems list/1774</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot">Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics, pages 306-312, Berlin, Germany, August 7-12, 2016. c 2016 Association for Computational Linguistics</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1">http://www.leffingwell.com/top_10.htm</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4">Downloading took place in February 2015</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot">Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics, pages 313-319, Berlin, Germany, August 7-12, 2016. c 2016 Association for Computational Linguistics</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot">Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics, pages 320-325, Berlin, Germany, August 7-12, 2016. c 2016 Association for Computational Linguistics</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1">http://www.mturk.com</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4">data collected late December, 2015 5 The data set introduced in this paper is available at http://lit.eecs.umich.edu/research/ downloads.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot">Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics, pages 326-331, Berlin, Germany, August 7-12, 2016. c 2016 Association for Computational Linguistics</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1">A constant is added to the input, xn = [xn; 1], and an appropriate bias, never corrupted, is incorporated within W.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3">Experimental results We test our approach on two standard domain adaptation datasets: the Amazon reviews (AMT) and the 20Newsgroups (NG). The AMT dataset consists of products reviews with 2 classes (positive and negative) represented by tf-idf normalized 2 It requires concatenating the class predictions from different sources at step 1 and averaging the reconstructed predictions per class at step 3.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3">We also experimented with other classifiers, such as SVM , Multinomial Naive Bayes, and obtained similar improvement after applying TPA. Results are not shown due to the space limitation.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot">Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics, pages 332-336, Berlin, Germany, August 7-12, 2016. c 2016 Association for Computational Linguistics</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3">https://mahout.apache.org 4 www.graphlab.org 5 http://www.cs.cmu.edu/ chongw/citeulike/</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot">Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics, pages 337-343, Berlin, Germany, August 7-12, 2016. c 2016 Association for Computational Linguistics</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1">http://storage.googleapis.com/ sentencecomp/compressiondata.json</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2">The negative value that the headlines receive for this met-</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot">Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics, pages 344-350, Berlin, Germany, August 7-12, 2016. c 2016 Association for Computational Linguistics</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1">http://www.gutenberg.org</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2">Note that each cluster generally includes large numbers of non-names, which we ignore.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3">Using cross-validation over the training data, we tested other solvers, L1 regularization, and settings of the C parameter, but saw no appreciable improvement in performance.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4">https://opennlp.apache.org/ 5 http://alias-i.com/lingpipe</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="6">See http://www.projectgutentag.org</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot">Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics, pages 351-356, Berlin, Germany, August 7-12, 2016. c 2016 Association for Computational Linguistics</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1">http://www.business2community.com/ infographics/impact-online-reviews-</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3">www.trustpilot.com 4 For a more detailed description of the data, see Hovy et al. (2015).</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot">Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics, pages 357-361, Berlin, Germany, August 7-12, 2016. c 2016 Association for Computational Linguistics</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2">http://dl4mt.computing.dcu.ie/</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot">Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics, pages 362-368, Berlin, Germany, August 7-12, 2016. c 2016 Association for Computational Linguistics</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1">In contrast, Wieting et al. (2016) initialize W with highquality but resource intensive embeddings -they are trained using word-level PPDB paraphrases, tuned on SimLex-999, and regularized to penalize deviations from initial GloVe embeddings (Pennington et al., 2014). 2 MAX (use the unaligned phrase of minimum distance) or MIX (use MAX with probability 0.5 and sample randomly otherwise)</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3">Further, more than 80% of words that appear in both bilingual sentences and bilingual phrases occur in 460 (in average) more bilingual sentences than in bilingual phrases. The remaining 20% were found to be the rare words (e.g. zazvorkova, woldesmayat, yellow-bellies) that hardly occur in test sets.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot">Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics, pages 369-373, Berlin, Germany, August 7-12, 2016. c 2016 Association for Computational Linguistics</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot">Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics, pages 374-379, Berlin, Germany, August 7-12, 2016. c 2016 Association for Computational Linguistics</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2">Related Work Extracting information from conflict related reports has been a topic of interest at various times for both the conflict analysis, information extraction, and natural language processing communi-1 More information about the IBC-C dataset can be found on: http://andrejzg.github.io/ibcc/</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2">Base named entities such as PERSON and LOCATION were found using Stanford's named entity recogniser (Finkel et al., 2005).</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot">Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics, pages 380-386, Berlin, Germany, August 7-12, 2016. c 2016 Association for Computational Linguistics</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3">http://qwone.com/˜jason/20Newsgroups/ 4 Available at http://www.nltk.org/</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="5">See http://scikit-learn.org/stable/. 6 LFTM: https://github.com/datquocnguyen/LFTM BTM: https://github.com/xiaohuiyan/BTM GLDA: https://github.com/rajarshd/Gaussian LDA</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot">Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics, pages 387-392, Berlin, Germany, August 7-12, 2016. c 2016 Association for Computational Linguistics</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1">https://dumps.wikimedia.org/ 2 http://www.wordvectors.org/</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3">https://github.com/jiangfeng1124/ acl15-clnndep</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1">While the authors annotated and released 9 datasets, here we make use of 4 sufficiently large datasets.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot">Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics, pages 399-405, Berlin, Germany, August 7-12, 2016. c 2016 Association for Computational Linguistics</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2">Commonly believed in Bulgaria to mean troll in Russian (which it does not). 3 The Bulgarian Prime Minister Mr. Boyko Borisov. 4 Boyko Borisov's party GERB had fallen down due to protests and here is being accused of organizing protests in turn against the new Socialist government that replaced it. 5 http://members.unine.ch/jacques. savoy/clef/bulgarianST.txt</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="6">http://urbanoalvarez.es/blog/2008/04/ 04/bad-words-list/ 7 https://github.com/tbmihailov/ gate-lang-bulgarian-gazetteers/ -GATE resources for Bulgarian, including sentiment lexicons, bad words lexicons, politicians' names, etc.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot">Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics, pages 406-411, Berlin, Germany, August 7-12, 2016. c 2016 Association for Computational Linguistics</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1">Running time can be further reduced if we compute the set of words covered by each phrase pair xi before executing the greedy algorithm.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1">https://github.com/clab/cnn</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4">We observe the same pattern with more, 40, iterations.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot">Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics, pages 419-424, Berlin, Germany, August 7-12, 2016. c 2016 Association for Computational Linguistics</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1">Following Mikolov et al. (2013b) it is the unigram distribution raised to the 3/4 power.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2">Words with unigram relative frequency f &gt; t are discarded from the training corpus with probability pw = 1 − t/f . 3 http://www.cs.cmu.edu/ mfaruqui/suite.html</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot">Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics, pages 425-431, Berlin, Germany, August 7-12, 2016. c 2016 Association for Computational Linguistics</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2">The code-switching treebank follows the Universal Treebank v2.0 annotations. It can be obtained by asking any of the authors.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="5">Acknowledgments This research is supported by the Ministerio de Economía y Competitividad (FFI2014-51978-C2). David Vilares is funded by the Ministerio de Educación, Cultura y Deporte (FPU13/01180). Carlos Gómez-Rodríguez is funded by an Oportunius program grant (Xunta de Galicia). We thank Marcos Garcia for helping with the codeswitching treebank. We also thank the reviewers for their comments and suggestions.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot">Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics, pages 432-437, Berlin, Germany, August 7-12, 2016. c 2016 Association for Computational Linguistics</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1">Since Specialisation is a development of LIMERIC, the two models are not independent which means we would expect to see relatively high confidence values for relatively small gains in score (see Berg-Kirkpatrick et al., 2012).</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1">Perhaps counterintuitively, most proper nouns are uninformative for sentence completion, since they refer to specific named entities (e.g. people, locations, organizations, etc.).</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot">Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics, pages 449-453, Berlin, Germany, August 7-12, 2016. c 2016 Association for Computational Linguistics</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1">http://ml.memect.com/ 2 https://github.com/fxsjy/jieba</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot">Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics, pages 454-459, Berlin, Germany, August 7-12, 2016. c 2016 Association for Computational Linguistics</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1">http://www.wordnik.com</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot">Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics, pages 460-466, Berlin, Germany, August 7-12, 2016. c 2016 Association for Computational Linguistics</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3">When an author thanks somebody, this post is typically a bad answer to the original question. 4 Can detect slang, foreign language, etc., which would indicate a bad answer.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="5">We also tried Kendall's Tau (τ ), but it performed worse.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot">Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics, pages 467-473, Berlin, Germany, August 7-12, 2016. c 2016 Association for Computational Linguistics</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3">https://www.kaggle.com/c/the-allen-ai-sciencechallenge/</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1">http://knowitall.github.io/openie 2 Open IE-4 is based on ClearNLPs SRL, allowing for a direct comparison.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3">Currently these consist of automatically annotated verbs.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4">This order is arbitrary, chosen solely to provide a deterministic process. Alternating the steps would yield an identical set. 5 An annotated answer is judged to match the PropBank argument if either (1) the gold argument head is within the annotated answer span, or (2) the gold argument head is a preposition and at least one of its children is within the answer span.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="6">For example, in "The American Stock Exchange said a seat was sold for $ 160,000 , down $ 5,000 from the previous sale last Friday .", one annotator did not reduce ARG1, while the second annotator chose to restrict the span of the argument to "a seat was sold for $ 160,00", interpreting the remaining part of the clause as an addition by the author. 7 https://www.mturk.com 8 To be clear, the annotators saw only the raw text and questions from QA-SRL and were not exposed to the PropBank annotations.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot">Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics, pages 479-485, Berlin, Germany, August 7-12, 2016. c 2016 Association for Computational Linguistics</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2">Max number of summaries per person 31, min number 2. The summaries are available for download at http: //www.cl.cam.ac.uk/˜sht25.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3">The scores of L and LR are very close, but not identical. 4 We use the paired Wilcoxon test (two-tailed). Differences between O and each other summariser at p &lt; 0.01. All</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot">Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics, pages 486-492, Berlin, Germany, August 7-12, 2016. c 2016 Association for Computational Linguistics</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2">We tune the SVM parameter C on the dev set. We use Stanford CoreNLP, HILDA parser (Feng and Hirst, 2014) and JAMR (Flanigan et al., 2014) for preprocessing.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot">Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics, pages 493-498, Berlin, Germany, August 7-12, 2016. c 2016 Association for Computational Linguistics</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2">https://github.com/gouwsmeister/ bilbowa</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot">Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics, pages 499-505, Berlin, Germany, August 7-12, 2016. c 2016 Association for Computational Linguistics</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1">See (Pecina, 2008) for a detailed survey of such measures.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2">https://code.google.com/archive/p/word2vec/</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4">As one of the reviewers pointed out, BNC might not be optimal as a collocation reference corpus. On the one hand, it does not capture collocations that might be idiosyncratic to American English, and, on the other hand, it might be outdated (and thus not contain more recent collocations). It is subject of future work to verify whether another representative corpus of English serves better.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="6">Obviously, collocate candidates were considered as incorrect if they formed incorrect collocations with the base. Examples of such incorrect collocations are stop [the] calm and develop [a] calculation.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot">Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics, pages 506-511, Berlin, Germany, August 7-12, 2016. c 2016 Association for Computational Linguistics</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot">Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics, pages 512-517, Berlin, Germany, August 7-12, 2016. c 2016 Association for Computational Linguistics</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1">− α * . We do a batch gradient descent where each batch contains the same number of positive and negative examples. This means the number of examples in the lexica -which give rise to more negative than positive examples -does not influence the training.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2">This results in an even number of 25 * 26 = 650 questions per POS combination, 4 * 2 * 650 = 5200 in total (4 POS combinations, where each POS can be used as query POS).</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3">We would like to thank an anonymous reviewer for suggesting this alternative approach.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot">Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics, pages 518-524, Berlin, Germany, August 7-12, 2016. c 2016 Association for Computational Linguistics</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1">We use the latest Version 1.2 UD treebanks: http://universaldependencies.org/</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2">https://bitbucket.org/yoavgo/word2vecf For details concerning the implementation and learning, we refer the interested reader to (Goldberg and Levy, 2014; Levy and Goldberg, 2014a).</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3">Results with another context type relying on substitute vectors (Yatbaz et al., 2012; Melamud et al., 2015) are omitted due to its subpar performance in our experiments as well as across a variety of semantic tasks in a recent Englishfocused study (Melamud et al., 2016).</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4">https://sites.google.com/site/rmyeid/projects/polyglot 5 http://www.cs.cmu.edu/ ark/TurboParser/ 6 Besides EN, DE, and IT, we also UPOS-tagged and UDparsed Wikipedias in NL, ES, and HR. We believe that the full UPOS-tagged and UD-parsed Wikipedias in six languages are a valuable asset for future research and we plan to make the resource publicly available at: http://ltl.mml.cam.ac.uk/resources/ 7 https://code.google.com/archive/p/mate-tools/ 8 We opted for the Mate parser due to its speed, simplicity, and state-of-the-art performance according to very recent parser evaluations (Choi et al., 2015).</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="9">Note that the correlation scores for all models on the re-annotated version of SimLex-999 (Leviant and Reichart, 2015) are lower than those on the original SimLex-999. 10 The comparison is valid since DEPS-LEVY were trained on exactly the same data with the same vocabulary.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot">Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics, pages 525-530, Berlin, Germany, August 7-12, 2016. c 2016 Association for Computational Linguistics</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1">data is avaiable at https://www.research.ibm. com/haifa/dept/vst/mlta_data.shtml. 2 UMLS Reference Manual [Internet]. Bethesda (MD): National Library of Medicine (US); 2009 Sep-. 6, SPE-CIALIST Lexicon and Lexical Tools. Available from:</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot">Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics, pages 531-536, Berlin, Germany, August 7-12, 2016. c 2016 Association for Computational Linguistics</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1">This does not match with Table 1 as samples labeled with 2 senses are double counted. Multi-sense training samples are splitted into multiple samples, each labelled with one of the senses. In testing, a prediction is considered correct if it matches with one of the multiple senses.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot">Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics, pages 537-542, Berlin, Germany, August 7-12, 2016. c 2016 Association for Computational Linguistics</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2">http://qwone.com/˜jason/20Newsgroups/ 3 http://www.cs.nyu.edu/˜roweis/data. html 4 https://code.google.com/p/word2vec/</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot">Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics, pages 543-548, Berlin, Germany, August 7-12, 2016. c 2016 Association for Computational Linguistics</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot">Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics, pages 549-554, Berlin, Germany, August 7-12, 2016. c 2016 Association for Computational Linguistics</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1">The annotated dataset, T OEF Larg, is available at https://github.com/debanjanghosh/argessay ACL2016/ measure for overlap matches (between two annotators) for argument components is 73.98% and for argument relation is 67.56%.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot">Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics, pages 555-560, Berlin, Germany, August 7-12, 2016. c 2016 Association for Computational Linguistics</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3">For our experiments we ran the code available at github.com/mfaruqui/morph-trans. We used the enc-dec-attn model as overall results for the CELEX task were better than with the sep-morph model. 4 13SIA=1st/3rd sg. ind. past; 13SKE=1st/3rd sg. subjunct. pres.; 2PIE=2nd pl. ind. pres.; 13PKE=1st/3rd pl. subjunct. pres.; 2PKE=2nd. pl. subjunct. pres.; z=infinitive; rP=imperative pl.; pA=past part.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot">Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics, pages 561-566, Berlin, Germany, August 7-12, 2016. c 2016 Association for Computational Linguistics</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2">https://bitbucket.org/lowlands/ release</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="5">https://github.com/bplank/ multilingualtokenizer</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="9">https://bitbucket.org/lowlands/ release</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot">Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics, pages 567-572, Berlin, Germany, August 7-12, 2016. c 2016 Association for Computational Linguistics</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot">Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics, pages 573-578, Berlin, Germany, August 7-12, 2016. c 2016 Association for Computational Linguistics</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1">(Begin, Intermediate, Other, End, Single)</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2">The tags used are available here: http://cistern. cis.lmu.de/marmot/models/CURRENT/</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot">Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics, pages 579-584, Berlin, Germany, August 7-12, 2016. c 2016 Association for Computational Linguistics</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2">https://code.google.com/archive/p/ wikily-supervised-pos-tagger/</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3">defined as saccades going further back than w i−2</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot">Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics, pages 585-590, Berlin, Germany, August 7-12, 2016. c 2016 Association for Computational Linguistics</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3">d bottom is always greater than dtop in our experiments because better performing systems tend to have closer scores under all metrics and more often are not significantly different from one another. When comparing two metrics, greater d does not imply greater dtop and d bottom : we use Bonferroni correction for which the significance level depends on the number of compared values, so a difference which is significant when comparing eight systems, for example, can become insignificant when comparing 16 systems.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot">Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics, pages 591-598, Berlin, Germany, August 7-12, 2016. c 2016 Association for Computational Linguistics</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1">With few exceptions, such as dialogue research (Joel Tetreault, pers. comm.)</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2">Héctor Martínez Alonso, personal communication 3 Except for annotation: there are a number of papers on the status of crowdsource workers (Fort et al., 2011; Pavlick et al., 2014).Couillault et al. (2014) also briefly discuss annotators, but mainly in the context of quality control.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot">Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics, pages 599-605, Berlin, Germany, August 7-12, 2016. c 2016 Association for Computational Linguistics</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1">Comparing, for example, German Kuckuck with French coucou and English cuckoo may yield quite different scores, although the English and the French words are almost identical in pronunciation.</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgments</head><p>The authors gratefully acknowledge the financial support of their research by the German Ministry for Education and Research (BMBF) as part of the CLARIN-D research infrastructure grant givenAcknowledgements This research was supported in part by NSF BIGDATA grant IIS-1546482 and a gift from Bloomberg LP.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>References</head><p>Fabian Abel, Qi Gao, Geert-Jan Houben, and Ke Tao.</p><p>2011. Analyzing user modeling on twitter for personalized news recommendations. In User Modeling, Adaption and Personalization -19th Interna</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgments</head><p>This research was partially supported by Ministry of Science and Technology, Taiwan, under grant MOST-102-2221-E-002-103-MY3. We thank the anonymous reviewers for their constructive comments to revise this paper.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgments</head><p>We thank the anonymous reviewers for comments. We also thank Taro Watanabe, Muhua Zhu, and Yue Zhang for sharing their code, Haitao Mi for producing greedy results from his parser, and Ashish Vaswani and Yoav Goldberg for discussions. The authors were supported in part by DARPA FA8750-13-2-0041 (DEFT), NSF IIS-1449278, and a Google Faculty Research Award.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgments</head><p>This research was funded in part by the Netherlands Organization for Scientific Research (NWO) under project numbers 639.022.213 and 612.001.218. We thank Arianna Bisazza and the anonymous reviewers for their comments.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgments</head><p>This work was funded by the Ministry of Education, Youth and Sports of the Czech Republic under the grant agreement LK11221 and core research funding, SVV project 260 333, and GAUK grant 2058214 of Charles University in Prague. It used language resources stored and distributed by the LINDAT/CLARIN project of the Ministry of Education, Youth and Sports of the Czech Republic (project LM2015071). We thank our colleagues and the anonymous reviewers for helpful comments.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgements</head><p>This research was funded by NSF grants 1422987 and 1421695. We are grateful for the advice of three anonymous reviewers, and to Sharon Goldwater for distributing the baseline DPSeg system.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>References</head><p>Leonardo Badino, Claudia Canevari, Luciano Fadiga, and Giorgio Metta.</p><p>2014. An auto-encoder based approach to unsupervised learning of subword units. In Acoustics, Speech and Signal Processing (ICASSP), 2014 IEEE International Conference on, pages 7634-7638. IEEE.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Acknowledgments</head><p>The authors give great thanks to Ying Lin (RPI) and Shen Liu for (HIT) the fruitful discussions. We also would like to thank three anonymous reviewers for their valuable comments and suggestions. RPI co-authors were supported by the U. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>References 6 Acknowledgments</head><p>We would like to thank the anonymous reviewers for their detailed reviews and suggestions. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgments</head><p>The authors would like to thank the anonymous reviewers for their valuable comments and suggestions to improve the quality of the paper. This work was supported in part by JSPS KAKENHI Grant Number 26730126.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgment</head><p>We are grateful to the ACL reviewers for their helpful feedback. Ekaterina Shutova's research is supported by the Leverhulme Trust Early Career Fellowship.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>References Acknowledgment</head><p>We thank the anonymous reviewers for their comments.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgments</head><p>We thank all anonymous reviewers for their constructive comments, especially those on complexity issues. We also We would especially like to thank Ani Nenkova for suggesting this line of research and for providing the initial ideas on which this work builds. We would also like to thank Courtney Napoles and Wei Xu for valuable discussions, the anonymous reviewers for thoughtful comments, and the Amazon Mechanical Turk annotators for their contributions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgments</head><p>This work has been partly funded by projects PARSEME-FR <ref type="figure">(</ref> </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgements</head><p>We would like to thank John Glauert of the School of Computing Sciences, UEA, for his invaluable help with JASigning, and Nuance Inc for generously making their software available to us for research purposes.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgements</head><p>We would like to thank Miloš Stanojević for providing us with the preprocessed Japanese data. We would also like to thank our reviewers for their helpful feedback. This work was supported by the Netherlands Organization for Scientific Research (NWO) VICI Grant nr. 277-89-002.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgments</head><p>This research was conducted while the first author was visiting the Saarland University Spoken Language Systems group. The work was partially funded by the Saarland University SFB1102 Collaborative Research Center for Information Density and Linguistic Encoding.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgments</head><p>This work is supported by ERC Consolidator Grant LEXICAL (648909) and KU Leuven Grant PDMK/14/117. SC is supported by ERC Starting Grant DisCoTex (306920). We thank the anonymous reviewers for their helpful comments.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgments</head><p>We thank the anonymous reviewers for their detailed and insightful comments on this paper. The work is partially supported by DARPA Contract No. FA8750-13-2-0041 and AFOSR award No. FA9550-15-1-0346. Any opinions, findings, and conclusions or recommendations expressed are those of the authors and do not necessarily reflect the views of the funding agencies. We thank Trang Tran, Hao Fang and Mari Ostendorf at University of Washington for sharing the Reddit data they collected.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgments</head><p>We thank Andrei Aron for the initial design of the labeling interface. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgments</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgements</head><p>This work was supported by the German Research Foundation via the German-Israeli Project Cooperation (grant DA 1600/1-1), the Israel Science Foundation grant 880/12, and by grants from the MAGNET program of the Israeli Office of the Chief Scientist (OCS).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgments</head><p>The research was supported by the DFG Research Project "Distributional Approaches to Semantic Relatedness" (Maximilian Köper) and the DFG Heisenberg Fellowship SCHU-2580/1 (Sabine Schulte im Walde).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgments</head><p>This research received funding from the EPSRC projects GUI (EP/L026775/1), DILiGENt (EP/M005429/1) and MaDrIgAL (EP/N017536/1).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgments</head><p>We would like to thank Alex Smola, Yun Fu, Hsiao-Yu Fish Tung, Ruslan Salakhutdinov, and Barnabas Poczos for useful discussions. We would also like to thank Juergen Pfeffer for providing access to the Twitter data, and the reviewers for their comments.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgments</head><p>This research has received funding from the Peo- </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgments</head><p>This work has been partially supported by the ECfunded projects ModernMT (H2020 grant agreement no. 645487) and EXPERT (FP7 grant agreement no. 317471). The work carried out at FBK by Masoud Jalili Sabet was sponsored by the EAMT Summer internships 2015 program. The authors would like to thank Anders Søgaard for sharing the initial version of the code for computing word embeddings.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgments</head><p>This paper has received funding from the European Union's Horizon 2020 research and innovation programme under grant agreement n o 645452 (QT21).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgements</head><p>This work was supported in part by the U.K. Engineering and Physical Sciences Research Council (EPSRC grant EP/L027623/1).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgments</head><p>Part of this work was funded by The Netherlands Organization for Scientific Research: NWO VICI grant "Human olfaction at the intersection of language, culture and biology", project number 277-70-011.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgments</head><p>The authors acknowledge the support from Templeton Religion Trust, grant TRT-0048. We also wish to thank Prof. Iryna Gurevych for supporting the collaboration.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgements</head><p>We would like to thank Seong Ju Park, Tian Bao, and Yihan Li for their assistance in the initial project that led to this work. This material is based in part upon work supported by the National Science Foundation award #1344257 and by grant #48503 from the John Templeton Foundation. Any opinions, findings, and conclusions or recommendations expressed in this material are those of the authors and do not necessarily reflect the views of the National Science Foundation or the John Templeton Foundation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgement</head><p>We would like to thank the anonymous reviewers for their valuable feedback and grant MEXT KAKENHI #16K16114.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgments</head><p>This research was partially funded by the ERC Starting Grant LOWLANDS No. 313695, as well as by Trygfonden.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgments</head><p>The author would like to thank the members of the COASTAL group and the anonymous reviewers for their detailed comments and suggestions, and Noah Smith for pointing out a missing reference. This research was funded under the ERC Starting Grant LOWLANDS No. 313695.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgements</head><p>This work is supported by the 7th Framework Program of the European Commission through the International Outgoing Fellowship Marie Curie Action (IMTraP-2011-29951)  and also by the Spanish Ministerio de Economía y Competitividad and European Regional Developmend Fund, contract TEC2015-69266-P (MINECO/FEDER, UE).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgments</head><p>We thank anonymous reviewers for their constructive feedback. We also thank Hideki Mima for helpful discussions and Paul Thompson for insightful reviews on the paper. This paper is based on results obtained from a project commissioned by the New Energy and Industrial Technology Development Organization (NEDO).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgment</head><p>The authors thank Shyam Upadhyay for his help with the dependency parser embeddings results, and Eric Horn for his help with this write-up. This work was supported by DARPA under agreement numbers HR0011-15-2-0025 and FA8750-13-2-0008. The U.S. Government is authorized to reproduce and distribute reprints for Governmental purposes notwithstanding any copyright notation thereon. The views and conclusions contained herein are those of the authors and should not be interpreted as necessarily representing the official policies or endorsements, either expressed or implied, of any of the organizations that supported the work.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgments</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">Acknowledgements</head><p>The authors thank their anonymous reviewers and members of the Schwa Lab at the University of Sydney for their insightful and helpful feedback. The first author was supported by an Australian Postgraduate Award scholarship.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgments</head><p>This work has been funded by the National Science Foundation under CRII IIS grant 1459300.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgments</head><p>The work was supported by National Natural Science Foundation of China <ref type="formula">(61331011)</ref> </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgments</head><p>We would like to thank Luheng He and Luke Zettlemoyer for the fruitful discussions, and the anonymous reviewers for their helpful comments.</p><p>This work was supported in part by grants from the MAGNET program of the Israeli Office of the Chief Scientist (OCS), the Israel Science Foundation grant 880/12, and the German Research Foundation through the German-Israeli Project Cooperation (DIP, grant DA 1600/1-1).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgments</head><p>The CSC Cambridge International Scholarship for the first author is gratefully acknowledged. differences between all summarisers other than O are insignificant (p &gt; 0.05).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgments</head><p>This work was partially supported by grants from Japan Society for the Promotion of Science KAK-ENHI (24300106, 16H01547 and 16H02789) to HS.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Acknowledgements</head><p>The present work has been partially funded by the Spanish Ministry of Economy and Competitiveness (MINECO), through a predoctoral grant (BES-2012-057036)  in the framework of the project HARenES (FFI2011-30219-C02-02), and by the European Commission under the grant number H2020-645012-RIA. We also acknowledge support from the Maria de Maeztu Excellence Program (MDM-2015-0502). Many thanks to the three anonymous reviewers for insightful comments and suggestions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Concluding Remarks</head><p>We proposed a novel framework for modeling relational knowledge in word embeddings using rank-1 subspace regularization. Our model can be seen as a generalization of the constant translational model for relations <ref type="bibr" target="#b446">(Bordes et al., 2013;</ref><ref type="bibr" target="#b691">Xu et al., 2014)</ref>. In the future, we would like to study the interplay between word frequencies and the strength of regularization, and perform an exhaustive empirical evaluation. The study of higher rank subspaces for relation modeling is also an important future direction. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Word Embedding Calculus in Meaningful Ultradense</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgements</head><p>This paper is based on work supported by the DARPA-DEFT program. The views expressed are those of the authors and do not reflect the official policy or position of the Department of Defense or the U.S. Government. The authors thank the anonymous reviewers for helpful comments.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgments</head><p>We gratefully acknowledge the financial support of Siemens for this research.</p><p>Acknowledgements This research is partially funded by the ERC Starting Grant LOWLANDS (#313695). </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Acknowledgments</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Supplementary Material</head><p>The Sup. Material contains results, benchmark datasets, and code, downloadable at: https:// zenodo.org/record/51328.</p></div>
			</div>

			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Discussion</head><p>Overall, we have seen that our classifier for telling apart comments by mentioned trolls vs. such by non-trolls performs almost equally well for paid trolls vs. non-trolls, where the non-troll comments are sampled from the same threads that the troll comments come from. Moreover, the most and the least important features ablated from all are also similar. This suggests that mentioned trolls are very similar to paid trolls (except for their reply rate, time and day of posting patterns). However, using just mentions might be a "witch hunt": some users could have been accused of being "trolls" unfairly. One way to test this is to look not at comments, but at users and to see which users were called trolls by several different other users. <ref type="table">Table 7</ref> shows the results for distinguishing users with a given number of alleged troll comments from non-troll users; the classification is based on all comments by the corresponding users. We can see that finding users who have been called trolls more often is easier, which suggests they might be trolls indeed. Omer . Neural word embedding as implicit matrix factorization. In Advances in Neural Information Processing Systems. pages 2177-2185.</p><p>Omer . Improving distributional similarity with lessons learned from word embeddings. Transactions of the Association for Computational Linguistics pages 211-225.</p><p>Omer <ref type="bibr">Levy, Yoav Goldberg, and Israel RamatGan. 2014</ref>. Linguistic regularities in sparse and explicit word representations. CoNLL-2014 page 171.</p><p>Dekang <ref type="bibr">Lin. 1998</ref>. Automatic retrieval and clustering of similar words. In of the 36th and 17th , Volume 2. Montreal, Quebec, Canada, pages 768-774.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Our Approach</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Task Definition</head><p>We denote a set of users by . We assume that a user tweeting, retweeting or commenting on a microblog text reflects that the user is interested in that microblog. Given In this section, we introduce one baseline method and then propose two different neural network methods for user and microblog embedding. The baseline averages the vector representation of microblog texts into a user vector representation. Our proposed two methods learn user vector representations jointly with word and text vectors, either indirectly or directly from word vectors.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Paragraph Vector</head><p>As our methods are mainly based on the Paragraph Vector model proposed by <ref type="bibr" target="#b233">(Le and Mikolov, 2014)</ref>, we start by introducing this framework first.</p><p>Paragraph Vector is an unsupervised framework that learns continuous distributed vector representations for pieces of texts. In this approach, every paragraph is mapped to a unique vector, represented by a column in matrix D and every word is also mapped to a unique vector, represented by a column in matrix W . This approach is similar to the Word2Vec approach proposed in , except that a paragraph token is added to the paragraph and is treated as a special word. The paragraph vector is asked to contribute to the prediction work in addition to the word vectors in the context of the word to be predicted. The paragraph vector and word vectors are averaged to predict the next word in a context. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>., ) t i t k t k t p w d w w T</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head> </head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Averaging Microblog Text Vectors as User Vector</head><p>An intuitive baseline approach to map a microblog user into a vector space is to build such representation from the vector representations of the microblogs he or she likes. We treat microblog texts as paragraphs, and then apply the Paragraph Vector model introduced in Section 3.2 to learn vector representations of the microblog texts. After learning all vector representations of microblog texts, for each user, we average all vectors of microblog   texts he or she likes in the training set as the user vector.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">Learning User Vectors Indirectly From Word Vectors</head><p>Besides the above-mentioned baseline approach we further consider to jointly learn the vectors of users and microblog texts. In this framework, every user is mapped to a vector represented in a column in matrix U , in addition to the microblog text matrix D and the word matrixW . Given a microblog text The structure of this framework is shown in <ref type="figure">Figure 1</ref>. We name this framework User2Vec#1.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.5">Learning User Vectors Directly From Word Vectors</head><p>In the above framework, the user vectors are learned only from microblog text vectors, not directly from word vectors. Another framework we proposed for learning user vector representation is to put user vectors and microblog vectors in the same layer. Unlike User2Vec#1, we do not use user vectors to predict microblog text vector. Instead, we directly add user vectors into the input layer of word vector prediction task, along with the microblog text vector. In this framework, the average log probability we want to maximize is 1 1 ( log ( | , ,..., , ,..., )</p><p>In practical tasks, we modify the dataset by copying each microblog once for each user in ̃( ), and make each copied microblog text only relate to one user. All copies of the same microblog text share a same vector representation.</p><p>The structure of the framework is shown in <ref type="figure">Figure 2</ref>. We name this framework User2Vec#2.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.6">Recommending Microblogs</head><p>When recommending microblogs, given a microblog </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Evaluation</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Data Preparation</head><p>To evaluate our proposed user embedding methods in a scholarly microblog recommending system, we built a dataset by crawling from the website Machine Learning Daily 1 . The Machine Learning Daily is a Chinese website which focuses on collecting and labeling scholarly microblogs related to machine learning, natural language processing, information retrieval and data mining on Sina Weibo. These microblog texts were collected by a combination of manual and automatic methods, and each microblog text is annotated with multiple tags by experts, yielding an excellent dataset for our experiment. The microblog texts in our dataset can be written in a mixture of both Chinese and English. We removed stop words from the raw texts, leaving 16,797 words in our corpus. The texts were then segmented with the Jieba Chinese text segmentation tool 2 . </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Machine Translation Evaluation Meets Community Question Answering</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Abstract</head><p>We explore the applicability of machine translation evaluation (MTE) methods to a very different problem: answer ranking in community Question Answering. In particular, we adopt a pairwise neural network (NN) architecture, which incorporates MTE features, as well as rich syntactic and semantic embeddings, and which efficiently models complex non-linear interactions. The evaluation results show state-of-the-art performance, with sizeable contribution from both the MTE features and from the pairwise NN architecture.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction and Motivation</head><p>In a community Question Answering (cQA) task, we are given a question from a community forum and a thread of associated text comments intended to answer the given question; and the goal is to rank the comments according to their appropriateness to the question. Since cQA forum threads are noisy (e.g., because over time people tend to engage in discussion and to deviate from the original question), as many comments are not answers to the question, the challenge lies in learning to rank all good comments above all bad ones.</p><p>Here, we adopt the definition and the datasets from SemEval-2016 Task 3  on "Community Question Answering", focusing on subtask A (Question-Comment Similarity) only. 1 See the task description paper and the task website 2 for more detail. An annotated example is shown in <ref type="figure">Figure 1.</ref> 1 SemEval-2016 Task 3 had two more subtasks: subtask B on Question-Question Similarity, and subtask C on QuestionExternal Comment Similarity, which are out of our scope. However, they could be potentially addressed within our general MTE-NN framework, with minor variations.</p><p>2 http://alt.qcri.org/semeval2016/task3/ In this paper, we tackle the task from a novel perspective: by using ideas from machine translation evaluation (MTE) to decide on the quality of a comment. In particular, we extend our MTE neural network framework from <ref type="bibr" target="#b274">(Guzmán et al., 2015)</ref>, showing that it is applicable to the cQA task as well. We believe that this neural network is interesting for the cQA problem because: (i) it works in a pairwise fashion, i.e., given two translation hypotheses and a reference translation to compare to, the network decides which translation hypothesis is better, which is appropriate for a ranking problem; (ii) it allows for an easy incorporation of rich syntactic and semantic embedded representations of the input texts, and it efficiently models complex non-linear relationships between them; (iii) it uses a number of machine translation evaluation measures that have not been explored for the cQA task before, e.g., TER <ref type="bibr" target="#b288">(Snover et al., 2006)</ref>, METEOR <ref type="bibr" target="#b277">(Lavie and Denkowski, 2009)</ref>, and BLEU <ref type="bibr" target="#b284">(Papineni et al., 2002)</ref>.</p><p>The analogy we apply to adapt the neural MTE architecture to the cQA problem is the following: given two comments c 1 and c 2 from the question thread-which play the role of the two competing translation hypotheses-we have to decide whether c 1 is a better answer than c 2 to question q-which plays the role of the translation reference. If we have a function f (q, c 1 , c 2 ) to make this decision, then we can rank the finite list of comments in the thread by comparing all possible pairs and by accumulating for each comment the scores for it given by f .</p><p>From a general point of view, MTE and the cQA task addressed in this paper seem similar: both reason about the similarity of two competing texts against a reference text in order to decide which one is better. However, there are some profound differences, which have implications on how each task is solved. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Abstract</head><p>We present improvements to our incremental proposition-based summariser, which is inspired by <ref type="bibr" target="#b340">Kintsch and van Dijk's (1978)</ref> text comprehension model. Argument overlap is a central concept in this summariser. Our new model replaces the old overlap method based on distributional similarity with one based on lexical chains. We evaluate on a new corpus of 124 summaries of educational texts, and show that our new system outperforms the old method and several stateof-the-art non-proposition-based summarisers. The experiment also verifies that the incremental nature of memory cycles is beneficial in itself, by comparing it to a non-incremental algorithm using the same underlying information.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Machine Comprehension using Rich Semantic Representations</head><p>Mrinmaya Sachan Eric P. Xing School of Computer Science Carnegie Mellon University {mrinmays, epxing}@cs.cmu.edu</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Abstract</head><p>Machine comprehension tests the system's ability to understand a piece of text through a reading comprehension task. For this task, we propose an approach using the Abstract Meaning Representation (AMR) formalism. We construct meaning representation graphs for the given text and for each question-answer pair by merging the AMRs of comprising sentences using cross-sentential phenomena such as coreference and rhetorical structures. Then, we reduce machine comprehension to a graph containment problem. We posit that there is a latent mapping of the question-answer meaning representation graph onto the text meaning representation graph that explains the answer. We present a unified max-margin framework that learns to find this mapping (given a corpus of texts and question-answer pairs), and uses what it learns to answer questions on novel texts. We show that this approach leads to state of the art results on the task.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Appendix</head><p>In this Appendix, we discuss the relationships between CL-LSI and CL-Eigenwords. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Semantics-Driven Recognition of Collocations Using Word Embeddings</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Abstract</head><p>L2 learners often produce "ungrammatical" word combinations such as, e.g., *give a suggestion or *make a walk. This is because of the "collocationality" of one of their items (the base) that limits the acceptance of collocates to express a specific meaning ('perform' above). We propose an algorithm that delivers, for a given base and the intended meaning of a collocate, the actual collocate lexeme(s) (make / take above). The algorithm exploits the linear mapping between bases and collocates from examples and generates a collocation transformation matrix which is then applied to novel unseen cases. The evaluation shows a promising line of research in collocation discovery. <ref type="bibr" target="#b428">Lin, 1999;</ref><ref type="bibr" target="#b426">Kilgarriff, 2006;</ref><ref type="bibr" target="#b415">Evert, 2007;</ref><ref type="bibr" target="#b436">Pecina, 2008;</ref><ref type="bibr" target="#b407">Bouma, 2010;</ref><ref type="bibr" target="#b418">Futagi et al., 2008;</ref><ref type="bibr" target="#b419">Gao, 2013)</ref>. Most of this work is based on statistical measures that indicate how likely the elements of a possible collocation are to co-occur, while ignoring the semantics of the collocations. Semantic classification of collocations has been addressed, for instance, in <ref type="bibr" target="#b441">(Wanner et al., 2006;</ref><ref type="bibr" target="#b420">Gelbukh and Kolesnikova., 2012;</ref><ref type="bibr" target="#b433">Moreno et al., 2013;</ref>. However, to the best of our knowledge, our work is the first to automatically retrieve and typify collocations simultaneously. We have illustrated our approach with 10 semantic collocation glosses. We believe that this approach is also valid for the coverage of the remaining glosses <ref type="bibr" target="#b429">(Mel'čuk (1996)</ref> lists in his typology 64 glosses in total).</p><p>Distributed vector representations (or word embeddings) ), which we use, have proven useful in a plethora of NLP tasks, including semantic similarity and relatedness <ref type="bibr" target="#b424">(Huang et al., 2012;</ref><ref type="bibr" target="#b408">Camacho-Collados et al., 2015;</ref><ref type="bibr" target="#b425">Iacobacci et al., 2015)</ref>, dependency parsing <ref type="bibr" target="#b414">(Duong et al., 2015)</ref>, and Named Entity Recognition <ref type="bibr" target="#b440">(Tang et al., 2014)</ref>. We show that they also work for semantic retrieval of collocations. Only a small amount of collocations and big unannotated corpora have been necessary to perform the experiments. This makes our approach highly scalable and portable. Given the lack of semantically tagged collocation resources for most languages, our work has the potential to become influential in the context of second language learning. The datasets on which we performed the experiments as well as the details concerning the code and its use can be found at http://www.taln.upf.edu/content/resources/765. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Incorporating</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Abstract</head><p>Incorporating lexical knowledge from semantic resources (e.g., WordNet ) has been shown to improve the quality of distributed word representations. This knowledge often comes in the form of relational triplets (x, r, y) where words x and y are connected by a relation type r. Existing methods either ignore the relation types, essentially treating the word pairs as generic related words, or employ rather restrictive assumptions to model the relational knowledge. We propose a novel approach to model relational knowledge based on low-rank subspace regularization, and conduct experiments on standard tasks to evaluate its effectiveness.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Distributed word representations, also known as word embeddings, are low-dimensional vector representations for words that capture semantic aspects . The algorithms for learning the word embeddings rely on distributional hypothesis (Harris, 1954) that words occurring in similar contexts tend to have similar meanings. Word embeddings have been shown to capture interesting linguistic regularities by simple vector arithmetic (e.g., v(king)-v(man)+v(woman)≈ v(queen)) . They have also been used to derive downstream features for various NLP tasks, such as named entity recognition, chunking, dependency parsing, sentiment analysis, paraphrase detection and machine translation <ref type="bibr" target="#b449">Dhillon et al., 2011;</ref><ref type="bibr" target="#b458">Maas et al., 2011;</ref><ref type="bibr" target="#b465">Socher et al., 2011;</ref><ref type="bibr" target="#b470">Zou et al., 2013)</ref>. Their promise as semantic word representations has led to increasing research efforts on improving their quality.</p><p>To this end, researchers have attempted to incorporate lexical knowledge into word embeddings by using additional regularization or loss terms in the learning objective. This lexical knowledge is often available in the form of triplets {(w i , r, w j )}, where the words w i and w j are connected by relation type r. These methods can be broadly classified into two categories. First family of methods use a (over-)generalized notion of similarity between words and ignore the type of relations, essentially treating the two words as generic similar words <ref type="bibr" target="#b469">(Yu and Dredze, 2014;</ref>. This places an implicit restriction on the types of relations that can be used with these methods. Second family of methods model each relation type by a distinct operator. <ref type="bibr" target="#b446">Bordes et al. (2013)</ref> assumed a distinct relation vector r for every relation and minimize the distance between the translated first word and the second word, i.e., d(w i + r, w j ) for every triplet (w i , r, w j ).  proposed a neural tensor network which uses a distinct tensor operator for every relation. These methods were used to learn entity and relation embeddings from a large collection of relation triplets for the task of knowledge base completion. Since these methods did not use any co-occurrence information from a text corpus, all entities were required to appear at least once in the training data, ruling out generalization to unseen entities 1 . More recently, <ref type="bibr" target="#b691">Xu et al. (2014)</ref> combined the training objective of SKIP-GRAM  with the training objective of <ref type="bibr" target="#b446">(Bordes et al., 2013</ref>) to incorporate lexical 1 There exists work on relation extraction and knowledgebase completion that combines structured relation triplets and logical rules with unstructured text using various forms of latent variable models <ref type="bibr" target="#b463">(Riedel et al., 2013;</ref><ref type="bibr" target="#b468">Chang et al., 2014;</ref><ref type="bibr" target="#b466">Toutanova et al., 2015;</ref><ref type="bibr" target="#b464">Rocktäschel et al., 2015)</ref>. 506 knowledge into word embeddings. <ref type="bibr" target="#b452">Fried and Duh (2014)</ref> combine the training objective of <ref type="bibr" target="#b446">(Bordes et al., 2013)</ref> with that of neural language model  using alternating direction method of multipliers <ref type="bibr" target="#b447">(Boyd et al., 2011)</ref>.</p><p>Constant translation model <ref type="bibr" target="#b446">(Bordes et al., 2013;</ref><ref type="bibr" target="#b691">Xu et al., 2014;</ref><ref type="bibr" target="#b452">Fried and Duh, 2014</ref>) (referred as CTM from now on), although an important step in modeling relational knowledge, makes a rather restrictive assumption requiring all triplets (w i , r, w j ) pertaining to a relation type r to satisfy w i + r ≈ w j , ∀(i, j). This restriction can be severe when learning from a large text corpus since vector representation of a word also needs to respect a huge set of co-occurrence instances with other words. CTM is also not suitable for (i) modeling symmetric relations (e.g., synonyms, antonyms), and (ii) modeling transitive relations (e.g., synonyms, hypernyms). In this paper, we propose a novel formulation for modeling the relational knowledge which addresses these issues by relaxing the constant translation assumption and modeling each relation by a low-rank subspace, i.e., all the word pairs pertaining to a relation are assumed to lie in a low-rank subspace. We demonstrate effectiveness of the learned word representations on the tasks of knowledge-base completion and word analogy.</p><p>2 Subspace-regularized word embedding Although our proposed framework for relational modeling is general enough to use with any existing word embedding method, we work with Word2Vec model  in this paper for illustrating our ideas and later for empirical evaluations. Word2Vec is a neural network model trained on sequence of words and its hidden layer activations can be read out as the word representations. Two variants were proposed in ) -SKIP-GRAM, which maximizes the log likelihood of the local context words given the target word, and CBOW, which maximizes the log likelihood of the target word given its local context. More specifically, CBOW maximizes the objective</p><p>where w t+c t−c represents the words (or tokens) in the local context window around the t'th word (or token) and v t = −c≤i≤c,i =0 w t+i can be seen as the average context vector. The vectors w, w ∈ R d denote the input and output embeddings for word w, respectively. The input embeddings are taken as the final word representations. Negative sampling was proposed to efficiently optimize Eq. 1 . We report empirical results with CBOW since it was computationally faster than SKIP-GRAM while giving similar results in our early explorations.</p><p>We assume access to relational knowledge in the form of triplets R k = {(w i , r k , w j )} ∀1 ≤ k ≤ m, where words w i and w j are connected by relation r k and R k is the set of all triplets corresponding to relation r k with |R k | = n k . This form of knowledge is commonly available from Knowledge Bases like WordNet <ref type="bibr" target="#b477">(Fellbaum, 1998)</ref>. Our framework is suitable for both symmetric relations where words can be interchanged (e.g., synonyms) and asymmetric relations which have a directional nature (e.g., hypernyms).</p><p>Let</p><p>denote the difference vector for the triplet (w i , r k , w j ) which points from the vector of word w i to that of word w j . Let us construct a matrix D k ∈ R d×n k by stacking the difference vectors corresponding to all the triplets in relation r k , i.e.,</p><p>To incorporate this relational knowledge into word embeddings, we enforce an approximate low-rank constraint on D k assuming</p><p>where U k ∈ R d×p , p d is the relation basis whose linear span contains all the difference vectors pertaining to relation r k . For p = 2, this assumption implies that all the difference vectors pertaining to a relation lie in a 2-D plane. For</p><p>implying that all the difference vectors for a relation are collinear. In this paper, we mainly study the rank-1 model (p=1) since it seems to be a natural starting point for evaluating the idea of subspace-regularized relational modeling. The study of higher rank models will potentially require a careful exploration of various structural regularizers for reconstruction matrix A k as well as a different evaluation scheme. We leave this study for future work.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Is "Universal Syntax" Universally Useful for Learning Distributed Word Representations? Ivan Vulić and Anna Korhonen</head><p>Language Technology Lab DTAL, University of Cambridge {iv250, alk23}@cam.ac.uk</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Abstract</head><p>Recent comparative studies have demonstrated the usefulness of dependencybased contexts (DEPS) for learning distributed word representations for similarity tasks. In English, DEPS tend to perform better than the more common, less informed bag-of-words contexts (BOW). In this paper, we present the first crosslinguistic comparison of different context types for three different languages. DEPS are extracted from "universal parses" without any language-specific optimization. Our results suggest that the universal DEPS (UDEPS) are useful for detecting functional similarity (e.g., verb similarity, solving syntactic analogies) among languages, but their advantage over BOW is not as prominent as previously reported on English. We also show that simple "post-parsing" filtering of useful UDEPS contexts leads to consistent improvements across languages.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Dense real-valued distributed representations of words known as word embeddings (WEs) have become ubiquitous in NLP, serving as invaluable features in a broad range of NLP tasks, e.g., <ref type="bibr" target="#b496">Chen and Manning, 2014)</ref>. The omnipresent word2vec skip-gram model with negative sampling (SGNS) ) is still considered the stateof-the-art word representation model, due to its simplicity, fast training, as well as its solid and robust performance across a wide variety of semantic tasks .</p><p>The original implementation of SGNS learns word representations from local bag-of-words contexts (BOW). However, the underlying SGNS model is equally applicable to other context types.</p><p>Recent comparative studies have demonstrated the usefulness of dependency-based contexts (DEPS) <ref type="bibr" target="#b517">(Padó and Lapata, 2007)</ref> for the task. In comparison with BOW, syntactic contexts steer the induced semantic spaces towards functional similarity (e.g., tiger:cat) rather than towards topical similarity/relatedness (e.g., tiger:jungle). DEPS-based embeddings outperform the less informed BOW-based embeddings in a variety of similarity tasks <ref type="bibr" target="#b512">Melamud et al., 2016)</ref>. However, these studies have all focused solely on English. A comparison extending to additional languages is required before any cross-lingual generalisations can be drawn.</p><p>Following recent initiatives on languageagnostic and cross-linguistically consistent universal natural language processing (i.e., universal POS (UPOS) tagging and dependency (UD) parsing) <ref type="bibr" target="#b516">(Nivre et al., 2015)</ref>, this paper is concerned with two important questions:</p><p>(Q1) Can one usefully replace the DEPS extraction pipeline optimised for tools developed for English with a pipeline that relies on languageuniversal syntactic processing (UDEPS)?</p><p>(Q2) Are UDEPS universally better than BOW for learning distributed word representations in other languages?</p><p>Regarding Q1, the results show that it is possible to replace original DEPS with UDEPS for English and to obtain benchmarking results with only a slight drop in performance. As for Q2, the framework is not equally effective in other languages, as suggested by the performance in Italian and German, which sheds new light on the usefulness of BOW and dependency-based contexts. Further, the results reveal that even a simple preliminary "post-parsing" selection of use-518 ful UDEPS contexts leads to consistent improvements across languages, especially in detecting functional similarity.</p><p>This focused contribution is the first crosslinguistic comparison of different context types for learning word representations in three languages, reaching beyond English. It also constitutes a first completely language-universal and widely applicable framework for UDEPS extraction.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Methodology</head><p>Universal Multilingual Resources The departure point in our experiments is the Universal Dependencies project <ref type="bibr" target="#b516">Nivre et al., 2015)</ref> which develops crosslinguistically consistent treebank annotation. <ref type="bibr">1</ref> The annotation scheme leans on the universal Stanford dependencies <ref type="bibr" target="#b500">(de Marneffe et al., 2014)</ref> complemented with the Google universal POS tagset <ref type="bibr" target="#b518">(Petrov et al., 2012)</ref> and the Interset interlingua for morphological tagsets . It provides a universal and consistent inventory of categories for similar syntactic constructions across languages.</p><p>The main aim of the "universal initiative" is to facilitate cross-lingual and multilingual learning (e.g., multilingual parser development, typologies) by capturing structural similarities across languages and by exploiting connections that exist naturally between them . Here, we test the ability of such a universal annotation scheme to encode potentially useful semantic knowledge crosslinguistically; in this case, to yield more informed UDEPS contexts for improved word embeddings.</p><p>The extraction of UDEPS as the new variant of dependency-based contexts is completely language-agnostic on purpose: exactly the same procedure is followed for each language in comparison in order to make the representation learning framework completely universal.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Context Types</head><p>Prequel: Representation Model For all the context types, we opt for the standard and robust choice in vector space modeling: SGNS . In all our experiments we use word2vecf, a reimplementa- </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Abstract</head><p>Computational Argumentation has two main goals -the detection and analysis of arguments on the one hand, and the synthesis of arguments on the other. Much attention has been given to the former, but considerably less to the latter. A key component in synthesizing arguments is the synthesis of claims. One way to do so is by employing argumentation mining to detect claims within an appropriate corpus. In general, this appears to be a hard problem. Thus, it is interesting to explore if -for the sake of synthesis -there may be other ways to generate claims.</p><p>Here we explore such a method: we extract the predicate of simple, manuallydetected, claims, and attempt to generate novel claims from them. Surprisingly, this simple method yields fairly good results.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>When people argue, how do they come up with the arguments they present, and can a machine emulate this? The motivation for this work comes from this second question, for which the relevant field of study is Computational Argumentation, an emerging field with roots in Computer Science, Mathematics, Philosophy and Rhetorics. However, while much attention is given in the field to the modeling and analysis of arguments, automatic synthesis of arguments receives considerably less.</p><p>So, how do people come up with arguments? One way is to read-up on the topic and present the arguments you find in the literature. Another -if the topic at hand is within your field of expertise -is to communicate your opinion. Yet a third way is to "recycle" arguments you are familiar with and apply them to new domains. For example, someone who's concerned about the free speech might use an argument like "it's a violation of free speech" when discussing any one of these topics: whether violent video games should be banned, whether some Internet content should be censored, or whether certain types of advertisement should be restricted.</p><p>Argumentation Mining (Mochales <ref type="bibr" target="#b535">Palau and Moens, 2011</ref>) is analogous to the first option: Given a corpus, it aims to detect arguments therein (and the relations among them). Thus, it can be used to suggest claims when a relevant corpus is available. The second option is analogous to Natural Language Generation (NLG; <ref type="bibr" target="#b536">(Reiter and Dale, 2000)</ref>), where applications such as recommender systems synthesize arguments to explain their recommendations, as done for example in <ref type="bibr">(Carenini and Moore, 2006)</ref> . These approaches yield good results when applied to specific domains. In an NLG application, there is commonly a specific knowledge base which the system communicates. The form and content of arguments are derived and determined by it and are thus limited to the knowledge therein. Similarly, argument mining works well when an argument-rich and topic-related corpus is available -e.g. <ref type="bibr" target="#b541">(Wyner et al., 2010</ref>) -but in general seems to be hard . Thus, it is interesting and challenging to synthesize arguments in an open domain. To the best of our knowledge, this is the first work that directly attempts to address this task.</p><p>Modeling of arguments goes back to the ancient Greeks and Aristotle, and more modern work starting perhaps most famously with the Toulmin argument model <ref type="bibr" target="#b538">(Toulmin, 1958)</ref>. A common element in all such models is the claim (or conclusion) being forwarded by the argument. Thus, a natural first step in synthesizing arguments in a general setting is being able to synthesize claims in such a setting.</p><p>We suggest here a simple way for doing so, 525 based on the aforementioned notion of argument "recycling". Specifically, that the predicate of a claim -what it says on the topic at hand -may be applicable to other topics as well. For example, if we are familiar with the claim "banning violent video games is a violation of free speech" in the context of the topic "banning violent video games", we could synthesize the claim "Internet censorship is a violation of free speech" when presented with the topic "Internet Censorship". The challenge is then to determine whether the synthesized claim is actually coherent and relevant to the new topic, which we do using statistical Machine Learning techniques, as described in Section 2.1. This two-stages framework -generating text and then selecting whether or not it is appropriateis reminiscent of Statistical NLG (SNLG; <ref type="bibr">(Langklide and Knight, 1998)</ref>). In an SNLG system, after the macro-planning and micro-planning stages (see <ref type="bibr" target="#b536">(Reiter and Dale, 2000)</ref>) are executed, and the message to be communicated is determined, multiple candidate realizations are produced, and then statistical methods are used to determine which of these realizations is the best (based on a reference corpus).</p><p>Our work differs from SNLG in that there are no pre-determined messages. The generation stage produces candidate content. Each candidate claim is a different message, and the selection stage attempts to identify those which are coherent and relevant, rather than best realized. In other words, while the classical NLG paradigm is to first select the content and then realize it in a natural language, here our building blocks from the onset are natural language elements, and statistical methods are used to determine which content selectionsimplied by combining them -are valid.</p><p>Finally, the notion that predicates of claims regarding one topic may be applicable to another is reminiscent of the motivation for the work of <ref type="bibr" target="#b526">(Card et al., 2015)</ref>, who observe that there are commonalities (so called "framing dimensions") among the way different topics are framed in news articles.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Algorithm</head><p>The claim synthesis algorithm is composed of three components. The first is a pre-processing component, in which the Predicate Lexicon is constructed. The second is the Generation Component -the input to this component is a topic (and the Predicate Lexicon), and the output is a list of candidate claims. The final component is the Selection Component, in which a classifier is used to determine which (if any) of the candidate claims are coherent and relevant for the topic. In what follows we describe these three steps in greater detail.</p><p>The Predicate Lexicon (PL) was constructed by parsing manually-detected claims (Aharoni et al., 2014) using the Watson ESG parser <ref type="bibr" target="#b533">(McCord et al., 2012)</ref>, and considering those which have exactly one verb. Then the verb and a concatenation of its right-modifiers, termed here the predicate, were extracted from each claim and added to the PL if they contained at least one sentiment word from the sentiment lexicon of . The sentiment criterion was added to select for predicates which have a clear stance with respect to the topic. All in all, there are 1203 entries in the PL used here. <ref type="bibr">1</ref> A key feature in filtering and selecting candidate claims is text similarity. The similarity between text segments was defined based on the constituent words' word2vec embedding : Consider two list of words, l = w 1 , . . . , w n and l = w 1 , . . . , w n . Denote by w2v(w, w ) the word2vec similarity between w and w -the cosine of the angle between the embeddings of w and w . Then the similarity between l and l is defined : sim(l, l ) = 1 n i=1,...,n max j=1,...,n w2v(w i , w j ) + 1 n j=1,...,n max i=1,...,n w2v(w j , w i ) (words without embeddings are ignored). Additionally, if S is a set of text segments, define:</p><p>Given a new topic t, the Generation Component sorts the predicates p in the PL according to sim(t, p), and takes the top k. It then constructs k claim candidate sentences by setting the subject of the sentence to be the topic t, and the predicate to be one of these k. This may require some manipulation, as the plurality of the topic determines the appropriate surface realization of the predicate verb. We determine the topic's plurality using the Watson parser <ref type="bibr" target="#b533">(McCord et al., 2012)</ref>, and do the surface realization with SimpleNLG <ref type="bibr" target="#b528">(Gatt and Reiter, 2009)</ref>  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Abstract</head><p>Traditional topic models do not account for semantic regularities in language. Recent distributional representations of words exhibit semantic consistency over directional metrics such as cosine similarity. However, neither categorical nor Gaussian observational distributions used in existing topic models are appropriate to leverage such correlations. In this paper, we propose to use the von Mises-Fisher distribution to model the density of words over a unit sphere. Such a representation is well-suited for directional data. We use a Hierarchical Dirichlet Process for our base topic model and propose an efficient inference algorithm based on Stochastic Variational Inference. This model enables us to naturally exploit the semantic structures of word embeddings while flexibly discovering the number of topics. Experiments demonstrate that our method outperforms competitive approaches in terms of topic coherence on two different text corpora while offering efficient inference. 1</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Prior work on topic modeling has mostly involved the use of categorical likelihoods <ref type="bibr" target="#b572">Blei and Lafferty, 2006;</ref><ref type="bibr" target="#b589">Rosen-Zvi et al., 2004)</ref>. Applications of topic models in the textual domain treat words as discrete observations, ignoring the semantics of the language. Recent developments in distributional representations of words   2014) have succeeded in capturing certain semantic regularities, but have not been explored extensively in the context of topic modeling. In this paper, we propose a probabilistic topic model with a novel observational distribution that integrates well with directional similarity metrics.</p><p>One way to employ semantic similarity is to use the Euclidean distance between word vectors, which reduces to a Gaussian observational distribution for topic modeling <ref type="bibr" target="#b576">(Das et al., 2015)</ref>. The cosine distance between word embeddings is another popular choice and has been shown to be a good measure of semantic relatedness . The von Mises-Fisher (vMF) distribution is well-suited to model such directional data <ref type="bibr" target="#b577">(Dhillon and Sra, 2003;</ref><ref type="bibr" target="#b571">Banerjee et al., 2005)</ref> but has not been previously applied to topic models.</p><p>In this work, we use vMF as the observational distribution. Each word can be viewed as a point on a unit sphere with topics being canonical directions. More specifically, we use a Hierarchical Dirichlet Process (HDP) <ref type="bibr" target="#b590">(Teh et al., 2006)</ref>, a Bayesian nonparametric variant of Latent Dirichlet Allocation (LDA), to automatically infer the number of topics. We implement an efficient inference scheme based on Stochastic Variational Inference (SVI) <ref type="bibr" target="#b580">(Hoffman et al., 2013)</ref>.</p><p>We perform experiments on two different English text corpora: 20 NEWSGROUPS and NIPS and compare against two baselines -HDP and Gaussian LDA. Our model, spherical HDP (sHDP), outperforms all three systems on the measure of topic coherence. For instance, sHDP obtains gains over Gaussian LDA of 97.5% on the NIPS dataset and 65.5% on the 20 NEWSGROUPS dataset. Qualitative inspection reveals consistent topics produced by sHDP. We also empirically demonstrate that employing SVI leads to efficient 537 topic inference.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Related Work</head><p>Topic modeling and word embeddings <ref type="bibr" target="#b576">Das et al. (2015)</ref> proposed a topic model which uses a Gaussian distribution over word embeddings. By performing inference over the vector representations of the words, their model is encouraged to group words that are semantically similar, leading to more coherent topics. In contrast, we propose to utilize von Mises-Fisher (vMF) distributions which rely on the cosine similarity between the word vectors instead of euclidean distance.</p><p>vMF in topic models The vMF distribution has been used to model directional data by placing points on a unit sphere <ref type="bibr" target="#b577">(Dhillon and Sra, 2003)</ref>. <ref type="bibr" target="#b588">Reisinger et al. (2010)</ref> propose an admixture model that uses vMF to model documents represented as vector of normalized word frequencies. This does not account for word level semantic similarities. Unlike their method, we use vMF over word embeddings. In addition, our model is nonparametric.</p><p>Nonparametric topic models HDP and its variants have been successfully applied to topic modeling <ref type="bibr" target="#b586">(Paisley et al., 2015;</ref>; however, all these models assume a categorical likelihood in which the words are encoded as one-hot representation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Model</head><p>In this section, we describe the generative process for documents. Rather than one-hot representation of words, we employ normalized word embeddings  to capture semantic meanings of associated words. Word n from document d is represented by a normalized Mdimensional vector x dn and the similarity between words is quantified by the cosine of angle between the corresponding word vectors.</p><p>Our model is based on the Hierarchical Dirichlet Process (HDP). The model assumes a collection of "topics" that are shared across documents in the corpus. The topics are represented by the topic centers µ k ∈ R M . Since word vectors are normalized, the µ k can be viewed as a direction on unit sphere. Von Mises−Fisher (vMF) is a distribution that is commonly used to model directional data. The likelihood of the topic k for word</p><p>Figure 1: Graphical representation of our spherical HDP (sHDP) model. The symbol next to each random variable denotes the parameter of its variational distribution. We assume D documents in the corpus, each document contains N d words and there are countably infinite topics represented by</p><p>is:</p><p>where κ k is the concentration of the topic k, the</p><p>is the normalization constant, and I ν (·) is the modified Bessel function of the first kind at order ν. Interestingly, the log-likelihood of the vMF is proportional to µ T k x dn (up to a constant), which is equal to the cosine distance between two vectors. This distance metric is also used in <ref type="bibr" target="#b534">Mikolov et al. (2013)</ref> to measure semantic proximity.</p><p>When sampling a new document, a subset of topics determine the distribution over words. We let z dn denote the topic selected for the word n of document d. Hence, z dn is drawn from a categorical distribution: z dn ∼ Mult(π d ), where π d is the proportion of topics for document d. We draw π d from a Dirichlet Process which enables us to estimate the the number of topics from the data. The generative process for the generation of new document is as follows:</p><p>where GEM(γ) is the stick-breaking distribution with concentration parameter γ, DP(α, β) is a Dirichlet process with concentration parameter α and stick proportions β <ref type="bibr">(Teh et al., 2012</ref> </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Abstract</head><p>Big data presents new challenges for understanding large text corpora. Topic modeling algorithms help understand the underlying patterns, or "topics", in data. Researchersauthor often read these topics in order to gain an understanding of the underlying corpus. It is important to evaluate the interpretability of these automatically generated topics. Methods have previously been designed to use crowdsourcing platforms to measure interpretability. In this paper, we demonstrate the necessity of a key concept, coherence, when assessing the topics and propose an effective method for its measurement. We show that the proposed measure of coherence captures a different aspect of the topics than existing measures. We further study the automation of these topic measures for scalability and reproducibility, showing that these measures can be automated. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Abstract</head><p>Scoring the quality of persuasive essays is an important goal of discourse analysis, addressed most recently with highlevel persuasion-related features such as thesis clarity, or opinions and their targets. We investigate whether argumentation features derived from a coarse-grained argumentative structure of essays can help predict essays scores. We introduce a set of argumentation features related to argument components (e.g., the number of claims and premises), argument relations (e.g., the number of supported claims) and typology of argumentative structure (chains, trees). We show that these features are good predictors of human scores for TOEFL essays, both when the coarsegrained argumentative structure is manually annotated and automatically predicted.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Single-Model Encoder-Decoder with Explicit Morphological</head><p>Representation for Reinflection </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Morphological analysis and generation of previously unseen word forms is a fundamental problem in many areas of natural language processing (NLP). Its accuracy is crucial for the success of downstream tasks like machine translation and question answering. Accordingly, learning morphological inflection patterns from labeled data is an important challenge. The task of morphological reinflection (MRI) consists of producing an inflected form for a given source form, source tag and target tag. A special case is morphological inflection (MI), the task of finding an inflected form for a given lemma and target tag. An English example is "tree"+PLURAL → "trees". Prior work on MI and MRI includes machine learning models and models that exploit the paradigm structure of the language <ref type="bibr" target="#b632">(Ahlberg et al., 2015;</ref><ref type="bibr" target="#b639">Dreyer, 2011;</ref><ref type="bibr" target="#b652">Nicolai et al., 2015)</ref>.</p><p>In this work, we propose the neural encoderdecoder MED -Morphological Encoder-Decoder -a character-level sequence-to-sequence attention model that is a language-independent solution for MRI. In contrast to prior work, we train a single model that is trained on all source to target mappings of the language that are attested in the training set. This radically reduces the amount of training data needed for the encoder-decoder because most MRI patterns occur in many source-target tag pairs. In our model design, what is learned for one pair can be transferred to others.</p><p>The key enabler for this single-model approach is a novel representation we use for MRI. We encode the input as a single sequence of (i) the morphological tags of the source form, (ii) the morphological tags of the target form and (iii) the sequence of letters of the source form. The output is the sequence of letters of the target form. As the decoder produces each letter, the attention mechanism can focus on the input letter sequence for parts of the output that simply copy the input. For other parts of the output, e.g., an inflectional ending that is predicted using the target tags, the attention mechanism can focus on the target morphological tags. In more complex cases, simultaneous attention can be paid to subsequences of all three input types -source tags, target tags and input letter sequence. We can train a single generic encoder-decoder per language on this representation that can handle all tag pairs, thus making it possible to make efficient use of the available training data. MED outperformed other systems on the SIGMORPHON16 shared task 1 for all ten languages that were covered <ref type="bibr" target="#b649">(Kann and Schütze, 2016;</ref><ref type="bibr">Cotterell et al., 2016)</ref>.</p><p>We also present POET -Prefer Observed Edit Trees -a new generic method for correcting the output of an MRI system. The combination of MED and POET is state-of-the-art or close to it on a CELEX-based evaluation of MRI even though this evaluation makes it difficult to exploit gener-1 ryancotterell.github.io/ sigmorphon2016/ 555 alizations across tag pairs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Model Description</head><p>Neural network model. Our model is based on the network architecture proposed by  for machine translation. 2 They describe the model in detail; unless we explicitly say so in the description of our model below, we use the same network configuration as . 's model is an extension of the recurrent neural network (RNN) encoderdecoder developed by  and . The encoder of the latter consists of an RNN that reads an input sequence of vectors x and encodes it into a fixed-length context vector c, computing hidden states h t and c by</p><p>with nonlinear functions f and q. The decoder is trained to predict each output y t dependent on c and previous predictions y 1 , ..., y t−1 :</p><p>with y = (y 1 , ..., y Ty ) and each conditional probability being modeled with an RNN as p(y t |{y 1 , ..., y t−1 }, c) = g(y t−1 , s t , c)</p><p>where g is a nonlinear function and s t is the hidden state of the RNN.  proposed an attentionbased extension of this model that allows different vectors c t for each step by automatic learning of an alignment model. Additionally, they made the encoder bidirectional: each hidden state h j at time step j does not only depend on the preceding, but also on the following input:</p><p>The formula for p(y) changes as follows: </p><p>2 Our implementation of MED is based on github.com/mila-udem/blocks-examples/ tree/master/machine_translation. with s t being an RNN hidden state for time t and c t being the weighted sum of the annotations (h 1 , ..., h Tx ) produced by the encoder, using the attention weights. Further descriptions can be found in .</p><p>The final model is a multilayer network with a single maxout <ref type="bibr" target="#b643">(Goodfellow et al., 2013)</ref> hidden layer that computes the conditional probability of each element in the output sequence (a letter in our case, <ref type="bibr" target="#b653">(Pascanu et al., 2014)</ref>). As MRI is less complex than machine translation, we reduce the number of hidden units and embedding size. After initial experiments, we fixed the hyperparameters of our system and did not further adapt them to a specific task or language. Encoder and decoder RNNs have 100 hidden units each. For training, we use stochastic gradient descent, Adadelta (Zeiler, 2012) and a minibatch size of 20. We initialize all weights in the encoder, decoder and the embeddings except for the GRU weights in the decoder with the identity matrix as well as all biases with zero <ref type="bibr" target="#b650">(Le et al., 2015)</ref>. We train all models for 20,000 iterations. We settled on this number in early experimentation because training usually converged before that limit.</p><p>MED is an ensemble of five RNN encoderdecoders. The final decision is made by majority voting. In case of a tie, the answer is chosen randomly among the most frequent predictions.</p><p>Input and output format. We define the alphabet Σ lang as the set of characters used in the application language. As each morphological tag consists of one or more subtags, e.g. "number" or "case", we further define Σ src and Σ trg as the set of morphological subtags seen during training as part of the source tag and target tag, respectively. Let S start and S end be predefined start and end symbols. Then each input of our system is of the format S start Σ src + Σ trg + Σ lang + S end . In the same way, we define the output format as S start Σ lang + S end .</p><p>A sample input for German is &lt;w&gt; IN=pos=ADJ IN=case=GEN IN=num=PL OUT=pos=ADJ OUT=case=ACC OUT=num=PL i s o l i e r t e r &lt;/w&gt;. The system should produce the corresponding output &lt;w&gt; i s o l i e r t e &lt;/w&gt;. The high-level structure of MED can be seen in <ref type="figure">Figure 1</ref>.</p><p>POET. We now describe POET (Prefer Observed Edit Trees), a new generic method for correcting the output of an MRI system. We use it in combination with MED in this paper, but it can in Joint part-of-speech and dependency projection from multiple sources Anders JohannsenŽeljko Agić Anders Søgaard Center for Language Technology, University of Copenhagen, Denmark anders@johannsen.com</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Abstract</head><p>Most previous work on annotation projection has been limited to a subset of IndoEuropean languages, using only a single source language, and projecting annotation for one task at a time. In contrast, we present an Integer Linear Programming (ILP) algorithm that simultaneously projects annotation for multiple tasks from multiple source languages, relying on parallel corpora available for hundreds of languages. When training POS taggers and dependency parsers on jointly projected POS tags and syntactic dependencies using our algorithm, we obtain better performance than a standard approach on 20/23 languages using one parallel corpus; and 18/27 languages using another.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Cross-language annotation projection for unsupervised POS tagging and syntactic parsing was introduced fifteen years ago <ref type="bibr" target="#b662">Hwa et al., 2005)</ref>, and the best unsupervised dependency parsers today rely on annotation projection <ref type="bibr" target="#b671">(Rasooli and Collins, 2015)</ref>. Despite the maturity of the field, there is an inherent language bias in previous work on crosslanguage annotation projection. Cross-language annotation projection experiments require training data in m source languages, a parallel corpus of translations from the m source languages into the target language of interest, as well as evaluation data for the target language. 1 Since the canonical resource for parallel text is the Europarl Corpus , which covers languages spoken in the European parliament, annotation projection is 1 All previous work that we are aware of-with the possible exception of ; but see Sections 2 and 5-uses only a single source (m = 1), but in our experiments, we use multiple source languages. typically limited to the subset of Indo-European languages that have treebanks.</p><p>Previous work is also limited in another respect. While treebanks typically contain multiple layers of annotation, previous work has focused on projecting data for a single task.</p><p>We go significantly beyond previous work in two ways: 1) by considering multi-source projection across languages in parallel corpora that are available for hundreds of languages, including many non-Indo-European languages; and 2) by jointly projecting annotation for two mutually dependent tasks, namely POS tagging and dependency parsing. Using multiple source languages makes our projections denser. In single source projection, the source language may not contain all syntactic phenomena of the target language; we combat this by transferring syntactic information from multiple source languages. Our work also differs from previous work on annotation projection in projecting soft rather than hard constraints, i.e., scores rather than labels and edges.</p><p>Contributions We present a novel ILP-based algorithm for jointly projecting POS labels and dependency annotations across word-aligned parallel corpora. The performance of our algorithm compares favorably to that of a state-of-the-art projection algorithm, as well as to multi-source delexicalized transfer. Our experiments include between 23 and 27 languages using two parallel corpora that are available for hundreds of languages, namely a collection of Bibles and Watchtower periodicals. Finally, we make both the parallel corpora and the code publicly available. 2</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Projection algorithm</head><p>The projection algorithm is divided into two distinct steps. First, we project potential syntactic </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Word segmentation is an important pre-process step in Chinese language processing. Most widely used approaches treat Chinese word segmentation (CWS) task as a sequence labeling problem in which each character in the input sequence is assigned with a tag. Many previous approaches have been effectively applied to CWS problem <ref type="bibr" target="#b692">Xue and Shen, 2003;</ref><ref type="bibr" target="#b689">Sun et al., 2012;</ref><ref type="bibr" target="#b691">Sun, 2014;</ref><ref type="bibr" target="#b679">Cheng et al., 2015)</ref>. However, these approaches incorporated many handcrafted features, thus restricting the generalization ability of these models. Neural network models have the advantage of minimizing the effort in feature engineering.  developed a general neural network architecture for sequence labeling tasks. Following this work, neural network approaches have been well studied and widely applied to CWS task with good results <ref type="bibr" target="#b697">(Zheng et al., 2013;</ref><ref type="bibr" target="#b685">Pei et al., 2014;</ref><ref type="bibr" target="#b684">Ma and Hinrichs, 2015;</ref>.</p><p>"The ground is covered with thick snow " "This area is really not small." <ref type="figure">Figure 1</ref>: An illustration for the segmentation ambiguity. The character "面" is labeled as "E" (end of word) in the top sentence while labeled as "B" (begin of word) in the bottom one even though "面" has the same adjacent characters, "地" and "积".</p><p>However, these models focus more on collecting local features while long distance dependencies are not well learned. In fact, relying on the information of adjacent words is not enough for CWS task. An example is shown in <ref type="figure">Figure 1</ref>. The character "面" has different tags in two sentences, even with the same adjacent characters, " 地" and " 积". Only long distance dependencies can help the model recognize tag correctly in this example. Thus, long distance information is an important factor for CWS task.</p><p>The main limitation of chain structure for sequence labeling is that long distance dependencies decay inevitably. Though forget gate mechanism is added, it is difficult for bi-directional long short term memory network (Bi-LSTM), a kind of chain structure, to avoid this problem. In general, tree structure works better than chain structure to model long term information. Therefore, we use gated recursive neural network (GRNN)  which is a kind of tree structure to capture long distance dependencies.</p><p>Motivated by the fact, we propose the dependency-based gated recursive neural network (DGRNN) to integrate local features with long dis-567 tance dependencies. <ref type="figure">Figure 2</ref> shows the structure of DGRNN. First of all, local features are collected by Bi-LSTM. Secondly, GRNN recursively combines and refines local features to capture long distance dependencies. Finally, with the help of local features and long distance dependencies, our model generates the probability of the tag of word.</p><p>The main contributions of the paper are as follows:</p><p>• We present the dependency-based gated recursive neural network to combine local features with long distance dependencies.</p><p>• To verify the effectiveness of the proposed approach, we conduct experiments on three widely used datasets. Our proposed model achieves the best performance compared with other state-of-the-art approaches.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Dependency-based Gated Recursive Neural Network</head><p>In order to capture local features and long distance dependencies, we propose dependency-based gated recursive neural network. <ref type="figure">Figure 2</ref> illustrates the structure of the model.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>…… …… ……</head><p>Window Context "This area is really not small."</p><p>Figure 2: Architecture of DGRNN for Chinese Word Segmentation. Cell is the basic unit of GRN-N.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Collect Local Features</head><p>We use bi-directional long short term memory (Bi-LSTM) with single layer to collect local features. Bi-LSTM is composed of two directional tanh sig sig tanh f <ref type="bibr">(t)</ref> h <ref type="bibr">(t)</ref> s <ref type="bibr">(t)</ref> i <ref type="bibr">(t)</ref> s <ref type="bibr">(t-1)</ref> sig o <ref type="bibr">(t)</ref> x <ref type="bibr">(t)</ref> , h (t-1) <ref type="figure">Figure 3</ref>: Structure of LSTM unit. The behavior of the LSTM cell is controlled by three "gates", namely input gate i (t) , forget gate f (t) and output gate o (t) .</p><p>long short term memory networks with single layer, which can model word representation with context information. <ref type="figure">Figure 3</ref> shows the calculation process of LSTM. The behavior of LSTM cell is controlled by three "gates", namely input gate i (t) , forget gate f (t) and output gate o (t) . The input of LSTM cell are x (t) , s (t−1) and h (t−1) . x (t) is the character embeddings of input sentence. s (t−1) and h (t−1) stand for the state and output of the former LSTM cell, respectively. The core of the L-STM model is s (t) , which is computed using the former state of cell and two gates, i (t) and f (t) . In the end, the output of LSTM cell h (t) is calculated making use of s (t) and o (t) .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Refine Long Distance Dependencies</head><p>GRNN recursively combines and refines local features to capture long distance dependencies. The structure of GRNN is like a binary tree, where every two continuous vectors in a sentence is combined to form a new vector. For a sequence s with length n, there are n layers in total. <ref type="figure">Figure 4</ref> shows the calculation process of GRNN cell. The core of GRNN cell are two kinds of gates, reset gates, r L , r R , and update gates z. Reset gates control how to adjust the proportion of the input h i−1 and h i , which results to the current new activation h ′ . By the update gates, the activation of an output neuron can be regarded as a choice among the current new activation h ′ , the left child h i−1 and the right child h i .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Loss Function</head><p>Following the work of <ref type="bibr" target="#b685">Pei et al. (2014)</ref>, we adopt the max-margin criterion as loss function. For an input sentence c [1:n] with a tag sequence t [1:n] , a sentence-level score is given by the sum of net-</p><p>The structure of GRNN cell. work scores:</p><p>where</p><p>is the score output for tag t i at the i th character by the network with parameters θ. We define a structured margin loss ∆(y i , y) for predicting a tag sequence y and a given correct tag sequence y i :</p><p>where κ is a discount parameter. This leads to the regularized objective function for m training examples:</p><p>where J(θ) is a loss function with parameters θ. λ is regularization factor. By minimizing this object, the score of the correct tag sequence y i is increased and score of the highest scoring incorrect tag sequence y is decreased.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.4">Amplification Gate and Training</head><p>A direct adaptive method for faster backpropagation learning method (RPROP) <ref type="bibr" target="#b686">(Riedmiller and Braun, 1993</ref>) was a practical adaptive learning method to train large neural networks. We use mini-batch version RPROP (RMSPROP) <ref type="bibr" target="#b682">(Hinton, 2012)</ref> to minimize the loss function. Intuitively, extra hidden layers are able to improve accuracy performance. However, it is common that extra hidden layers decrease classification accuracy. This is mainly because extra hidden layers lead to the inadequate training of later layers due to the vanishing gradient problem. This problem will decline the utilization of local and long distance information in our model. To overcome this problem, we propose a simple amplification gate mechanism which appropriately expands the value of gradient while not changing the direction.</p><p>Higher amplification may not always perform better while lower value may bring about the unsatisfied result. Therefore, the amplification gate must be carefully selected. Large magnification will cause expanding gradient problem. On the contrary, small amplification gate will hardly reach the desired effect. Thus, we introduce the threshold mechanism to guarantee the robustness of the algorithm, where gradient which is greater than threshold will not be expanded. Amplification gate of difference layer is distinct. For every sample, the training procedure is as follows.</p><p>First, recursively calculate m t and v t which depend on the gradient of time t − 1 or the square of gradient respectively. β 1 and β 2 aim to control the impact of last state.</p><p>Second, calculate ∆W (t) based on v t and square of m t . ϵ and µ are smooth parameters.</p><p>Third, update weight based on the amplification gate and ∆W (t). The parameter update for the i th parameter for the Θ t,i at time step t with amplification gate γ is as follows: </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Abstract</head><p>Morphologically rich languages (MRL) are languages in which much of the structural information is contained at the wordlevel, leading to high level word-form variation. Historically, syntactic parsing has been mainly tackled using generative models. These models assume input features to be conditionally independent, making difficult to incorporate arbitrary features. In this paper, we investigate the greedy discriminative parser described in <ref type="bibr" target="#b705">(Legrand and Collobert, 2015)</ref>, which relies on word embeddings, in the context of MRL. We propose to learn morphological embeddings and propagate morphological information through the tree using a recursive composition procedure. Experiments show that such embeddings can dramatically improve the average performance on different languages. Moreover, it yields state-of-the art performance for a majority of languages.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Morphologically rich languages (MRL) are languages for which important information concerning the syntactic structure is expressed through word formation, rather than constituent-order patterns. Unlike English, they can have complex word structure as well as flexible word order. A common practice when dealing with such languages is to incorporate morphological information explicitly . However this poses two problems to the classical generative models: they assume input features to be conditionally independent which makes the incorpora- * All research was conducted at the Idiap Research Institute, before Ronan Collobert joined Facebook AI Research tion of arbitrary features difficult. Moreover, refining input features leads to a data sparsity issue.</p><p>In the other hand, neural network-based models using continuous word representations as input have been able to overcome the data sparsity problem inherent in NLP <ref type="bibr" target="#b704">(Huang and Yates, 2009</ref>). Furthermore, neural networks allow to incorporate arbitrary features and learn complex non-linear relations between them. <ref type="bibr" target="#b705">Legrand and Collobert (2015)</ref> introduced a greedy syntactic parser, based on neural networks which relies on word embeddings. This model maintains a history of the previous node predictions, in the form of vector representations, by leveraging a recursive composition procedure.</p><p>In this paper, we propose to enhance this model for syntactic parsing of MRL, by learning morphological embeddings. We take advantage of a recursive composition procedure similar to the one used in <ref type="bibr" target="#b705">(Legrand and Collobert, 2015)</ref> to propagate morphological information during the parsing process. We evaluate our approach on the SPMRL (Syntactic Parsing of MRL) Shared Task 2014  on nine different languages. Each of them comes with a set of morphological features allowing to augment words with information such as their grammatical functions, relation with other words in the sentence, prefixes, affixes and lemmas. We show that integrating morphological features allows to increase dramatically the average performance and yields state-of-theart performance for a majority of languages.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.1">Related work</head><p>Both the baseline (Berkeley parser) and the current state-of-the-art model on the SPMRL Shared Task 2014  rely on probabilistic context free grammar (PCFG)-based features. The latter uses a product of PCFG with latent annotation based models <ref type="bibr" target="#b707">(Petrov, 2010)</ref>, with a coarse-to- On the other hand, raw text, and often also dictionaries, can be harvested from the web for many of these languages, and part-of-speech taggers can be trained with these resources. At the same time, previous research shows that eye-tracking data, which can be obtained without explicit annotation, contains clues to partof-speech information. In this work, we bring these two ideas together and show that given raw text, a dictionary, and eyetracking data obtained from naive participants reading text, we can train a weakly supervised PoS tagger using a secondorder HMM with maximum entropy emissions. The best model use type-level aggregates of eye-tracking data and significantly outperforms a baseline that does not have access to eye-tracking data.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>According to Ethnologue, there are around 7,000 languages in the world. 1 For most of these languages, no or very little linguistically annotated resources are available. This is why over the past decade or so, NLP researchers have focused on developing unsupervised algorithms that learn from raw text, which for many languages is widely available on the web. An example is part-ofspeech (PoS) tagging, in which unsupervised approaches have been increasingly successful (see <ref type="bibr" target="#b714">Christodoulopoulos et al. (2010)</ref> for an overview). The performance of unsupervised PoS taggers can be improved further if dictionary information is available, making it possible to constrain the PoS 1 http://www.ethnologue.com/world tagging process. Again, dictionary information can be harvested readily from the web for many languages .</p><p>In this paper, we show that PoS tagging performance can be improved further by using a weakly supervised model which exploits eye-tracking data in addition to raw text and dictionary information. Eye-tracking data can be obtained by getting native speakers of the target language to read text while their gaze behavior is recorded. Reading is substantially faster than manual annotation, and competent readers are available for languages where trained annotators are hard to find or non-existent. While high quality eye-tracking equipment is still expensive, $100 eye-trackers such as the EyeTribe are already on the market, and cheap eye-tracking equipment is likely to be widely available in the near future, including eyetracking by smartphone or webcam <ref type="bibr" target="#b721">(Skovsgaard et al., 2013;</ref>.</p><p>Gaze patterns during reading are strongly influenced by the parts of speech of the words being read. Psycholinguistic experiments show that readers are less likely to fixate on closed-class words that are predictable from context. Readers also fixate longer on rare words, on words that are semantically ambiguous, and on words that are morphologically complex <ref type="bibr" target="#b720">(Rayner, 1998)</ref>. These findings indicate that eye-tracking data should be useful for classifying words by part of speech, and indeed  show that word-type-level aggregate statistics collected from eye-tracking corpora can be used as features for supervised PoS tagging, leading to substantial gains in accuracy across domains. This leads us to hypothesize that gaze data should also improve weakly supervised PoS tagging.</p><p>In this paper, we test this hypothesis by experimenting with a PoS tagging model that uses raw text, dictionary information, and eye-tracking data, but requires no explicit annotation. We start with a state-of-the-art unsupervised PoS tagging model, the second-order hidden Markov model with maximum entropy emissions of , which uses only textual features. We augment this model with a wide range of features derived from an eye-tracking corpus at training time (type-level gaze features). We also experiment with token-level gaze features; the use of these features implies that eye-tracking is available both at training time and at test time. We find that eyetracking features lead to a significant increase in PoS tagging accuracy, and that type-level aggregates work better than token-level features.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">The Dundee Treebank</head><p>The Dundee Treebank  is a Universal Dependency annotation layer that has recently been added to the world's largest eyetracking corpus, the Dundee Corpus <ref type="bibr" target="#b717">(Kennedy et al., 2003)</ref>. The English portion of the corpus contains 51,502 tokens and 9,776 types in 2,368 sentences. The Dundee Corpus is a well-known and widely used resource in psycholinguistic research. The corpus enables researchers to study the reading of contextualized, running text obtained under relatively naturalistic conditions. The eyemovements in the Dundee Corpus were recorded with a high-end eye-tracker, sampling at 1000 Hz. The corpus contains the eye-movements of ten native English speakers as they read the same twenty newspaper articles from The Independent. The 3 Type-constrained second-order HMM PoS tagging</p><p>We build on the type-constrained second-order hidden Markov model with maximum entropy emissions (SHMM-ME) proposed by . This model is an extension of the first-order max-ent HMM introduced by <ref type="bibr">BergKirkpatrick et al. (2010)</ref>.   </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Abstract</head><p>The aim of this paper is to investigate suitable evaluation strategies for the task of word-level quality estimation of machine translation. We suggest various metrics to replace F 1 -score for the "BAD" class, which is currently used as main metric. We compare the metrics' performance on real system outputs and synthetically generated datasets and suggest a reliable alternative to the F 1 -BAD score -the multiplication of F 1 -scores for different classes. Other metrics have lower discriminative power and are biased by unfair labellings.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Quality estimation (QE) of machine translation (MT) is a task of determining the quality of an automatically translated text without any oracle <ref type="bibr">(reference)</ref> translation. This task has lately been receiving significant attention: from confidence estimation (i.e. estimation of how confident a particular MT system is on a word or a phrase <ref type="bibr" target="#b726">(Gandrabur and Foster, 2003)</ref>) it evolved to systemindependent QE and is performed at the word level <ref type="bibr" target="#b728">(Luong et al., 2014)</ref>, sentence level <ref type="bibr" target="#b731">(Shah et al., 2013)</ref> and document level .</p><p>The emergence of a large variety of approaches to QE led to need for reliable ways to compare them. The evaluation metrics that have been used to compare the performance of systems participating in QE shared tasks 1 have received some criticisms. <ref type="bibr" target="#b727">Graham (2015)</ref> shows that Pearson correlation better suits for the evaluation of sentence-level QE systems than mean absolute error (MAE), often used for this purpose. Pearson correlation evaluates how well a system captures 1 http://statmt.org/wmt15/ quality-estimation-task.html the regularities in the data, whereas MAE essentially measures the difference between the true and the predicted scores and in many cases can be minimised by always predicting the average score as given by the training set labels.</p><p>Word-level QE is commonly framed as a binary task, i.e., the classification of every translated word as "OK" or "BAD". This task has been evaluated in terms of F 1 -score for the "BAD" class, a metric that favours 'pessimistic' systems -i.e. systems that tend to assign the "BAD" label to most words. A trivial baseline strategy that assigns the label "BAD" to all words can thus receive a high score while being completely uninformative <ref type="bibr" target="#b724">(Bojar et al., 2014)</ref>. However, no analysis of the word-level metrics' performance has been done and no alternative metrics have been proposed that are more reliable than the F 1 -BAD score.</p><p>In this paper we compare existing evaluation metrics for word-level QE, suggest a number of alternatives, and show that one of these alternatives leads to more objective and reliable results.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Metrics</head><p>One of the reasons word-level QE is a challenging problem is the fact that "OK" and "BAD" labels are not equally important: we are generally more interested in finding incorrect words than in assigning a suitable category to every single word. An ideal metric should be oriented towards the recall for the "BAD" class. However, the case of F 1 -BAD score shows that this is not the only requirement: in order to be useful the metric should not favour pessimistic labellings, i.e., all or most words labelled as "BAD". Below we describe possible alternatives to the F 1 -BAD score.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">F 1 -score variants</head><p>Word-level F 1 -scores. Since F 1 -BAD score is too pessimistic, an obvious solution would be to</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>The Social Impact of Natural Language Processing</head><p>This situation has changed lately due to the increased use of social media data, where authors are current individuals, who can be directly affected by the results of NLP applications. <ref type="bibr" target="#b746">Couillault et al. (2014)</ref> touch upon these issues under "traceability" (i.e., whether individuals can be identified): this is undesirable for experimental subjects, but might be useful in the case of annotators.</p><p>Most importantly, though: the subject of NLPlanguage-is a proxy for human behavior, and a strong signal of individual characteristics. People use this signal consciously, to portray themselves in a certain way, but can also be identified as members of specific groups by their use of subconscious traits <ref type="bibr" target="#b791">(Silverstein, 2003;</ref><ref type="bibr">Agha, 2005;</ref><ref type="bibr" target="#b755">Hovy and Johannsen, 2016)</ref>.</p><p>Language is always situated , i.e., it is uttered in a specific situation at a particular place and time, and by an individual speaker with all the characteristics outlined above. All of these factors can therefore leave an imprint on the utterance, i.e., the texts we use in NLP carry latent information about the author and situation, albeit to varying degrees.</p><p>This information can be used to predict author characteristics from text <ref type="bibr" target="#b788">(Rosenthal and McKeown, 2011;</ref><ref type="bibr" target="#b776">Nguyen et al., 2011;</ref><ref type="bibr" target="#b736">Alowibdi et al., 2013;</ref><ref type="bibr" target="#b745">Ciot et al., 2013;</ref><ref type="bibr" target="#b768">Liu and Ruths, 2013;</ref><ref type="bibr" target="#b802">Volkova et al., 2014;</ref><ref type="bibr" target="#b803">Volkova et al., 2015;</ref><ref type="bibr" target="#b780">Plank and Hovy, 2015;</ref><ref type="bibr" target="#b784">Preotiuc-Pietro et al., 2015a;</ref><ref type="bibr" target="#b785">Preoţiuc-Pietro et al., 2015b)</ref>, and the characteristics in turn can be detected by and influence the performance of our models <ref type="bibr" target="#b769">(Mandel et al., 2012;</ref><ref type="bibr" target="#b801">Volkova et al., 2013;</ref><ref type="bibr" target="#b757">Hovy, 2015)</ref>.</p><p>As more and more language-based technologies are becoming available, the ethical implications of NLP research become more important. What research is carried out, and its quality, directly affect the functionality and impact of those technologies.</p><p>The following is meant to start a discussion addressing ethical issues that can emerge in (and from) NLP research.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">The social impact of NLP research</head><p>We have outlined the relation between language and individual traits above. Language is also a political instrument, though, and an instrument of power. This influence stretches into politics and everyday competition, for example for turntaking <ref type="bibr" target="#b767">(Laskowski, 2010;</ref><ref type="bibr" target="#b744">Bracewell and Tomlinson, 2012;</ref><ref type="bibr" target="#b781">Prabhakaran and Rambow, 2013;</ref><ref type="bibr">Prab-</ref> In research, we can observe this effect in waves of research topics that receive increased mainstream attention, often to fall out of fashion or become more specialized, cf. ACL papers with "grammars" vs. "neural" in the title <ref type="figure">(Figure 1</ref>).</p><p>Such topic overexposure may lead to a psychological effect called availability heuristic <ref type="bibr" target="#b800">(Tversky and Kahneman, 1973)</ref>: if people can recall a certain event, or have knowledge about specific things, they infer it must be more important. For instance, people estimate the size of cities they recognize to be larger than that of unknown cities <ref type="bibr" target="#b753">(Goldstein and Gigerenzer, 2002)</ref>.</p><p>However, the same holds for individuals/groups/characteristics we research. The heuristics become ethically charged when characteristics such as violence or negative emotions are more strongly associated with certain groups or ethnicities <ref type="bibr" target="#b792">(Slovic et al., 2007)</ref>. If research repeatedly found that the language of a certain demographic group was harder to process, it could create a situation where this group was perceived to be difficult, or abnormal, especially in the presence of existing biases. The confirmation of biases through the gendered use of language, for example, has also been at the core of second and third wave feminism <ref type="bibr" target="#b772">(Mills, 2012)</ref>.</p><p>Overexposure thus creates biases which can lead to discrimination. To some extent, the frantic public discussion on the dangers of AI can be seen as a result of overexposure <ref type="bibr" target="#b796">(Sunstein, 2004)</ref>.</p><p>There are no easy solutions to this problem, which might only become apparent in hindsight. It can help to assess whether the research direction of a project feeds into existing biases, or whether it overexposes certain groups.</p><p>Underexposure can negatively impact evaluation. Similar to the WEIRD-situation in psychology, NLP tends to focus on Indo-European data/text sources, rather than small languages from other language groups, for example in Asia or Africa. This focus creates an imbalance in the available amounts of labeled data. Most of the exisitng labeled data covers only a small set of languages. When analyzing a random sample of Twitter data from 2013, we found that there were no treebanks for 11 of the 31 most frequent languages, and even fewer semantically annotated resources (the ACE corpus covers only English, Arabic, Chinese, and Spanish). <ref type="bibr">4</ref> Even if there is a potential wealth of data available from other languages, most NLP tools are geared towards English <ref type="bibr" target="#b790">(Schnoebelen, 2013;</ref><ref type="bibr" target="#b775">Munro, 2013)</ref>. The prevalence of resources for English has created an underexposure to typological variety: both morphology and syntax of English are global outliers. Would we have focused on n-gram models to the same extent if English was as morhpologically complex as, say, Finnish?</p><p>While there are many approaches to develop multi-lingual and cross-lingual NLP tools for linguistic outliers , there simply are more commercial incentives to overexpose English, rather than other languages. Even if other languages are equally (or more) interesting from a linguistic and cultural point of view, English is one of the most widely spoken language and therefore opens up the biggest market for NLP tools. This focus on English may be self-reinforcing: the existence of off-the-shelf tools for English makes it easy to try new ideas, while to start exploring other languages requires a higher startup cost in terms of basic models, so researchers are less likely to work on them.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Dual-use problems</head><p>Even if we address all of the above concerns and do not intend any harm in our experiments, they can still have unintended consequences that negatively affect people's lives <ref type="bibr" target="#b762">(Jonas, 1984)</ref>.</p><p>Advanced analysis techniques can vastly improve search and educational applications 4 Thanks to Barbara Plank for the analysis! 594 , but can re-enforce prescriptive linguistic norms when degrading on non-standard language.</p><p>Stylometric analysis can shed light on the provenance of historic texts <ref type="bibr" target="#b774">(Mosteller and Wallace, 1963)</ref>, but also endanger the anonymity of political dissenters. Text classification approaches help decode slang and hidden messages <ref type="bibr" target="#b760">(Huang et al., 2013)</ref>, but have the potential to be used for censorship. At the same time, NLP can also help uncovering such restrictions <ref type="bibr" target="#b739">(Bamman et al., 2012)</ref>. As recently shown by <ref type="bibr" target="#b758">Hovy (2016)</ref>, NLP techniques can be used to detect fake reviews, but also to generate them in the first place.</p><p>All these examples indicate that we should become more aware of the way other people appropriate NLP technology for their own purposes. The unprecedented scale and availability can make the consequences of NLP technologies hard to gauge.</p><p>The unintended consequences of research are also linked to the incentives associated with funding sources. The topic of government and military involvement in the field deserves special attention in this respect. On the one hand, <ref type="bibr" target="#b737">Anderson et al. (2012)</ref> show how a series of DARPA-funded workshops have been formative for ACL as a field in the 1990s. On the other hand, there are scholars who refuse military-related funding for moral reasons. <ref type="bibr">5</ref> While this decision is up to the individual researcher, the examples show that moral considerations go beyond the immediate research projects. We may not directly be held responsible for the unintended consequences of our research, but we can acknowledge the ways in which NLP can enable morally questionable/sensitive practices, raise awareness, and lead the discourse on it in an informed manner. The role of the researcher in such ethical discussions has recently been pointed out by <ref type="bibr" target="#b787">Rogaway (2015)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Conclusion</head><p>In this position paper, we outlined the potential social impact of NLP, and discussed ways for the practitioner to address this. We also introduced exclusion, overgeneralization, bias confirmation, topic overexposure, and dual use. Countermeasures for exclusion include bias control techniques <ref type="bibr">5</ref> For a perspective in a related field see https: //web.eecs.umich.edu/˜kuipers/opinions/ no-military-funding.html like downsampling or priors; for overgeneralization: dummy labels, error weighting, or confidence thresholds. Exposure problems can only be addressed by careful research design, and dual-use problems seem hardly addressable on the level of the individual researcher, but require the concerted effort of our community.</p><p>We hope this paper can point out ethical considerations for collecting our data, designing the experimental setup, and assessing the potential application of our systems, and help start an open discussion in the field about the limitations and problems of our methodology. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Using Sequence Similarity Networks to Identify Partial Cognates in Multilingual Wordlists</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Abstract</head><p>Increasing amounts of digital data in historical linguistics necessitate the development of automatic methods for the detection of cognate words across languages. Recently developed methods work well on language families with moderate time depths, but they are not capable of identifying cognate morphemes in words which are only partially related. Partial cognacy, however, is a frequently recurring phenomenon, especially in language families with productive derivational morphology. This paper presents a pilot approach for partial cognate detection in which networks are used to represent similarities between word parts and cognate morphemes are identified with help of state-of-theart algorithms for network partitioning. The approach is tested on a newly created benchmark dataset with data from three sub-branches of Sino-Tibetan and yields very promising results, outperforming all algorithms which are not sensible to partial cognacy.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>In a very general notion, cognacy is similar to the concept of homology in biology <ref type="bibr" target="#b815">(Haggerty et al. 2014)</ref>, denoting a relation between words which share a common history <ref type="bibr" target="#b824">(List 2014b)</ref>. In classical linguistics, borrowings are often excluded from this notion <ref type="bibr" target="#b838">(Trask 2000)</ref>. Quantitative approaches additionally distinguish cognates which have retained, and cognates which have shifted their meaning <ref type="bibr" target="#b837">(Starostin 2013b)</ref>. Further aspects of cognacy are rarely distinguished, although they are obvious and common. Words which go back to the same ancestor form can for example have been morphologically modified, such as French soleil which does not go directly back to Latin sōl`sun' but to sōliculus`small sun' which is itself a derivation of sōl <ref type="bibr" target="#b830">(Meyer-Lübke 1911</ref>  Another problem are words which have been created from two or more morphemes via processes of compounding. While these cases are rather rare in the core vocabulary of IndoEuropean languages, they are very frequent in South-East Asian language families like SinoTibetan or Austro-Asiatic. In 200 basic words across 23 Chinese dialects <ref type="bibr">(Ben Hamed and Wang 2006)</ref>, for example, almost 50% of the nouns and more than 30% of all words consist of two or more morphemes (see the Sup. Material for details).</p><p>The presence of words consisting of more than one morpheme challenges the notion that words can either be cognate or not. It poses problems for phylogenetic approaches which require binary presence-absence matrices as input and model language evolution as cognate gain and cognate loss <ref type="bibr" target="#b807">(Atkinson and Gray 2006)</ref>. This is illustrated in <ref type="table">Table 1</ref> where words for`moon' in four Chinese dialects <ref type="bibr" target="#b818">(Hóu 2004</ref>) are compared, with cognate elements being given the same color. If we assign cognacy strictly, only matching those words which are identical in all their elements (Ben Hamed and Wang 2006), we would have to label all words as being not cognate. If we assign cognacy loosely (Satterthwaite-Phillips 2011), labeling all words as cognate when only they share a common morpheme, we would have to label all 599 words as cognate. No matter how we code in phylogenetic analyses, as long as we use binary states, we will loose information <ref type="bibr" target="#b825">(List 2016)</ref>.</p><p>Partial cognacy is also a problem for current cognate detection algorithms which compare words in their entirety <ref type="bibr" target="#b824">(List 2014b</ref><ref type="bibr" target="#b839">, Turchin et al. 2010</ref>. Given the frequency of compound words in South-East Asian languages, it is not surprising that the algorithms perform much worse on diverse South-East Asian language families, than they perform on other language families where compounding is less frequent <ref type="bibr">(List 2014b:197f)</ref>. This paper presents a new algorithm for cognate detection which does not identify cognate words but instead searches for cognate elements in words. The algorithm takes multilingual word lists as input and outputs statements regarding the cognacy of morphemes, just as the ones shown in the last column of  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Materials</head><p>Three gold standard datasets from different branches of Sino-Tibetan with different degrees of diversity were prepared, including Bai dialects, Chinese dialects, and Tujia dialects. All datasets were taken from existing datasets with cognate codings provided independently. To facilitate further use of the data, all languages were linked to Glottolog <ref type="bibr" target="#b816">(Hammarström et al. 2015</ref>) and all concepts were linked to the Concepticon <ref type="bibr" target="#b826">(List et al. 2016a)</ref>. Furthermore, phonetic transcriptions were cleaned by segmenting phonetic entries into meaningful sound units and unifying phonetic variants representing the same pronunciation. Morphological segmentation was not required, since all languages in our sample (and the majority of all South-East Asian languages) have a morphemesyllabic structure in which each syllable denotes one morpheme. Partial cognate judgments are displayed with help of multiple integer IDs assigned to a word in the order of its morphemes, as displayed above in <ref type="table">Table 1</ref>. For the Chinese dataset, partial cognate information was provided in the source itself, for Bai and Tujia, it was manually derived from the cognate judgments in the sources. Detailed information regarding the datasets is given in <ref type="table">Table 2</ref>, and the full dataset along with further information is given in the Sup. Material.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Methods</head><p>The workflow for partial cognate detection consists of three major steps.</p><p>(1) In a first step, pairwise sequence similarities are determined between all morphemes of all words in the same meaning slot in a word list. (2) These similarities are then used to create a similarity network in which nodes represent morphemes and edges between the nodes represent similarities between the morphemes. <ref type="formula">(3)</ref> In a third step, an algorithm for network partitioning is used to cluster the nodes of the network into groups of cognate morphemes.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Sequence Similarity</head><p>There are various ways to determine the similarity or distance between words and morphemes. A general distinction can be made between language-independent and language-specific approaches. The former determine the word similarity independently of the languages to which the words belong. As a result, the scores only depend on the substantial and structural differences between words. Examples for language-independent similarity measures are SCA distances, as produced by the Sound-Class-Based Phonetic Alignment algorithm <ref type="bibr" target="#b822">(List 2012b)</ref>, or PMI similarities as produced by the Weighted String Alignment algorithm <ref type="bibr" target="#b820">(Jäger 2013)</ref>. Language-specific approaches, on the other hand, are based on previously identified recurring correspondences between the languages from which the words are taken <ref type="bibr">(List 2014b: 48-50</ref>) and may differ across languages. 1 An example for language-specific similarity measures is the LexStat algorithm, first proposed in <ref type="bibr" target="#b821">List (2012a)</ref> and later refined in List</p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">References References Diego Ceccarelli, Claudio Lucchese, Salvatore Orlando, Raffaele Perego, and Fabrizio Silvestri. 2011. Caching query-biased snippets for efficient retrieval</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Markus</forename><surname>Becker</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anette</forename><surname>Frank</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Conference on Extending Database Technology, EDBT/ICDT &apos;11</title>
		<meeting>the International Conference on Extending Database Technology, EDBT/ICDT &apos;11</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2002" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="93" to="104" />
		</imprint>
	</monogr>
	<note>Proceedings of the 19th international conference on Computational linguistics</note>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Transitionbased spinal parsing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Ballesteros</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Carreras</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of CoNLL</title>
		<meeting>of CoNLL</meeting>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Keyaki treebank: phrase structure with functional information for japanese</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Butler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Hong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Hotta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Otomo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Yoshimoto</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Zhou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of Text Annotation Workshop</title>
		<meeting>of Text Annotation Workshop</meeting>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Languageindependent parsing with empty elements</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Cai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Chiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Goldberg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of ACL-HLT</title>
		<meeting>of ACL-HLT</meeting>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="page" from="212" to="216" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">TAG, dynamic programming, and the perceptron for efficient, feature-rich parsing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Carreras</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Collins</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Koo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of CoNLL</title>
		<meeting>of CoNLL</meeting>
		<imprint>
			<date type="published" when="2008" />
			<biblScope unit="page" from="9" to="16" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Automated extraction of tags from the penn treebank</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><forename type="middle">K</forename><surname>Shanker</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">New developments in parsing technology</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2004" />
			<biblScope unit="page" from="73" to="89" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Named entity extraction using adaboost</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xavier</forename><surname>Carreras</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Lluís Màrques, and Lluís Padró</title>
		<imprint>
			<date type="published" when="2002" />
			<biblScope unit="page" from="167" to="170" />
		</imprint>
	</monogr>
	<note>Proceedings of CoNLL-2002</note>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Discriminative training methods for hidden markov models: Theory and experiments with perceptron algorithms</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Collins</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. EMNLP</title>
		<meeting>EMNLP</meeting>
		<imprint>
			<date type="published" when="2002" />
			<biblScope unit="page" from="1" to="8" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Search-based structured prediction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hal</forename><surname>Daumé</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Iii</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Langford</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Marcu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Machine Learning</title>
		<imprint>
			<date type="published" when="2009" />
			<biblScope unit="volume">75</biblScope>
			<biblScope unit="page" from="297" to="325" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Bahdanau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Cho</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
		<title level="m">Neural Machine Translation by Jointly Learning to Align and Translate</title>
		<imprint>
			<date type="published" when="2014-09" />
		</imprint>
	</monogr>
	<note>ArXiv e-prints</note>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Combining shallow and deep NLP methods for recognizing textual entailment</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Johan</forename><surname>Bos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Katja</forename><surname>Markert</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the First PASCAL Challenges Workshop on Recognising Textual Entailment</title>
		<meeting>the First PASCAL Challenges Workshop on Recognising Textual Entailment</meeting>
		<imprint>
			<date type="published" when="2005" />
			<biblScope unit="page" from="65" to="68" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Inter-coder agreement for computational linguistics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ron</forename><surname>Artstein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Massimo</forename><surname>Poesio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computational Linguistics</title>
		<imprint>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="555" to="596" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">The mathematics of statistical machine translation: Parameter estimation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alfred</forename><forename type="middle">V</forename><surname>Aho</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeffrey</forename><forename type="middle">D</forename><surname>Ullman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Computer and System Sciences</title>
		<editor>References Peter F. Brown, Vincent J.Della Pietra, Stephen A. Della Pietra, and Robert. L. Mercer</editor>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="263" to="311" />
			<date type="published" when="1969" />
		</imprint>
	</monogr>
	<note>Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">A simple, fast, and effective reparameterization of IBM model 2</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Dyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Victor</forename><surname>Chahuneau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Noah</forename><forename type="middle">A</forename><surname>Smith</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of NAACL</title>
		<meeting>NAACL</meeting>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Topics in semantic representation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas</forename><forename type="middle">L</forename><surname>Griffiths</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mark</forename><surname>Steyvers</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joshua</forename><forename type="middle">B</forename><surname>Tenenbaum</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Psychological review</title>
		<imprint>
			<biblScope unit="volume">114</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="211" to="244" />
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Scalable modified Kneser-Ney language model estimation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kenneth</forename><surname>Heafield</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ivan</forename><surname>Pouzyrevsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathan</forename><forename type="middle">H</forename><surname>Clark</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philipp</forename><surname>Koehn</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 51st Annual Meeting of the Association for Computational Linguistics<address><addrLine>Sofia, Bulgaria</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="690" to="696" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Improving nonparameteric Bayesian inference: Experiments on unsupervised word segmentation with adaptor grammars</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mark</forename><surname>Johnson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sharon</forename><surname>Goldwater</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NAACL &apos;09</title>
		<imprint>
			<date type="published" when="2009" />
			<biblScope unit="page" from="317" to="325" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Moses: Open source toolkit for statistical machine translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philipp</forename><surname>Koehn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hieu</forename><surname>Hoang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexandra</forename><surname>Birch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Callison-Burch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marcello</forename><surname>Federico</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nicola</forename><surname>Bertoldi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Brooke</forename><surname>Cowan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wade</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christine</forename><surname>Moran</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Zens</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Dyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ondřej</forename><surname>Bojar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexandra</forename><surname>Constantin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Evan</forename><surname>Herbst</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 45th Annual Meeting of the ACL on Interactive Poster and Demonstration Sessions, ACL &apos;07</title>
		<meeting>the 45th Annual Meeting of the ACL on Interactive Poster and Demonstration Sessions, ACL &apos;07</meeting>
		<imprint>
			<date type="published" when="2007" />
			<biblScope unit="page" from="177" to="180" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Alignment by agreement</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Percy</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ben</forename><surname>Taskar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Klein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">HLT-NAACL &apos;06</title>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2006" />
			<biblScope unit="page" from="104" to="111" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Polyglot: Distributed word representations for multilingual NLP</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bryan</forename><surname>References Rami Al-Rfou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Steven</forename><surname>Perozzi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Skiena</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CoNLL</title>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="183" to="192" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<monogr>
		<title level="m" type="main">Reference</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Barbara</forename><surname>Abbott</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2010" />
			<publisher>Oxford University Press</publisher>
			<pubPlace>Oxford, UK</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">A neural probabilistic language model</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rejean</forename><surname>Ducharme</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pascal</forename><surname>Vincent</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christian</forename><surname>Jauvin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="1137" to="1155" />
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">A simple domain-independent probabilistic approach to generation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Percy</forename><surname>References Gabor Angeli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Klein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Conference on Empirical Methods in Natural Language Processing (EMNLP)</title>
		<imprint>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Extracting parallel fragments from comparable corpora for data-to-text generation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anja</forename><surname>Belz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eric</forename><surname>Kow</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">6th International Natural Language Generation Conference (INLG)</title>
		<imprint>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<monogr>
		<title level="m" type="main">Environmental Modelling: An Uncertain Future? Routledge</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Keith</forename><surname>Beven</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Edward</forename><forename type="middle">T</forename><surname>Cokely</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mirta</forename><surname>Galesic</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eric</forename><surname>Schulz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Saima</forename><surname>Ghazal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rocio</forename><surname>Garcia-Retamero</surname></persName>
		</author>
		<title level="m">Measuring risk literacy: The berlin numeracy test. Judgment and Decision Making</title>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page" from="25" to="47" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">A neural probabilistic language model</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Réjean</forename><surname>References Yoshua Bengio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pascal</forename><surname>Ducharme</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christian</forename><surname>Vincent</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Janvin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="1137" to="1155" />
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Dynamic Translation Memory: Using Statistical Machine Translation to Improve Translation Memory Fuzzy Matches</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ergun</forename><surname>References</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marc</forename><surname>Biçici</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Dymetman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 9th International Conference on Computational Linguistics and Intelligent Text Processing</title>
		<meeting>the 9th International Conference on Computational Linguistics and Intelligent Text Processing<address><addrLine>Haifa, Israel</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2008-02" />
			<biblScope unit="page" from="454" to="465" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">An Empirical Study of Smoothing Techniques for Language Modeling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Stanley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joshua</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Goodman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 34th Annual Meeting on Association for Computational Linguistics</title>
		<meeting>the 34th Annual Meeting on Association for Computational Linguistics<address><addrLine>Santa Cruz, California</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1996-06" />
			<biblScope unit="page" from="310" to="318" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Investigations on phrase-based decoding with recurrent neural network language and translation models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Colin</forename><surname>Cherry</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">George</forename><surname>Foster</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2012 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</title>
		<meeting>the 2012 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies<address><addrLine>Montreal, Canada, June. References Tamer Alkhouli, Felix Rietig, and Hermann Ney; Lisbon, Portugal</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="page" from="294" to="303" />
		</imprint>
	</monogr>
	<note>EMNLP 2015 Tenth Workshop on Statistical Machine Translation (WMT 2015)</note>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Probabilistic topic models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Davis</forename><forename type="middle">M</forename><surname>Blei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Communications of the ACM</title>
		<imprint>
			<biblScope unit="volume">55</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="77" to="84" />
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">LIX and RIX: Variations on a Little-Known Readability Index</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathan</forename><forename type="middle">Anderson</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Reading</title>
		<imprint>
			<biblScope unit="page" from="490" to="496" />
			<date type="published" when="1983" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Automatically Profiling the Author of an Anonymous Text</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shlomo</forename><surname>Argamon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Moshe</forename><surname>Koppel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">James</forename><forename type="middle">W</forename><surname>Pennebaker</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathan</forename><surname>Schler</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Communications of the ACM</title>
		<imprint>
			<biblScope unit="volume">52</biblScope>
			<biblScope unit="issue">2</biblScope>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Success with style: Using writing style to predict the success of novels</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Song</forename><surname>Vikas Ganjigunte Ashok</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yejin</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Choi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Gender Identity and Lexical Variation in Social Media</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Bamman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jacob</forename><surname>Eisenstein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tyler</forename><surname>Schnoebelen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Sociolinguistics</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="135" to="160" />
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Towards Fine-Grained Readability Measures for Self-Directed Language Learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lisa</forename><surname>Beinborn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Torsten</forename><surname>Zesch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Iryna</forename><surname>Gurevych</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the SLTC 2012 workshop on NLP for CALL</title>
		<meeting>the SLTC 2012 workshop on NLP for CALL</meeting>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Nlp-oriented contrastive study of linguistic productions of alzheimer and control people</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maité</forename><surname>Boyé</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thi</forename><forename type="middle">Mai</forename><surname>Tran</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Natalia</forename><surname>Grabar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Natural Language Processing</title>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="412" to="424" />
		</imprint>
	</monogr>
	<note>LNCS 8686 Springer</note>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Discriminating Gender on Twitter</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D. John</forename><surname>Burger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Henderson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">George</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guido</forename><surname>Zarrella</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2011 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2011 Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">You are where you Tweet: A Content-based Approach to Geo-locating Twitter Users</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhiyuan</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">James</forename><surname>Caverlee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kyumin</forename><surname>Lee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 19th ACM Conference on Information and Knowledge Management, CIKM</title>
		<meeting>the 19th ACM Conference on Information and Knowledge Management, CIKM</meeting>
		<imprint>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">A Computer Readability Formula Designed for Machine Scoring</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Meri</forename><surname>Coleman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Liau</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Applied Psychology</title>
		<imprint>
			<biblScope unit="volume">60</biblScope>
			<biblScope unit="issue">2</biblScope>
			<date type="published" when="1975" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Mark my Words!: Linguistic Style Accommodation in Social Media</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cristian</forename><surname>Danescu-Niculescu-Mizil</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Gamon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Susan</forename><surname>Dumais</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 20th International Conference on World Wide Web</title>
		<meeting>the 20th International Conference on World Wide Web</meeting>
		<imprint>
			<publisher>WWW</publisher>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Latent dirichlet allocation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Blei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Ng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Jordan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="993" to="1022" />
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Convex collective matrix factorization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guillaume</forename><surname>Bouchard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shengbo</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dawei</forename><surname>Yin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AISTATS</title>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Generative models for item adoptions using social correlation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Freddy Chong Tat</forename><surname>Chua</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hady</forename><forename type="middle">W</forename><surname>Lauw</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ee-Peng</forename><surname>Lim</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. on Knowl. and Data Eng</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="page" from="2036" to="2048" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">A logit model of brand choice calibrated on scanner data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Peter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Guadagni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Dc Little</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Marketing science</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="203" to="238" />
			<date type="published" when="1983" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Consistent collective matrix completion under joint low rank structure</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Suriya</forename><surname>Gunasekar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Makoto</forename><surname>Yamada</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dawei</forename><surname>Yin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yi</forename><surname>Chang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AISTATS</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<monogr>
		<title level="m" type="main">Sparse Approximate Solutions to Semidefinite Programs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Elad</forename><surname>Hazan</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2008" />
			<publisher>Springer</publisher>
			<biblScope unit="page" from="306" to="316" />
			<pubPlace>Berlin Heidelberg</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">An algorithmic framework for performing collaborative filtering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathan</forename><forename type="middle">L</forename><surname>Herlocker</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joseph</forename><forename type="middle">A</forename><surname>Konstan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Al</forename><surname>Borchers</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Riedl</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SIGIR</title>
		<imprint>
			<date type="published" when="1999" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">A simple algorithm for nuclear norm regularized problems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Martin</forename><surname>Jaggi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marek</forename><surname>Sulovsky</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML</title>
		<imprint>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">Evaluation of item-based top-n recommendation algorithms</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">George</forename><surname>Karypis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CIKM</title>
		<imprint>
			<date type="published" when="2001" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">Cassa: A context-aware synonym simplification algorithm</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ricardo</forename><surname>References</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luz</forename><surname>Baeza-Yates</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Julia</forename><surname>Rello</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Dembowski</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2015 Conference of the North American Chapter of the Association for Computational Linguistics on Human Language Technology</title>
		<meeting>the 2015 Conference of the North American Chapter of the Association for Computational Linguistics on Human Language Technology</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="1380" to="1385" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">Automatic extraction of social networks from literary text: A case study on Alice in Wonderland</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anup</forename><surname>References Apoorv Agarwal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Owen</forename><surname>Kotalwa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Rambow</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The Proceedings of the 6th International Joint Conference on Natural Language Processign (IJC-NLP &apos;13)</title>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title level="a" type="main">Clustering of novels represented as social networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Coll</forename><surname>Mariona</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Caroline</forename><surname>Ardanuy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Sporleder</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Linguistic Issues in Language Technology</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="issue">4</biblScope>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main">A Bayesian mixed effects model of literary character</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Bamman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ted</forename><surname>Underwood</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Noah</forename><forename type="middle">A</forename><surname>Smith</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 52st Annual Meeting of the Association for Computational Linguistics (ACL &apos;14)</title>
		<meeting>the 52st Annual Meeting of the Association for Computational Linguistics (ACL &apos;14)</meeting>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main">GutenTag: An NLP-driven tool for digital humanities research in the Project Gutenberg corpus</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Julian</forename><surname>Brooke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adam</forename><surname>Hammond</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Graeme</forename><surname>Hirst</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 4nd Workshop on Computational Literature for Literature (CLFL &apos;15)</title>
		<meeting>the 4nd Workshop on Computational Literature for Literature (CLFL &apos;15)</meeting>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<analytic>
		<title level="a" type="main">Class-based n-gram models of natural language</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Peter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peter</forename><forename type="middle">V</forename><surname>Brown</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Robert</forename><forename type="middle">L</forename><surname>Desouza</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vincent</forename><forename type="middle">J</forename><surname>Mercer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jenifer</forename><forename type="middle">C</forename><surname>Della Pietra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Lai</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computational Linguistics</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="467" to="479" />
			<date type="published" when="1992" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b56">
	<analytic>
		<title level="a" type="main">Tune your Brown clustering, please</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Leon</forename><surname>Derczynski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sean</forename><surname>Chester</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kenneth</forename><forename type="middle">S</forename><surname>Bgh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of Recent Advances in Natural Language Processing</title>
		<meeting>Recent Advances in Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
	<note>RANLP 15</note>
</biblStruct>

<biblStruct xml:id="b57">
	<analytic>
		<title level="a" type="main">Structured generative models for unsupervised named-entity clustering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Micha</forename><surname>Elsner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eugene</forename><surname>Charniak</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mark</forename><surname>Johnson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2009 Annual Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (NAACL &apos;09)</title>
		<meeting>the 2009 Annual Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (NAACL &apos;09)</meeting>
		<imprint>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b58">
	<analytic>
		<title level="a" type="main">Extracting social networks from literary fiction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><forename type="middle">K</forename><surname>Elson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nicholas</forename><surname>Dames</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kathleen</forename><forename type="middle">R</forename><surname>Mckeown</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics (ACL &apos;10)</title>
		<meeting>the 48th Annual Meeting of the Association for Computational Linguistics (ACL &apos;10)</meeting>
		<imprint>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b59">
	<analytic>
		<title level="a" type="main">Incorporating non-local information into information extraction systems by gibbs sampling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jenny</forename><forename type="middle">Rose</forename><surname>Finkel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Trond</forename><surname>Grenager</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><surname>Manning</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 43rd Annual Meeting on Association for Computational Linguistics (ACL &apos;05)</title>
		<meeting>the 43rd Annual Meeting on Association for Computational Linguistics (ACL &apos;05)</meeting>
		<imprint>
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b60">
	<analytic>
		<title level="a" type="main">One sense per discourse</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">William</forename><forename type="middle">A</forename><surname>Gale</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kenneth</forename><forename type="middle">W</forename><surname>Church</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Yarowsky</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 4th DARPA Speech and Natural Language Workshop</title>
		<meeting>the 4th DARPA Speech and Natural Language Workshop</meeting>
		<imprint>
			<date type="published" when="1992" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b61">
	<analytic>
		<title level="a" type="main">One sense per tweeter ... and other lexical semantic tales of twitter</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Spandana</forename><surname>Gella</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Paul</forename><surname>Cook</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Timothy</forename><surname>Baldwin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 14th Conference of the European Chapter of the Association for Computational Linguistics</title>
		<meeting>the 14th Conference of the European Chapter of the Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b62">
	<monogr>
		<title level="m" type="main">English Gigaword. Linguistic Data Consortium</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Graff</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><surname>Cieri</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b63">
	<analytic>
		<title level="a" type="main">Identification of speakers in novels</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hua</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Denilson</forename><surname>Barbosa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Grzegorz</forename><surname>Kondrak</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics (ACL &apos;13)</title>
		<meeting>the 51st Annual Meeting of the Association for Computational Linguistics (ACL &apos;13)</meeting>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b64">
	<monogr>
		<title level="m" type="main">Semi-supervised learning for natural language</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Percy</forename><surname>Liang</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2005" />
		</imprint>
	</monogr>
	<note>Master&apos;s thesis, MIT</note>
</biblStruct>

<biblStruct xml:id="b65">
	<analytic>
		<title level="a" type="main">Building a large annotated corpus of English: the Penn treebank</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mitchell</forename><forename type="middle">P</forename><surname>Marcus</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Beatrice</forename><surname>Santorini</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mary</forename><forename type="middle">Ann</forename><surname>Marcinkiewicz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computational Linguistics</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="313" to="330" />
			<date type="published" when="1993" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b66">
	<analytic>
		<title level="a" type="main">Relation guided bootstrapping of semantic lexicons</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tara</forename><surname>Mcintosh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lars</forename><surname>Yencken</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">James</forename><forename type="middle">R</forename><surname>Curran</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Timothy</forename><surname>Baldwin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies (ACL HLT</title>
		<meeting>the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies (ACL HLT</meeting>
		<imprint>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b67">
	<analytic>
		<title level="a" type="main">Name tagging with word clusters and discriminative training</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Scott</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jethran</forename><surname>Miller</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex</forename><surname>Guinness</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Zamanian</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2004 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (NAACL HLT &apos;13)</title>
		<meeting>the 2004 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (NAACL HLT &apos;13)</meeting>
		<imprint>
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b68">
	<analytic>
		<title level="a" type="main">Unsupervised named-entity recognition: Generating gazetteers and resolving ambiguity</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Nadeau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peter</forename><forename type="middle">D</forename><surname>Turney</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stan</forename><surname>Matwin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 19th International Conference on Advances in Artificial Intelligence: Canadian Society for Computational Studies of Intelligence, AI&apos;06</title>
		<meeting>the 19th International Conference on Advances in Artificial Intelligence: Canadian Society for Computational Studies of Intelligence, AI&apos;06</meeting>
		<imprint>
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b69">
	<analytic>
		<title level="a" type="main">Scikit-learn: Machine learning in Python</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Pedregosa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Varoquaux</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Gramfort</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Michel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Thirion</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Grisel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Blondel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Prettenhofer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Weiss</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Dubourg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Vanderplas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Passos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Cournapeau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Brucher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Perrot</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Duchesnay</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="page" from="2825" to="2830" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b70">
	<analytic>
		<title level="a" type="main">Design challenges and misconceptions in named entity recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lev</forename><surname>Ratinov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Roth</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Thirteenth Conference on Computational Natural Language Learning (CoNLL &apos;09)</title>
		<meeting>the Thirteenth Conference on Computational Natural Language Learning (CoNLL &apos;09)</meeting>
		<imprint>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b71">
	<analytic>
		<title level="a" type="main">Named entity recognition in tweets: An experimental study</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alan</forename><surname>Ritter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sam</forename><surname>Clark</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mausam</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oren</forename><surname>Etzioni</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2011 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2011 Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b72">
	<analytic>
		<title level="a" type="main">A bootstrapping method for learning semantic lexicons using extraction pattern contexts</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Thelen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ellen</forename><surname>Riloff</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2002 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2002 Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b73">
	<analytic>
		<title level="a" type="main">Mr. Bennet, his coachman, and the Archbishop walk into a bar but only one of them gets 349 recognized: On the difficulty of detecting characters in literary texts</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hardik</forename><surname>Vala</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Jurgens</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Piper</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Derek</forename><surname>Ruths</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing (EMNLP &apos;15)</title>
		<meeting>the 2015 Conference on Empirical Methods in Natural Language Processing (EMNLP &apos;15)</meeting>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b74">
	<analytic>
		<title level="a" type="main">Multiple narrative disentanglement: Unraveling Infinite Jest</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Byron</forename><forename type="middle">C</forename><surname>Wallace</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2012 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (NAACL-HLT &apos;12)</title>
		<meeting>the 2012 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (NAACL-HLT &apos;12)</meeting>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b75">
	<analytic>
		<title level="a" type="main">Identifying real or fake articles: Towards better language modeling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sachin</forename><surname>References Sameer Badaskar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shilpa</forename><surname>Agarwal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Arora</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Third International Joint Conference on Natural Language Processing</title>
		<meeting>the Third International Joint Conference on Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
	<note>II</note>
</biblStruct>

<biblStruct xml:id="b76">
	<monogr>
		<title level="m" type="main">An empirical study of smoothing techniques for language modeling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stanley</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joshua</forename><surname>Goodman</surname></persName>
		</author>
		<idno>TR-10-98</idno>
		<imprint>
			<date type="published" when="1998" />
		</imprint>
		<respStmt>
			<orgName>Harvard University</orgName>
		</respStmt>
	</monogr>
<note type="report_type">Technical Report</note>
</biblStruct>

<biblStruct xml:id="b77">
	<analytic>
		<title level="a" type="main">No country for old members: User lifecycle and linguistic change in online communities</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cristian</forename><surname>Danescu-Niculescu-Mizil</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Robert</forename><surname>West</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Jurafsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jure</forename><surname>Leskovec</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><surname>Potts</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 22nd international conference on World Wide Web</title>
		<meeting>the 22nd international conference on World Wide Web</meeting>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="307" to="318" />
		</imprint>
	</monogr>
	<note>International World Wide Web Conferences Steering Committee</note>
</biblStruct>

<biblStruct xml:id="b78">
	<monogr>
		<title level="m" type="main">An introduction to the bootstrap</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bradley</forename><surname>Efron</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Robert</forename><surname>Tibshirani</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1993" />
			<publisher>Chapman &amp; Hall</publisher>
			<pubPlace>Boca Raton, FL</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b79">
	<analytic>
		<title level="a" type="main">Identifying fake amazon reviews as learning from crowds</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tomes</forename><surname>Fornaciari</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Massimo</forename><surname>Poesio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 14th Conference of the European Chapter of the Association for Computational Linguistics</title>
		<meeting>the 14th Conference of the European Chapter of the Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="279" to="287" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b80">
	<monogr>
		<title level="m" type="main">Neural machine translation by jointly learning to align and translate</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">References</forename><surname>Dimitry Bahdanau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kyunghyun</forename><surname>Cho</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
		<idno>abs/1409.0473</idno>
		<imprint>
			<date type="published" when="2015" />
			<publisher>CoRR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b81">
	<analytic>
		<title level="a" type="main">Improved transition-based parsing by modeling characters instead of words with lstms</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Miguel</forename><surname>Ballesteros</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Dyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Noah</forename><forename type="middle">A</forename><surname>Smith</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2015 Conference on Empirical Methods in Natural Language Processing<address><addrLine>Lisbon, Portugal</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2015-09" />
			<biblScope unit="page" from="349" to="359" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b82">
	<analytic>
		<title level="a" type="main">Compositional Morphology for Word Representations and Language Modelling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jan</forename><forename type="middle">A</forename><surname>Botha</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Phil</forename><surname>Blunsom</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 31st International Conference on Machine Learning (ICML)</title>
		<meeting>the 31st International Conference on Machine Learning (ICML)<address><addrLine>Beijing, China</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
	<note>jun. *Award for best application paper*</note>
</biblStruct>

<biblStruct xml:id="b83">
	<analytic>
		<title level="a" type="main">Joint learning of character and word embeddings</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xinxiong</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lei</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhiyuan</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maosong</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Huan-Bo</forename><surname>Luan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IJCAI</title>
		<editor>Qiang Yang and Michael Wooldridge</editor>
		<imprint>
			<publisher>AAAI Press</publisher>
			<date type="published" when="2015" />
			<biblScope unit="page" from="1236" to="1242" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b84">
	<analytic>
		<title level="a" type="main">On the properties of neural machine translation: Encoderdecoder approaches</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kyunghyun</forename><surname>Cho</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bart</forename><surname>Van Van Merrienboer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dzmitry</forename><surname>Bahdanau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the Eighth Workshop on Syntax, Semantics and Structure in Statistical Translation</title>
		<meeting>of the Eighth Workshop on Syntax, Semantics and Structure in Statistical Translation<address><addrLine>Doha</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b85">
	<analytic>
		<title level="a" type="main">Normalizing tweets with edit scripts and recurrent neural embeddings</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Grzegorz</forename><surname>Chrupala</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics, ACL 2014</title>
		<meeting>the 52nd Annual Meeting of the Association for Computational Linguistics, ACL 2014<address><addrLine>Baltimore, MD, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Short Papers</publisher>
			<date type="published" when="2014-06-22" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="680" to="686" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b86">
	<monogr>
		<title level="m" type="main">A character-level decoder without explicit segmentation for neural machine translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Junyoung</forename><surname>Chung</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kyunghyun</forename><surname>Cho</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
		<idno>abs/1603.06147</idno>
		<imprint>
			<date type="published" when="2016" />
			<publisher>CoRR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b87">
	<monogr>
		<title level="m" type="main">Multi-language image description with neural sequence models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Desmond</forename><surname>Elliott</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stella</forename><surname>Frank</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eva</forename><surname>Hasler</surname></persName>
		</author>
		<idno>abs/1510.04709</idno>
		<imprint>
			<date type="published" when="2015" />
			<publisher>CoRR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b88">
	<analytic>
		<title level="a" type="main">Montreal neural machine translation systems for wmt15</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sebastien</forename><surname>Jean</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Orhan</forename><surname>Firat</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kyunghun</forename><surname>Cho</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Roland</forename><surname>Memisevic</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the 10th Workshop on Statistical Machine Translation</title>
		<meeting>of the 10th Workshop on Statistical Machine Translation<address><addrLine>Lisbon</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b89">
	<analytic>
		<title level="a" type="main">Recurrent continuous translation models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nal</forename><surname>Kalchbrenner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Phil</forename><surname>Blunsom</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>of the Conference on Empirical Methods in Natural Language essing<address><addrLine>Seattle</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b90">
	<analytic>
		<title level="a" type="main">Character-aware neural language models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoon</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yacine</forename><surname>Jernite</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Sontag</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander</forename><forename type="middle">M</forename><surname>Rush</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 30th AAAI Conference on Artificial Intelligence (AAAI&apos;16)</title>
		<meeting>the 30th AAAI Conference on Artificial Intelligence (AAAI&apos;16)</meeting>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b91">
	<analytic>
		<title level="a" type="main">Statistical Phrase-Based Translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philipp</forename><surname>Koehn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Franz</forename><forename type="middle">Joseph</forename><surname>Och</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Marcu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the 41th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>of the 41th Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b92">
	<analytic>
		<title level="a" type="main">Moses: Open Source Toolkit for Statistical Machine Translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philipp</forename><surname>Koehn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hieu</forename><surname>Hoang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexandra</forename><surname>Birch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Callison-Burch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marcello</forename><surname>Federico</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nicolas</forename><surname>Bertoldi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Brooke</forename><surname>Cowan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wade</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christine</forename><surname>Moran</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Zens</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Dyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ondrej</forename><surname>Bojar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexandra</forename><surname>Constantin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Evan</forename><surname>Herbst</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the 45th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>of the 45th Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2007" />
			<biblScope unit="page" from="177" to="180" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b93">
	<analytic>
		<title level="a" type="main">Finding function in form: Compositional character models for open vocabulary word representation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wang</forename><surname>Ling</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Dyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alan</forename><forename type="middle">W</forename><surname>Black</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Isabel</forename><surname>Trancoso</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ramon</forename><surname>Fermandez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Silvio</forename><surname>Amir</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luis</forename><surname>Marujo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tiago</forename><surname>Luis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2015 Conference on Empirical Methods in Natural Language Processing<address><addrLine>Lisbon</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="1520" to="1530" />
		</imprint>
	</monogr>
	<note>Portugal, September. Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b94">
	<monogr>
		<title level="m" type="main">Character-based neural machine translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wang</forename><surname>Ling</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Isabel</forename><surname>Trancoso</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Dyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alan</forename><forename type="middle">W</forename><surname>Black</surname></persName>
		</author>
		<idno>abs/1511.04586</idno>
		<imprint>
			<date type="published" when="2015" />
			<publisher>CoRR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b95">
	<monogr>
		<title level="m" type="main">Character-based neural machine translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Min-Thang</forename><surname>Luong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cristopher</forename><forename type="middle">D</forename><surname>Manning</surname></persName>
		</author>
		<idno>abs/1511.04586</idno>
		<imprint>
			<date type="published" when="2016" />
			<publisher>CoRR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b96">
	<analytic>
		<title level="a" type="main">Boosting named entity recognition with neural character embeddings</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Cicero</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Victor</forename><surname>Santos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Guimar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Fifth Named Entity Workshop</title>
		<meeting>the Fifth Named Entity Workshop<address><addrLine>Beijing, China</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2015-07" />
			<biblScope unit="page" from="25" to="33" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b97">
	<analytic>
		<title level="a" type="main">Learning character-level representations for part-ofspeech tagging</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Cicero</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bianca</forename><surname>Santos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Zadrozny</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 31st International Conference on Machine Learning (ICML-14)</title>
		<editor>Tony Jebara and Eric P. Xing</editor>
		<meeting>the 31st International Conference on Machine Learning (ICML-14)</meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="1818" to="1826" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b98">
	<monogr>
		<title level="m" type="main">Neural machine translation of rare words with subword units</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rico</forename><surname>Sennrich</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Barry</forename><surname>Haddow</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexandra</forename><surname>Birch</surname></persName>
		</author>
		<idno>abs/1508.07909</idno>
		<imprint>
			<date type="published" when="2015" />
			<publisher>CoRR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b99">
	<analytic>
		<title level="a" type="main">Semeval-2012 task 6: A pilot on semantic textual similarity</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ilya</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oriol</forename><surname>Vinyals</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Quoc</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Le</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Ghahramani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Welling</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><forename type="middle">D</forename><surname>Cortes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">Q</forename><surname>Lawrence</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Weinberger</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the First Joint Conference on Lexical and Computational Semantics</title>
		<meeting>the First Joint Conference on Lexical and Computational Semantics<address><addrLine>Mona Diab, Daniel Cer, and Aitor Gonzalez-Agirre</addrLine></address></meeting>
		<imprint>
			<publisher>Curran Associates, Inc. References Eneko Agirre</publisher>
			<date type="published" when="2012" />
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="page" from="385" to="393" />
		</imprint>
	</monogr>
	<note>Proceedings of the Sixth International Workshop on Semantic Evaluation</note>
</biblStruct>

<biblStruct xml:id="b100">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pascal</forename><surname>References Frédéric Bastien</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Razvan</forename><surname>Lamblin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">James</forename><surname>Pascanu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ian</forename><surname>Bergstra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Arnaud</forename><surname>Goodfellow</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nicolas</forename><surname>Bergeron</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Bouchard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Warde-Farley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Bengio</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1211.5590</idno>
		<title level="m">Theano: new features and speed improvements</title>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b101">
	<analytic>
		<title level="a" type="main">Event data on armed conflict and security: New perspectives, old challenges, and some solutions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sven</forename><surname>Chojnacki</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christian</forename><surname>Ickler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Spies</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Wiesel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Interactions</title>
		<imprint>
			<biblScope unit="volume">38</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="382" to="401" />
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b102">
	<analytic>
		<title level="a" type="main">Incorporating non-local information into information extraction systems by gibbs sampling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jenny</forename><forename type="middle">Rose</forename><surname>Finkel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Trond</forename><surname>Grenager</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><surname>Manning</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 43rd Annual Meeting on Association for Computational Linguistics</title>
		<meeting>the 43rd Annual Meeting on Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2005" />
			<biblScope unit="page" from="363" to="370" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b103">
	<analytic>
		<title level="a" type="main">Mikael Eriksson, Margareta Sollenberg, and Håvard Strand</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nils</forename><forename type="middle">Petter</forename><surname>Gleditsch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peter</forename><surname>Wallensteen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of peace research</title>
		<imprint>
			<biblScope unit="volume">39</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="615" to="637" />
			<date type="published" when="2002" />
		</imprint>
	</monogr>
	<note>Armed conflict 1946-2001: A new dataset</note>
</biblStruct>

<biblStruct xml:id="b104">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Gtd</surname></persName>
		</author>
		<ptr target="http://www.start.umd.edu/gtd" />
		<title level="m">Global terrorism database</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b105">
	<analytic>
		<title level="a" type="main">analysis by perpetrator, weapon, time, and location</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Madelyn Hsiao-Rei</forename><surname>Hicks</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hamit</forename><surname>Dardagan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gabriela</forename><forename type="middle">Guerrero</forename><surname>Serdán</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Peter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><forename type="middle">A</forename><surname>Bagnall</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Sloboda</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Spagat</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">PLoS Med</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page">1000415</biblScope>
			<date type="published" when="2003" />
		</imprint>
	</monogr>
	<note>Violent deaths of iraqi civilians</note>
</biblStruct>

<biblStruct xml:id="b106">
	<monogr>
		<title level="m" type="main">Iraq body count</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Ibc</surname></persName>
		</author>
		<ptr target="https://www.iraqbodycount.org/database/" />
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b107">
	<analytic>
		<title level="a" type="main">Predicting the future with social media</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sitaram</forename><surname>Asur</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Bernardo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Huberman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Web Intelligence and Intelligent Agent Technology (WI-IAT), 2010 IEEE/WIC/ACM International Conference on</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2010" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="492" to="499" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b108">
	<analytic>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>David</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Blei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Andrew</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael I Jordan</forename><surname>Ng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Latent Dirichlet allocation. the Journal of machine Learning research</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="993" to="1022" />
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b109">
	<analytic>
		<title level="a" type="main">User based aggregation for biterm topic model</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Weizheng</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jinpeng</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yan</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hongfei</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaoming</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 53rd Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="489" to="494" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b110">
	<analytic>
		<title level="a" type="main">A neural probabilistic language model</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Réjean</forename><surname>References Yoshua Bengio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pascal</forename><surname>Ducharme</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christian</forename><surname>Vincent</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Janvin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Machine Learning Researc</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="1137" to="1155" />
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b111">
	<analytic>
		<title level="a" type="main">Class-based n-gram models of natural language</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Peter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Brown</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">Della</forename><surname>Vincent</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peter</forename><forename type="middle">V</forename><surname>Pietra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jennifer</forename><forename type="middle">C</forename><surname>De Souza</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Robert</forename><forename type="middle">L</forename><surname>Lai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Mercer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computational Linguistics</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="467" to="479" />
			<date type="published" when="1992" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b112">
	<analytic>
		<title level="a" type="main">Conll-x shared task on multilingual dependency parsing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sabine</forename><surname>Buchholz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Erwin</forename><surname>Marsi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CoNLL</title>
		<imprint>
			<date type="published" when="2006" />
			<biblScope unit="page" from="149" to="164" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b113">
	<analytic>
		<title level="a" type="main">Natural language processing (almost) from scratch</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ronan</forename><surname>Collobert</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jason</forename><surname>Weston</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Léon</forename><surname>Bottou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Karlen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Koray</forename><surname>Kavukcuoglu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pavel</forename><forename type="middle">P</forename><surname>Kuksa</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="page" from="2493" to="2537" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b114">
	<analytic>
		<title level="a" type="main">Improving vector space word representations using multilingual correlation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Manaal</forename><surname>Faruqui</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Dyer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EACL</title>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="462" to="471" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b115">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Manaal</forename><surname>Faruqui</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yulia</forename><surname>Tsvetkov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dani</forename><surname>Yogatama</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Dyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Noah</forename><forename type="middle">A</forename><surname>Smith</surname></persName>
		</author>
		<title level="m">Sparse overcomplete word vector representations. In ACL</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="1491" to="1500" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b116">
	<analytic>
		<title level="a" type="main">Revisiting embedding features for simple semi-supervised learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiang</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wanxiang</forename><surname>Che</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Haifeng</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ting</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EMNLP</title>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="110" to="120" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b117">
	<analytic>
		<title level="a" type="main">Cross-lingual dependency parsing based on distributed representations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiang</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wanxiang</forename><surname>Che</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Yarowsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Haifeng</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ting</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="1234" to="1244" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b118">
	<analytic>
		<title level="a" type="main">Deep learning with limited numerical precision</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Suyog</forename><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ankur</forename><surname>Agrawal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kailash</forename><surname>Gopalakrishnan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pritish</forename><surname>Narayanan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="1737" to="1746" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b119">
	<analytic>
		<title level="a" type="main">Improving distributional similarity with lessons learned from word embeddings</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Omer</forename><surname>Levy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoav</forename><surname>Goldberg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ido</forename><surname>Dagan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">TACL</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="211" to="225" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b120">
	<analytic>
		<title level="a" type="main">Distributed representations of words and phrases and their compositionality</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tomas</forename><surname>Mikolov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ilya</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kai</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Greg</forename><forename type="middle">S</forename><surname>Corrado</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeff</forename><surname>Dean</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS</title>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="3111" to="3119" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b121">
	<analytic>
		<title level="a" type="main">Linguistic regularities in continuous space word representations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tomas</forename><surname>Mikolov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yih</forename><surname>Wen-Tau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geoffrey</forename><surname>Zweig</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NAACL-HLT</title>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="746" to="751" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b122">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jerome</forename><forename type="middle">L</forename><surname>Myers</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Arnold</forename><forename type="middle">D</forename><surname>Well</surname></persName>
		</author>
		<title level="m">Research Design &amp; Statistical Analysisn. Routledge</title>
		<imprint>
			<date type="published" when="1995" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b123">
	<analytic>
		<title level="a" type="main">Design challenges and misconceptions in named entity recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lev</forename><surname>Ratinov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Roth</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of CoNLL-09</title>
		<meeting>CoNLL-09</meeting>
		<imprint>
			<date type="published" when="2009" />
			<biblScope unit="page" from="147" to="155" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b124">
	<analytic>
		<title level="a" type="main">Word representations: A simple and general method for semi-supervised learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joseph</forename><surname>Turian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lev-Arie</forename><surname>Ratinov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL</title>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="page" from="384" to="394" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b125">
	<analytic>
		<title level="a" type="main">From paraphrase database to compositional paraphrase model and back</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Wieting</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mohit</forename><surname>Bansal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kevin</forename><surname>Gimpel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Karen</forename><surname>Livescu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">TACL</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="345" to="358" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b126">
	<monogr>
		<title level="m" type="main">Modeling opinion dynamics in diffusion networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Isabel</forename><surname>References Abir De</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Niloy</forename><surname>Valera</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sourangshu</forename><surname>Ganguly</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Manuel</forename><surname>Bhattacharya</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Gomez-Rodriguez</surname></persName>
		</author>
		<idno>abs/1506.05474</idno>
		<imprint>
			<date type="published" when="2015" />
			<publisher>CoRR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b127">
	<analytic>
		<title level="a" type="main">Classifying twitter favorites: Like, bookmark, or thanks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Genevieve</forename><surname>Gorrell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kalina</forename><surname>Bontcheva</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of the Association for Information Science and Technology</title>
		<imprint>
			<biblScope unit="volume">67</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="17" to="25" />
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b128">
	<analytic>
		<title level="a" type="main">Spectra of Some Self-Exciting and Mutually Exciting Point Processes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alan</forename><forename type="middle">G</forename><surname>Hawkes</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Biometrika</title>
		<imprint>
			<biblScope unit="volume">58</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="83" to="90" />
			<date type="published" when="1971" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b129">
	<analytic>
		<title level="a" type="main">Conditional Random Fields: Probabilistic Models for Segmenting and Labeling Sequence Data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><forename type="middle">D</forename><surname>Lafferty</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Mccallum</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fernando</forename><forename type="middle">C N</forename><surname>Pereira</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of International Conference on Machine Learning (ICML)</title>
		<meeting>of International Conference on Machine Learning (ICML)</meeting>
		<imprint>
			<date type="published" when="2001" />
			<biblScope unit="page" from="282" to="289" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b130">
	<analytic>
		<title level="a" type="main">Misinformation and its correction continued influence and successful debiasing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stephan</forename><surname>Lewandowsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">H</forename><surname>Ullrich</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Colleen</forename><forename type="middle">M</forename><surname>Ecker</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Norbert</forename><surname>Seifert</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Schwarz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Cook</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Psychological Science in the Public Interest</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="page" from="106" to="131" />
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b131">
	<analytic>
		<title level="a" type="main">Classifying Tweet Level Judgements of Rumours in Social Media</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michal</forename><surname>Lukasik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Trevor</forename><surname>Cohn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kalina</forename><surname>Bontcheva</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of Empirical Methods in Natural Language Processing (EMNLP)</title>
		<meeting>of Empirical Methods in Natural Language essing (EMNLP)</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="2590" to="2595" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b132">
	<analytic>
		<title level="a" type="main">Point process modelling of rumour dynamics in social media</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michal</forename><surname>Lukasik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Trevor</forename><surname>Cohn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kalina</forename><surname>Bontcheva</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the 53rd ACL</title>
		<meeting>of the 53rd ACL</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="518" to="523" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b133">
	<monogr>
		<title level="m" type="main">Introduction to Information Retrieval</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><forename type="middle">D</forename><surname>Manning</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Prabhakar</forename><surname>Raghavan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hinrich</forename><surname>Schütze</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2008" />
			<publisher>Cambridge University Press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b134">
	<analytic>
		<title level="a" type="main">Rumor has it: Identifying misinformation in microblogs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Emily</forename><surname>Vahed Qazvinian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Rosengren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Dragomir</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qiaozhu</forename><surname>Radev</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Mei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of Empirical Methods in Natural Language Processing (EMNLP)</title>
		<meeting>of Empirical Methods in Natural Language essing (EMNLP)</meeting>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="page" from="1589" to="1599" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b135">
	<analytic>
		<title level="a" type="main">Short text classification: A survey</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ge</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yunming</forename><surname>Ye</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaolin</forename><surname>Du</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaohui</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shifu</forename><surname>Bie</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Multimedia</title>
		<imprint>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page">9</biblScope>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b136">
	<analytic>
		<title level="a" type="main">Mixture of mutually exciting processes for viral diffusion</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hong</forename><surname>Shuang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hongyuan</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Zha</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of International Conference on Machine Learning (ICML)</title>
		<meeting>of International Conference on Machine Learning (ICML)</meeting>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="page" from="1" to="9" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b137">
	<analytic>
		<title level="a" type="main">Seismic: A self-exciting point process model for predicting tweet popularity</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qingyuan</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Murat</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Erdogdu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Hera</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anand</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jure</forename><surname>Rajaraman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Leskovec</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of International Conference on Knowledge Discovery and Data Mining (KDD)</title>
		<meeting>of International Conference on Knowledge Discovery and Data Mining (KDD)</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="1513" to="1522" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b138">
	<analytic>
		<title level="a" type="main">Analysing how people orient to and spread rumours in social media by looking at conversational threads</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Arkaitz</forename><surname>Zubiaga</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maria</forename><surname>Liakata</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rob</forename><surname>Procter</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">PLoS ONE</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page">3</biblScope>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
	<note>Geraldine Wong Sak Hoi, and Peter Tolmie</note>
</biblStruct>

<biblStruct xml:id="b139">
	<analytic>
		<title level="a" type="main">Trolls just want to have fun</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Erin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Buckels</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Paul</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Trapnell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Delroy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Paulhus</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Personality and individual Differences</title>
		<imprint>
			<biblScope unit="volume">67</biblScope>
			<biblScope unit="page" from="97" to="102" />
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b140">
	<analytic>
		<title level="a" type="main">Do not feel the trolls</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Erik</forename><surname>Cambria</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Praphul</forename><surname>Chandra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Avinash</forename><surname>Sharma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Amir</forename><surname>Hussain</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 3rd International Workshop on Social Data on the Web, SDoW &apos;10</title>
		<meeting>the 3rd International Workshop on Social Data on the Web, SDoW &apos;10<address><addrLine>Shanghai, China</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b141">
	<analytic>
		<title level="a" type="main">Adversarial web search</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Carlos</forename><surname>Castillo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Brian</forename><forename type="middle">D</forename><surname>Davison</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Found. Trends Inf. Retr</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="377" to="486" />
			<date type="published" when="2011-05" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b142">
	<analytic>
		<title level="a" type="main">Detecting offensive language in social media to protect adolescent online safety</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ying</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yilu</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sencun</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Heng</forename><surname>Xu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2012 International Conference on Privacy, Security, Risk and Trust and of the 2012 International Conference on Social Computing</title>
		<meeting>the 2012 International Conference on Privacy, Security, Risk and Trust and of the 2012 International Conference on Social Computing<address><addrLine>Amsterdam, Netherlands</addrLine></address></meeting>
		<imprint>
			<publisher>PAS-SAT/SocialCom</publisher>
			<date type="published" when="2012" />
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="page" from="71" to="80" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b143">
	<analytic>
		<title level="a" type="main">GATE: an architecture for development of robust HLT applications</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hamish</forename><surname>Cunningham</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Diana</forename><surname>Maynard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kalina</forename><surname>Bontcheva</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Valentin</forename><surname>Tablan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of 40th Annual Meeting of the Association for Computational Linguistics, ACL &apos;02</title>
		<meeting>40th Annual Meeting of the Association for Computational Linguistics, ACL &apos;02<address><addrLine>Philadelphia, Pennsylvania, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2002" />
			<biblScope unit="page" from="168" to="175" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b144">
	<monogr>
		<title level="m" type="main">Text Processing with GATE</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hamish</forename><surname>Cunningham</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Diana</forename><surname>Maynard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kalina</forename><surname>Bontcheva</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2011" />
			<publisher>Gateway Press CA</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b145">
	<analytic>
		<title level="a" type="main">Mining the peanut gallery: Opinion extraction and semantic classification of product reviews</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kushal</forename><surname>Dave</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Steve</forename><surname>Lawrence</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><forename type="middle">M</forename><surname>Pennock</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 12th International World Wide Web conference, WWW &apos;03</title>
		<meeting>the 12th International World Wide Web conference, WWW &apos;03<address><addrLine>Hungary</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2003" />
			<biblScope unit="page" from="519" to="528" />
		</imprint>
	</monogr>
<note type="report_type">Budapest</note>
</biblStruct>

<biblStruct xml:id="b146">
	<analytic>
		<title level="a" type="main">Strategic manipulation of internet opinion forums: Implications for consumers and firms</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chrysanthos</forename><surname>Dellarocas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Management Science</title>
		<imprint>
			<biblScope unit="volume">52</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page" from="1577" to="1593" />
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b147">
	<analytic>
		<title level="a" type="main">Liblinear: A library for large linear classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kai-Wei</forename><surname>Rong-En Fan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cho-Jui</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiangrui</forename><surname>Hsieh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chih-Jen</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Lin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Mach. Learn. Res</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page" from="1871" to="1874" />
			<date type="published" when="2008-06" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b148">
	<analytic>
		<title level="a" type="main">Supervised machine learning for the detection of troll profiles in Twitter social network: Application to a real case of cyberbullying</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Patxi</forename><surname>Galán-García</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">José</forename><surname>Gaviria De La Puerta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Carlos</forename><forename type="middle">Laorden</forename><surname>Gómez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Igor</forename><surname>Santos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pablo</forename><forename type="middle">García</forename><surname>Bringas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Joint Conference SOCO13-CISIS13-ICEUTE13, Advances in Intelligent Systems and Computing</title>
		<meeting>the International Joint Conference SOCO13-CISIS13-ICEUTE13, Advances in Intelligent Systems and Computing</meeting>
		<imprint>
			<publisher>Springer International Publishing</publisher>
			<date type="published" when="2014" />
			<biblScope unit="page" from="419" to="428" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b149">
	<analytic>
		<title level="a" type="main">Featurerich named entity recognition for Bulgarian using conditional random fields</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Georgi</forename><surname>Georgiev</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Preslav</forename><surname>Nakov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kuzman</forename><surname>Ganchev</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Petya</forename><surname>Osenova</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kiril</forename><surname>Simov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Conference Recent Advances in Natural Language Processing, RANLP &apos;09</title>
		<meeting>the International Conference Recent Advances in Natural Language Processing, RANLP &apos;09<address><addrLine>Borovets, Bulgaria</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2009" />
			<biblScope unit="page" from="113" to="117" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b150">
	<analytic>
		<title level="a" type="main">Searching for safety online: Managing &quot;trolling&quot; in a feminist forum</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Susan</forename><surname>Herring</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kirk</forename><surname>Job-Sluder</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rebecca</forename><surname>Scheckler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sasha</forename><surname>Barab</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The Information Society</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="371" to="384" />
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b151">
	<analytic>
		<title level="a" type="main">Mining and summarizing customer reviews</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Minqing</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bing</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 10th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, KDD &apos;04</title>
		<meeting>the 10th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, KDD &apos;04<address><addrLine>Seattle, Washington, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2004" />
			<biblScope unit="page" from="168" to="177" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b152">
	<analytic>
		<title level="a" type="main">Accurately detecting trolls in slashdot zoo via decluttering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Srijan</forename><surname>Kumar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Francesca</forename><surname>Spezzano</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><forename type="middle">S</forename><surname>Subrahmanian</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2014 IEEE/ACM International Conference on Advances in Social Network Analysis and Mining, ASONAM &apos;14</title>
		<meeting>the 2014 IEEE/ACM International Conference on Advances in Social Network Analysis and Mining, ASONAM &apos;14<address><addrLine>Beijing, China</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="188" to="195" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b153">
	<analytic>
		<title level="a" type="main">Combining multiple email filters based on multivariate statistical analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wenbin</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ning</forename><surname>Zhong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chunnian</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Foundations of Intelligent Systems</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2006" />
			<biblScope unit="page" from="729" to="738" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b154">
	<analytic>
		<title level="a" type="main">Finding opinion manipulation trolls in news community forums</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Todor</forename><surname>Mihaylov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Georgi</forename><surname>Georgiev</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Preslav</forename><surname>Nakov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Nineteenth Conference on Computational Natural Language Learning, CoNLL &apos;15</title>
		<meeting>the Nineteenth Conference on Computational Natural Language Learning, CoNLL &apos;15<address><addrLine>Beijing, China</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="310" to="314" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b155">
	<analytic>
		<title level="a" type="main">Exposing paid opinion manipulation trolls</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Todor</forename><surname>Mihaylov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ivan</forename><surname>Koychev</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Georgi</forename><surname>Georgiev</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Preslav</forename><surname>Nakov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Conference Recent Advances in Natural Language Processing, RANLP &apos;15</title>
		<meeting>the International Conference Recent Advances in Natural Language Processing, RANLP &apos;15<address><addrLine>Hissar, Bulgaria</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="443" to="450" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b156">
	<analytic>
		<title level="a" type="main">Crowdsourcing a word-emotion association lexicon</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Saif</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peter</forename><forename type="middle">D</forename><surname>Mohammad</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Turney</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computational Intelligence</title>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="436" to="465" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b157">
	<analytic>
		<title level="a" type="main">Building an inflectional stemmer for Bulgarian</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Preslav</forename><surname>Nakov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 4th International Conference on Computer Systems and Technologies: E-Learning, CompSysTech &apos;03</title>
		<meeting>the 4th International Conference on Computer Systems and Technologies: E-Learning, CompSysTech &apos;03<address><addrLine>Rousse, Bulgaria</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2003" />
			<biblScope unit="page" from="419" to="424" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b158">
	<analytic>
		<title level="a" type="main">BulStem: Design and evaluation of inflectional stemmer for Bulgarian</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Preslav</forename><surname>Nakov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of Workshop on Balkan Language Resources and Tools (1st Balkan Conference in Informatics)</title>
		<meeting>Workshop on Balkan Language Resources and Tools (1st Balkan Conference in Informatics)<address><addrLine>Thessaloniki, Greece</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2003-11" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b159">
	<analytic>
		<title level="a" type="main">Propagation of trust and distrust for the detection of trolls in a social network</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Javier</forename><surname>Ortega</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jos</forename><forename type="middle">A</forename><surname>Troyano</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fermn</forename><forename type="middle">L</forename><surname>Cruz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Carlos</forename><forename type="middle">G</forename><surname>Vallejo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fernando</forename><surname>Enrquez</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computer Networks</title>
		<imprint>
			<biblScope unit="volume">56</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="2884" to="2895" />
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b160">
	<analytic>
		<title level="a" type="main">Finding deceptive opinion spam by any stretch of the imagination</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Myle</forename><surname>Ott</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yejin</forename><surname>Choi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Claire</forename><surname>Cardie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeffrey</forename><forename type="middle">T</forename><surname>Hancock</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies</title>
		<meeting>the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies<address><addrLine>Portland, Oregon</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="309" to="319" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b161">
	<analytic>
		<title level="a" type="main">Scikit-learn: Machine learning in Python</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Pedregosa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Varoquaux</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Gramfort</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Michel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Thirion</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Grisel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Blondel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Prettenhofer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Weiss</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Dubourg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Vanderplas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Passos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Cournapeau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Brucher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Perrot</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Duchesnay</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="page" from="2825" to="2830" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b162">
	<analytic>
		<title level="a" type="main">Truthy: Mapping the spread of astroturf in microblog streams</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jacob</forename><surname>Ratkiewicz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Conover</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mark</forename><surname>Meiss</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bruno</forename><surname>Gonçalves</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Snehal</forename><surname>Patil</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alessandro</forename><surname>Flammini</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Filippo</forename><surname>Menczer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 20th International Conference Companion on World Wide Web, WWW &apos;11</title>
		<meeting>the 20th International Conference Companion on World Wide Web, WWW &apos;11<address><addrLine>Hyderabad, India</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="page" from="249" to="252" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b163">
	<analytic>
		<title level="a" type="main">Assessing Trust: Contextual Accountability</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthew</forename><surname>Rowe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathan</forename><surname>Butters</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the First Workshop on Trust and Privacy on the Social and Semantic Web, SPOT &apos;09</title>
		<meeting>the First Workshop on Trust and Privacy on the Social and Semantic Web, SPOT &apos;09<address><addrLine>Heraklion, Greece</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b164">
	<analytic>
		<title level="a" type="main">Troll detection by domain-adapting sentiment analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chun-Wei</forename><surname>Seah</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hai</forename><forename type="middle">Leong</forename><surname>Chieu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kian Ming Adam</forename><surname>Chai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Loo-Nin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lee</forename><forename type="middle">Wei</forename><surname>Teow</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Yeong</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 18th International Conference on Information Fusion, FUSION &apos;15</title>
		<meeting>the 18th International Conference on Information Fusion, FUSION &apos;15<address><addrLine>Washington, DC, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="792" to="799" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b165">
	<analytic>
		<title level="a" type="main">Building a linguistically interpreted corpus of Bulgarian: the BulTreeBank</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kiril</forename><surname>Simov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Petya</forename><surname>Osenova</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Milena</forename><surname>Slavcheva</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sia</forename><surname>Kolkovska</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Elisaveta</forename><surname>Balabanova</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dimitar</forename><surname>Doikoff</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Krassimira</forename><surname>Ivanova</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Er</forename><surname>Simov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Milen</forename><surname>Kouylekov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Third International Conference on Language Resources and Evaluation, LREC &apos;02</title>
		<meeting>the Third International Conference on Language Resources and Evaluation, LREC &apos;02<address><addrLine>Canary Islands, Spain</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b166">
	<analytic>
		<title level="a" type="main">SU-FMI: System description for SemEval-2014 task 9 on sentiment analysis in Twitter</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Boris</forename><surname>Velichkov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Borislav</forename><surname>Kapukaranov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ivan</forename><surname>Grozev</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeni</forename><surname>Karanesheva</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Todor</forename><surname>Mihaylov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yasen</forename><surname>Kiprov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Preslav</forename><surname>Nakov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ivan</forename><surname>Koychev</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Georgi</forename><surname>Georgiev</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 8th International Workshop on Semantic Evaluation, SemEval &apos;14</title>
		<meeting>the 8th International Workshop on Semantic Evaluation, SemEval &apos;14<address><addrLine>Dublin, Ireland</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="590" to="595" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b167">
	<analytic>
		<title level="a" type="main">Recognizing contextual polarity in phraselevel sentiment analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Theresa</forename><surname>Wilson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Janyce</forename><surname>Wiebe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Paul</forename><surname>Hoffmann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Conference on Human Language Technology and Empirical Methods in Natural Language Processing, HLT &apos;05</title>
		<meeting>the Conference on Human Language Technology and Empirical Methods in Natural Language Processing, HLT &apos;05<address><addrLine>Vancouver, British Columbia, Canada</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2005" />
			<biblScope unit="page" from="347" to="354" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b168">
	<analytic>
		<title level="a" type="main">Filtering offensive language in online communities using grammatical relations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhi</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sencun</forename><surname>Zhu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Seventh Annual Collaboration, Electronic Messaging, Anti-Abuse and Spam Conference, CEAS &apos;10</title>
		<meeting>the Seventh Annual Collaboration, Electronic Messaging, Anti-Abuse and Spam Conference, CEAS &apos;10<address><addrLine>Redmond, Washington, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b169">
	<analytic>
		<title level="a" type="main">Polyglot: Distributed Word Representations for Multilingual NLP</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jun-Ming</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaojin</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Amy</forename><surname>Bellmore</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the First International Workshop on Issues of Sentiment Discovery and Opinion Mining, WISDOM &apos;12</title>
		<editor>References Rami Al-Rfou, Bryan Perozzi, and Steven Skiena</editor>
		<meeting>the First International Workshop on Issues of Sentiment Discovery and Opinion Mining, WISDOM &apos;12<address><addrLine>Beijing, China</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="page" from="1" to="10" />
		</imprint>
	</monogr>
	<note>CoNLL</note>
</biblStruct>

<biblStruct xml:id="b170">
	<analytic>
		<title level="a" type="main">Improved Transition-based Parsing by Modeling Characters instead of Words with LSTMs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Miguel</forename><surname>Ballesteros</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Dyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Noah</forename><forename type="middle">A</forename><surname>Smith</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EMNLP</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b171">
	<analytic>
		<title level="a" type="main">Tnt: a statistical part-ofspeech tagger</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thorsten</forename><surname>Brants</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the sixth conference on Applied natural language processing</title>
		<meeting>the sixth conference on Applied natural language processing</meeting>
		<imprint>
			<date type="published" when="2000" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b172">
	<analytic>
		<title level="a" type="main">Don&apos;t count, predict! a systematic comparison of context-counting vs. context-predicting semantic vectors</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">References</forename><surname>Marco Baroni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Georgiana</forename><surname>Dinu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Germán</forename><surname>Kruszewski</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 52nd Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="238" to="247" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b173">
	<analytic>
		<title level="a" type="main">Distributional semantics in technicolor</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Elia</forename><surname>Bruni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gemma</forename><surname>Boleda</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marco</forename><surname>Baroni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nam-Khanh</forename><surname>Tran</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics: Long Papers</title>
		<meeting>the 50th Annual Meeting of the Association for Computational Linguistics: Long Papers</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2012" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="136" to="145" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b174">
	<analytic>
		<title level="a" type="main">Extracting semantic representations from word cooccurrence statistics: A computational study</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><forename type="middle">A</forename><surname>Bullinaria</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joseph</forename><forename type="middle">P</forename><surname>Levy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Behavior research methods</title>
		<imprint>
			<biblScope unit="volume">39</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="510" to="526" />
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b175">
	<analytic>
		<title level="a" type="main">Extracting semantic representations from word cooccurrence statistics: stop-lists, stemming, and svd</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>John</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joseph P</forename><surname>Bullinaria</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Levy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Behavior research methods</title>
		<imprint>
			<biblScope unit="volume">44</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="890" to="907" />
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b176">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>References</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Ammar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Mulcaire</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Ballesteros</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><forename type="middle">A</forename><surname>Dyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Smith</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1602.01595</idno>
		<title level="m">Many languages, one parser</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b177">
	<analytic>
		<title level="a" type="main">MaltOptimizer: an optimization tool for MaltParser</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Ballesteros</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Nivre</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Demonstrations at the 13th Conference of the European Chapter of the Association for Computational Linguistics</title>
		<meeting>the Demonstrations at the 13th Conference of the European Chapter of the Association for Computational Linguistics</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2012" />
			<biblScope unit="page" from="58" to="62" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b178">
	<analytic>
		<title level="a" type="main">Controlling the false discovery rate: a practical and powerful approach to multiple testing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Benjamini</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Hochberg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of the Royal Statistical Society. Series B (Methodological)</title>
		<imprint>
			<biblScope unit="page" from="289" to="300" />
			<date type="published" when="1995" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b179">
	<analytic>
		<title level="a" type="main">Learning reliable information for dependency parsing adaptation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Isahara</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 22Nd International Conference on Computational Linguistics</title>
		<meeting>the 22Nd International Conference on Computational Linguistics<address><addrLine>Stroudsburg, PA, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2008" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="113" to="120" />
		</imprint>
	</monogr>
	<note>COLING &apos;08</note>
</biblStruct>

<biblStruct xml:id="b180">
	<analytic>
		<title level="a" type="main">An integrated framework for analyzing multilingual content in Web 2.0 social media</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Dang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Paul</forename><forename type="middle">J</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">A</forename><surname>Brown</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Ku</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Decision Support Systems</title>
		<imprint>
			<biblScope unit="volume">61</biblScope>
			<biblScope unit="page" from="126" to="135" />
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b181">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Daumé</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Iii</forename></persName>
		</author>
		<idno type="arXiv">arXiv:0907.1815</idno>
		<title level="m">Frustratingly easy domain adaptation</title>
		<imprint>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b182">
	<analytic>
		<title level="a" type="main">Exploring self training for Hindi dependency parsing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Goutam</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">R</forename><surname>Ambati</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of 5th International Joint Conference on Natural Language Processing</title>
		<meeting>5th International Joint Conference on Natural Language Processing<address><addrLine>Chiang Mai, Thailand</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2011-11" />
			<biblScope unit="page" from="1452" to="1456" />
		</imprint>
	</monogr>
	<note>Asian Federation of Natural Language Processing</note>
</biblStruct>

<biblStruct xml:id="b183">
	<analytic>
		<title level="a" type="main">Cross-lingual transfer parsing for low-resourced languages: An Irish case study</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Lynn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Foster</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Dras</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Tounsi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CLTW 2014. The First Celtic Language Technology Workshop. Proceedings of the Workshop</title>
		<meeting><address><addrLine>Dublin, Ireland</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="41" to="49" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b184">
	<analytic>
		<title level="a" type="main">Multisource transfer of delexicalized dependency parsers</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Mcdonald</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Petrov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Hall</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2011" />
			<biblScope unit="page" from="62" to="72" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b185">
	<analytic>
		<title level="a" type="main">Universal dependency annotation for multilingual parsing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Mcdonald</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Nivre</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Quirmbach-Brundage</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Goldberg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Das</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Ganchev</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Hall</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Petrov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hao</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Täckström</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Bedini</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Castelló</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Lee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 51st Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2013" />
			<biblScope unit="page" from="92" to="97" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b186">
	<analytic>
		<title level="a" type="main">Selective sharing for multilingual dependency parsing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Naseem</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Barzilay</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Globerson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 50th Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="page" from="629" to="637" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b187">
	<analytic>
		<title level="a" type="main">MaltParser: A language-independent system for datadriven dependency parsing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Nivre</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Hall</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Nilsson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Chanev</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Eryigit</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Kübler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Marinov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Marsi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Natural Language Engineering</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="95" to="135" />
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b188">
	<analytic>
		<title level="a" type="main">Two strategies for text parsing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Nivre</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">A Man of Measure: Festschrift in Honour of Fred Karlsson on his 60th Birthday</title>
		<editor>Mickael Suominen, Antti Arppe, Anu Airola, Orvoki Heinämäki, Matti Miestamo, Urho Määttä, Jussi Niemi, Kari K. Pitkänen, and Kaius Sinnemäki</editor>
		<imprint>
			<date type="published" when="2006" />
			<biblScope unit="page" from="440" to="448" />
		</imprint>
	</monogr>
	<note>A special supplement to SKY Journal of Linguistics 19</note>
</biblStruct>

<biblStruct xml:id="b189">
	<analytic>
		<title level="a" type="main">Algorithms for deterministic incremental dependency parsing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Nivre</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computational Linguistics</title>
		<imprint>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="513" to="553" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b190">
	<monogr>
		<title level="m" type="main">A universal part-of-speech tagset</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Petrov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Das</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Mcdonald</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1104.2086</idno>
		<imprint>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b191">
	<analytic>
		<title level="a" type="main">Bilingual Parsing with Factored Estimation: Using English to Parse Korean</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">A</forename><surname>Smith</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><forename type="middle">A</forename><surname>Smith</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of EMNLP 2004</title>
		<editor>Dekang Lin and Dekai Wu</editor>
		<meeting>EMNLP 2004<address><addrLine>Barcelona, Spain</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2004-07" />
			<biblScope unit="page" from="49" to="56" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b192">
	<analytic>
		<title level="a" type="main">Rediscovering annotation projection for cross-lingual parser induction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Tiedemann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of COLING 2014: 25th International Conference on Computational Linguistics</title>
		<meeting>COLING 2014: 25th International Conference on Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="1854" to="1864" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b193">
	<analytic>
		<title level="a" type="main">Enriching the knowledge sources used in a maximum entropy partof-speech tagger</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Toutanova</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Manning</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2000 Joint SIGDAT conference on Empirical methods in natural language processing and very large corpora: held in conjunction with the 38th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 2000 Joint SIGDAT conference on Empirical methods in natural language processing and very large corpora: held in conjunction with the 38th Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2000" />
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="page" from="63" to="70" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b194">
	<analytic>
		<title level="a" type="main">Inducing multilingual text analysis tools via robust projection across aligned corpora</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Yarowsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Ngai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Wicentowski</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 1st International Conference on Human Language Technology Research</title>
		<meeting>the 1st International Conference on Human Language Technology Research</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2001" />
			<biblScope unit="page" from="1" to="8" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b195">
	<analytic>
		<title level="a" type="main">Cross-language parser adaptation between related languages</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Zeman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Resnik</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IJCNLP 2008 Workshop on NLP for Less Privileged Languages</title>
		<meeting><address><addrLine>Hyderabad, India</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2008" />
			<biblScope unit="page" from="35" to="42" />
		</imprint>
	</monogr>
	<note>International Institute of Information Technology</note>
</biblStruct>

<biblStruct xml:id="b196">
	<analytic>
		<title level="a" type="main">HamleDT: To Parse or Not to Parse?</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Zeman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Mareček</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Popel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Ramasamy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Štěpánek</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Žabokrtský</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Hajič</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Nicoletta Calzolari (Conference Chair)</title>
		<meeting><address><addrLine>Khalid Choukri, References</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b197">
	<monogr>
		<title level="m" type="main">Accessibility theory: An overview. Text representation: Linguistic and psycholinguistic aspects</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mira</forename><forename type="middle">Ariel</forename></persName>
		</author>
		<imprint>
			<date type="published" when="2001" />
			<biblScope unit="page" from="29" to="87" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b198">
	<analytic>
		<title level="a" type="main">Understanding the value of features for coreference resolution</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eric</forename><surname>Bengtson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Roth</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2008" />
			<biblScope unit="page" from="294" to="303" />
		</imprint>
		<respStmt>
			<orgName>Association for Computational Linguistics</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b199">
	<analytic>
		<title level="a" type="main">An empirical investigation of statistical significance in nlp</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Taylor</forename><surname>Berg-Kirkpatrick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Burkett</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Klein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2012 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning</title>
		<meeting>the 2012 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning<address><addrLine>Jeju Island, Korea</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2012" />
			<biblScope unit="page" from="995" to="1005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b200">
	<analytic>
		<title level="a" type="main">Learning structured perceptrons for coreference resolution with latent antecedents and non-local features</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anders</forename><surname>Björkelund</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonas</forename><surname>Kuhn</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACL</title>
		<imprint>
			<date type="published" when="2014-06" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b201">
	<analytic>
		<title level="a" type="main">Specialized models and ranking for coreference resolution</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pascal</forename><surname>Denis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jason</forename><surname>Baldridge</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2008" />
			<biblScope unit="page" from="660" to="669" />
		</imprint>
		<respStmt>
			<orgName>Association for Computational Linguistics</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b202">
	<analytic>
		<title level="a" type="main">Easy victories and uphill battles in coreference resolution</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Greg</forename><surname>Durrett</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Klein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b203">
	<analytic>
		<title level="a" type="main">A joint model for entity analysis: Coreference, typing, and linking</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Greg</forename><surname>Durrett</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Klein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Transactions of the Association for Computational Linguistics</title>
		<meeting>the Transactions of the Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b204">
	<analytic>
		<title level="a" type="main">Latent structure perceptron with feature induction for unrestricted coreference resolution</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eraldo</forename><surname>Fernandes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ruy</forename><surname>Cícero Dos Santos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Milidiú</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Joint Conference on EMNLP and CoNLL -Shared Task</title>
		<meeting><address><addrLine>Jeju Island, Korea</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="page" from="41" to="48" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b205">
	<analytic>
		<title level="a" type="main">Centering: A framework for modeling the local coherence of discourse</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Barbara</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Scott</forename><surname>Grosz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aravind K</forename><surname>Weinstein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Joshi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computational Linguistics</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="203" to="225" />
			<date type="published" when="1995" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b206">
	<monogr>
		<title level="m" type="main">Joint coreference resolution and named-entity linking with multi-pass sieves</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hannaneh</forename><surname>Hajishirzi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Leila</forename><surname>Zilles</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Daniel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luke</forename><surname>Weld</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Zettlemoyer</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="289" to="299" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b207">
	<monogr>
		<title level="m" type="main">Scoring coreference partitions of predicted mentions: A reference implementation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaoqiang</forename><surname>Sameer Pradhan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marta</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eduard</forename><surname>Recasens</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vincent</forename><surname>Hovy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Ng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Strube</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b208">
	<analytic>
		<title level="a" type="main">Conll-2012 shared task: Modeling multilingual unrestricted coreference in ontonotes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alessandro</forename><surname>Sameer Pradhan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nianwen</forename><surname>Moschitti</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Olga</forename><surname>Xue</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuchen</forename><surname>Uryupina</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Joint Conference on EMNLP and CoNLL -Shared Task</title>
		<meeting><address><addrLine>Jeju Island, Korea</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2012" />
			<biblScope unit="page" from="1" to="40" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b209">
	<analytic>
		<title level="a" type="main">Conll-2011 shared task: Modeling unrestricted coreference in ontonotes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sameer</forename><surname>Pradhan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lance</forename><surname>Ramshaw</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mitchell</forename><surname>Marcus</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Martha</forename><surname>Palmer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ralph</forename><surname>Weischedel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nianwen</forename><surname>Xue</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Fifteenth Conference on Computational Natural Language Learning: Shared Task</title>
		<meeting>the Fifteenth Conference on Computational Natural Language Learning: Shared Task<address><addrLine>Portland, Oregon, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2011" />
			<biblScope unit="page" from="1" to="27" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b210">
	<analytic>
		<title level="a" type="main">Ontonotes: a unified relational semantic representation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Sameer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eduard</forename><forename type="middle">H</forename><surname>Pradhan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mitchell</forename><forename type="middle">P</forename><surname>Hovy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Martha</forename><surname>Marcus</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lance</forename><forename type="middle">A</forename><surname>Palmer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ralph</forename><forename type="middle">M</forename><surname>Ramshaw</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Weischedel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Int. J. Semantic Computing</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="405" to="419" />
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b211">
	<analytic>
		<title level="a" type="main">Coreference resolution with world knowledge</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Altaf</forename><surname>Rahman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vincent</forename><surname>Ng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 49th</title>
		<meeting>the 49th</meeting>
		<imprint>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b212">
	<monogr>
				<title level="m">Annual Meeting of the Association for Computational Linguistics: Human Language Technologies</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="814" to="824" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b213">
	<analytic>
		<title level="a" type="main">Learning-based multi-sieve co-reference resolution with knowledge</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lev</forename><surname>Ratinov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Roth</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EMNLP</title>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b214">
	<analytic>
		<title level="a" type="main">The life and death of discourse entities: Identifying singleton mentions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marta</forename><surname>Recasens</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marie-Catherine</forename><surname>De Marneffe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><surname>Potts</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2013 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</title>
		<meeting>the 2013 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies<address><addrLine>Atlanta, Georgia</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2013" />
			<biblScope unit="page" from="627" to="633" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b215">
	<analytic>
		<title level="a" type="main">The language factor in mathematics tests</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jamal</forename><surname>Abedi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Carol</forename><surname>Lord</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Applied Measurement in Education</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="219" to="234" />
			<date type="published" when="2001" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b216">
	<analytic>
		<title level="a" type="main">Complexity matching in dyadic conversation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Drew</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexandra</forename><surname>Abney</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rick</forename><surname>Paxton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><forename type="middle">T</forename><surname>Dale</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Kello</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Experimental Psychology: General</title>
		<imprint>
			<biblScope unit="volume">143</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="2304" to="2315" />
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b217">
	<analytic>
		<title level="a" type="main">Topic segmentation with an aspect hidden Markov model</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>David</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pedro</forename><forename type="middle">J</forename><surname>Blei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Moreno</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 24th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval</title>
		<meeting>the 24th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2001" />
			<biblScope unit="page" from="343" to="348" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b218">
	<monogr>
		<title level="m" type="main">The British National Corpus</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Bnc</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2007" />
		</imprint>
	</monogr>
	<note>version 3 (BNC XML Edition</note>
</biblStruct>

<biblStruct xml:id="b219">
	<analytic>
		<title level="a" type="main">Syntactic co-ordination in dialogue</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Holly P Branigan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Martin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexandra</forename><forename type="middle">A</forename><surname>Pickering</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Cleland</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Cognition</title>
		<imprint>
			<biblScope unit="volume">75</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="13" to="25" />
			<date type="published" when="2000" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b220">
	<monogr>
		<title level="m" type="main">Using language</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Herbert</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Clark</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1996" />
			<publisher>Cambridge University Press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b221">
	<analytic>
		<title level="a" type="main">Grounding in communication</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Herbert</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Susan</forename><forename type="middle">E</forename><surname>Clark</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Brennan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Perspectives on socially shared cognition</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="page" from="127" to="149" />
			<date type="published" when="1991" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b222">
	<analytic>
		<title level="a" type="main">Bayesian unsupervised topic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jacob</forename><surname>Eisenstein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Regina</forename><surname>Barzilay</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Conference on Empirical Methods in Natural Language Processing. Association for Computational Linguistics</title>
		<meeting>the Conference on Empirical Methods in Natural Language Processing. Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2008" />
			<biblScope unit="page" from="334" to="343" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b223">
	<analytic>
		<title level="a" type="main">Saying what you mean in dialogue: A study in conceptual and semantic co-ordination</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Simon</forename><surname>Garrod</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anthony</forename><surname>Anderson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Cognition</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="181" to="218" />
			<date type="published" when="1987" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b224">
	<analytic>
		<title level="a" type="main">Entropy rate constancy in text</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dmitriy</forename><surname>Genzel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eugene</forename><surname>Charniak</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 40th Annual Meeting of the Association for Computational Linguistics. Association for Computational Linguistics</title>
		<meeting>40th Annual Meeting of the Association for Computational Linguistics. Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2002" />
			<biblScope unit="page" from="199" to="206" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b225">
	<analytic>
		<title level="a" type="main">Variation of entropy and parse trees of sentences as a function of the sentence number</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dmitriy</forename><surname>Genzel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eugene</forename><surname>Charniak</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 2003 Conference on Empirical Methods in Natural Language Processing. Association for Computational Linguistics</title>
		<meeting>2003 Conference on Empirical Methods in Natural Language essing. Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2003" />
			<biblScope unit="page" from="65" to="72" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b226">
	<analytic>
		<title level="a" type="main">Switchboard: Telephone speech corpus for research and development</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>John</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Godfrey</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Edward</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jane</forename><surname>Holliman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Mcdaniel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Acoustics, Speech, and Signal Processing</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="1992" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="517" to="520" />
		</imprint>
	</monogr>
	<note>ICASSP-92., 1992 IEEE International Conference on</note>
</biblStruct>

<biblStruct xml:id="b227">
	<analytic>
		<title level="a" type="main">Towards social-based user modeling and personalization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Marti</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Hearst</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Information Sciences and Technologies Bulletin of the ACM Slovakia</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="issue">1</biblScope>
			<date type="published" when="1997" />
		</imprint>
	</monogr>
	<note>Texttiling: Segmenting text References Michal Barla</note>
</biblStruct>

<biblStruct xml:id="b228">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Parantapa</forename><surname>Bhattacharya</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Muhammad</forename><surname>Bilal Zafar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Niloy</forename><surname>Ganguly</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Saptarshi</forename><surname>Ghosh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Krishna</forename><forename type="middle">P</forename></persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b229">
	<analytic>
		<title level="a" type="main">Inferring user interests in the twitter social network</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Gummadi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 8th ACM Conference on Recommender systems</title>
		<meeting>the 8th ACM Conference on Recommender systems</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b230">
	<analytic>
		<title level="a" type="main">Collaborative personalized tweet recommendation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kailong</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tianqi</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guoqing</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ou</forename><surname>Jin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Enpeng</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yong</forename><surname>Yu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 35th international ACM SIGIR conference on Research and development in information retrieval</title>
		<meeting>the 35th international ACM SIGIR conference on Research and development in information retrieval</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b231">
	<analytic>
		<title level="a" type="main">Tweets You Like: Personalized Tweets Recommendation based on Dynamic Users Interests</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shaymaa</forename><surname>Khater</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Hicham</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Elmongui</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ASE Conference</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b232">
	<analytic>
		<title level="a" type="main">A comprehensive ranking model for tweets big data in online social network</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li</forename><surname>Kuang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiang</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Meiqi</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yujian</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kehua</forename><surname>Guo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">EUR-ASIP Journal on Wireless Communications and Networking</title>
		<imprint>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page">2016</biblScope>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b233">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Quoc</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tomas</forename><surname>Le</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Mikolov</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1405.4053</idno>
		<title level="m">Distributed representations of sentences and documents</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b234">
	<analytic>
		<title level="a" type="main">Using mined coreference chains as a resource for a semantic task</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Heike</forename><surname>Adel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hinrich</forename><surname>Schütze</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2014 Conference on Empirical Methods in Natural Language Processing<address><addrLine>Doha, Qatar</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="1447" to="1452" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b235">
	<analytic>
		<title level="a" type="main">Evaluating WordNet-based measures of lexical semantic relatedness</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander</forename><surname>Budanitsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Graeme</forename><surname>Hirst</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computational Linguistics</title>
		<imprint>
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="13" to="47" />
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b236">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">James</forename><surname>Deese</surname></persName>
		</author>
		<title level="m">The Structure of Associations in Language and Thought</title>
		<meeting><address><addrLine>Baltimore, MD</addrLine></address></meeting>
		<imprint>
			<publisher>The John Hopkins Press</publisher>
			<date type="published" when="1965" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b237">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stefan</forename><forename type="middle">Evert</forename></persName>
		</author>
		<title level="m">The Statistics of Word Cooccurrences</title>
		<imprint>
			<date type="published" when="2005" />
		</imprint>
		<respStmt>
			<orgName>Stuttgart University</orgName>
		</respStmt>
	</monogr>
	<note>Ph.D. thesis</note>
</biblStruct>

<biblStruct xml:id="b238">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>John</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Firth</surname></persName>
		</author>
		<title level="m">Papers in Linguistics 1934-51. Longmans</title>
		<meeting><address><addrLine>London, UK</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1957" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b239">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Zellig</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Harris</surname></persName>
		</author>
		<title level="m">Distributional structure. Word</title>
		<imprint>
			<date type="published" when="1954" />
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="page" from="146" to="162" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b240">
	<analytic>
		<title level="a" type="main">Simlex-999: Evaluating semantic models with (genuine) similarity estimation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Felix</forename><surname>Hill</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Roi</forename><surname>Reichart</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anna</forename><surname>Korhonen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computational Linguistics</title>
		<imprint>
			<biblScope unit="volume">41</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="665" to="695" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b241">
	<analytic>
		<title level="a" type="main">Directional distributional similarity for lexical inference</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lili</forename><surname>Kotlerman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ido</forename><surname>Dagan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Idan</forename><surname>Szpektor</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maayan</forename><surname>Zhitomirsky-Geffet</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Natural Language Processing</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="359" to="389" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b242">
	<monogr>
		<title level="m" type="main">Neural word embedding as implicit matrix factorization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Omer</forename><surname>Levy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoav</forename><surname>Goldberg</surname></persName>
		</author>
		<editor>Z. Ghahramani, M. Welling, C. Cortes, N.D</editor>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b243">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">Q</forename><surname>Lawrence</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Weinberger</surname></persName>
		</author>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="page" from="2177" to="2185" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b244">
	<analytic>
		<title level="a" type="main">Identifying synonyms among distributionally similar words</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dekang</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shaojun</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lijuan</forename><surname>Qin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ming</forename><surname>Zhou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 18th International Joint Conference on Artificial Intelligence</title>
		<meeting>the 18th International Joint Conference on Artificial Intelligence<address><addrLine>Acapulco, Mexico</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2003" />
			<biblScope unit="page" from="1492" to="1493" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b245">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Lyons</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1977" />
			<publisher>Cambridge University Press</publisher>
			<biblScope unit="volume">1</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b246">
	<monogr>
		<title level="m" type="main">Efficient estimation of word representations in vector space</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tomas</forename><surname>Mikolov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kai</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Greg</forename><surname>Corrado</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeffrey</forename><surname>Dean</surname></persName>
		</author>
		<idno>abs/1301.3781</idno>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
<note type="report_type">Computing Research Repository</note>
</biblStruct>

<biblStruct xml:id="b247">
	<analytic>
		<title level="a" type="main">Linguistic regularities in continuous space word representations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tomas</forename><surname>Mikolov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yih</forename><surname>Wen-Tau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geoffrey</forename><surname>Zweig</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</title>
		<meeting>the Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies<address><addrLine>Atlanta</addrLine></address></meeting>
		<imprint>
			<publisher>Georgia</publisher>
			<date type="published" when="2013" />
			<biblScope unit="page" from="746" to="751" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b248">
	<analytic>
		<title level="a" type="main">Semantic networks of English</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">George</forename><forename type="middle">A</forename><surname>Miller</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christiane</forename><surname>Fellbaum</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Cognition</title>
		<imprint>
			<biblScope unit="volume">41</biblScope>
			<biblScope unit="page" from="197" to="229" />
			<date type="published" when="1991" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b249">
	<analytic>
		<title level="a" type="main">WordNet: A lexical database for English</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">George</forename><forename type="middle">A</forename><surname>Miller</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Communications of the ACM</title>
		<imprint>
			<biblScope unit="volume">38</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="39" to="41" />
			<date type="published" when="1995" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b250">
	<analytic>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Saif</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bonnie</forename><forename type="middle">J</forename><surname>Mohammad</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Graeme</forename><surname>Dorr</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peter</forename><forename type="middle">D</forename><surname>Hirst</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Turney</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computing lexical contrast. Computational Linguistics</title>
		<imprint>
			<biblScope unit="volume">39</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="555" to="590" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b251">
	<analytic>
		<title level="a" type="main">Word embedding-based antonym detection using thesauri and distributional information</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Masataka</forename><surname>Ono</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Makoto</forename><surname>Miwa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yutaka</forename><surname>Sasaki</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</title>
		<meeting>the Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies<address><addrLine>Denver, Colorado</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="984" to="989" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b252">
	<analytic>
		<title level="a" type="main">A multitask objective to inject lexical contrast into distributional semantics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Angeliki</forename><surname>Nghia The Pham</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marco</forename><surname>Lazaridou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Baroni</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing</title>
		<meeting>the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing<address><addrLine>Beijing, China</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="21" to="26" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b253">
	<analytic>
		<title level="a" type="main">Combining word patterns and discourse markers for paradigmatic relation classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Roth</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sabine</forename><surname>Schulte Im Walde</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 52nd Annual Meeting of the Association for Computational Linguistics<address><addrLine>Baltimore, MD</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="524" to="530" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b254">
	<analytic>
		<title level="a" type="main">Chasing hypernyms in vector spaces with entropy</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Enrico</forename><surname>Santus</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alessandro</forename><surname>Lenci</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qin</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sabine</forename><surname>Schulte Im Walde</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 14th Conference of the European Chapter of the Association for Computational Linguistics</title>
		<meeting>the 14th Conference of the European Chapter of the Association for Computational Linguistics<address><addrLine>Gothenburg, Sweden</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="38" to="42" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b255">
	<analytic>
		<title level="a" type="main">Taking antonymy mask off in vector space</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Enrico</forename><surname>Santus</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qin</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alessandro</forename><surname>Lenci</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chu-Ren</forename><surname>Huang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 28th Pacific Asia Conference on Language, Information and Computation</title>
		<meeting>the 28th Pacific Asia Conference on Language, Information and Computation</meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="135" to="144" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b256">
	<analytic>
		<title level="a" type="main">Building large corpora from the web using a new efficient tool chain</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Roland</forename><surname>Schäfer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Felix</forename><surname>Bildhauer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 8th International Conference on Language Resources and Evaluation</title>
		<meeting>the 8th International Conference on Language Resources and Evaluation<address><addrLine>Istanbul, Turkey</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="page" from="486" to="493" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b257">
	<analytic>
		<title level="a" type="main">Processing and querying large web corpora with the COW14 architecture</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Roland</forename><surname>Schäfer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 3rd Workshop on Challenges in the Management of Large Corpora</title>
		<meeting>the 3rd Workshop on Challenges in the Management of Large Corpora</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="28" to="34" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b258">
	<analytic>
		<title level="a" type="main">Uncovering distributional differences between synonyms and antonyms in a word space model</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Silke</forename><surname>Scheible</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sabine</forename><surname>Schulte Im Walde</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sylvia</forename><surname>Springorum</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 6th International Joint Conference on Natural Language Processing</title>
		<meeting>the 6th International Joint Conference on Natural Language Processing<address><addrLine>Nagoya, Japan</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="489" to="497" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b259">
	<monogr>
		<title level="m" type="main">Nonparametric Statistics for the Behavioral Sciences</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sidney</forename><surname>Siegel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N. John</forename><surname>Castellan</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1988" />
			<publisher>McGraw-Hill</publisher>
			<pubPlace>Boston, MA</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b260">
	<analytic>
		<title level="a" type="main">From frequency to meaning: Vector space models of semantics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Peter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Patrick</forename><surname>Turney</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Pantel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Artificial Intelligence Research</title>
		<imprint>
			<biblScope unit="volume">37</biblScope>
			<biblScope unit="page" from="141" to="188" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b261">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ellen</forename><forename type="middle">M</forename><surname>Voorhees</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Donna</forename><forename type="middle">K</forename><surname>Harman</surname></persName>
		</author>
		<title level="m">The 7th Text REtrieval Conference (trec-7). National Institute of Standards and Technology</title>
		<imprint>
			<publisher>NIST</publisher>
			<date type="published" when="1999" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b262">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alberto</forename><surname>Barrón-Cedeño</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Giovanni</forename><surname>Da San</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shafiq</forename><surname>Martino</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alessandro</forename><surname>Joty</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Moschitti</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">Al</forename><surname>Fahad</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Salvatore</forename><surname>Obaidli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kateryna</forename><surname>Romeo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Antonio</forename><surname>Tymoshenko</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Uva</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
	<note>ConvKN at SemEval-2016</note>
</biblStruct>

<biblStruct xml:id="b263">
	<analytic>
		<title level="a" type="main">Answer and question selection for question answering on Arabic and English fora</title>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 10th International Workshop on Semantic Evaluation, SemEval &apos;16</title>
		<meeting>the 10th International Workshop on Semantic Evaluation, SemEval &apos;16<address><addrLine>San Diego, CA</addrLine></address></meeting>
		<imprint>
			<biblScope unit="volume">3</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b264">
	<analytic>
		<title level="a" type="main">Understanding the difficulty of training deep feedforward neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xavier</forename><surname>Glorot</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 13th International Conference on Artificial Intelligence and Statistics, AISTATS &apos;10</title>
		<meeting>the 13th International Conference on Artificial Intelligence and Statistics, AISTATS &apos;10<address><addrLine>Sardinia, Italy</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="page" from="249" to="256" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b265">
	<analytic>
		<title level="a" type="main">Bridging the lexical chasm: Statistical approaches to answer-finding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adam</forename><surname>Berger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rich</forename><surname>Caruana</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Cohn</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 23rd Annual International ACM Conference on Research and Development in Information Retrieval, SIGIR &apos;00</title>
		<meeting>the 23rd Annual International ACM Conference on Research and Development in Information Retrieval, SIGIR &apos;00<address><addrLine>Athens, Greece</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2000" />
			<biblScope unit="page" from="192" to="199" />
		</imprint>
	</monogr>
	<note>Dayne Freitag, and Vibhu Mittal</note>
</biblStruct>

<biblStruct xml:id="b266">
	<analytic>
		<title level="a" type="main">Theano: a CPU and GPU math expression compiler</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">James</forename><surname>Bergstra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Olivier</forename><surname>Breuleux</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Frédéric</forename><surname>Bastien</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pascal</forename><surname>Lamblin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Razvan</forename><surname>Pascanu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guillaume</forename><surname>Desjardins</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joseph</forename><surname>Turian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Warde-Farley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Python for Scientific Computing Conference, SciPy &apos;10</title>
		<meeting>the Python for Scientific Computing Conference, SciPy &apos;10<address><addrLine>Austin, Texas, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b267">
	<analytic>
		<title level="a" type="main">Automatic evaluation of machine translation quality using n-gram cooccurrence statistics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">George</forename><surname>Doddington</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Second International Conference on Human Language Technology Research, HLT &apos;02</title>
		<meeting>the Second International Conference on Human Language Technology Research, HLT &apos;02<address><addrLine>San Diego, California, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2002" />
			<biblScope unit="page" from="138" to="145" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b268">
	<analytic>
		<title level="a" type="main">Learning hybrid representations to retrieve semantically equivalent questions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Santos</forename><surname>Cicero Dos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luciano</forename><surname>Barbosa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dasha</forename><surname>Bogdanova</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bianca</forename><surname>Zadrozny</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing, ACL-IJCNLP &apos;15</title>
		<meeting>the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing, ACL-IJCNLP &apos;15<address><addrLine>Beijing, China</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="694" to="699" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b269">
	<analytic>
		<title level="a" type="main">Adaptive subgradient methods for online learning and stochastic optimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Duchi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Elad</forename><surname>Hazan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoram</forename><surname>Singer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="page" from="2121" to="2159" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b270">
	<analytic>
		<title level="a" type="main">A noisy-channel approach to question answering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Abdessamad</forename><surname>Echihabi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Marcu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 41st Annual Meeting of the Association for Computational Linguistics, ACL &apos;03</title>
		<meeting>the 41st Annual Meeting of the Association for Computational Linguistics, ACL &apos;03<address><addrLine>Sapporo, Japan</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2003" />
			<biblScope unit="page" from="16" to="23" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b271">
	<analytic>
		<title level="a" type="main">Applying deep learning to answer selection: A study and an open task</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Minwei</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bing</forename><surname>Xiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Michael</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lidan</forename><surname>Glass</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bowen</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Zhou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2015 IEEE Automatic Speech Recognition and Understanding Workshop, ASRU &apos;15</title>
		<meeting>the 2015 IEEE Automatic Speech Recognition and Understanding Workshop, ASRU &apos;15<address><addrLine>Scottsdale, Arizona, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b272">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Simone</forename><surname>Filice</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Danilo</forename><surname>Croce</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alessandro</forename><surname>Moschitti</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Roberto</forename><surname>Basili</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b273">
	<analytic>
		<title level="a" type="main">Learning semantic relations between questions and answers</title>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 10th International Workshop on Semantic Evaluation, SemEval &apos;16</title>
		<meeting>the 10th International Workshop on Semantic Evaluation, SemEval &apos;16<address><addrLine>San Diego, California, USA</addrLine></address></meeting>
		<imprint>
			<biblScope unit="volume">3</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b274">
	<analytic>
		<title level="a" type="main">Pairwise neural machine translation evaluation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Francisco</forename><surname>Guzmán</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shafiq</forename><surname>Joty</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lluís</forename><surname>Màrquez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Preslav</forename><surname>Nakov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing, ACL-IJCNLP &apos;15</title>
		<meeting>the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing, ACL-IJCNLP &apos;15<address><addrLine>Beijing, China</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="805" to="814" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b275">
	<analytic>
		<title level="a" type="main">MTE-NN at SemEval-2016 Task 3: Can machine translation evaluation help community question answering?</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Francisco</forename><surname>Guzmán</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lluís</forename><surname>Màrquez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Preslav</forename><surname>Nakov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 10th International Workshop on Semantic Evaluation, SemEval &apos;16</title>
		<meeting>the 10th International Workshop on Semantic Evaluation, SemEval &apos;16<address><addrLine>San Diego, California, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b276">
	<analytic>
		<title level="a" type="main">Finding similar questions in large question and answer archives</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><forename type="middle">Bruce</forename><surname>Jiwoon Jeon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joon Ho</forename><surname>Croft</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Lee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 14th ACM International Conference on Information and Knowledge Management, CIKM &apos;05</title>
		<meeting>the 14th ACM International Conference on Information and Knowledge Management, CIKM &apos;05<address><addrLine>Germany</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2005" />
			<biblScope unit="page" from="84" to="90" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b277">
	<monogr>
		<title level="m" type="main">The ME-TEOR metric for automatic evaluation of machine translation. Machine Translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alon</forename><surname>Lavie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Denkowski</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2009" />
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="page" from="105" to="115" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b278">
	<analytic>
		<title level="a" type="main">Semi-supervised question retrieval with gated convolutions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tao</forename><surname>Lei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hrishikesh</forename><surname>Joshi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Regina</forename><surname>Barzilay</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tommi</forename><forename type="middle">S</forename><surname>Jaakkola</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kateryna</forename><surname>Tymoshenko</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 15th Annual Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, NAACL-HLT &apos;16</title>
		<meeting>the 15th Annual Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, NAACL-HLT &apos;16<address><addrLine>San Diego, California, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
	<note>Alessandro Moschitti, and Lluís Màrquez</note>
</biblStruct>

<biblStruct xml:id="b279">
	<analytic>
		<title level="a" type="main">Improving question recommendation by exploiting information need</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shuguang</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Suresh</forename><surname>Manandhar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies, HLT &apos;11</title>
		<meeting>the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies, HLT &apos;11<address><addrLine>Portland, Oregon, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="page" from="1425" to="1434" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b280">
	<analytic>
		<title level="a" type="main">SemanticZ at SemEval-2016 Task 3: Ranking relevant answers in community question answering using semantic similarity based on fine-tuned word embeddings</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Todor</forename><surname>Mihaylov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Preslav</forename><surname>Nakov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 10th International Workshop on Semantic Evaluation, SemEval &apos;16</title>
		<meeting>the 10th International Workshop on Semantic Evaluation, SemEval &apos;16<address><addrLine>San Diego, California, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b281">
	<analytic>
		<title level="a" type="main">Linguistic regularities in continuous space word representations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tomas</forename><surname>Mikolov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yih</forename><surname>Wen-Tau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geoffrey</forename><surname>Zweig</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2013 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, NAACL-HLT &apos;13</title>
		<meeting>the 2013 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, NAACL-HLT &apos;13<address><addrLine>Atlanta, Georgia, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="746" to="751" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b282">
	<analytic>
		<title level="a" type="main">Abed Alhakim Freihat, Jim Glass, and Bilal Randeree</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Preslav</forename><surname>Nakov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lluís</forename><surname>Màrquez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alessandro</forename><surname>Moschitti</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Walid</forename><surname>Magdy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hamdy</forename><surname>Mubarak</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 10th International Workshop on Semantic Evaluation, SemEval &apos;16</title>
		<meeting>the 10th International Workshop on Semantic Evaluation, SemEval &apos;16<address><addrLine>San Diego, California, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
	<note>SemEval-2016 task 3: Community question answering</note>
</biblStruct>

<biblStruct xml:id="b283">
	<analytic>
		<title level="a" type="main">QCRI: Answer selection for community question answeringexperiments for Arabic and English</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Massimo</forename><surname>Nicosia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Simone</forename><surname>Filice</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alberto</forename><surname>Barrón-Cedeño</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Iman</forename><surname>Saleh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hamdy</forename><surname>Mubarak</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Preslav</forename><surname>Nakov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Giovanni</forename><surname>Da San</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alessandro</forename><surname>Martino</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kareem</forename><surname>Moschitti</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lluís</forename><surname>Darwish</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shafiq</forename><surname>Màrquez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Walid</forename><surname>Joty</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Magdy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 9th International Workshop on Semantic Evaluation, SemEval &apos;15</title>
		<meeting>the 9th International Workshop on Semantic Evaluation, SemEval &apos;15<address><addrLine>Denver, Colorado, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="203" to="209" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b284">
	<analytic>
		<title level="a" type="main">BLEU: a method for automatic evaluation of machine translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kishore</forename><surname>Papineni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Salim</forename><surname>Roukos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Todd</forename><surname>Ward</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Weijing</forename><surname>Zhu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of 40th Annual Meting of the Association for Computational Linguistics, ACL &apos;02</title>
		<meeting>40th Annual Meting of the Association for Computational Linguistics, ACL &apos;02<address><addrLine>Philadelphia, Pennsylvania, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2002" />
			<biblScope unit="page" from="311" to="318" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b285">
	<analytic>
		<title level="a" type="main">Statistical machine translation for query expansion in answer retrieval</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stefan</forename><surname>Riezler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander</forename><surname>Vasserman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ioannis</forename><surname>Tsochantaridis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vibhu</forename><surname>Mittal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yi</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 45th Annual Meeting of the Association of Computational Linguistics, ACL &apos;07</title>
		<meeting>the 45th Annual Meeting of the Association of Computational Linguistics, ACL &apos;07<address><addrLine>Prague, Czech Republic</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2007" />
			<biblScope unit="page" from="464" to="471" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b286">
	<analytic>
		<title level="a" type="main">Learning to rank short text pairs with convolutional deep neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aliaksei</forename><surname>Severyn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alessandro</forename><surname>Moschitti</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 38th International ACM SIGIR Conference on Research and Development in Information Retrieval, SIGIR &apos;15</title>
		<meeting>the 38th International ACM SIGIR Conference on Research and Development in Information Retrieval, SIGIR &apos;15<address><addrLine>Santiago, Chile</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="373" to="382" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b287">
	<monogr>
		<title level="m" type="main">Word embedding based correlation model for question/answer matching</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yikang</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wenge</forename><surname>Rong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nan</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Baolin</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jie</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhang</forename><surname>Xiong</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1511.04646</idno>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b288">
	<analytic>
		<title level="a" type="main">A study of translation edit rate with targeted human annotation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthew</forename><surname>Snover</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bonnie</forename><surname>Dorr</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Schwartz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Linnea</forename><surname>Micciulla</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Makhoul</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 7th Biennial Conference of the Association for Machine Translation in the Americas, AMTA &apos;06</title>
		<meeting>the 7th Biennial Conference of the Association for Machine Translation in the Americas, AMTA &apos;06<address><addrLine>Cambridge, Massachusetts, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2006" />
			<biblScope unit="page" from="223" to="231" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b289">
	<analytic>
		<title level="a" type="main">Parsing with compositional vector grammars</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Socher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Bauer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><forename type="middle">D</forename><surname>Manning</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ng</forename><surname>Andrew</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics, ACL &apos;13</title>
		<meeting>the 51st Annual Meeting of the Association for Computational Linguistics, ACL &apos;13<address><addrLine>Sofia, Bulgaria</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="455" to="465" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b290">
	<analytic>
		<title level="a" type="main">Automatic question answering using the web: Beyond the factoid</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Radu</forename><surname>Soricut</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eric</forename><surname>Brill</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Inf. Retr</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="191" to="206" />
			<date type="published" when="2006-03" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b291">
	<analytic>
		<title level="a" type="main">Learning to rank answers to nonfactoid questions from web collections</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mihai</forename><surname>Surdeanu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Massimiliano</forename><surname>Ciaramita</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hugo</forename><surname>Zaragoza</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Comput. Linguist</title>
		<imprint>
			<biblScope unit="volume">37</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="351" to="383" />
			<date type="published" when="2011-06" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b292">
	<monogr>
		<title level="m" type="main">LSTM-based deep learning models for non-factoid answer selection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ming</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bing</forename><surname>Xiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bowen</forename><surname>Zhou</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1511.04108</idno>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b293">
	<analytic>
		<title level="a" type="main">JAIST: Combining multiple features for answer selection in community question answering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vu</forename><surname>Quan Hung Tran</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tu</forename><surname>Tran</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Minh</forename><surname>Vu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Son</forename><forename type="middle">Bao</forename><surname>Nguyen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Pham</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 9th International Workshop on Semantic Evaluation, SemEval &apos;15</title>
		<meeting>the 9th International Workshop on Semantic Evaluation, SemEval &apos;15<address><addrLine>Denver, Colorado, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="215" to="219" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b294">
	<analytic>
		<title level="a" type="main">A long shortterm memory model for answer sentence selection in question answering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Di</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eric</forename><surname>Nyberg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing, ACL-IJCNLP &apos;15</title>
		<meeting>the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing, ACL-IJCNLP &apos;15<address><addrLine>Beijing, China</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="707" to="712" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b295">
	<analytic>
		<title level="a" type="main">Learning continuous word embedding with metadata for question retrieval in community question answering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guangyou</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tingting</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jun</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Po</forename><surname>Hu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing, ACL-IJCNLP &apos;15</title>
		<meeting>the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing, ACL-IJCNLP &apos;15<address><addrLine>Beijing, China</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="250" to="259" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b296">
	<analytic>
		<title level="a" type="main">Semantic parsing on freebase from question-answer pairs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Berant</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of Empirical Methods in Natural Language Processing</title>
		<meeting>Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="1533" to="1544" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b297">
	<analytic>
		<title level="a" type="main">Discriminative word alignment with conditional random fields</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Phil</forename><surname>Blunsom</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Trevor</forename><surname>Cohn</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 21st International Conference on Computational Linguistics and the 44th annual meeting of the Association for Computational Linguistics</title>
		<meeting>the 21st International Conference on Computational Linguistics and the 44th annual meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2006" />
			<biblScope unit="page" from="65" to="72" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b298">
	<analytic>
		<title level="a" type="main">Combining retrieval, statistics, and inference to answer elementary science questions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">[</forename><surname>Clark</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of AAAI</title>
		<meeting>AAAI</meeting>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b299">
	<monogr>
		<title level="m" type="main">Elementary School Science and Math Tests as a Driver for AI:Take the Aristo Challenge! In Proceedings of IAAI</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peter</forename><surname>Clark</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b300">
	<analytic>
		<title level="a" type="main">Natural language processing (almost) from scratch</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Collobert</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="page" from="2493" to="2537" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b301">
	<analytic>
		<title level="a" type="main">Regularized multi-task learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Theodoros</forename><surname>Evgeniou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Massimiliano</forename><surname>Pontil</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Tenth ACM SIGKDD International Conference on Knowledge Discovery and Data Mining</title>
		<meeting>the Tenth ACM SIGKDD International Conference on Knowledge Discovery and Data Mining</meeting>
		<imprint>
			<date type="published" when="2004" />
			<biblScope unit="page" from="109" to="117" />
		</imprint>
	</monogr>
	<note>Evgeniou and Pontil2004</note>
</biblStruct>

<biblStruct xml:id="b302">
	<analytic>
		<title level="a" type="main">A linear-time bottom-up discourse parser with constraints and post-editing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hirst2014] Vanessa Wei</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Graeme</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Hirst</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 52nd Annual Meeting of the Association for Computational Linguistics<address><addrLine>Long Papers</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="511" to="521" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b303">
	<analytic>
		<title level="a" type="main">Introduction to &quot;this is watson</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>David</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Ferrucci</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IBM Journal of Research and Development</title>
		<imprint>
			<biblScope unit="volume">56</biblScope>
			<biblScope unit="issue">3.4</biblScope>
			<biblScope unit="page" from="1" to="1" />
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b304">
	<analytic>
		<title level="a" type="main">Long short-term memory</title>
	</analytic>
	<monogr>
		<title level="m">Sepp Hochreiter and Jürgen Schmidhuber</title>
		<imprint>
			<date type="published" when="1997" />
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page" from="1735" to="1780" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b305">
	<analytic>
		<title level="a" type="main">A neural network for factoid question answering over paragraphs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Iyyer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of Empirical Methods in Natural Language Processing</title>
		<meeting>Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b306">
	<analytic>
		<title level="a" type="main">Discourse complements lexical semantics for non-factoid answer reranking</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">[</forename><surname>Jansen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics, ACL 2014</title>
		<meeting>the 52nd Annual Meeting of the Association for Computational Linguistics, ACL 2014<address><addrLine>Baltimore, MD, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Long Papers</publisher>
			<date type="published" when="2014-06-22" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="977" to="986" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b307">
	<analytic>
		<title level="a" type="main">jmwe: A java toolkit for detecting multi-word expressions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">[</forename><surname>Kulkarni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Finlayson2011] Nidhi</forename><surname>Kulkarni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mark</forename><forename type="middle">Alan</forename><surname>Finlayson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Workshop on Multiword Expressions: from Parsing and Generation to the Real World</title>
		<meeting>the Workshop on Multiword Expressions: from Parsing and Generation to the Real World</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2011" />
			<biblScope unit="page" from="122" to="124" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b308">
	<analytic>
		<title level="a" type="main">A phrasebased alignment model for natural language inference</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Maccartney</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the conference on empirical methods in natural language processing</title>
		<meeting>the conference on empirical methods in natural language processing</meeting>
		<imprint>
			<date type="published" when="2008" />
			<biblScope unit="page" from="802" to="811" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b309">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">[</forename><surname>Mann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>William</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sandra</forename><forename type="middle">A</forename><surname>Mann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Thompson</surname></persName>
		</author>
		<title level="m">{Rhetorical Structure Theory: Toward a functional theory of text organisation}. Text</title>
		<imprint>
			<date type="published" when="1988" />
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="234" to="281" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b310">
	<analytic>
		<title level="a" type="main">Vector-based models of semantic composition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lapata2008] Jeff</forename><surname>Mitchell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mirella</forename><surname>Mitchell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Lapata</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL 2008, Proceedings of the 46th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting><address><addrLine>Columbus, Ohio, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2008-06-15" />
			<biblScope unit="page" from="236" to="244" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b311">
	<analytic>
		<title level="a" type="main">Mctest: A challenge dataset for the open-domain machine comprehension of text</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Richardson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of Empirical Methods in Natural Language Processing</title>
		<meeting>Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<publisher>EMNLP</publisher>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b312">
	<analytic>
		<title level="a" type="main">Learning answer-entailing structures for machine comprehension</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Sachan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b313">
	<monogr>
		<title level="m" type="main">Relation alignment for textual entailment recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Sammons</surname></persName>
			<affiliation>
				<orgName type="collaboration">TAC</orgName>
			</affiliation>
		</author>
		<imprint>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b314">
	<analytic>
		<title level="a" type="main">A walk-based semantically enriched tree kernel over distributed word representations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hovy2013] Shashank</forename><surname>Srivastava</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dirk</forename><surname>Srivastava</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Hovy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of Empirical Methods in Natural Language Processing</title>
		<meeting>Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="1411" to="1416" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b315">
	<analytic>
		<title level="a" type="main">Biutee: A modular open-source system for recognizing textual entailment</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Asher</forename><surname>Stern</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ido</forename><surname>Dagan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the ACL 2012 System Demonstrations</title>
		<meeting>the ACL 2012 System Demonstrations</meeting>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="page" from="73" to="78" />
		</imprint>
	</monogr>
	<note>Stern and Dagan2012</note>
</biblStruct>

<biblStruct xml:id="b316">
	<analytic>
		<title level="a" type="main">Back to basics for monolingual alignment: Exploiting word similarity and contextual evidence</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Steven</forename><surname>Arafat Md Sultan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tamara</forename><surname>Bethard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Sumner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Transactions of the Association of Computational Linguistics</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="219" to="230" />
			<date type="published" when="2014" />
		</imprint>
	</monogr>
	<note>Issue</note>
</biblStruct>

<biblStruct xml:id="b317">
	<analytic>
		<title level="a" type="main">Information extraction over structured data: Question answering with freebase</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">[</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Van Durme2014] Xuchen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Benjamin</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Van Durme</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 52nd Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2014" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="956" to="966" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b318">
	<analytic>
		<title level="a" type="main">A lightweight and high performance monolingual word aligner</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">[</forename><surname>Yao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL (2)</title>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="702" to="707" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b319">
	<analytic>
		<title level="a" type="main">Question answering using enhanced lexical semantic models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Yih</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 51st Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b320">
	<analytic>
		<title level="a" type="main">The concave-convex procedure</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">[</forename><surname>Yuille And Rangarajan2003</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">] A</forename><forename type="middle">L</forename><surname>Yuille</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anand</forename><surname>Rangarajan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural Comput</title>
		<imprint>
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b321">
	<analytic>
		<title level="a" type="main">Leveraging linguistic structure for open domain information extraction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Melvin</forename><forename type="middle">Johnson</forename><surname>References Gabor Angeli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><forename type="middle">D</forename><surname>Premkumar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Manning</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics (ACL</title>
		<meeting>the 53rd Annual Meeting of the Association for Computational Linguistics (ACL</meeting>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b322">
	<monogr>
		<title level="m" type="main">Optimization of Natural Language Processing Components for Robustness and Scalability</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Jinho</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Choi</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2012" />
			<pubPlace>Boulder, CO, USA. AAI3549172</pubPlace>
		</imprint>
	</monogr>
<note type="report_type">Ph.D. thesis</note>
</biblStruct>

<biblStruct xml:id="b323">
	<analytic>
		<title level="a" type="main">Open information extraction from the Web</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oren</forename><surname>Etzioni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michele</forename><surname>Banko</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stephen</forename><surname>Soderland</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><forename type="middle">S</forename><surname>Weld</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Communications of the ACM</title>
		<imprint>
			<biblScope unit="volume">51</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="68" to="74" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b324">
	<analytic>
		<title level="a" type="main">Identifying relations for open information extraction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anthony</forename><surname>Fader</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stephen</forename><surname>Soderland</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oren</forename><surname>Etzioni</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2011" />
			<biblScope unit="page" from="1535" to="1545" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b325">
	<analytic>
		<title level="a" type="main">Question-answer driven semantic role labeling: Using natural language to annotate natural language</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luheng</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mike</forename><surname>Lewis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luke</forename><surname>Zettlemoyer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">the Conference on Empirical Methods in Natural Language Processing</title>
		<imprint>
			<publisher>EMNLP</publisher>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b326">
	<monogr>
		<title level="m" type="main">The cambridge grammar of english</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rodney</forename><surname>Huddleston</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geoffrey</forename><forename type="middle">K</forename><surname>Pullum</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2002" />
			<publisher>Cambridge University Press</publisher>
			<pubPlace>Language. Cambridge</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b327">
	<analytic>
		<title level="a" type="main">Open language learning for information extraction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Mausam</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stephen</forename><surname>Schmitz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Robert</forename><surname>Soderland</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oren</forename><surname>Bart</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Etzioni</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2012 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning</title>
		<meeting>the 2012 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning<address><addrLine>Jeju Island, Korea</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2012-07" />
			<biblScope unit="page" from="523" to="534" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b328">
	<analytic>
		<title level="a" type="main">The proposition bank: An annotated corpus of semantic roles</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Martha</forename><surname>Palmer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Gildea</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Paul</forename><surname>Kingsbury</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computational linguistics</title>
		<imprint>
			<biblScope unit="volume">31</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="71" to="106" />
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b329">
	<analytic>
		<title level="a" type="main">Open IE as an intermediate structure for semantic tasks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gabriel</forename><surname>Stanovsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ido</forename><surname>Dagan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mausam</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 53rd Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b330">
	<analytic>
		<title level="a" type="main">Using lexical chains for text summarization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Regina</forename><surname>Barzilay</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Elhadad</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the ACL Workshop on Intelligent Scalable Text Summarization</title>
		<meeting>the ACL Workshop on Intelligent Scalable Text Summarization</meeting>
		<imprint>
			<date type="published" when="1997" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b331">
	<analytic>
		<title level="a" type="main">IDP Education Australia, and University of Cambridge Local Examinations Syndicate</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">British</forename><surname>Council</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Official IELTS Practice Materials</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
	<note>Paperback with CD. Klett Ernst /Schulbuch</note>
</biblStruct>

<biblStruct xml:id="b332">
	<analytic>
		<title level="a" type="main">Discovery of topically coherent sentences for extractive summarization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Asli</forename><surname>Celikyilmaz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dilek</forename><surname>Hakkani-Tür</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies</title>
		<meeting>the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies</meeting>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="491" to="499" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b333">
	<analytic>
		<title level="a" type="main">Sentence compression beyond word deletion</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Trevor</forename><surname>Cohn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mirella</forename><surname>Lapata</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 22nd International Conference on Computational Linguistics</title>
		<meeting>the 22nd International Conference on Computational Linguistics</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2008" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="137" to="144" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b334">
	<analytic>
		<title level="a" type="main">Lexical cohesion based topic modeling for summarization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gonenc</forename><surname>Ercan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ilyas</forename><surname>Cicekli</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computational Linguistics and Intelligent Text Processing</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2008" />
			<biblScope unit="page" from="582" to="592" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b335">
	<analytic>
		<title level="a" type="main">Lexrank: Graph-based lexical centrality as salience in text summarization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Günes</forename><surname>Erkan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Dragomir R Radev</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Artificial Intelligence Research</title>
		<imprint>
			<biblScope unit="page" from="457" to="479" />
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b336">
	<monogr>
		<title level="m" type="main">A summariser based on human memory limitations and lexical competition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yimai</forename><surname>Fang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Simone</forename><surname>Teufel</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page">732</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b337">
	<analytic>
		<title level="a" type="main">Improving Word Sense Disambiguation in Lexical Chaining</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michel</forename><surname>Galley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kathleen</forename><surname>Mckeown</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IJCAI</title>
		<imprint>
			<date type="published" when="2003" />
			<biblScope unit="page" from="1486" to="1488" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b338">
	<monogr>
		<title level="m" type="main">Educational research: Competencies for analysis and application</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Lorraine</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geoffrey</forename><forename type="middle">E</forename><surname>Gay</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Mills</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Peter W Airasian</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1976" />
			<pubPlace>Merrill Columbus, OH</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b339">
	<analytic>
		<title level="a" type="main">Computing text constituency: An algorithmic approach to the generation of text graphs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Udo</forename><surname>Hahn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ulrich</forename><surname>Reimer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 7th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, SIGIR &apos;84</title>
		<meeting>the 7th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, SIGIR &apos;84<address><addrLine>Swinton, UK.</addrLine></address></meeting>
		<imprint>
			<publisher>British Computer Society</publisher>
			<date type="published" when="1984" />
			<biblScope unit="page" from="343" to="368" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b340">
	<analytic>
		<title level="a" type="main">Toward a model of text comprehension and production</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Walter</forename><surname>Kintsch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Teun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Van Dijk</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Psychological review</title>
		<imprint>
			<biblScope unit="volume">85</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="363" to="394" />
			<date type="published" when="1978" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b341">
	<monogr>
		<title level="m" type="main">Comprehension: A paradigm for cognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Walter</forename><surname>Kintsch</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1998" />
			<publisher>Cambridge university press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b342">
	<analytic>
		<title level="a" type="main">Statisticsbased summarization-step one: Sentence compression</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kevin</forename><surname>Knight</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Marcu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AAAI/IAAI</title>
		<imprint>
			<date type="published" when="2000" />
			<biblScope unit="page" from="703" to="710" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b343">
	<monogr>
		<title level="m" type="main">Cognition in practice: Mind, mathematics and culture in everyday life</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jean</forename><surname>Lave</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1988" />
			<publisher>Cambridge University Press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b344">
	<analytic>
		<title level="a" type="main">Plot units and narrative summarization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Wendy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Lehnert</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Cognitive Science</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="293" to="331" />
			<date type="published" when="1981" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b345">
	<analytic>
		<title level="a" type="main">The potential and limitations of automatic sentence extraction for summarization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chin-Yew</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eduard</forename><surname>Hovy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the HLT-NAACL 03 on Text summarization workshop</title>
		<meeting>the HLT-NAACL 03 on Text summarization workshop</meeting>
		<imprint>
			<date type="published" when="2003" />
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page" from="73" to="80" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b346">
	<analytic>
		<title level="a" type="main">ROUGE: A package for automatic evaluation of summaries</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chin-Yew</forename><surname>Lin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Text Summarization Branches Out: Proceedings of the ACL-04</title>
		<imprint>
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b347">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Workshop</surname></persName>
		</author>
		<imprint>
			<biblScope unit="page" from="74" to="81" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b348">
	<analytic>
		<title level="a" type="main">Generating summaries of multiple news articles</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kathleen</forename><surname>Mckeown</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Dragomir R Radev</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 18th annual international ACM SIGIR conference on Research and development in information retrieval</title>
		<meeting>the 18th annual international ACM SIGIR conference on Research and development in information retrieval</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="1995" />
			<biblScope unit="page" from="74" to="82" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b349">
	<analytic>
		<title level="a" type="main">Textrank: Bringing order into texts</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rada</forename><surname>Mihalcea</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Paul</forename><surname>Tarau</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EMNLP 2004. Association for Computational Linguistics</title>
		<imprint>
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b350">
	<monogr>
		<title level="m" type="main">Efficient estimation of word representations in vector space</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tomas</forename><surname>Mikolov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kai</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Greg</forename><surname>Corrado</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeffrey</forename><surname>Dean</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1301.3781</idno>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b351">
	<analytic>
		<title level="a" type="main">WordNet: a lexical database for English</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>George</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Miller</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Communications of the ACM</title>
		<imprint>
			<biblScope unit="volume">38</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="39" to="41" />
			<date type="published" when="1995" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b352">
	<analytic>
		<title level="a" type="main">Summarization of texts found on the world wide web</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marie-Francine</forename><surname>Moens</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Roxana</forename><surname>Angheluta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rik</forename><forename type="middle">De</forename><surname>Busser</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Knowledge-Based Information Retrieval and Filtering from the Web</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2003" />
			<biblScope unit="page" from="101" to="120" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b353">
	<analytic>
		<title level="a" type="main">Introduction to duc: an intrinsic evaluation of generic news text summarization systems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Paul</forename><surname>Over</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Liggett</surname></persName>
		</author>
		<ptr target="http://wwwnlpir.nist.gov/projects/duc/guidelines/2002.html" />
	</analytic>
	<monogr>
		<title level="m">Proc. DUC</title>
		<meeting>DUC</meeting>
		<imprint>
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b354">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Allan</forename><surname>Paivio</surname></persName>
		</author>
		<title level="m">Mental representations</title>
		<imprint>
			<publisher>Oxford University Press</publisher>
			<date type="published" when="1990" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b355">
	<analytic>
		<title level="a" type="main">MEAD -a platform for multidocument multilingual text summarization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dragomir</forename><surname>Radev</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Timothy</forename><surname>Allison</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sasha</forename><surname>Blairgoldensohn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Blitzer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Arda</forename><surname>Celebi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stanko</forename><surname>Dimitrov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Elliott</forename><surname>Drabek</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ali</forename><surname>Hakim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wai</forename><surname>Lam</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Danyu</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of LREC</title>
		<meeting>LREC</meeting>
		<imprint>
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b356">
	<analytic>
		<title level="a" type="main">Efficiently Computed Lexical Chains as an Intermediate Representation for Automatic Text Summarization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gregory</forename><surname>Silber</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kathleen</forename><forename type="middle">F</forename><surname>Mccoy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computational Linguistics</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="487" to="496" />
			<date type="published" when="2002" />
			<publisher>December</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b357">
	<analytic>
		<title level="a" type="main">Salomon: automatic abstracting of legal cases for effective access to court decisions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Caroline</forename><surname>Uyttendaele</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marie-Francine</forename><surname>Moens</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jos</forename><surname>Dumortier</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Artificial Intelligence and Law</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="59" to="79" />
			<date type="published" when="1998" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b358">
	<monogr>
		<title level="m" type="main">Co-reference Guidelines for English OntoNotes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ralph</forename><surname>Weischedel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sameer</forename><surname>Pradhan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lance</forename><surname>Ramshaw</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michelle</forename><surname>Franchini</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mohammed</forename><surname>El-Bachouti</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Martha</forename><surname>Palmer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mitchell</forename><surname>Marcus</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ann</forename><surname>Taylor</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Craig</forename><surname>Greenberg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eduard</forename><surname>Hovy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Robert</forename><surname>Belvin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ann</forename><surname>Houston</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2007" />
			<publisher>Linguistic Data Consortium</publisher>
		</imprint>
	</monogr>
<note type="report_type">Technical report</note>
</biblStruct>

<biblStruct xml:id="b359">
	<analytic>
		<title level="a" type="main">Extractive summarization using supervised and semi-supervised learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kam-Fai</forename><surname>Wong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mingli</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wenjie</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 22nd International Conference on Computational Linguistics</title>
		<meeting>the 22nd International Conference on Computational Linguistics</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2008" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="985" to="992" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b360">
	<analytic>
		<title level="a" type="main">Coherent narrative summarization with a cognitive model</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Renxian</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wenjie</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Naishi</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dehong</forename><surname>Gao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computer Speech &amp; Language</title>
		<imprint>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="page" from="134" to="160" />
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b361">
	<analytic>
		<title level="a" type="main">Abstract meaning representation for sembanking</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">[</forename><surname>References</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Banarescu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 7th Linguistic Annotation Workshop and Interoperability with Discourse</title>
		<meeting>the 7th Linguistic Annotation Workshop and Interoperability with Discourse<address><addrLine>Sofia, Bulgaria</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2013-08" />
			<biblScope unit="page" from="178" to="186" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b362">
	<analytic>
		<title level="a" type="main">Distributional memory: A general framework for corpus-based semantics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">[</forename><surname>Baroni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marco</forename><surname>Baroni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alessandro</forename><surname>Lenci</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computational Linguistics</title>
		<imprint>
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="673" to="721" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b363">
	<analytic>
		<title level="a" type="main">Reranking bilingually extracted paraphrases using monolingual distributional similarity</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chan</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the GEMS 2011 Workshop on GEometrical Models of Natural Language Semantics</title>
		<meeting>the GEMS 2011 Workshop on GEometrical Models of Natural Language Semantics</meeting>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="page" from="33" to="42" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b364">
	<analytic>
		<title level="a" type="main">Natural language processing (almost) from scratch</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Collobert</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="page" from="2493" to="2537" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b365">
	<analytic>
		<title level="a" type="main">Factoid question answering over unstructured and structured content on the web</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Agichtein2005] S</forename><surname>Cucerzan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Cucerzan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Agichtein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of TREC 2005</title>
		<meeting>TREC 2005</meeting>
		<imprint>
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b366">
	<monogr>
		<title level="m" type="main">The individuation of events</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Donald</forename><surname>Davidson</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1969" />
			<publisher>Springer</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b367">
	<analytic>
		<title level="a" type="main">A structured vector space model for word meaning in context</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Padó2008] Katrin</forename><surname>Erk</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sebastian</forename><surname>Erk</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Padó</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Conference on Empirical Methods in Natural Language Processing, EMNLP &apos;08</title>
		<meeting>the Conference on Empirical Methods in Natural Language Processing, EMNLP &apos;08<address><addrLine>Stroudsburg, PA, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2008" />
			<biblScope unit="page" from="897" to="906" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b368">
	<analytic>
		<title level="a" type="main">A linear-time bottom-up discourse parser with constraints and post-editing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hirst2014] Vanessa Wei</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Graeme</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Hirst</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 52nd Annual Meeting of the Association for Computational Linguistics<address><addrLine>Long Papers</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="511" to="521" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b369">
	<analytic>
		<title level="a" type="main">A discriminative graph-based parser for the abstract meaning representation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Flanigan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics, ACL 2014</title>
		<meeting>the 52nd Annual Meeting of the Association for Computational Linguistics, ACL 2014<address><addrLine>Baltimore, MD, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Long Papers</publisher>
			<date type="published" when="2014-06-22" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="1426" to="1436" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b370">
	<monogr>
		<title level="m" type="main">Shashank Srivastava, and Eduard H. Hovy. 2013. A structured distributional semantic model for event co-reference</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Goyal</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b371">
	<monogr>
				<title level="m">Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics, ACL 2013</title>
		<meeting>the 51st Annual Meeting of the Association for Computational Linguistics, ACL 2013<address><addrLine>Sofia, Bulgaria</addrLine></address></meeting>
		<imprint>
			<publisher>Short Papers</publisher>
			<date type="published" when="2013-08" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="467" to="473" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b372">
	<analytic>
		<title level="a" type="main">Discourse complements lexical semantics for non-factoid answer reranking</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">[</forename><surname>Jansen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 52nd Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<publisher>Long Papers</publisher>
			<date type="published" when="2014" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="977" to="986" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b373">
	<analytic>
		<title level="a" type="main">Dirt@ sbt@ discovery of inference rules from text</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pantel2001] Dekang</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Patrick</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Pantel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the seventh ACM SIGKDD international conference on Knowledge discovery and data mining</title>
		<meeting>the seventh ACM SIGKDD international conference on Knowledge discovery and data mining</meeting>
		<imprint>
			<date type="published" when="2001" />
			<biblScope unit="page" from="323" to="328" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b374">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">[</forename><surname>Mann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>William</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sandra</forename><forename type="middle">A</forename><surname>Mann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Thompson</surname></persName>
		</author>
		<title level="m">{Rhetorical Structure Theory: Toward a functional theory of text organisation}. Text</title>
		<imprint>
			<date type="published" when="1988" />
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="234" to="281" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b375">
	<analytic>
		<title level="a" type="main">Linguistic regularities in continuous space word representations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">[</forename><surname>Mikolov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2013 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</title>
		<meeting>the 2013 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies<address><addrLine>Atlanta, Georgia</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2013-06" />
			<biblScope unit="page" from="746" to="751" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b376">
	<analytic>
		<title level="a" type="main">Vector-based models of semantic composition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lapata2008] Jeff</forename><surname>Mitchell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mirella</forename><surname>Mitchell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Lapata</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL 2008, Proceedings of the 46th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting><address><addrLine>Columbus, Ohio, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2008-06-15" />
			<biblScope unit="page" from="236" to="244" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b377">
	<analytic>
		<title level="a" type="main">Machine comprehension with discourse relations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Barzilay2015] Karthik</forename><surname>Narasimhan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Regina</forename><surname>Narasimhan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Barzilay</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing of the Asian Federation of Natural Language Processing</title>
		<meeting>the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing of the Asian Federation of Natural Language Processing<address><addrLine>Beijing, China</addrLine></address></meeting>
		<imprint>
			<publisher>Long Papers</publisher>
			<date type="published" when="2015-07-26" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="1253" to="1262" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b378">
	<monogr>
		<title level="m" type="main">Events in the Semantics of English</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Terence</forename><surname>Parsons</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1990" />
			<publisher>MIT Press</publisher>
			<biblScope unit="volume">5</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b379">
	<analytic>
		<title level="a" type="main">Mctest: A challenge dataset for the open-domain machine comprehension of text</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Richardson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of Empirical Methods in Natural Language Processing</title>
		<meeting>Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<publisher>EMNLP</publisher>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b380">
	<analytic>
		<title level="a" type="main">Learning answer-entailing structures for machine comprehension</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Sachan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b381">
	<analytic>
		<title level="a" type="main">A strong lexical matching method for the machine comprehension test</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ellery</forename><surname>Smith</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nicola</forename><surname>Greco</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matko</forename><surname>Bosnjak</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andreas</forename><surname>Vlachos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2015 Conference on Empirical Methods in Natural Language Processing<address><addrLine>Lisbon, Portugal</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2015-09-17" />
			<biblScope unit="page" from="1693" to="1698" />
		</imprint>
	</monogr>
	<note>Smith et al.2015</note>
</biblStruct>

<biblStruct xml:id="b382">
	<analytic>
		<title level="a" type="main">A walk-based semantically enriched tree kernel over distributed word representations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hovy2013] Shashank</forename><surname>Srivastava</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dirk</forename><surname>Srivastava</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Hovy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of Empirical Methods in Natural Language Processing</title>
		<meeting>Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="1411" to="1416" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b383">
	<analytic>
		<title level="a" type="main">Machine comprehension with syntax, frames, and semantics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing of the Asian Federation of Natural Language Processing</title>
		<meeting>the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing of the Asian Federation of Natural Language Processing<address><addrLine>Beijing, China</addrLine></address></meeting>
		<imprint>
			<publisher>Short Papers</publisher>
			<date type="published" when="2015-07-26" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="700" to="706" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b384">
	<analytic>
		<title level="a" type="main">Towards ai-complete question answering: A set of prerequisite toy tasks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Weston</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1502.05698</idno>
		<idno>arXiv:1602.04341</idno>
	</analytic>
	<monogr>
		<title level="m">Wenpeng Yin, Sebastian Ebert, and Hinrich Schtze. 2016. Attention-based convolutional neural network for machine comprehension</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
	<note>Yin et al.2016</note>
</biblStruct>

<biblStruct xml:id="b385">
	<analytic>
		<title level="a" type="main">The concave-convex procedure</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">[</forename><surname>Yuille And Rangarajan2003</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">] A</forename><forename type="middle">L</forename><surname>Yuille</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anand</forename><surname>Rangarajan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural Comput</title>
		<imprint>
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b386">
	<analytic>
		<title level="a" type="main">Transgram, fast cross-lingual word-embeddings</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jean-Marc</forename><surname>References Jocelyn Coulmance</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guillaume</forename><surname>Marty</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Amine</forename><surname>Wenzek</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Benhalloum</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2015 Conference on Empirical Methods in Natural Language Processing<address><addrLine>Lisbon, Portugal</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2015-09" />
			<biblScope unit="page" from="1109" to="1113" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b387">
	<monogr>
		<title level="m" type="main">Indexing by latent semantic analysis. Journal of the American society for information science</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Scott</forename><surname>Deerwester</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Susan</forename><forename type="middle">T</forename><surname>Dumais</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">George</forename><forename type="middle">W</forename><surname>Furnas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas</forename><forename type="middle">K</forename><surname>Landauer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Harshman</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1990" />
			<biblScope unit="volume">41</biblScope>
			<biblScope unit="page">391</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b388">
	<analytic>
		<title level="a" type="main">Two step cca: A new spectral method for estimating vector models of words</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Paramveer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jordan</forename><surname>Dhillon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dean</forename><forename type="middle">P</forename><surname>Rodu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lyle</forename><forename type="middle">H</forename><surname>Foster</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Ungar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 29th International Conference on Machine Learning (ICML-12), ICML &apos;12</title>
		<editor>John Langford and Joelle Pineau</editor>
		<meeting>the 29th International Conference on Machine Learning (ICML-12), ICML &apos;12<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Omnipress</publisher>
			<date type="published" when="2012-07" />
			<biblScope unit="page" from="1551" to="1558" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b389">
	<analytic>
		<title level="a" type="main">Eigenwords: Spectral word embeddings</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Paramveer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dean</forename><forename type="middle">P</forename><surname>Dhillon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lyle</forename><forename type="middle">H</forename><surname>Foster</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Ungar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="page" from="3035" to="3078" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b390">
	<analytic>
		<title level="a" type="main">Improving vector space word representations using multilingual correlation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Manaal</forename><surname>Faruqui</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Dyer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 14th Conference of the European Chapter of the Association for Computational Linguistics</title>
		<meeting>the 14th Conference of the European Chapter of the Association for Computational Linguistics<address><addrLine>Gothenburg, Sweden</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2014-04" />
			<biblScope unit="page" from="462" to="471" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b391">
	<analytic>
		<title level="a" type="main">Bilbowa: Fast bilingual distributed representations without word alignments</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stephan</forename><surname>Gouws</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Greg</forename><surname>Corrado</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 32nd International Conference on Machine Learning</title>
		<meeting>the 32nd International Conference on Machine Learning<address><addrLine>Lille, France</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2015-07" />
			<biblScope unit="page" from="748" to="756" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b392">
	<analytic>
		<title level="a" type="main">Finding structure with randomness: Probabilistic algorithms for constructing approximate matrix decompositions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nathan</forename><surname>Halko</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joel</forename><forename type="middle">A</forename><surname>Per-Gunnar Martinsson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Tropp</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">SIAM review</title>
		<imprint>
			<biblScope unit="volume">53</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="217" to="288" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b393">
	<analytic>
		<title level="a" type="main">Relations between two sets of variates</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Harold</forename><surname>Hotelling</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Biometrika</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="issue">3/4</biblScope>
			<biblScope unit="page" from="321" to="377" />
			<date type="published" when="1936" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b394">
	<analytic>
		<title level="a" type="main">Europarl: A Parallel Corpus for Statistical Machine Translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philipp</forename><surname>Koehn</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Conference Proceedings: the tenth Machine Translation Summit</title>
		<meeting><address><addrLine>Phuket, Thailand. AAMT</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2005" />
			<biblScope unit="page" from="79" to="86" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b395">
	<analytic>
		<title level="a" type="main">Combining language and vision with a multimodal skip-gram model</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Angeliki</forename><surname>Lazaridou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marco</forename><surname>The Nghia Pham</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Baroni</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2015 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</title>
		<meeting>the 2015 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2015" />
			<biblScope unit="page" from="153" to="163" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b396">
	<analytic>
		<title level="a" type="main">Dependencybased word embeddings</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Omer</forename><surname>Levy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoav</forename><surname>Goldberg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 52nd Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<publisher>Short Papers</publisher>
			<date type="published" when="2014" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="302" to="308" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b397">
	<analytic>
		<title level="a" type="main">Neural word embedding as implicit matrix factorization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Omer</forename><surname>Levy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoav</forename><surname>Goldberg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="2177" to="2185" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b398">
	<analytic>
		<title level="a" type="main">Automatic cross-language information retrieval using latent semantic indexing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><forename type="middle">L</forename><surname>Littman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Susan</forename><forename type="middle">T</forename><surname>Dumais</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas</forename><forename type="middle">K</forename><surname>Landauer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Cross-language information retrieval</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="1998" />
			<biblScope unit="page" from="51" to="62" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b399">
	<monogr>
		<title level="m" type="main">Exploiting similarities among languages for machine translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tomas</forename><surname>Mikolov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Quoc</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ilya</forename><surname>Le</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Sutskever</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1309.4168</idno>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b400">
	<analytic>
		<title level="a" type="main">Distributed representations of words and phrases and their compositionality</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tomas</forename><surname>Mikolov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ilya</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kai</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Greg</forename><surname>Corrado</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeff</forename><surname>Dean</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="3111" to="3119" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b401">
	<analytic>
		<title level="a" type="main">Multinomial relation prediction in social data: A dimension reduction approach</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nozomi</forename><surname>Nori</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Danushka</forename><surname>Bollegala</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hisashi</forename><surname>Kashima</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AAAI</title>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="page" from="115" to="121" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b402">
	<analytic>
		<title level="a" type="main">Learning cross-lingual word embeddings via matrix co-factorization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tianze</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhiyuan</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yang</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maosong</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing</title>
		<meeting>the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing<address><addrLine>Beijing, China</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2015-07" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="567" to="572" />
		</imprint>
	</monogr>
	<note>Short Papers). Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b403">
	<analytic>
		<title level="a" type="main">Cross-validation of matching correlation analysis by resampling matching weights</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hidetoshi</forename><surname>Shimodaira</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural Networks</title>
		<imprint>
			<biblScope unit="volume">75</biblScope>
			<biblScope unit="page" from="126" to="140" />
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b404">
	<analytic>
		<title level="a" type="main">Graph embedding and extensions: A general framework for dimensionality reduction. Pattern Analysis and Machine Intelligence</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shuicheng</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dong</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Benyu</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hong-Jiang</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qiang</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stephen</forename><surname>Lin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on</title>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="40" to="51" />
			<date type="published" when="2007-01" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b405">
	<analytic>
		<title level="a" type="main">Towards a Motivated Annotation Schema of Collocation Errors in Learner Corpora</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">Alonso</forename><surname>Ramos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Wanner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Vincze</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Casamayor</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Vázquez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Mosqueira</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Prieto</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 7th International Conference on Language Resources and Evaluation (LREC)</title>
		<meeting>the 7th International Conference on Language Resources and Evaluation (LREC)<address><addrLine>La Valetta, Malta</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="page" from="3209" to="3214" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b406">
	<monogr>
		<title level="m" type="main">Should we Teach EFL Students Collocations? System</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Bahns</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Eldaw</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1993" />
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="page" from="101" to="114" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b407">
	<analytic>
		<title level="a" type="main">Collocation Extraction beyond the Independence Assumption</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Bouma</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the ACL 2010</title>
		<meeting>the ACL 2010<address><addrLine>Uppsala</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
	<note>Short paper track</note>
</biblStruct>

<biblStruct xml:id="b408">
	<analytic>
		<title level="a" type="main">NASARI: a Novel Approach to a Semantically-Aware Representation of Items</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Camacho-Collados</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">T</forename><surname>Pilehvar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Navigli</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of NAACL</title>
		<meeting>NAACL</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="567" to="577" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b409">
	<analytic>
		<title level="a" type="main">Improving Collocation Correction by Ranking Suggestions Using Linguistic Knowledge</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Carlini</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Codina-Filba</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Wanner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 3rd Workshop on NLP for Computer-Assisted Language Learning</title>
		<meeting>the 3rd Workshop on NLP for Computer-Assisted Language Learning<address><addrLine>Uppsala, Sweden</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b410">
	<analytic>
		<title level="a" type="main">Looking for Needles in a Haystack or Locating Interesting Collocational Expressions in Large Textual Databases</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Choueka</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the RIAO</title>
		<meeting>the RIAO</meeting>
		<imprint>
			<date type="published" when="1988" />
			<biblScope unit="page" from="34" to="38" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b411">
	<analytic>
		<title level="a" type="main">Word Association Norms, Mutual Information, and Lexicography</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Church</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Hanks</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 27th Annual Meeting of the ACL</title>
		<meeting>the 27th Annual Meeting of the ACL</meeting>
		<imprint>
			<date type="published" when="1989" />
			<biblScope unit="page" from="76" to="83" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b412">
	<analytic>
		<title level="a" type="main">Phraseology</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Cowie</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The Encyclopedia of Language and Linguistics</title>
		<editor>R.E. Asher and J.M.Y. Simpson</editor>
		<meeting><address><addrLine>Pergamon, Oxford</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1994" />
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page" from="3168" to="3171" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b413">
	<analytic>
		<title level="a" type="main">Correcting Semantic Collocation Errors with L1-Induced Paraphrases</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Dahlmeier</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><forename type="middle">T</forename><surname>Ng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2011" />
			<biblScope unit="page" from="107" to="117" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b414">
	<analytic>
		<title level="a" type="main">A Neural Network Model for Low-Resource Universal Dependency Parsing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Duong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Cohn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Bird</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Cook</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2015 Conference on Empirical Methods in Natural Language Processing<address><addrLine>Lisbon, Portugal</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2015-09-17" />
			<biblScope unit="page" from="339" to="348" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b415">
	<analytic>
		<title level="a" type="main">Corpora and Collocations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Evert</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Corpus Linguistics. An International Handbook. Mouton de Gruyter</title>
		<editor>A. Lüdeling and M. Kytö</editor>
		<meeting><address><addrLine>Berlin</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b416">
	<analytic>
		<title level="a" type="main">Retrofitting Word Vectors to Semantic Lexicons</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Faruqui</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Dodge</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jauhar</forename><forename type="middle">S K</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Dyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">H</forename><surname>Hovy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><forename type="middle">A</forename><surname>Smith</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The 2015 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</title>
		<meeting><address><addrLine>Denver, Colorado, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2015-05-31" />
			<biblScope unit="page" from="1606" to="1615" />
		</imprint>
	</monogr>
	<note>NAACL HLT 2015</note>
</biblStruct>

<biblStruct xml:id="b417">
	<analytic>
		<title level="a" type="main">Learning Semantic Hierarchies via Word Embeddings</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Fu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Qin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Che</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 52th Annual Meeting of the Association for Computational Linguistics: Long Papers</title>
		<meeting>the 52th Annual Meeting of the Association for Computational Linguistics: Long Papers</meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="volume">1</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b418">
	<analytic>
		<title level="a" type="main">A Computational Approach to Detecting Collocation Errors in the Writing of Non-Native Speakers of English</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Futagi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Deane</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Chodorow</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Tetreault</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computer Assisted Language Learning</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="353" to="367" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b419">
	<monogr>
		<title level="m" type="main">Automatic Identification of English Collocation Errors based on Dependency Relations. Sponsors: National Science Council, Executive Yuan</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><forename type="middle">M</forename><surname>Gao</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2013" />
			<publisher>Academia Sinica NCCU Office of Research and Development</publisher>
			<biblScope unit="page">550</biblScope>
		</imprint>
		<respStmt>
			<orgName>ROC Institute of Linguistics</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b420">
	<monogr>
		<title level="m" type="main">Semantic Analysis of Verbal Collocations with Lexical Functions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Gelbukh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Kolesnikova</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2012" />
			<publisher>Springer</publisher>
			<pubPlace>Heidelberg</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b421">
	<analytic>
		<title level="a" type="main">Prefabricated Patterns in Advanced EFL Writing: Collocations and Formulae</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Granger</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Phraseology: Theory, Analysis and Applications</title>
		<editor>A. Cowie</editor>
		<meeting><address><addrLine>Oxford</addrLine></address></meeting>
		<imprint>
			<publisher>Oxford University Press</publisher>
			<date type="published" when="1998" />
			<biblScope unit="page" from="145" to="160" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b422">
	<analytic>
		<title level="a" type="main">Wortschatzlernen ist Kollokationslernen</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><forename type="middle">J</forename><surname>Hausmann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Zum Lehren und Lernen französischer Wortwendungen. Praxis des neusprachlichen Unterrichts</title>
		<imprint>
			<biblScope unit="volume">31</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="395" to="406" />
			<date type="published" when="1984" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b423">
	<analytic>
		<title level="a" type="main">Le dictionnaire de collocations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><forename type="middle">J</forename><surname>Hausmann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Wörterbücher, Dictionaries, Dictionnaires: An international Handbook of Lexicography</title>
		<editor>F.J. Hausmann, O. Reichmann, H.E. Wiegand, and L. Zgusta</editor>
		<meeting><address><addrLine>Berlin/New-York</addrLine></address></meeting>
		<imprint>
			<publisher>De Gruyter</publisher>
			<date type="published" when="1989" />
			<biblScope unit="page" from="1010" to="1019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b424">
	<analytic>
		<title level="a" type="main">Improving Word Representations via Global Context and Multiple Word Prototypes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">H</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Socher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">D</forename><surname>Manning</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">Y</forename><surname>Ng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics: Long Papers</title>
		<meeting>the 50th Annual Meeting of the Association for Computational Linguistics: Long Papers</meeting>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="873" to="882" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b425">
	<analytic>
		<title level="a" type="main">SENSEMBED: Enhancing Word Embeddings for Semantic Similarity and Relatedness</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Iacobacci</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">T</forename><surname>Pilehvar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Navigli</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ACL</title>
		<meeting>ACL<address><addrLine>Beijing, China</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2015-07" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b426">
	<analytic>
		<title level="a" type="main">Collocationality (and How to Measure it)</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Kilgarriff</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Euralex Conference</title>
		<meeting>the Euralex Conference<address><addrLine>Turin, Italy</addrLine></address></meeting>
		<imprint>
			<publisher>Springer-Verlag</publisher>
			<date type="published" when="2006" />
			<biblScope unit="page" from="997" to="1004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b427">
	<analytic>
		<title level="a" type="main">Teaching Collocation. Further Developments in the Lexical Approach</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Lewis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Conzett</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">LTP</title>
		<imprint>
			<date type="published" when="2000" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b428">
	<analytic>
		<title level="a" type="main">Automatic Identification of NonCompositional Phrases</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Lin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 37th annual meeting of the Association for Computational Linguistics on Computational Linguistics</title>
		<meeting>the 37th annual meeting of the Association for Computational Linguistics on Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="1999" />
			<biblScope unit="page" from="317" to="324" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b429">
	<analytic>
		<title level="a" type="main">Lexical functions: A Tool for the Description of Lexical Relations in the Lexicon</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><forename type="middle">A</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Lexical Functions in Lexicography and Natural Language Processing</title>
		<editor>L. Wanner</editor>
		<meeting><address><addrLine>Amsterdam</addrLine></address></meeting>
		<imprint>
			<publisher>Benjamins Academic Publishers</publisher>
			<date type="published" when="1996" />
			<biblScope unit="page" from="37" to="102" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b430">
	<monogr>
		<title level="m" type="main">Efficient Estimation of Word Representations in Vector Space</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Mikolov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Corrado</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Dean</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1301.3781</idno>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b431">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Mikolov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><forename type="middle">V</forename><surname>Le</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Sutskever</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1309.4168</idno>
		<title level="m">Exploiting Similarities among Languages for Machine Translation</title>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b432">
	<analytic>
		<title level="a" type="main">Linguistic Regularities in Continuous Space Word Representations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Mikolov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Yih</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Zweig</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">HLT-NAACL</title>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="746" to="751" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b433">
	<analytic>
		<title level="a" type="main">Can we Determine the Semantics of Collocations without using Semantics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Moreno</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Ferraro</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Wanner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the eLex 2013 conference</title>
		<editor>I. Kosem, J. Kallas, P. Gantar, S. Krek, M. Langemets, and M. Tuulik</editor>
		<meeting>the eLex 2013 conference<address><addrLine>Tallinn &amp; Ljubljana. Trojina</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
		<respStmt>
			<orgName>Institute for Applied Slovene Studies &amp; Eesti Keele Instituut</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b434">
	<monogr>
		<title level="m" type="main">Collocations in a Learner Corpus</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Nesselhauf</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2005" />
			<publisher>Benjamins Academic Publishers</publisher>
			<pubPlace>Amsterdam</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b435">
	<analytic>
		<title level="a" type="main">Is the Sky Pure Today? awkchecker: an Assistive Tool for Detecting and Correcting Collocation Errors</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Park</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Lank</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Poupart</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Terry</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 21st annual ACM symposium on User interface software and technology</title>
		<meeting>the 21st annual ACM symposium on User interface software and technology</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2008" />
			<biblScope unit="page" from="121" to="130" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b436">
	<analytic>
		<title level="a" type="main">A Machine Learning Approach to Multiword Expression Extraction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Pecina</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the LREC 2008 Workshop Towards a Shared Task for Multiword Expressions (MWE 2008)</title>
		<meeting>the LREC 2008 Workshop Towards a Shared Task for Multiword Expressions (MWE 2008)<address><addrLine>Marrakech</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2008" />
			<biblScope unit="page" from="54" to="57" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b437">
	<analytic>
		<title level="a" type="main">Example-based Acquisition of Fine-grained Collocation Resources</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Rodríguez-Fernández</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Carlini</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Espinosa-Anke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Wanner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of LREC</title>
		<meeting>LREC<address><addrLine>Portorož, Slovenia</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b438">
	<analytic>
		<title level="a" type="main">Retrieving Collocations from Text: X-Tract</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Smadja</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computational Linguistics</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="143" to="177" />
			<date type="published" when="1993" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b439">
	<analytic>
		<title level="a" type="main">Lexical Comparison Between Wikipedia and Twitter Corpora by Using Word Embeddings</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Clarke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Smucker</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing</title>
		<meeting>the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing<address><addrLine>Beijing, China</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2015-07" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="657" to="661" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b440">
	<monogr>
		<title level="m" type="main">Evaluating Word Representation Features in Biomedical Named Entity Recognition Tasks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Xu</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
	<note>BioMed research international</note>
</biblStruct>

<biblStruct xml:id="b441">
	<analytic>
		<title level="a" type="main">Making Sense of Collocations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Wanner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Bohnet</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Giereth</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computer Speech and Language</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="609" to="624" />
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b442">
	<analytic>
		<title level="a" type="main">Towards Distributional Semantics-based Classification of Collocations for Collocation Dictionaries</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Wanner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Ferraro</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Moreno</surname></persName>
		</author>
		<idno type="doi">10.1093/ijl/ecw002</idno>
	</analytic>
	<monogr>
		<title level="j">International Journal of Lexicography</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b443">
	<analytic>
		<title level="a" type="main">Automatic Collocation Suggestion in Academic Writing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">C</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><forename type="middle">C</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Mitamura</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">S</forename><surname>Chang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the ACL Conference</title>
		<meeting>the ACL Conference<address><addrLine>Uppsala</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
	<note>Short paper track</note>
</biblStruct>

<biblStruct xml:id="b444">
	<analytic>
		<title level="a" type="main">Tailoring continuous word representations for dependency parsing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mohit</forename><surname>Bansal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kevin</forename><surname>Gimpel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Karen</forename><surname>Livescu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ACL 2014</title>
		<meeting>ACL 2014</meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="809" to="815" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b445">
	<analytic>
		<title level="a" type="main">A neural probabilistic language model</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Réjean</forename><surname>Ducharme</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pascal</forename><surname>Vincent</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christian</forename><surname>Janvin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="1137" to="1155" />
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b446">
	<analytic>
		<title level="a" type="main">Translating embeddings for modeling multirelational data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Antoine</forename><surname>Bordes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nicolas</forename><surname>Usunier</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alberto</forename><surname>Garciaduran</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jason</forename><surname>Weston</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oksana</forename><surname>Yakhnenko</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of NIPS 2013</title>
		<meeting>NIPS 2013</meeting>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="2787" to="2795" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b447">
	<analytic>
		<title level="a" type="main">Distributed optimization and statistical learning via the alternating direction method of multipliers</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stephen</forename><surname>Boyd</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Neal</forename><surname>Parikh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eric</forename><surname>Chu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Borja</forename><surname>Peleato</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathan</forename><surname>Eckstein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Machine Learning</title>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="1" to="122" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b448">
	<analytic>
		<title level="a" type="main">Typed tensor decomposition of knowledge bases for relation extraction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kai-Wei</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wen-Tau</forename><surname>Yih</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bishan</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><surname>Meek</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EMNLP</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b449">
	<analytic>
		<title level="a" type="main">Multi-view learning of word embeddings via CCA</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Paramveer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dean</forename><surname>Dhillon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lyle</forename><surname>Foster</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Ungar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of NIPS 2011</title>
		<meeting>NIPS 2011</meeting>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="page" from="199" to="207" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b450">
	<analytic>
		<title level="a" type="main">Retrofitting word vectors to semantic lexicons</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Manaal</forename><surname>Faruqui</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jesse</forename><surname>Dodge</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Sujay</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Jauhar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eduard</forename><surname>Dyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Noah</forename><forename type="middle">A</forename><surname>Hovy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Smith</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of NAACL-HLT 2015</title>
		<meeting>NAACL-HLT 2015</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="1606" to="1615" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b451">
	<monogr>
		<title level="m" type="main">WordNet: An Electronic Lexical Database</title>
		<editor>Christiane Fellbaum</editor>
		<imprint>
			<date type="published" when="1998" />
			<publisher>MIT Press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b452">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Fried</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kevin</forename><surname>Duh</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1412.4369</idno>
		<title level="m">Incorporating both distributional and relational semantics in word representations</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b453">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bin</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiang</forename><surname>Bian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tie-Yan</forename><surname>Liu</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1407.1640</idno>
		<title level="m">Wordrep: A benchmark for research on learning word representations</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b454">
	<monogr>
		<title level="m" type="main">word2vec explained: deriving mikolov et al.&apos;s negativesampling word-embedding method</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoav</forename><surname>Goldberg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Omer</forename><surname>Levy</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1402.3722</idno>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b455">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Zellig</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Harris</surname></persName>
		</author>
		<title level="m">Distributional structure. Word</title>
		<imprint>
			<date type="published" when="1954" />
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="page" from="146" to="162" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b456">
	<monogr>
		<title level="m" type="main">Linguistic regularities in sparse and explicit word representations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Omer</forename><surname>Levy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoav</forename><surname>Goldberg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Israel</forename><surname>Ramat-Gan</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page">171</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b457">
	<analytic>
		<title level="a" type="main">Learning semantic word embeddings based on ordinal knowledge constraints</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Quan</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hui</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Si</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhen-Hua</forename><surname>Ling</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yu</forename><surname>Hu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ACL</title>
		<meeting>ACL</meeting>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b458">
	<analytic>
		<title level="a" type="main">Learning word vectors for sentiment analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><forename type="middle">L</forename><surname>Maas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Raymond</forename><forename type="middle">E</forename><surname>Daly</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peter</forename><forename type="middle">T</forename><surname>Pham</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><forename type="middle">Y</forename><surname>Ng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><surname>Potts</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ACL 2011</title>
		<meeting>ACL 2011</meeting>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="page" from="142" to="150" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b459">
	<analytic>
		<title level="a" type="main">Efficient estimation of word representations in vector space</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tomas</forename><surname>Mikolov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kai</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Greg</forename><surname>Corrado</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeffrey</forename><surname>Dean</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ICLR 2013</title>
		<meeting>ICLR 2013</meeting>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b460">
	<analytic>
		<title level="a" type="main">Distributed representations of words and phrases and their compositionality</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tomas</forename><surname>Mikolov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ilya</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kai</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Greg</forename><forename type="middle">S</forename><surname>Corrado</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeff</forename><surname>Dean</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="3111" to="3119" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b461">
	<analytic>
		<title level="a" type="main">Linguistic regularities in continuous space word representations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tomas</forename><surname>Mikolov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yih</forename><surname>Wen-Tau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geoffrey</forename><surname>Zweig</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of HLT-NAACL</title>
		<meeting>HLT-NAACL</meeting>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="746" to="751" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b462">
	<analytic>
		<title level="a" type="main">GloVe: Global vectors for word representation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeffrey</forename><surname>Pennington</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Socher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><forename type="middle">D</forename><surname>Manning</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of EMNLP 2014</title>
		<meeting>EMNLP 2014</meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="1532" to="1543" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b463">
	<analytic>
		<title level="a" type="main">Relation extraction with matrix factorization and universal schemas</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sebastian</forename><surname>Riedel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Limin</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Benjamin</forename><forename type="middle">M</forename><surname>Marlin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Mccallum</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">HLT-NAACL</title>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b464">
	<monogr>
		<title level="m" type="main">Injecting logical background knowledge into embeddings for relation extraction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tim</forename><surname>Rocktäschel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sameer</forename><surname>Singh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sebastian</forename><surname>Riedel</surname></persName>
		</author>
		<editor>HLT-NAALC</editor>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b465">
	<analytic>
		<title level="a" type="main">Dynamic pooling and unfolding recursive autoencoders for paraphrase detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Socher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eric</forename><forename type="middle">H</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeffrey</forename><surname>Pennington</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><forename type="middle">Y</forename><surname>Ng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><forename type="middle">D</forename><surname>Manning</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of NIPS 2011</title>
		<meeting>NIPS 2011</meeting>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="page" from="801" to="809" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b466">
	<analytic>
		<title level="a" type="main">Representing text for joint embedding of text and knowledge bases</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kristina</forename><surname>Toutanova</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Danqi</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Patrick</forename><surname>Pantel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pallavi</forename><surname>Choudhury</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Gamon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ACL</title>
		<meeting>ACL</meeting>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b467">
	<analytic>
		<title level="a" type="main">Word representations: A simple and general method for semi-supervised learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joseph</forename><surname>Turian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lev</forename><surname>Ratinov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ACL 2010</title>
		<meeting>ACL 2010</meeting>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="page" from="384" to="394" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b468">
	<analytic>
		<title level="a" type="main">RC-NET: A general framework for incorporating knowledge into word representations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chang</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yalong</forename><surname>Bai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiang</forename><surname>Bian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bin</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gang</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaoguang</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tie-Yan</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of CIKM 2014</title>
		<meeting>CIKM 2014</meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="1219" to="1228" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b469">
	<analytic>
		<title level="a" type="main">Improving lexical embeddings with semantic knowledge</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mo</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mark</forename><surname>Dredze</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ACL 2014</title>
		<meeting>ACL 2014</meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="545" to="550" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b470">
	<analytic>
		<title level="a" type="main">Bilingual word embeddings for phrase-based machine translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Will</forename><forename type="middle">Y</forename><surname>Zou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Socher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Cer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><forename type="middle">D</forename><surname>Manning</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of EMNLP 2013</title>
		<meeting>EMNLP 2013</meeting>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="1393" to="1398" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b471">
	<monogr>
		<title level="m" type="main">Opinion Lexicon (Hu and Liu, 2004) and NRC Emotion lexicons (Mohammad and Turney, 2013) for polarity; BWK, a lexicon of 40</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Method</forename><surname>Setup</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">;</forename><surname>Eqs</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Mikolov</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2005" />
		</imprint>
	</monogr>
	<note>2/3 can be combined to train an orthogonal transformation matrix. 000 English words. for concreteness; the order in the word embedding file for frequency; and the training set of the FLORS tagger (Schnabel and Schütze, 2014) for POS. The application of the transformation ma</note>
</biblStruct>

<biblStruct xml:id="b472">
	<analytic>
		<title level="a" type="main">Using mined coreference chains as a resource for a semantic task</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Heike</forename><surname>Adel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hinrich</forename><surname>Schütze</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of EMNLP</title>
		<meeting>EMNLP</meeting>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b473">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Jan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Phil</forename><surname>Botha</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Blunsom</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1405.4273</idno>
		<title level="m">Compositional morphology for word representations and language modelling</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b474">
	<analytic>
		<title level="a" type="main">Concreteness ratings for 40 thousand generally known english word lemmas</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marc</forename><surname>Brysbaert</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Amy</forename><forename type="middle">Beth</forename><surname>Warriner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Victor</forename><surname>Kuperman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Behavior research methods</title>
		<imprint>
			<biblScope unit="volume">46</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="904" to="911" />
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b475">
	<analytic>
		<title level="a" type="main">Morphological word-embeddings</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ryan</forename><surname>Cotterell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hinrich</forename><surname>Schütze</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2015 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</title>
		<meeting>the 2015 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies<address><addrLine>Denver, Colorado</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2015-05" />
			<biblScope unit="page" from="1287" to="1292" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b476">
	<analytic>
		<title level="a" type="main">Good, great, excellent: Global inference of semantic intensities</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gerard</forename><surname>De Melo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mohit</forename><surname>Bansal</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Transactions of the Association for Computational Linguistics</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="279" to="290" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b477">
	<monogr>
		<title level="m" type="main">WordNet: An Electronic Lexical Database</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christiane</forename><surname>Fellbaum</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1998" />
			<publisher>Bradford Books</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b478">
	<analytic>
		<title level="a" type="main">Mining and Summarizing Customer Reviews</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Minqing</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bing</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">KDD</title>
		<imprint>
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b479">
	<monogr>
		<title level="m" type="main">Efficient estimation of word representations in vector space</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tomas</forename><surname>Mikolov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kai</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Greg</forename><surname>Corrado</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeffrey</forename><surname>Dean</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1301.3781</idno>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b480">
	<analytic>
		<title level="a" type="main">Crowdsourcing a Word-Emotion Association Lexicon</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Saif</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peter</forename><forename type="middle">D</forename><surname>Mohammad</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Turney</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computational Intelligence</title>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="issue">3</biblScope>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b481">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sascha</forename><surname>Rothe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sebastian</forename><surname>Ebert</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hinrich</forename><surname>Schütze</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1602.07572</idno>
		<title level="m">Ultradense word embeddings by orthogonal transformation</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b482">
	<analytic>
		<title level="a" type="main">Flors: Fast and simple domain adaptation for part-ofspeech tagging</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tobias</forename><surname>Schnabel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hinrich</forename><surname>Schütze</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Transactions of the Association for Computational Linguistics</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="15" to="26" />
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b483">
	<analytic>
		<title level="a" type="main">Symmetric pattern based word embeddings for improved word similarity prediction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Roy</forename><surname>Schwartz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Roi</forename><surname>Reichart</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ari</forename><surname>Rappoport</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of CoNLL</title>
		<meeting>CoNLL</meeting>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b484">
	<analytic>
		<title level="a" type="main">Adjective intensity and sentiment analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Raksha</forename><surname>Sharma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mohit</forename><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Astha</forename><surname>Agarwal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pushpak</forename><surname>Bhattacharyya</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of EMNLP</title>
		<meeting>EMNLP</meeting>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b485">
	<analytic>
		<title level="a" type="main">Distance metric learning for large margin nearest neighbor classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Kilian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lawrence</forename><forename type="middle">K</forename><surname>Weinberger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Saul</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Mach. Learn. Res</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="page" from="207" to="244" />
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b486">
	<analytic>
		<title level="a" type="main">Recognizing contextual polarity in phrase-level sentiment analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Theresa</forename><surname>Wilson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Janyce</forename><surname>Wiebe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Paul</forename><surname>Hoffmann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of HLT/EMNLP</title>
		<meeting>HLT/EMNLP</meeting>
		<imprint>
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b487">
	<analytic>
		<title level="a" type="main">Polarity inducing latent semantic analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geoffrey</forename><surname>Wen-Tau Yih</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John C</forename><surname>Zweig</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Platt</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of EMNLP</title>
		<meeting>EMNLP</meeting>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b488">
	<analytic>
		<title level="a" type="main">Online updating of word representations for part-of-speech tagging</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wenpeng</forename><surname>Yin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tobias</forename><surname>Schnabel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hinrich</forename><surname>Schütze</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of EMNLP</title>
		<meeting>EMNLP</meeting>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b489">
	<analytic>
		<title level="a" type="main">Polyglot: Distributed word representations for multilingual NLP</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rami</forename><surname>Al-Rfou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bryan</forename><surname>Perozzi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Steven</forename><surname>Skiena</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CoNLL</title>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="183" to="192" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b490">
	<analytic>
		<title level="a" type="main">Tailoring continuous word representations for dependency parsing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mohit</forename><surname>Bansal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kevin</forename><surname>Gimpel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Karen</forename><surname>Livescu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL</title>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="809" to="815" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b491">
	<analytic>
		<title level="a" type="main">Don&apos;t count, predict! A systematic comparison of context-counting vs. context-predicting semantic vectors</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marco</forename><surname>Baroni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Georgiana</forename><surname>Dinu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Germán</forename><surname>Kruszewski</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL</title>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="238" to="247" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b492">
	<analytic>
		<title level="a" type="main">On achieving and evaluating language-independence in NLP</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Emily</forename><forename type="middle">M</forename><surname>Bender</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Linguistic Issues in Language Technology</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="1" to="28" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b493">
	<analytic>
		<title level="a" type="main">Word embeddings go to Italy: A comparison of models and training datasets</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Giacomo</forename><surname>Berardi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrea</forename><surname>Esuli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Diego</forename><surname>Marcheggiani</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Italian Information Retrieval Workshop</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b494">
	<analytic>
		<title level="a" type="main">Phylogenetic grammar induction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Taylor</forename><surname>Berg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">-</forename><surname>Kirkpatrick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Klein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL</title>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="page" from="1288" to="1297" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b495">
	<analytic>
		<title level="a" type="main">Top accuracy and fast dependency parsing is not a contradiction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bernd</forename><surname>Bohnet</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">COLING</title>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="page" from="89" to="97" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b496">
	<analytic>
		<title level="a" type="main">A fast and accurate dependency parser using neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Danqi</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><forename type="middle">D</forename><surname>Manning</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EMNLP</title>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="740" to="750" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b497">
	<analytic>
		<title level="a" type="main">It depends: Dependency parser comparison using a Web-based evaluation tool</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Jinho</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joel</forename><surname>Choi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Amanda</forename><surname>Tetreault</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Stent</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="387" to="396" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b498">
	<analytic>
		<title level="a" type="main">Unsupervised structure prediction with nonparallel multilingual guidance</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Shay</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dipanjan</forename><surname>Cohen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Noah</forename><forename type="middle">A</forename><surname>Das</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Smith</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EMNLP</title>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="page" from="50" to="61" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b499">
	<analytic>
		<title level="a" type="main">Natural language processing (almost) from scratch</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ronan</forename><surname>Collobert</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jason</forename><surname>Weston</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Léon</forename><surname>Bottou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Karlen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Koray</forename><surname>Kavukcuoglu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pavel</forename><forename type="middle">P</forename><surname>Kuksa</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="page" from="2493" to="2537" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b500">
	<analytic>
		<title level="a" type="main">Universal Stanford dependencies: A cross-linguistic typology</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marie-Catherine</forename><surname>De Marneffe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Timothy</forename><surname>Dozat</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Natalia</forename><surname>Silveira</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Katri</forename><surname>Haverinen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Filip</forename><surname>Ginter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joakim</forename><surname>Nivre</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><forename type="middle">D</forename><surname>Manning</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">LREC</title>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="4585" to="4592" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b501">
	<monogr>
		<title level="m" type="main">Word2vec explained: Deriving Mikolov et al.&apos;s negativesampling word-embedding method</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoav</forename><surname>Goldberg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Omer</forename><surname>Levy</surname></persName>
		</author>
		<idno>abs/1402.3722</idno>
		<imprint>
			<date type="published" when="2014" />
			<publisher>CoRR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b502">
	<analytic>
		<title level="a" type="main">SimLex-999: Evaluating semantic models with (genuine) similarity estimation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Felix</forename><surname>Hill</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Roi</forename><surname>Reichart</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anna</forename><surname>Korhonen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computational Linguistics</title>
		<imprint>
			<biblScope unit="volume">41</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="665" to="695" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b503">
	<analytic>
		<title level="a" type="main">Multilingual reliability and &quot;semantic&quot; structure of continuous word spaces</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maximilian</forename><surname>Köper</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christian</forename><surname>Scheible</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sabine</forename><surname>Schulte Im Walde</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IWCS</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="40" to="45" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b504">
	<monogr>
		<title level="m" type="main">Separated by an un-common language: Towards judgment language informed vector space modeling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ira</forename><surname>Leviant</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Roi</forename><surname>Reichart</surname></persName>
		</author>
		<idno>abs/1508.00106</idno>
		<imprint>
			<date type="published" when="2015" />
			<publisher>CoRR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b505">
	<analytic>
		<title level="a" type="main">Dependencybased word embeddings</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Omer</forename><surname>Levy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoav</forename><surname>Goldberg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL</title>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="302" to="308" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b506">
	<analytic>
		<title level="a" type="main">Linguistic regularities in sparse and explicit word representations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Omer</forename><surname>Levy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoav</forename><surname>Goldberg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CoNLL</title>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="171" to="180" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b507">
	<analytic>
		<title level="a" type="main">Improving distributional similarity with lessons learned from word embeddings</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Omer</forename><surname>Levy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoav</forename><surname>Goldberg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ido</forename><surname>Dagan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Transactions of the ACL</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="211" to="225" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b508">
	<analytic>
		<title level="a" type="main">Turning on the turbo: Fast third-order non-projective turbo parsers</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><forename type="middle">T</forename><surname>André</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Miguel</forename><forename type="middle">B</forename><surname>Martins</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Noah</forename><forename type="middle">A</forename><surname>Almeida</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Smith</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL</title>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="617" to="622" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b509">
	<analytic>
		<title level="a" type="main">Multi-source transfer of delexicalized dependency parsers</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ryan</forename><surname>Mcdonald</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Slav</forename><surname>Petrov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Keith</forename><surname>Hall</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EMNLP</title>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="page" from="62" to="72" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b510">
	<analytic>
		<title level="a" type="main">Universal dependency annotation for multilingual parsing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ryan</forename><forename type="middle">T</forename><surname>Mcdonald</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joakim</forename><surname>Nivre</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yvonne</forename><surname>Quirmbach-Brundage</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoav</forename><surname>Goldberg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dipanjan</forename><surname>Das</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kuzman</forename><surname>Ganchev</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Keith</forename><forename type="middle">B</forename><surname>Hall</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Slav</forename><surname>Petrov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hao</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oscar</forename><surname>Täckström</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Claudia Bedini, Núria Bertomeu Castelló, and Jungmee Lee</title>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="92" to="97" />
		</imprint>
	</monogr>
	<note>ACL</note>
</biblStruct>

<biblStruct xml:id="b511">
	<analytic>
		<title level="a" type="main">Modeling word meaning in context with substitute vectors</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oren</forename><surname>Melamud</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ido</forename><surname>Dagan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jacob</forename><surname>Goldberger</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NAACL-HLT</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="472" to="482" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b512">
	<analytic>
		<title level="a" type="main">The role of context types and dimensionality in learning word embeddings</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oren</forename><surname>Melamud</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Mcclosky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Siddharth</forename><surname>Patwardhan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mohit</forename><surname>Bansal</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NAACL-HLT</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b513">
	<analytic>
		<title level="a" type="main">Efficient estimation of word representations in vector space</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tomas</forename><surname>Mikolov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kai</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gregory</forename><forename type="middle">S</forename><surname>Corrado</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeffrey</forename><surname>Dean</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICLR Workshop Papers</title>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b514">
	<analytic>
		<title level="a" type="main">Distributed representations of words and phrases and their compositionality</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tomas</forename><surname>Mikolov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ilya</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kai</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gregory</forename><forename type="middle">S</forename><surname>Corrado</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeffrey</forename><surname>Dean</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS</title>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="3111" to="3119" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b515">
	<analytic>
		<title level="a" type="main">Selective sharing for multilingual dependency parsing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tahira</forename><surname>Naseem</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Regina</forename><surname>Barzilay</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Amir</forename><surname>Globerson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL</title>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="page" from="629" to="637" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b516">
	<monogr>
		<title level="m" type="main">Universal Dependencies 1.2. LINDAT/CLARIN digital library at Institute of Formal and Applied Linguistics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joakim</forename><surname>Nivre</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
		<respStmt>
			<orgName>Charles University in Prague</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b517">
	<analytic>
		<title level="a" type="main">Dependency-based construction of semantic space models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sebastian</forename><surname>Padó</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mirella</forename><surname>Lapata</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computational Linguistics</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="161" to="199" />
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b518">
	<analytic>
		<title level="a" type="main">A universal part-of-speech tagset</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Slav</forename><surname>Petrov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dipanjan</forename><surname>Das</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ryan</forename><forename type="middle">T</forename><surname>Mcdonald</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">LREC</title>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="page" from="2089" to="2096" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b519">
	<analytic>
		<title level="a" type="main">Symmetric pattern based word embeddings for improved word similarity prediction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Roy</forename><surname>Schwartz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Roi</forename><surname>Reichart</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ari</forename><surname>Rappoport</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CoNLL</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="258" to="267" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b520">
	<analytic>
		<title level="a" type="main">Cross-lingual dependency parsing with universal dependencies and predicted PoS labels</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jörg</forename><surname>Tiedemann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">DepLing</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="340" to="349" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b521">
	<analytic>
		<title level="a" type="main">Word representations: A simple and general method for semi-supervised learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joseph</forename><forename type="middle">P</forename><surname>Turian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lev-Arie</forename><surname>Ratinov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL</title>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="page" from="384" to="394" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b522">
	<analytic>
		<title level="a" type="main">Learning syntactic categories using paradigmatic representations of word context</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Enis</forename><surname>Mehmet Ali Yatbaz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Deniz</forename><surname>Sert</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Yuret</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EMNLP</title>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="page" from="940" to="951" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b523">
	<analytic>
		<title level="a" type="main">Crosslanguage parser adaptation between related languages</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Zeman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philip</forename><surname>Resnik</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IJCNLP</title>
		<imprint>
			<date type="published" when="2008" />
			<biblScope unit="page" from="35" to="42" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b524">
	<analytic>
		<title level="a" type="main">A Benchmark Dataset for Automatic Detection of Claims and Evidence in the Context of Controversial Topics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anatoly</forename><surname>References Ehud Aharoni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tamar</forename><surname>Polnarov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Lavee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ran</forename><surname>Hershcovich</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ruty</forename><surname>Levy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Rinott</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Noam</forename><surname>Gutfreund</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Slonim</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Workshop on Argumentation Mining</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b525">
	<analytic>
		<title level="a" type="main">A Two-Phase Framework for Learning Logical Structures of Paragraphs in Legal Articles</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Ngo Xuan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nguyen</forename><forename type="middle">Le</forename><surname>Bach</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tran</forename><forename type="middle">Thi</forename><surname>Minh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Akira</forename><surname>Oanh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Shimazu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">In ACM Transactions on Asian Language Information Processing (TALIP)</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page">3</biblScope>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b526">
	<analytic>
		<title level="a" type="main">The Media Frames Corpus: Annotations of Frames Across Issues</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dallas</forename><surname>Card</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Amber</forename><forename type="middle">E</forename><surname>Boydstun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Justin</forename><forename type="middle">H</forename><surname>Gross</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philip</forename><surname>Resnik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Noah</forename><forename type="middle">A</forename><surname>Smith</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Association for Computational Linguistics Conference (ACL)</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b527">
	<analytic>
		<title level="a" type="main">Generating and evaluating evaluative arguments</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Giuseppe</forename><surname>Carenini</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Johanna</forename><forename type="middle">D</forename><surname>Moore</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Artificial Intelligence</title>
		<imprint>
			<biblScope unit="volume">170</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="925" to="952" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b528">
	<analytic>
		<title level="a" type="main">SimpleNLG: A realisation engine for practical applications</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Gatt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Reiter</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ENLG-2009</title>
		<meeting>ENLG-2009</meeting>
		<imprint>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b529">
	<analytic>
		<title level="a" type="main">Mining and summarizing customer reviews</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Minqing</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bing</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Knowledge Discovery and Data Mining</title>
		<imprint>
			<date type="published" when="2004" />
			<biblScope unit="page" from="168" to="177" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b530">
	<analytic>
		<title level="a" type="main">The measurement of observer agreement for categorical data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">R</forename><surname>Landis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">G</forename><surname>Kock</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Biometrics</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page">159174</biblScope>
			<date type="published" when="1977" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b531">
	<analytic>
		<title level="a" type="main">Generation that exploits corpus-based statistical knowledge</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Irene</forename><surname>Langkilde</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kevin</forename><surname>Knight</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 36th Annual Meeting of the Association for Computational Linguistics and 17th International Conference on Computational Linguistics -Volume</title>
		<meeting>the 36th Annual Meeting of the Association for Computational Linguistics and 17th International Conference on Computational Linguistics -Volume<address><addrLine>Stroudsburg, PA, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="1998" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="704" to="710" />
		</imprint>
	</monogr>
	<note>ACL &apos;98)</note>
</biblStruct>

<biblStruct xml:id="b532">
	<analytic>
		<title level="a" type="main">Context Dependent Claim Detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ran</forename><surname>Levy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yonatan</forename><surname>Bilu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Hershcovich</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ehud</forename><surname>Aharoni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Noam</forename><surname>Slonim</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The 25th International Conference on Computational Linguistics</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b533">
	<analytic>
		<title level="a" type="main">Deep parsing in Watson</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><forename type="middle">C</forename><surname>Mccord</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">William</forename><surname>Murdock</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Branimir</forename><forename type="middle">K</forename><surname>Boguraev</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IBM Journal of Research and Development</title>
		<imprint>
			<biblScope unit="volume">56</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="3" to="4" />
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b534">
	<analytic>
		<title level="a" type="main">Distributed representations of words and phrases and their compositionality</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tomas</forename><surname>Mikolov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ilya</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kai</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Greg</forename><forename type="middle">S</forename><surname>Corrado</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeff</forename><surname>Dean</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="3111" to="3119" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b535">
	<analytic>
		<title level="a" type="main">Argumentation mining</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mochales</forename><surname>Palau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marie-Francine</forename><surname>Moens</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Artificial Intelligence and Law</title>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="page" from="1" to="22" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b536">
	<monogr>
		<title level="m" type="main">Building Natural Language Generation Systems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ehud</forename><surname>Reiter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Robert</forename><surname>Dale</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2000" />
			<publisher>Cambridge University Press</publisher>
			<pubPlace>New York, NY, USA</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b537">
	<analytic>
		<title level="a" type="main">Show Me Your Evidencean Automatic Method for Context Dependent Evidence Detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ruty</forename><surname>Rinott</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lena</forename><surname>Dankin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Carlos</forename><surname>Alzate</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Mitesh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ehud</forename><surname>Khapra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Noam</forename><surname>Aharoni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Slonim</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2015 Conference on Empirical Methods in NLP (EMNLP)</title>
		<meeting>the 2015 Conference on Empirical Methods in NLP (EMNLP)<address><addrLine>Lisbon, Portugal</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="17" to="21" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b538">
	<monogr>
		<title level="m" type="main">The Uses of Argument</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stephen</forename><surname>Toulmin</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1958" />
			<publisher>Cambridge University Press</publisher>
			<pubPlace>Cambridge</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b539">
	<analytic>
		<title level="a" type="main">Argument Mining by Applying Argumentation Schemes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Douglas</forename><surname>Walton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Studies in Logic</title>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="page" from="38" to="64" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b540">
	<monogr>
		<title level="m" type="main">Argumentation schemes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Douglas</forename><surname>Walton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><surname>Reed</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fabrizio</forename><surname>Macagno</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2008" />
			<publisher>Cambridge University Press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b541">
	<analytic>
		<title level="a" type="main">Approaches to text mining arguments from legal cases</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adam</forename><surname>Wyner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Raquel</forename><surname>Mochales-Palau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marie-Francine</forename><surname>Moens</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Milward</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Semantic processing of legal texts</title>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="page" from="60" to="79" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b542">
	<monogr>
		<title level="m" type="main">Game theory and pragmatics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anton</forename><surname>Benz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gerhard</forename><surname>Jäger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Robert</forename><surname>Van Rooij</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Robert</forename><surname>Van Rooij</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2016" />
			<publisher>Springer</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b543">
	<monogr>
		<title level="m" type="main">Pragmatic reasoning through semantic inference</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Leon</forename><surname>Bergen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Roger</forename><surname>Levy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Noah</forename><forename type="middle">D</forename><surname>Goodman</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b544">
	<monogr>
		<title level="m" type="main">Using language</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Herbert</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Clark</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1996" />
			<publisher>Cambridge university press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b545">
	<monogr>
		<title level="m" type="main">Bayesian brain: Probabilistic approaches to neural coding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kenji</forename><surname>Doya</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2007" />
			<publisher>MIT press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b546">
	<analytic>
		<title level="a" type="main">Predicting pragmatic reasoning in lanugage games</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Michael</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Noah</forename><forename type="middle">D</forename><surname>Frank</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Goodman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Science</title>
		<imprint>
			<biblScope unit="volume">336</biblScope>
			<biblScope unit="issue">6084</biblScope>
			<biblScope unit="page">998</biblScope>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b547">
	<analytic>
		<title level="a" type="main">The motor theory of speech perception reviewed</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bruno</forename><surname>Galantucci</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><forename type="middle">T</forename><surname>Fowler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Turvey</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Psychonomic bulletin &amp; review</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="361" to="377" />
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b548">
	<monogr>
		<title level="m" type="main">Probabilistic semantics and pragmatics: Uncertainty in language and thought. Handbook of Contemporary Semantic Theory</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Noah</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Goodman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Lassiter</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2014" />
			<publisher>Wiley-Blackwell</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b549">
	<analytic>
		<title level="a" type="main">Knowledge and implicature: modeling language understanding as social cognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Noah</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andreas</forename><surname>Goodman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Stuhlmüller</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Topics in cognitive science</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="173" to="184" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b550">
	<monogr>
		<title level="m" type="main">Logic and conversation in p</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Hp Grice</surname></persName>
		</author>
		<editor>. cole and j. morgan</editor>
		<imprint>
			<date type="published" when="1975" />
			<biblScope unit="volume">3</biblScope>
		</imprint>
	</monogr>
	<note>Speech acts</note>
</biblStruct>

<biblStruct xml:id="b551">
	<analytic>
		<title level="a" type="main">Game theory in semantics and pragmatics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gerhard</forename><surname>Jäger</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Semantics: An International Handbook of Natural Language Meaning</title>
		<editor>Claudia Maienborn, Klaus von Heusinger, and Paul Portner</editor>
		<imprint>
			<publisher>Mouton de Gruyter</publisher>
			<date type="published" when="2012" />
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="2487" to="2425" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b552">
	<analytic>
		<title level="a" type="main">Nonliteral understanding of number words</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Justine</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Kao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Jean</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Leon</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Noah D</forename><surname>Bergen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Goodman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Proceedings of the National Academy of Sciences</title>
		<imprint>
			<biblScope unit="volume">111</biblScope>
			<biblScope unit="issue">33</biblScope>
			<biblScope unit="page" from="12002" to="12007" />
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b553">
	<analytic>
		<title level="a" type="main">Predictive coding: an account of the mirror neuron system</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>James</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Karl</forename><forename type="middle">J</forename><surname>Kilner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><forename type="middle">D</forename><surname>Friston</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Frith</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Cognitive processing</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="159" to="166" />
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b554">
	<analytic>
		<title level="a" type="main">Context, scale structure, and statistics in the interpretation of positive-form adjectives</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Lassiter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Noah D Goodman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Semantics and Linguistic Theory</title>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="page" from="587" to="610" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b555">
	<analytic>
		<title level="a" type="main">Adjectival vagueness in a bayesian model of interpretation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Lassiter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Noah D Goodman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Synthese</title>
		<imprint>
			<biblScope unit="page" from="1" to="36" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b556">
	<monogr>
		<title level="m" type="main">Discourse markers in english: a discourse-pragmatic view. Approaches to discourse particles</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Diana</forename><surname>Lewis</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2006" />
			<biblScope unit="page" from="43" to="59" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b557">
	<analytic>
		<title level="a" type="main">The standord corenlp natural language processing toolkit</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><surname>Manning</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mihai</forename><surname>Surdeanu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Bauer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jenny</forename><surname>Finkey</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Steven</forename><forename type="middle">J</forename><surname>Bethard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Mcclosky</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Annual Meeting of the Association for Computational Linguistics: System Demonstrations</title>
		<meeting>the Annual Meeting of the Association for Computational Linguistics: System Demonstrations</meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="55" to="60" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b558">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Will</forename><surname>Monroe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><surname>Potts</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1510.06807</idno>
		<title level="m">Learning in the rational speech acts model</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b559">
	<analytic>
		<title level="a" type="main">Prcis of bayesian rationality: The probabilistic approach to human reasoning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mike</forename><surname>Oaksford</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nick</forename><surname>Chater</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Behavioral and Brain Sciences</title>
		<imprint>
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="page" from="69" to="84" />
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b560">
	<analytic>
		<title level="a" type="main">Why discourse affects speakers&apos; choice of refering expressions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Naho</forename><surname>Orita</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eliana</forename><surname>Vornov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Naomi</forename><forename type="middle">H</forename><surname>Feldman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hal</forename><surname>Daumé</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Iii</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b561">
	<analytic>
		<title level="a" type="main">Do people use language production to make predictions during comprehension?</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Martin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Simon</forename><surname>Pickering</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Garrod</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Trends in cognitive sciences</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="105" to="110" />
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b562">
	<analytic>
		<title level="a" type="main">An integrated theory of language production and comprehension</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Martin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Simon</forename><surname>Pickering</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Garrod</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Behavioral and Brain Sciences</title>
		<imprint>
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="issue">04</biblScope>
			<biblScope unit="page" from="329" to="347" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b563">
	<monogr>
		<title level="m" type="main">Embedded implicatures as pragmatic inferences under compositional lexical uncertainty</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><surname>Potts</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Lassiter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Roger</forename><surname>Levy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><forename type="middle">C</forename><surname>Frank</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
	<note>Manuscript</note>
</biblStruct>

<biblStruct xml:id="b564">
	<analytic>
		<title level="a" type="main">The penn discourse treebank 2.0</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rashmi</forename><surname>Prasad</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nikhit</forename><surname>Dinesh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alan</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eleni</forename><surname>Miltsakaki</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Livio</forename><surname>Robaldo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aravind</forename><surname>Joshi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bonnie</forename><surname>Webber</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Language Resource and Evaluation Conference</title>
		<meeting>the Language Resource and Evaluation Conference</meeting>
		<imprint>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b565">
	<analytic>
		<title level="a" type="main">A mathematical theory of communication</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">E</forename><surname>Shannon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The Bell System Technical Journal</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="page" from="623" to="656" />
			<date type="published" when="1948" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b566">
	<monogr>
		<title level="m" type="main">The semantics and pragmatics of functional coherence in discourse. Speech act theory: Ten years later</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Teun A Van Dijk</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1980" />
			<biblScope unit="page" from="49" to="66" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b567">
	<monogr>
		<title level="m" type="main">A refined end-toend discourse parser</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianxiang</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Man</forename><surname>Lan</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page">17</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b568">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nianwen</forename><surname>Xue</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sameer</forename><surname>Hwee Tou Ng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rashmi Prasado Christopher</forename><surname>Pradhan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Bryant</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Rutherford</surname></persName>
		</author>
		<title level="m">The conll-2015 shared task on shallow discourse parsing. CoNLL</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page">1</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b569">
	<monogr>
		<title level="m" type="main">Bayesian interpretation and optimality theory. Bidirectional Optimality Theory. Palgrave Macmillan</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Henk</forename><surname>Zeevat</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="page" from="191" to="220" />
			<pubPlace>Amsterdam</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b570">
	<analytic>
		<title level="a" type="main">Perspectives on bayesian natural language semantics and pragmatics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Henk</forename><surname>Zeevat</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Bayesian Natural Language Semantics and Pragmatics</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2015" />
			<biblScope unit="page" from="1" to="24" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b571">
	<analytic>
		<title level="a" type="main">Clustering on the unit hypersphere using von mises-fisher distributions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Arindam</forename><surname>Banerjee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Inderjit</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joydeep</forename><surname>Dhillon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Suvrit</forename><surname>Ghosh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Sra</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Journal of Machine Learning Research</title>
		<imprint>
			<date type="published" when="2005" />
			<biblScope unit="page" from="1345" to="1382" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b572">
	<analytic>
		<title level="a" type="main">Dynamic topic models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>David</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John D</forename><surname>Blei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Lafferty</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 23rd international conference on Machine learning</title>
		<meeting>the 23rd international conference on Machine learning</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2006" />
			<biblScope unit="page" from="113" to="120" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b573">
	<analytic>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>David</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Blei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Andrew</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael I Jordan</forename><surname>Ng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Latent dirichlet allocation. the Journal of machine Learning research</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="993" to="1022" />
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b574">
	<analytic>
		<title level="a" type="main">Probabilistic topic models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>David</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Blei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Communications of the ACM</title>
		<imprint>
			<biblScope unit="volume">55</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="77" to="84" />
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b575">
	<analytic>
		<title level="a" type="main">Truly nonparametric online variational inference for hierarchical dirichlet processes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Bryant</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Erik</forename><forename type="middle">B</forename><surname>Sudderth</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="page" from="2699" to="2707" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b576">
	<analytic>
		<title level="a" type="main">Gaussian LDA for topic models with word embeddings</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rajarshi</forename><surname>Das</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Manzil</forename><surname>Zaheer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Dyer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 53nd Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 53nd Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b577">
	<monogr>
		<title level="m" type="main">Modeling data using directional distributions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Inderjit</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Suvrit</forename><surname>Dhillon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Sra</surname></persName>
		</author>
		<idno>TR-03-06</idno>
		<ptr target="ftp://ftp.cs.utexas.edu/pub/techreports/tr03-06.ps.gz" />
		<imprint>
			<date type="published" when="2003" />
		</imprint>
		<respStmt>
			<orgName>Department of Computer Sciences, The University of Texas at Austin</orgName>
		</respStmt>
	</monogr>
<note type="report_type">Technical Report</note>
</biblStruct>

<biblStruct xml:id="b578">
	<monogr>
		<title level="m" type="main">Von misesfisher clustering models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Siddarth</forename><surname>Gopal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yiming</forename><surname>Yang</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b579">
	<analytic>
		<title level="a" type="main">Dynamic joint sentiment-topic model</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yulan</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chenghua</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kam-Fai</forename><surname>Wong</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Transactions on Intelligent Systems and Technology (TIST)</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page">6</biblScope>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b580">
	<analytic>
		<title level="a" type="main">Stochastic variational inference</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Matthew</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Hoffman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>David</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chong</forename><surname>Blei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Paisley</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1303" to="1347" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b581">
	<analytic>
		<title level="a" type="main">Stochastic variational inference for bayesian time series models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthew</forename><surname>Johnson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alan</forename><surname>Willsky</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 31st International Conference on Machine Learning (ICML-14)</title>
		<meeting>the 31st International Conference on Machine Learning (ICML-14)</meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="1854" to="1862" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b582">
	<analytic>
		<title level="a" type="main">Machine reading tea leaves: Automatically evaluating topic coherence and topic model quality</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Jey Han Lau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Timothy</forename><surname>Newman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Baldwin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EACL</title>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="530" to="539" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b583">
	<analytic>
		<title level="a" type="main">Improving distributional similarity with lessons learned from word embeddings</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Omer</forename><surname>Levy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoav</forename><surname>Goldberg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ido</forename><surname>Dagan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Transactions of the Association for Computational Linguistics</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="211" to="225" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b584">
	<analytic>
		<title level="a" type="main">Distributed representations of words and phrases and their compositionality</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tomas</forename><surname>Mikolov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ilya</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kai</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Greg</forename><forename type="middle">S</forename><surname>Corrado</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeff</forename><surname>Dean</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="3111" to="3119" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b585">
	<analytic>
		<title level="a" type="main">Automatic evaluation of topic coherence</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Newman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jey</forename><forename type="middle">Han</forename><surname>Lau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Karl</forename><surname>Grieser</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Timothy</forename><surname>Baldwin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Human Language Technologies: The 2010 Annual Conference of the North American Chapter of the Association for Computational Linguistics</title>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="page" from="100" to="108" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b586">
	<analytic>
		<title level="a" type="main">Nested hierarchical dirichlet processes. Pattern Analysis and Machine Intelligence</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Paisley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chingyue</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>David</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael I Jordan</forename><surname>Blei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on</title>
		<imprint>
			<biblScope unit="volume">37</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="256" to="270" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b587">
	<analytic>
		<title level="a" type="main">Glove: Global vectors for word representation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeffrey</forename><surname>Pennington</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Socher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><forename type="middle">D</forename><surname>Manning</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Empirical Methods in Natural Language Processing (EMNLP)</title>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="1532" to="1543" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b588">
	<analytic>
		<title level="a" type="main">Spherical topic models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joseph</forename><surname>Reisinger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Austin</forename><surname>Waters</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bryan</forename><surname>Silverthorn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Raymond J</forename><surname>Mooney</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 27th International Conference on Machine Learning (ICML-10)</title>
		<meeting>the 27th International Conference on Machine Learning (ICML-10)</meeting>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="page" from="903" to="910" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b589">
	<analytic>
		<title level="a" type="main">The author-topic model for authors and documents</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michal</forename><surname>Rosen-Zvi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas</forename><surname>Griffiths</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mark</forename><surname>Steyvers</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Padhraic</forename><surname>Smyth</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 20th conference on Uncertainty in artificial intelligence</title>
		<meeting>the 20th conference on Uncertainty in artificial intelligence</meeting>
		<imprint>
			<publisher>AUAI Press</publisher>
			<date type="published" when="2004" />
			<biblScope unit="page" from="487" to="494" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b590">
	<analytic>
		<title level="a" type="main">Hierarchical dirichlet processes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yee Whye</forename><surname>Teh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><forename type="middle">I</forename><surname>Jordan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Matthew</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><forename type="middle">M</forename><surname>Beal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Blei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of the American Statistical Association</title>
		<imprint>
			<biblScope unit="volume">101</biblScope>
			<biblScope unit="page" from="1566" to="1581" />
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b591">
	<analytic>
		<title level="a" type="main">Latent Dirichlet Allocation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">M</forename><surname>References</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">Y</forename><surname>Blei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">I</forename><surname>Ng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Jordan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="993" to="1022" />
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b592">
	<analytic>
		<title level="a" type="main">Topic modeling and digital humanities</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Blei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Digital Humanities</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="8" to="11" />
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b593">
	<analytic>
		<title level="a" type="main">Normalized (pointwise) mutual information in collocation extraction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gerlof</forename><surname>Bouma</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of GSCL</title>
		<meeting>GSCL</meeting>
		<imprint>
			<date type="published" when="2009" />
			<biblScope unit="page" from="31" to="40" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b594">
	<analytic>
		<title level="a" type="main">Reading tea leaves: How humans interpret topic models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathan</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jordan</forename><forename type="middle">L</forename><surname>Boyd-Graber</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sean</forename><surname>Gerrish</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chong</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><forename type="middle">M</forename><surname>Blei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS</title>
		<imprint>
			<date type="published" when="2009" />
			<biblScope unit="page" from="288" to="296" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b595">
	<monogr>
		<title level="m" type="main">Elements of Information Theory</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">M</forename><surname>Cover</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">A</forename><surname>Thomas</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2006" />
			<publisher>Wiley InterScience</publisher>
			<pubPlace>Hoboken, New Jersey</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b596">
	<monogr>
		<title level="m" type="main">Text as data: The promise and pitfalls of automatic content analysis methods for political texts</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Justin</forename><surname>Grimmer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Brandon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Stewart</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
	<note>Political Analysis</note>
</biblStruct>

<biblStruct xml:id="b597">
	<analytic>
		<title level="a" type="main">Discovering geographical topics in the twitter stream</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Liangjie</forename><surname>Hong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Amr</forename><surname>Ahmed</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Siva</forename><surname>Gurumurthy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander</forename><forename type="middle">J</forename><surname>Smola</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kostas</forename><surname>Tsioutsiouliklis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 21st international conference on World Wide Web, WWW &apos;12</title>
		<meeting>the 21st international conference on World Wide Web, WWW &apos;12<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2012" />
			<biblScope unit="page" from="769" to="778" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b598">
	<monogr>
		<title level="m" type="main">Semantic similarity based on corpus statistics and lexical taxonomy</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Jay</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><forename type="middle">W</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Conrath</surname></persName>
		</author>
		<idno>cmp-lg/9709008</idno>
		<imprint>
			<date type="published" when="1997" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b599">
	<analytic>
		<title level="a" type="main">Beyond &quot;local&quot;, &quot;categories&quot; and &quot;friends&quot;: clustering foursquare users with latent &quot;topics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kenneth</forename><surname>Joseph</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chun</forename><forename type="middle">How</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kathleen</forename><forename type="middle">M</forename><surname>Carley</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2012 ACM Conference on Ubiquitous Computing, UbiComp &apos;12</title>
		<meeting>the 2012 ACM Conference on Ubiquitous Computing, UbiComp &apos;12<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2012" />
			<biblScope unit="page" from="919" to="926" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b600">
	<analytic>
		<title level="a" type="main">Applications of Topics Models to Analysis of DisasterRelated Twitter Data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Kireyev</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Palen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Anderson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS Workshop on Applications for Topic Models: Text and Beyond</title>
		<imprint>
			<date type="published" when="2009" />
			<biblScope unit="page">1</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b601">
	<analytic>
		<title level="a" type="main">Whom Should I Follow?: Identifying Relevant Users During Crises</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shamanth</forename><surname>Kumar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fred</forename><surname>Morstatter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Reza</forename><surname>Zafarani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Huan</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 24th ACM Conference on Hypertext and Social Media, HT &apos;13</title>
		<meeting>the 24th ACM Conference on Hypertext and Social Media, HT &apos;13<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2013" />
			<biblScope unit="page" from="139" to="147" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b602">
	<analytic>
		<title level="a" type="main">Machine reading tea leaves: Automatically evaluating topic coherence and topic model quality</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Jey Han Lau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Timothy</forename><surname>Newman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Baldwin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the European Chapter of the Association for Computational Linguistics</title>
		<meeting>the European Chapter of the Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b603">
	<analytic>
		<title level="a" type="main">Exploratory analysis of highly heterogeneous document collections</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Arun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><forename type="middle">P</forename><surname>Maiya</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Francisco</forename><surname>Thompson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Robert M</forename><surname>Loaizalemos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Rolfe</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 19th ACM SIGKDD international conference on Knowledge discovery and data mining</title>
		<meeting>the 19th ACM SIGKDD international conference on Knowledge discovery and data mining</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2013" />
			<biblScope unit="page" from="1375" to="1383" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b604">
	<monogr>
		<title level="m" type="main">Mallet: A machine learning for language toolkit</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Mccallum</surname></persName>
		</author>
		<ptr target="http://mallet.cs.umass.edu" />
		<imprint>
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b605">
	<analytic>
		<title level="a" type="main">Optimizing semantic coherence in topic models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Mimno</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hanna</forename><forename type="middle">M</forename><surname>Wallach</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Edmund</forename><surname>Talley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Miriam</forename><surname>Leenders</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Mccallum</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Conference on Empirical Methods in Natural Language Processing, EMNLP &apos;11</title>
		<meeting>the Conference on Empirical Methods in Natural Language Processing, EMNLP &apos;11<address><addrLine>Stroudsburg, PA, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2011" />
			<biblScope unit="page" from="262" to="272" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b606">
	<analytic>
		<title level="a" type="main">Is the Sample Good Enough? Comparing Data from Twitters Streaming API with Twitters Firehose</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fred</forename><surname>Morstatter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jürgen</forename><surname>Pfeffer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Huan</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kathleen</forename><forename type="middle">M</forename><surname>Carley</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ICWSM</title>
		<meeting>ICWSM</meeting>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b607">
	<analytic>
		<title level="a" type="main">Tweetmotif: Exploratory search and topic summarization for twitter</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O&amp;apos;</forename><surname>Brendan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michel</forename><surname>Connor</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Krieger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Ahn</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICWSM</title>
		<imprint>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b608">
	<analytic>
		<title level="a" type="main">Space-time dynamics of topics in streaming text</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexei</forename><surname>Pozdnoukhov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christian</forename><surname>Kaiser</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the 3rd ACM SIGSPATIAL Int&apos;l Workshop on Location-Based Social Networks, LBSN &apos;11</title>
		<meeting>of the 3rd ACM SIGSPATIAL Int&apos;l Workshop on Location-Based Social Networks, LBSN &apos;11<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2011" />
			<biblScope unit="page" from="1" to="8" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b609">
	<analytic>
		<title level="a" type="main">Topic modeling for the social sciences</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Ramage</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Evan</forename><surname>Rosen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jason</forename><surname>Chuang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Christopher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel A</forename><surname>Manning</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Mcfarland</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS 2009 Workshop on Applications for Topic Models: Text and Beyond</title>
		<imprint>
			<date type="published" when="2009" />
			<biblScope unit="volume">5</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b610">
	<analytic>
		<title level="a" type="main">Words alone: Dismantling topic models in the humanities</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Benjamin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Schmidt</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Digital Humanities</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="49" to="65" />
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b611">
	<monogr>
		<title level="m" type="main">The proof and measurement of association between two things. The American journal of psychology</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Charles</forename><surname>Spearman</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1904" />
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="page" from="72" to="101" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b612">
	<analytic>
		<title level="a" type="main">Evaluation methods for topic models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Iain</forename><surname>Hanna M Wallach</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ruslan</forename><surname>Murray</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Salakhutdinov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Mimno</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML</title>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2009" />
			<biblScope unit="page" from="1105" to="1112" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b613">
	<analytic>
		<title level="a" type="main">Topic modeling on historical newspapers</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">-I</forename><surname>Tze</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><forename type="middle">J</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rada</forename><surname>Torget</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Mihalcea</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 5th ACL-HLT Workshop on Language Technology for Cultural Heritage, Social Sciences, and Humanities</title>
		<meeting>the 5th ACL-HLT Workshop on Language Technology for Cultural Heritage, Social Sciences, and Humanities</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2011" />
			<biblScope unit="page" from="96" to="104" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b614">
	<analytic>
		<title level="a" type="main">Geographical topic discovery and comparison</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhijun</forename><surname>Yin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Liangliang</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiawei</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chengxiang</forename><surname>Zhai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas</forename><surname>Huang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 20th international conference on World wide web, WWW &apos;11</title>
		<meeting>the 20th international conference on World wide web, WWW &apos;11<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2011" />
			<biblScope unit="page" from="247" to="256" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b615">
	<analytic>
		<title level="a" type="main">Automated essay scoring with e-rater R v. 2. The Journal of Technology</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yigal</forename><surname>Attali</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jill</forename><surname>Burstein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Learning and Assessment</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="issue">3</biblScope>
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b616">
	<analytic>
		<title level="a" type="main">Toefl11: A corpus of non-native english</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Blanchard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joel</forename><surname>Tetreault</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Derrick</forename><surname>Higgins</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aoife</forename><surname>Cahill</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Martin</forename><surname>Chodorow</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ETS Research Report Series</title>
		<imprint>
			<biblScope unit="volume">2013</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page">15</biblScope>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b617">
	<monogr>
		<title level="m" type="main">The e-rater R scoring engine: Automated essay scoring with natural language processing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jill</forename><surname>Burstein</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b618">
	<analytic>
		<title level="a" type="main">LIB-SVM: A library for support vector machines</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chih-Chung</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chih-Jen</forename><surname>Lin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Transactions on Intelligent Systems and Technology</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">27</biblScope>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b619">
	<analytic>
		<title level="a" type="main">Beyond essay length: Evaluating e-rater R &apos;s performance on toefl R essays</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Martin</forename><surname>Chodorow</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jill</forename><surname>Burstein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ETS Research Report Series</title>
		<imprint>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page">38</biblScope>
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b620">
	<analytic>
		<title level="a" type="main">Scoring persuasive essays using opinions and their targets</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Noura</forename><surname>Farra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Swapna</forename><surname>Somasundaran</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jill</forename><surname>Burstein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Tenth Workshop on Innovative Use of NLP for Building Educational Applications</title>
		<meeting>the Tenth Workshop on Innovative Use of NLP for Building Educational Applications<address><addrLine>Denver, Colorado</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2015-06" />
			<biblScope unit="page" from="64" to="74" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b621">
	<analytic>
		<title level="a" type="main">The weka data mining software: an update</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mark</forename><surname>Hall</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eibe</forename><surname>Frank</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geoffrey</forename><surname>Holmes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bernhard</forename><surname>Pfahringer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peter</forename><surname>Reutemann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ian</forename><forename type="middle">H</forename><surname>Witten</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM SIGKDD explorations newsletter</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="10" to="18" />
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b622">
	<monogr>
		<title level="m" type="main">Ontology-based argument mining and automatic essay scoring</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nathan</forename><surname>Ong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Diane</forename><surname>Litman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexandra</forename><surname>Brusilovsky</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page">24</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b623">
	<analytic>
		<title level="a" type="main">Modeling thesis clarity in student essays</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Isaac</forename><surname>Persing</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vincent</forename><surname>Ng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 51st Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<publisher>Long Papers</publisher>
			<date type="published" when="2013" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="260" to="269" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b624">
	<analytic>
		<title level="a" type="main">Modeling argument strength in student essays</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Isaac</forename><surname>Persing</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vincent</forename><surname>Ng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing</title>
		<meeting>the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing</meeting>
		<imprint>
			<publisher>Long Papers</publisher>
			<date type="published" when="2015" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="543" to="552" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b625">
	<monogr>
		<title level="m" type="main">The penn discourse treebank 2.0</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rashmi</forename><surname>Prasad</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nikhil</forename><surname>Dinesh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alan</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eleni</forename><surname>Miltsakaki</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Livio</forename><surname>Robaldo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Aravind</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bonnie</forename><forename type="middle">L</forename><surname>Joshi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Webber</surname></persName>
		</author>
		<editor>LREC. Citeseer</editor>
		<imprint>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b626">
	<analytic>
		<title level="a" type="main">Applying argumentation schemes for essay scoring</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yi</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Heilman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Beata</forename><forename type="middle">Beigman</forename><surname>Klebanov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Paul</forename><surname>Deane</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the First Workshop on Argumentation Mining</title>
		<meeting>the First Workshop on Argumentation Mining</meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="69" to="78" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b627">
	<analytic>
		<title level="a" type="main">Annotating argument components and relations in persuasive essays</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christian</forename><surname>Stab</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Iryna</forename><surname>Gurevych</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 25th International Conference on Computational Linguistics (COLING 2014)</title>
		<meeting>the 25th International Conference on Computational Linguistics (COLING 2014)</meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="1501" to="1510" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b628">
	<analytic>
		<title level="a" type="main">Identifying argumentative discourse structures in persuasive essays</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christian</forename><surname>Stab</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Iryna</forename><surname>Gurevych</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Conference on Empirical Methods in Natural Language Processing</title>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2014-10" />
		</imprint>
	</monogr>
	<note>p.(to appear</note>
</biblStruct>

<biblStruct xml:id="b629">
	<monogr>
		<title level="m" type="main">Parsing argumentation structure in persuasive essays</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christian</forename><surname>Stab</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Iryna</forename><surname>Gurevych</surname></persName>
		</author>
		<idno>arxiv.org/abs/1604.07370</idno>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b630">
	<monogr>
		<title level="m" type="main">Annotating expressions of opinions and emotions in language. Language resources and evaluation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Janyce</forename><surname>Wiebe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Theresa</forename><surname>Wilson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Claire</forename><surname>Cardie</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2005" />
			<biblScope unit="volume">39</biblScope>
			<biblScope unit="page" from="165" to="210" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b631">
	<analytic>
		<title level="a" type="main">Semi-supervised learning of morphological paradigms and lexicons</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>References Malin Ahlberg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Markus Forsberg, and Mans Hulden</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
	<note>Proc. of EACL</note>
</biblStruct>

<biblStruct xml:id="b632">
	<analytic>
		<title level="a" type="main">Paradigm classification in supervised learning of morphology</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Malin</forename><surname>Ahlberg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Markus Forsberg, and Mans Hulden</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
	<note>Proc. of NAACL</note>
</biblStruct>

<biblStruct xml:id="b633">
	<monogr>
		<title level="m" type="main">Neural machine translation by jointly learning to align and translate</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dzmitry</forename><surname>Bahdanau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kyunghyun</forename><surname>Cho</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1409.0473</idno>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b634">
	<monogr>
		<title level="m" type="main">On the properties of neural machine translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kyunghyun</forename><surname>Cho</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dzmitry</forename><surname>Bart Van Merriënboer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Bahdanau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Bengio</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1409.1259</idno>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
<note type="report_type">Encoder-decoder approaches. arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b635">
	<monogr>
		<title level="m" type="main">Towards a machinelearning architecture for lexical functional grammar parsing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Grzegorz</forename><surname>Chrupała</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2008" />
		</imprint>
		<respStmt>
			<orgName>Dublin City University</orgName>
		</respStmt>
	</monogr>
<note type="report_type">Ph.D. thesis</note>
</biblStruct>

<biblStruct xml:id="b636">
	<analytic>
		<title level="a" type="main">Jason Eisner, and Mans Hulden. 2016. The SIGMORPHON 2016 shared taskmorphological reinflection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ryan</forename><surname>Cotterell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christo</forename><surname>Kirov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Sylak-Glassman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Yarowsky</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the 2016 Meeting of SIGMORPHON</title>
		<meeting>of the 2016 Meeting of SIGMORPHON</meeting>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b637">
	<analytic>
		<title level="a" type="main">Morphemes as necessary concept for structures discovery from untagged corpora</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Hervé Déjean</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the Joint Conferences on New Methods in Language Processing and CoNLL</title>
		<meeting>of the Joint Conferences on New Methods in Language essing and CoNLL</meeting>
		<imprint>
			<date type="published" when="1998" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b638">
	<analytic>
		<title level="a" type="main">Latent-variable modeling of string transductions with finite-state methods</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Markus</forename><surname>Dreyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jason</forename><forename type="middle">R</forename><surname>Smith</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jason</forename><surname>Eisner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of EMNLP</title>
		<meeting>of EMNLP</meeting>
		<imprint>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b639">
	<monogr>
		<title level="m" type="main">A non-parametric model for the discovery of inflectional paradigms from plain text using graphical models over strings</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Markus</forename><surname>Dreyer</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2011" />
			<pubPlace>Baltimore, MD</pubPlace>
		</imprint>
		<respStmt>
			<orgName>Johns Hopkins University</orgName>
		</respStmt>
	</monogr>
<note type="report_type">Ph.D. thesis</note>
</biblStruct>

<biblStruct xml:id="b640">
	<analytic>
		<title level="a" type="main">Supervised learning of complete morphological paradigms</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Greg</forename><surname>Durrett</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Denero</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of HLT-NAACL</title>
		<meeting>of HLT-NAACL</meeting>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b641">
	<analytic>
		<title level="a" type="main">Automatic extraction of morphological lexicons from morphologically annotated corpora</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ramy</forename><surname>Eskander</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nizar</forename><surname>Habash</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Owen</forename><surname>Rambow</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of EMNLP</title>
		<meeting>of EMNLP</meeting>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b642">
	<monogr>
		<title level="m" type="main">Morphological inflection generation using character sequence to sequence learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Manaal</forename><surname>Faruqui</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yulia</forename><surname>Tsvetkov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Graham</forename><surname>Neubig</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Dyer</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1512.06110</idno>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b643">
	<analytic>
		<title level="a" type="main">Maxout networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ian</forename><surname>Goodfellow</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Warde-Farley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mehdi</forename><surname>Mirza</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aaron</forename><surname>Courville</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of ICML</title>
		<meeting>of ICML</meeting>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b644">
	<analytic>
		<title level="a" type="main">Framewise phoneme classification with bidirectional lstm and other neural network architectures</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex</forename><surname>Graves</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jürgen</forename><surname>Schmidhuber</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural Networks</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="602" to="610" />
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b645">
	<analytic>
		<title level="a" type="main">Speech recognition with deep recurrent neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alan</forename><surname>Graves</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mohamed</forename><surname>Abdel-Rahman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geoffrey</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">In Proc of. ICASSP</title>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b646">
	<monogr>
		<title level="m" type="main">Algorithms on strings, trees and sequences: computer science and computational biology</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Gusfield</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1997" />
			<publisher>Cambridge university press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b647">
	<monogr>
		<title level="m" type="main">Word segmentation by letter successor varieties. Information storage and retrieval</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Margaret</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Hafer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Stephen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Weiss</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1974" />
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="page" from="371" to="385" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b648">
	<analytic>
		<title level="a" type="main">From phoneme to morpheme</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Zellig</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Harris</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Language</title>
		<imprint>
			<biblScope unit="volume">31</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="190" to="222" />
			<date type="published" when="1955" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b649">
	<analytic>
		<title level="a" type="main">MED: The LMU system for the SIGMORPHON 2016 shared task on morphological reinflection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Katharina</forename><surname>Kann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hinrich</forename><surname>Schütze</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the 2016 Meeting of SIGMORPHON</title>
		<meeting>of the 2016 Meeting of SIGMORPHON</meeting>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b650">
	<monogr>
		<title level="m" type="main">A simple way to initialize recurrent networks of rectified linear units</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Navdeep</forename><surname>Quoc V Le</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geoffrey</forename><forename type="middle">E</forename><surname>Jaitly</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Hinton</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1504.00941</idno>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b651">
	<analytic>
		<title level="a" type="main">Joint lemmatization and morphological tagging with lemming</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas</forename><surname>Müller</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ryan</forename><surname>Cotterell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander</forename><surname>Fraser</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of EMNLP</title>
		<meeting>of EMNLP</meeting>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b652">
	<analytic>
		<title level="a" type="main">Inflection generation as discriminative string transduction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Garrett</forename><surname>Nicolai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Colin</forename><surname>Cherry</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Grzegorz</forename><surname>Kondrak</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of NAACL</title>
		<meeting>of NAACL</meeting>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b653">
	<analytic>
		<title level="a" type="main">How to construct deep recurrent neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Razvan</forename><surname>Pascanu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Caglar</forename><surname>Gulcehre</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kyunghyun</forename><surname>Cho</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of ICLR</title>
		<meeting>of ICLR</meeting>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b654">
	<analytic>
		<title level="a" type="main">Sequence to sequence learning with neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ilya</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oriol</forename><surname>Vinyals</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Quoc V</forename><surname>Le</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of NIPS</title>
		<meeting>of NIPS</meeting>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b655">
	<analytic>
		<title level="a" type="main">Grammar as a foreign language</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oriol</forename><surname>Vinyals</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Łukasz</forename><surname>Kaiser</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Terry</forename><surname>Koo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Slav</forename><surname>Petrov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ilya</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geoffrey</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of NIPS</title>
		<meeting>of NIPS</meeting>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b656">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Matthew</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Zeiler</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1212.5701</idno>
		<title level="m">Adadelta: an adaptive learning rate method</title>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b657">
	<analytic>
		<title level="a" type="main">If All You Have is a Bit of the Bible: Learning POS Taggers for Truly Low-Resource Languages</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dirk</forename><surname>Referenceš Zeljko Agić</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anders</forename><surname>Hovy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Søgaard</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b658">
	<monogr>
		<title level="m" type="main">Multilingual Projection for Parsing Truly Low-Resource Languages</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zeljko</forename><surname>Agić</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anders</forename><surname>Johannsen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Barbara</forename><surname>Plank</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Natalie</forename><surname>Héctor Martínez Alonso</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anders</forename><surname>Schluter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Søgaard</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page">4</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b659">
	<analytic>
		<title level="a" type="main">TnT -A Statistical Part-ofSpeech Tagger</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thorsten</forename><surname>Brants</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ANLP</title>
		<imprint>
			<date type="published" when="2000" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b660">
	<monogr>
		<title level="m" type="main">A Massively Parallel Corpus: The Bible in 100 Languages. Language Resources and Evaluation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christos</forename><surname>Christodouloupoulos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mark</forename><surname>Steedman</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="volume">49</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b661">
	<analytic>
		<title level="a" type="main">Unsupervised Part-of-Speech Tagging with Bilingual Graph-Based Projections</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dipanjan</forename><surname>Das</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Slav</forename><surname>Petrov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL</title>
		<imprint>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b662">
	<analytic>
		<title level="a" type="main">Bootstrapping Parsers via Syntactic Projection Across Parallel Texts</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rebecca</forename><surname>Hwa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philip</forename><surname>Resnik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Amy</forename><surname>Weinberg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Clara</forename><surname>Cabezas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Okan</forename><surname>Kolak</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Natural Language Engineering</title>
		<imprint>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page">11</biblScope>
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b663">
	<analytic>
		<title level="a" type="main">Europarl: A Parallel Corpus for Statistical Machine Translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philipp</forename><surname>Koehn</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">MT Summit</title>
		<imprint>
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b664">
	<analytic>
		<title level="a" type="main">Unsupervised Dependency Parsing with Transferring Distribution via Parallel Guidance and Entropy Regularization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xuezhe</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fei</forename><surname>Xia</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b665">
	<analytic>
		<title level="a" type="main">Turning on the Turbo: Fast ThirdOrder Non-Projective Turbo Parsers</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><forename type="middle">T</forename><surname>André</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Miguel</forename><surname>Martins</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Noah</forename><forename type="middle">A</forename><surname>Almeida</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Smith</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL</title>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b666">
	<monogr>
		<title level="m" type="main">The Geometry of Constrained Structured Prediction: Applications to Inference and Learning of Natural Language Syntax</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><forename type="middle">T</forename><surname>André</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Martins</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
		<respStmt>
			<orgName>Carnegie Mellon University and Instituto Superior Tecnico</orgName>
		</respStmt>
	</monogr>
<note type="report_type">Ph.D. thesis</note>
</biblStruct>

<biblStruct xml:id="b667">
	<analytic>
		<title level="a" type="main">Multi-Source Transfer of Delexicalized Dependency Parsers</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ryan</forename><surname>Mcdonald</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Slav</forename><surname>Petrov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Keith</forename><surname>Hall</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EMNLP</title>
		<imprint>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b668">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ryan</forename><surname>Mcdonald</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joakim</forename><surname>Nivre</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yvonne</forename><surname>Quirmbachbrundage</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoav</forename><surname>Goldberg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dipanjan</forename><surname>Das</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kuzman</forename><surname>Ganchev</surname></persName>
		</author>
		<title level="m">Claudia Bedini, Núria Bertomeu Castelló, and Jungmee Lee</title>
		<meeting><address><addrLine>Keith Hall, Slav Petrov, Hao Zhang, Oscar Täckström</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b669">
	<analytic>
		<title level="a" type="main">Universal Dependency Annotation for Multilingual Parsing</title>
	</analytic>
	<monogr>
		<title level="m">ACL</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b670">
	<analytic>
		<title level="a" type="main">Word Order Typology through Multilingual Word Alignment</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Robertöstling</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b671">
	<analytic>
		<title level="a" type="main">Density-Driven Cross-Lingual Transfer of Dependency Parsers</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mohammad</forename><surname>Sadegh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rasooli</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Collins</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EMNLP</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b672">
	<analytic>
		<title level="a" type="main">Parser Combination by Reparsing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kenji</forename><surname>Sagae</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alon</forename><surname>Lavie</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NAACL</title>
		<imprint>
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b673">
	<analytic>
		<title level="a" type="main">Data Point Selection for CrossLanguage Adaptation of Dependency Parsers</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anders</forename><surname>Søgaard</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL</title>
		<imprint>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b674">
	<analytic>
		<title level="a" type="main">Synthetic Treebanking for Cross-Lingual Dependency Parsing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jörg</forename><surname>Tiedemann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Agić</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Artificial Intelligence Research</title>
		<imprint>
			<biblScope unit="page">55</biblScope>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b675">
	<analytic>
		<title level="a" type="main">Rediscovering Annotation Projection for Cross-Lingual Parser Induction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jörg</forename><surname>Tiedemann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">COLING</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b676">
	<analytic>
		<title level="a" type="main">Inducing Multilingual Text Analysis Tools via Robust Projection Across Aligned Corpora</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Yarowsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Grace</forename><surname>Ngai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Wicentowski</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NAACL</title>
		<imprint>
			<date type="published" when="2001" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b677">
	<analytic>
		<title level="a" type="main">CrossLanguage Parser Adaptation between Related Languages</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Zeman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philip</forename><surname>Resnik</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IJCNLP Workshop on NLP for Less Privileged Languages</title>
		<imprint>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b678">
	<analytic>
		<title level="a" type="main">Gated recursive neural network for chinese word segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xipeng</forename><surname>References Xinchi Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chenxi</forename><surname>Qiu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xuanjing</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Huang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The Association for Computer Linguistics</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="1744" to="1753" />
		</imprint>
	</monogr>
	<note>ACL (1)</note>
</biblStruct>

<biblStruct xml:id="b679">
	<analytic>
		<title level="a" type="main">Synthetic word parsing improves chinese word segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fei</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kevin</forename><surname>Duh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuji</forename><surname>Matsumoto</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing</title>
		<meeting>the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing<address><addrLine>Beijing, China</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2015-07" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="262" to="267" />
		</imprint>
	</monogr>
	<note>Short Papers)</note>
</biblStruct>

<biblStruct xml:id="b680">
	<analytic>
		<title level="a" type="main">Natural language processing (almost) from scratch</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ronan</forename><surname>Collobert</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jason</forename><surname>Weston</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Léon</forename><surname>Bottou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Karlen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Koray</forename><surname>Kavukcuoglu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pavel</forename><surname>Kuksa</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Mach. Learn. Res</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="page" from="2493" to="2537" />
			<date type="published" when="2011-11" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b681">
	<analytic>
		<title level="a" type="main">The second international chinese word segmentation bakeoff</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas</forename><forename type="middle">Emerson</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Fourth SIGHAN Workshop on Chinese Language Processing</title>
		<meeting>the Fourth SIGHAN Workshop on Chinese Language Processing</meeting>
		<imprint>
			<date type="published" when="2005" />
			<biblScope unit="page" from="123" to="133" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b682">
	<monogr>
		<title level="m" type="main">Lecture 6.5: rmsprop: divide the gradient by a running average of its recent magnitude. coursera: Neural networks for machine learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Hinton</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b683">
	<analytic>
		<title level="a" type="main">Conditional random fields: Probabilistic models for segmenting and labeling sequence data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><forename type="middle">D</forename><surname>Lafferty</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Mccallum</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fernando</forename><forename type="middle">C N</forename><surname>Pereira</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Eighteenth International Conference on Machine Learning, number 8 in ICML &apos;01</title>
		<meeting>the Eighteenth International Conference on Machine Learning, number 8 in ICML &apos;01<address><addrLine>San Francisco, CA, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Morgan Kaufmann Publishers Inc</publisher>
			<date type="published" when="2001" />
			<biblScope unit="page" from="282" to="289" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b684">
	<analytic>
		<title level="a" type="main">Accurate linear-time chinese word segmentation via embedding matching</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianqiang</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Erhard</forename><surname>Hinrichs</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing</title>
		<meeting>the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing<address><addrLine>Beijing, China</addrLine></address></meeting>
		<imprint>
			<publisher>Long Papers</publisher>
			<date type="published" when="2015-07" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="1733" to="1743" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b685">
	<analytic>
		<title level="a" type="main">Maxmargin tensor neural network for chinese word segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wenzhe</forename><surname>Pei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tao</forename><surname>Ge</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Baobao</forename><surname>Chang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 52nd Annual Meeting of the Association for Computational Linguistics<address><addrLine>Maryland</addrLine></address></meeting>
		<imprint>
			<publisher>Long Papers</publisher>
			<date type="published" when="2014-06" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="293" to="303" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b686">
	<analytic>
		<title level="a" type="main">A direct adaptive method for faster backpropagation learning: The rprop algorithm</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Martin</forename><surname>Riedmiller</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Heinrich</forename><surname>Braun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE INTERNA-TIONAL CONFERENCE ON NEURAL NETWORK-S</title>
		<imprint>
			<date type="published" when="1993" />
			<biblScope unit="page" from="586" to="591" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b687">
	<analytic>
		<title level="a" type="main">Enhancing chinese word segmentation using unlabeled data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Weiwei</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jia</forename><surname>Xu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Conference on Empirical Methods in Natural Language Processing</title>
		<meeting><address><addrLine>Edinburgh, Uk</addrLine></address></meeting>
		<imprint>
			<publisher>John Mcintyre Conference Centre</publisher>
			<date type="published" when="2011-07" />
			<biblScope unit="volume">2011</biblScope>
			<biblScope unit="page" from="970" to="979" />
		</imprint>
	</monogr>
	<note>A Meeting of Sigdat, A Special Interest Group of the ACL</note>
</biblStruct>

<biblStruct xml:id="b688">
	<analytic>
		<title level="a" type="main">A discriminative latent variable chinese segmenter with hybrid word/character information</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xu</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yaozhong</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Takuya</forename><surname>Matsuzaki</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshimasa</forename><surname>Tsuruoka</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jun&amp;apos;ichi</forename><surname>Tsujii</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of Human Language Technologies: The 2009 Annual Conference of the North American Chapter of the Association for Computational Linguistics</title>
		<meeting>Human Language Technologies: The 2009 Annual Conference of the North American Chapter of the Association for Computational Linguistics<address><addrLine>Boulder, Colorado</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2009-06" />
			<biblScope unit="page" from="56" to="64" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b689">
	<analytic>
		<title level="a" type="main">Fast online training with frequency-adaptive learning rates for chinese word segmentation and new word detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xu</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Houfeng</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wenjie</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 50th Annual Meeting of the Association for Computational Linguistics<address><addrLine>Jeju Island, Korea</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2012-07" />
			<biblScope unit="page" from="253" to="262" />
		</imprint>
	</monogr>
	<note>Long Papers). Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b690">
	<analytic>
		<title level="a" type="main">Probabilistic chinese word segmentation with non-local information and stochastic training</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xu</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Takuya</forename><surname>Yao Zhong Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshimasa</forename><surname>Matsuzaki</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jun&amp;apos;ichi</forename><surname>Tsuruoka</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Tsujii</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Inf. Process. Manage</title>
		<imprint>
			<biblScope unit="volume">49</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="626" to="636" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b691">
	<analytic>
		<title level="a" type="main">Structure regularization for structured prediction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xu</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="page" from="2402" to="2410" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b692">
	<analytic>
		<title level="a" type="main">Chinese Word Segmentation as LMR Tagging</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Xue</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Shen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2nd SIGHAN Workshop on Chinese Language Processing</title>
		<meeting>the 2nd SIGHAN Workshop on Chinese Language Processing</meeting>
		<imprint>
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b693">
	<analytic>
		<title level="a" type="main">The Penn Chinese TreeBank: Phrase structure annotation of a large corpus</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Naiwen</forename><surname>Xue</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fei</forename><surname>Xia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fu-Dong</forename><surname>Chiou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marta</forename><surname>Palmer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Natural Language Engineering</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="207" to="238" />
			<date type="published" when="2005-06" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b694">
	<analytic>
		<title level="a" type="main">Chinese segmentation with a word-based perceptron algorithm</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yue</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stephen</forename><surname>Clark</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 45th Annual Meeting of the Association of Computational Linguistics</title>
		<meeting>the 45th Annual Meeting of the Association of Computational Linguistics<address><addrLine>Prague, Czech Republic</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2007-06" />
			<biblScope unit="page" from="840" to="847" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b695">
	<analytic>
		<title level="a" type="main">Subword-based tagging by conditional random fields for chinese word segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ruiqiang</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Genichiro</forename><surname>Kikui</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eiichiro</forename><surname>Sumita</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Human Language Technology Conference of the NAACL, Companion Volume: Short Papers, NAACL-Short &apos;06</title>
		<meeting>the Human Language Technology Conference of the NAACL, Companion Volume: Short Papers, NAACL-Short &apos;06<address><addrLine>Stroudsburg, PA, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2006" />
			<biblScope unit="page" from="193" to="196" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b696">
	<analytic>
		<title level="a" type="main">Exploring representations from unlabeled data with co-training for chinese word segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Longkai</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Houfeng</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xu</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mairgup</forename><surname>Mansur</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EMNLP</title>
		<imprint>
			<publisher>ACL</publisher>
			<date type="published" when="2013" />
			<biblScope unit="page" from="311" to="321" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b697">
	<analytic>
		<title level="a" type="main">Deep learning for chinese word segmentation and pos tagging</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaoqing</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hanyang</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tianyu</forename><surname>Xu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EMNLP</title>
		<imprint>
			<publisher>ACL</publisher>
			<date type="published" when="2013" />
			<biblScope unit="page" from="647" to="657" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b698">
	<analytic>
		<title level="a" type="main">Introducing the ims-wrocław-szeged-cis entry at the SPMRL 2014 shared task: Reranking and morpho-syntax meet unlabeled data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anders</forename><surname>Björkelund</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ozlem</forename><surname>Cetinoglu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Agnieszka</forename><surname>Falenska</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richárd</forename><surname>Farkas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas</forename><surname>Mueller</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the First Joint Workshop on Statistical Parsing of Morphologically Rich Languages and Syntactic Analysis of NonCanonical Languages</title>
		<meeting>the First Joint Workshop on Statistical Parsing of Morphologically Rich Languages and Syntactic Analysis of NonCanonical Languages</meeting>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
	<note>Wolfgang Seeker, and Zsolt Szántó</note>
</biblStruct>

<biblStruct xml:id="b699">
	<analytic>
		<title level="a" type="main">Coarseto-fine N-best parsing and MaxEnt discriminative reranking</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eugene</forename><surname>Charniak</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mark</forename><surname>Johnson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 43rd Annual Meeting on Association for Computational Linguistics</title>
		<meeting>the 43rd Annual Meeting on Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b700">
	<analytic>
		<title level="a" type="main">Morphology and reranking for the statistical parsing of spanish</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Brooke</forename><surname>Cowan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Collins</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of Human Language Technology Conference and Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>Human Language Technology Conference and Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b701">
	<analytic>
		<title level="a" type="main">Neural CRF parsing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Greg</forename><surname>Durrett</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Klein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Association for Computational Linguistics</title>
		<meeting>the Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b702">
	<analytic>
		<title level="a" type="main">Parsing as reduction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Fernández</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">-</forename><surname>González</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><forename type="middle">T</forename><surname>Andr</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Martins</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Annual Meeting of the Association for Computational Linguistics ACL</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b703">
	<analytic>
		<title level="a" type="main">Less grammar, more features</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Hall</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Greg</forename><surname>Durrett</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Klein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 52nd Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b704">
	<analytic>
		<title level="a" type="main">Distributional representations for handling sparsity in supervised sequence-labeling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fei</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander</forename><surname>Yates</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Joint Conference of the 47th Annual Meeting of the ACL and the 4th International Joint Conference on Natural Language Processing of the AFNLP</title>
		<meeting>the Joint Conference of the 47th Annual Meeting of the ACL and the 4th International Joint Conference on Natural Language Processing of the AFNLP</meeting>
		<imprint>
			<date type="published" when="2009" />
			<biblScope unit="volume">1</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b705">
	<analytic>
		<title level="a" type="main">Joint RNNbased greedy parsing and word composition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joël</forename><surname>Legrand</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ronan</forename><surname>Collobert</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ICLR</title>
		<meeting>ICLR</meeting>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b706">
	<analytic>
		<title level="a" type="main">Efficient higher-order CRFs for morphological tagging</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Mueller</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Schmid</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Schütze</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2013 Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b707">
	<analytic>
		<title level="a" type="main">Products of random latent variable grammars</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Slav</forename><surname>Petrov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NAACL-HLT</title>
		<imprint>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b708">
	<monogr>
		<title level="m" type="main">Learning sets of filters using back-propagation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>David</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geoffrey</forename><forename type="middle">E</forename><surname>Plaut</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Hinton</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1987" />
		</imprint>
		<respStmt>
			<orgName>Computer Speech and Language</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b709">
	<analytic>
		<title level="a" type="main">Wolfgang Seeker, Yannick Versley, Veronika Vincze, Marcin Wolińsk, Alina Wróblewska, andÉric Villemonte De La Clergerie</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Djamé</forename><surname>Seddah</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Reut</forename><surname>Tsarfaty</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sandra</forename><surname>Kübler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marie</forename><surname>Candito</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jinho</forename><forename type="middle">D</forename><surname>Choi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richárd</forename><surname>Farkas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jennifer</forename><surname>Foster</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Iakes</forename><surname>Goenaga</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Koldo</forename><surname>Gojenola</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoav</forename><surname>Goldberg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Spence</forename><surname>Green</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nizar</forename><surname>Habash</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marco</forename><surname>Kuhlmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wolfgang</forename><surname>Maier</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joakim</forename><surname>Nivre</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adam</forename><surname>Przepiórkowski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ryan</forename><surname>Roth</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 4th Workshop on Statistical Parsing of Morphologically Rich Languages: Shared Task</title>
		<meeting>the 4th Workshop on Statistical Parsing of Morphologically Rich Languages: Shared Task</meeting>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
	<note>Overview of the SPMRL 2013 shared task: A cross-framework evaluation of parsing morphologically rich languages</note>
</biblStruct>

<biblStruct xml:id="b710">
	<monogr>
		<title level="m" type="main">Parsing morphologically rich languages: Introduction to the special issue</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Reut</forename><surname>Tsarfaty</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Djamé</forename><surname>Seddah</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sandra</forename><surname>Kbler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joakim</forename><surname>Nivre</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2013" />
			<publisher>Computational Linguistics</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b711">
	<monogr>
		<title level="m" type="main">Reading behavior predicts syntactic categories</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maria</forename><surname>Barrett</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anders</forename><surname>Søgaard</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="345" to="349" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b712">
	<analytic>
		<title level="a" type="main">The dundee treebank</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maria</forename><surname>Barrett</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Željko</forename><surname>Agić</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anders</forename><surname>Søgaard</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The 14th International Workshop on Treebanks and Linguistic Theories (TLT 14)</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="242" to="248" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b713">
	<analytic>
		<title level="a" type="main">Painless unsupervised learning with features</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Taylor</forename><surname>Berg-Kirkpatrick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexandre</forename><surname>Bouchard-Cote</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Denero</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Klein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of NAACL</title>
		<meeting>NAACL</meeting>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="page" from="582" to="590" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b714">
	<analytic>
		<title level="a" type="main">Two decades of unsupervised POS induction: How far have we come?</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christos</forename><surname>Christodoulopoulos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sharon</forename><surname>Goldwater</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mark</forename><surname>Steedman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of EMNLP</title>
		<meeting>EMNLP</meeting>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="page" from="575" to="584" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b715">
	<analytic>
		<title level="a" type="main">Surprisal-based comparison between a symbolic and a connectionist model of sentence processing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stefan</forename><forename type="middle">L</forename><surname>Frank</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 31st annual Conference of the Cognitive Science Society</title>
		<meeting>the 31st annual Conference of the Cognitive Science Society</meeting>
		<imprint>
			<date type="published" when="2009" />
			<biblScope unit="page" from="1139" to="1144" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b716">
	<analytic>
		<title level="a" type="main">KenLM: faster and smaller language model queries</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kenneth</forename><surname>Heafield</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the EMNLP 2011 Sixth Workshop on Statistical Machine Translation</title>
		<meeting>the EMNLP 2011 Sixth Workshop on Statistical Machine Translation</meeting>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="page" from="187" to="197" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b717">
	<analytic>
		<title level="a" type="main">The dundee corpus</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alan</forename><surname>Kennedy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Robin</forename><surname>Hill</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joël</forename><surname>Pynte</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 12th European conference on eye movement</title>
		<meeting>the 12th European conference on eye movement</meeting>
		<imprint>
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b718">
	<analytic>
		<title level="a" type="main">Wikily supervised part-of-speech tagging</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shen</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">João</forename><surname>Graça</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ben</forename><surname>Taskar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EMNLP</title>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="page" from="1389" to="1398" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b719">
	<monogr>
		<title level="m" type="main">A universal part-of-speech tagset</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Slav</forename><surname>Petrov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dipanjan</forename><surname>Das</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ryan</forename><surname>Mcdonald</surname></persName>
		</author>
		<idno>CoRR abs/1104.2086</idno>
		<imprint>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b720">
	<analytic>
		<title level="a" type="main">Eye movements in reading and information processing: 20 years of research</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Keith</forename><surname>Rayner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Psychological bulletin</title>
		<imprint>
			<biblScope unit="volume">124</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="372" to="422" />
			<date type="published" when="1998" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b721">
	<analytic>
		<title level="a" type="main">Gaze tracking through smartphones</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Henrik</forename><surname>Skovsgaard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Paulin Hansen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Emilie</forename><surname>Møllenbach</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Gaze Interaction in the Post-WIMP World CHI 2013 One-day Workshop</title>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b722">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">A</forename><surname>Ehinger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Finkelstein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">R</forename><surname>Kulkarni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Xiao</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1504.06755</idno>
		<title level="m">TurkerGaze: Crowdsourcing saliency with webcam based eye tracking</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b723">
	<analytic>
		<title level="a" type="main">Part of speech induction with gaze features</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maria</forename><surname>Zelenina</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The bonferroni andšidák corrections for multiple comparisons. Encyclopedia of measurement and statistics</title>
		<imprint>
			<date type="published" when="2007" />
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="103" to="107" />
		</imprint>
		<respStmt>
			<orgName>University of Edinburgh, United Kingdom</orgName>
		</respStmt>
	</monogr>
	<note>References Hervé Abdi</note>
</biblStruct>

<biblStruct xml:id="b724">
	<analytic>
		<title level="a" type="main">Findings of the 2014 workshop on statistical machine translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ondrej</forename><surname>Bojar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christian</forename><surname>Buck</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christian</forename><surname>Federmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Barry</forename><surname>Haddow</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philipp</forename><surname>Koehn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Johannes</forename><surname>Leveling</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christof</forename><surname>Monz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pavel</forename><surname>Pecina</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matt</forename><surname>Post</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Herve</forename><surname>Saint-Amand</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Radu</forename><surname>Soricut</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lucia</forename><surname>Specia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aleš</forename><surname>Tamchyna</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Ninth Workshop on Statistical Machine Translation</title>
		<meeting>the Ninth Workshop on Statistical Machine Translation<address><addrLine>Baltimore, Maryland, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2014-06" />
			<biblScope unit="page" from="12" to="58" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b725">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ondřej</forename><surname>Bojar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rajen</forename><surname>Chatterjee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christian</forename><surname>Federmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Barry</forename><surname>Haddow</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthias</forename><surname>Huck</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Hokamp</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philipp</forename><surname>Koehn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Varvara</forename><surname>Logacheva</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christof</forename><surname>Monz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matteo</forename><surname>Negri</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matt</forename><surname>Post</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Carolina</forename><surname>Scarton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lucia</forename><surname>Specia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marco</forename><surname>Turchi</surname></persName>
		</author>
		<title level="m">Proceedings of the Tenth Workshop on Statistical Machine Translation</title>
		<meeting>the Tenth Workshop on Statistical Machine Translation<address><addrLine>Lisbon, Portugal</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="1" to="46" />
		</imprint>
	</monogr>
	<note>Findings of the 2015 workshop on statistical machine translation</note>
</biblStruct>

<biblStruct xml:id="b726">
	<analytic>
		<title level="a" type="main">Confidence estimation for translation prediction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Simona</forename><surname>Gandrabur</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">George</forename><surname>Foster</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">HLT-NAACL-2003</title>
		<meeting><address><addrLine>Edmonton, Canada</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2003" />
			<biblScope unit="page" from="95" to="102" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b727">
	<analytic>
		<title level="a" type="main">Improving evaluation of machine translation quality estimation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yvette</forename><surname>Graham</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing</title>
		<meeting>the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing</meeting>
		<imprint>
			<publisher>Long Papers</publisher>
			<date type="published" when="2015" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="1804" to="1813" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b728">
	<analytic>
		<title level="a" type="main">Lig system for word level qe task at wmt14</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ngoc</forename><forename type="middle">Quang</forename><surname>Luong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Laurent</forename><surname>Besacier</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Benjamin</forename><surname>Lecouteux</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">WMT-2014</title>
		<meeting><address><addrLine>USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2014-06" />
			<biblScope unit="page" from="335" to="341" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b729">
	<analytic>
		<title level="a" type="main">Evaluation: from precision, recall and F-measure to ROC, informedness, markedness and correlation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">W</forename><surname>David</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Powers</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Machine Learning Technologies</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="37" to="63" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b730">
	<analytic>
		<title level="a" type="main">Ushef and usaar-ushef participation in the wmt15 qe shared task</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Carolina</forename><surname>Scarton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Liling</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lucia</forename><surname>Specia</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Tenth Workshop on Statistical Machine Translation</title>
		<meeting>the Tenth Workshop on Statistical Machine Translation<address><addrLine>Lisbon, Portugal</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2015-09" />
			<biblScope unit="page" from="336" to="341" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b731">
	<analytic>
		<title level="a" type="main">An investigation on the effectiveness of features for translation quality estimation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kashif</forename><surname>Shah</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Trevor</forename><surname>Cohn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lucia</forename><surname>Specia</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">MT Summit XIV</title>
		<meeting><address><addrLine>Nice, France</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="167" to="174" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b732">
	<analytic>
		<title level="a" type="main">Introduction to the conll-2003 shared task: Language-independent named entity recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Erik</forename><forename type="middle">F</forename><surname>Tjong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kim</forename><surname>Sang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fien</forename><surname>De Meulder</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of CoNLL-2003</title>
		<meeting>CoNLL-2003</meeting>
		<imprint>
			<date type="published" when="2003" />
			<biblScope unit="page" from="142" to="147" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b733">
	<analytic>
		<title level="a" type="main">Design and Analysis of a Large Corpus of Post-Edited Translations: Quality Estimation, Failure Analysis and the Variability of Post-Edition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guillaume</forename><surname>Wisniewski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anil Kumar</forename><surname>Singh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Natalia</forename><surname>Segal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">François</forename><surname>Yvon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">MT Summit XIV: 14th Machine Translation Summit</title>
		<meeting><address><addrLine>Nice, France</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="117" to="124" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b734">
	<analytic>
		<title level="a" type="main">More accurate tests for the statistical significance of result differences</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander</forename><surname>Yeh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Coling-2000: the 18th Conference on Computational Linguistics</title>
		<meeting><address><addrLine>Saarbrücken, Germany</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2000" />
			<biblScope unit="page" from="38" to="59" />
		</imprint>
	</monogr>
	<note>References Asif Agha. 2005. Voice, footing, enregisterment</note>
</biblStruct>

<biblStruct xml:id="b735">
	<analytic>
		<title level="a" type="main">If all you have is a bit of the Bible: Learning POS taggers for truly low-resource languages</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zeljko</forename><surname>Agić</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dirk</forename><surname>Hovy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anders</forename><surname>Søgaard</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 53rd annual meeting of the ACL</title>
		<meeting>the 53rd annual meeting of the ACL</meeting>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b736">
	<analytic>
		<title level="a" type="main">Empirical evaluation of profile characteristics for gender classification on twitter</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ugo</forename><forename type="middle">A</forename><surname>Jalal S Alowibdi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philip</forename><surname>Buy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Yu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Machine Learning and Applications (ICMLA), 2013 12th International Conference on</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2013" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="365" to="369" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b737">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ashton</forename><surname>Anderson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Mcfarland</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Jurafsky</surname></persName>
		</author>
		<title level="m">Proceedings of the ACL-2012 Special Workshop on Rediscovering 50 Years of Discoveries</title>
		<meeting>the ACL-2012 Special Workshop on Rediscovering 50 Years of Discoveries</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2012" />
			<biblScope unit="page" from="13" to="21" />
		</imprint>
	</monogr>
	<note>Towards a computational history of the ACL</note>
</biblStruct>

<biblStruct xml:id="b738">
	<analytic>
		<title level="a" type="main">Identifying real or fake articles: Towards better language modeling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sameer</forename><surname>Badaskar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sachin</forename><surname>Agarwal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shilpa</forename><surname>Arora</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Third International Joint Conference on Natural Language Processing</title>
		<meeting>the Third International Joint Conference on Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
	<note>II</note>
</biblStruct>

<biblStruct xml:id="b739">
	<analytic>
		<title level="a" type="main">Censorship and deletion practices in Chinese social media</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Bamman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O&amp;apos;</forename><surname>Brendan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Noah</forename><surname>Connor</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Smith</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">First Monday</title>
		<imprint>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page">17</biblScope>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b740">
	<analytic>
		<title level="a" type="main">Distributed representations of geographically situated language</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Bamman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Dyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Noah</forename><forename type="middle">A</forename><surname>Smith</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 52nd Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="828" to="834" />
		</imprint>
	</monogr>
	<note>Proceedings of ACL</note>
</biblStruct>

<biblStruct xml:id="b741">
	<analytic>
		<title level="a" type="main">Keystroke patterns as prosody in digital writings: A case study with deceptive reviews and essays</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ritwik</forename><surname>Banerjee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Song</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yejin</forename><surname>Seok Jun Kang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Choi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP)</title>
		<meeting>the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP)</meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="1469" to="1473" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b742">
	<monogr>
		<title level="m" type="main">Principles of biomedical ethics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Tom</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">James F</forename><surname>Beauchamp</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Childress</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2001" />
			<publisher>Oxford University Press</publisher>
			<pubPlace>USA</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b743">
	<analytic>
		<title level="a" type="main">Reproduction in education</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pierre</forename><surname>Bourdieu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jean-Claude</forename><surname>Passeron</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">society and culture</title>
		<imprint>
			<date type="published" when="1990" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b744">
	<analytic>
		<title level="a" type="main">The language of power and its cultural influence</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Bracewell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marc</forename><surname>Tomlinson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The COLING 2012 Organizing Committee</title>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="page" from="155" to="164" />
		</imprint>
	</monogr>
	<note>Proceedings of COLING 2012: Posters</note>
</biblStruct>

<biblStruct xml:id="b745">
	<analytic>
		<title level="a" type="main">Gender Inference of Twitter Users in NonEnglish Contexts</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Morgane</forename><surname>Ciot</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Morgan</forename><surname>Sonderegger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Derek</forename><surname>Ruths</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2013 Conference on Empirical Methods in Natural Language Processing<address><addrLine>Seattle, Wash</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="18" to="21" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b746">
	<analytic>
		<title level="a" type="main">Evaluating corpora documentation with regards to the Ethics and Big Data Charter</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alain</forename><surname>Couillault</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Karën</forename><surname>Fort</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gilles</forename><surname>Adda</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hugues</forename><surname>Mazancourt</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Ninth International Conference on Language Resources and Evaluation (LREC-2014)</title>
		<meeting>the Ninth International Conference on Language Resources and Evaluation (LREC-2014)</meeting>
		<imprint>
			<publisher>ELRA</publisher>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b747">
	<analytic>
		<title level="a" type="main">Unsupervised part-of-speech tagging with bilingual graph-based projections</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dipanjan</forename><surname>Das</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Slav</forename><surname>Petrov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 49th annual meeting of the ACL</title>
		<meeting>the 49th annual meeting of the ACL</meeting>
		<imprint>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b748">
	<analytic>
		<title level="a" type="main">Bill Gates: Elon Musk Is Right, We Should All Be Scared Of Artificial Intelligence Wiping Out Humanity</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lisa</forename><forename type="middle">Eadicicco</forename></persName>
		</author>
		<ptr target="http://www.businessinsider.com/bill-gates-artificial-intelligence-2015-1" />
	</analytic>
	<monogr>
		<title level="j">Business Insider</title>
		<imprint>
			<date type="published" when="2015-01-28" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b749">
	<monogr>
		<title level="m" type="main">Its Time to Intelligently Discuss Artificial Intelligence. Backchannel</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oren</forename><forename type="middle">Etzioni</forename></persName>
		</author>
		<ptr target="https://backchannel.com/ai-wont-exterminate-us-it-will-empower-us-5b7224735bf3#.eia6vtimy" />
		<imprint>
			<date type="published" when="2014-12-09" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b750">
	<analytic>
		<title level="a" type="main">Identifying fake amazon reviews as learning from crowds</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tommaso</forename><surname>Fornaciari</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Massimo</forename><surname>Poesio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 14th Conference of the European Chapter of the Association for Computational Linguistics</title>
		<meeting>the 14th Conference of the European Chapter of the Association for Computational Linguistics</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2014" />
			<biblScope unit="page" from="279" to="287" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b751">
	<monogr>
		<title level="m" type="main">Amazon mechanical turk: Gold mine or coal mine? Computational Linguistics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Karën</forename><surname>Fort</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gilles</forename><surname>Adda</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Cohen</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="volume">37</biblScope>
			<biblScope unit="page" from="413" to="420" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b752">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Victor</forename><surname>Galaz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fredrik</forename><surname>Moberg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fernanda</forename><surname>Torre</surname></persName>
		</author>
		<ptr target="http://thebiospherecode.com/index.php/manifesto" />
		<title level="m">The Biosphere Code Manifesto</title>
		<imprint>
			<date type="published" when="2015-02-24" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b753">
	<analytic>
		<title level="a" type="main">Models of ecological rationality: the recognition heuristic</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Daniel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gerd</forename><surname>Goldstein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Gigerenzer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Psychological review</title>
		<imprint>
			<biblScope unit="volume">109</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page">75</biblScope>
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b754">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joseph</forename><surname>Henrich</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Steven</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ara</forename><surname>Heine</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Norenzayan</surname></persName>
		</author>
		<title level="m">The weirdest people in the world? Behavioral and brain sciences</title>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="page" from="61" to="83" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b755">
	<analytic>
		<title level="a" type="main">Exploring Language Variation Across Europe -A Web-based Tool for Computational Sociolinguistics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dirk</forename><surname>Hovy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anders</forename><surname>Johannsen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of LREC</title>
		<meeting>LREC</meeting>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b756">
	<analytic>
		<title level="a" type="main">Tagging performance correlates with author age</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dirk</forename><surname>Hovy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anders</forename><surname>Søgaard</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 53rd Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b757">
	<analytic>
		<title level="a" type="main">Demographic factors improve classification performance</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dirk</forename><surname>Hovy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 53rd Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b758">
	<analytic>
		<title level="a" type="main">The Enemy in Your Own Camp: How Well Can We Detect Statistically-Generated Fake Reviews-An Adversarial Study</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dirk</forename><surname>Hovy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 54th Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b759">
	<analytic>
		<title level="a" type="main">Control dangerous AI before it controls us, one expert says</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeremy</forename><surname>Hsu</surname></persName>
		</author>
		<ptr target="http://www.nbcnews.com/id/46590591/ns/technologyandscience-innovation" />
	</analytic>
	<monogr>
		<title level="j">NBC News</title>
		<imprint>
			<date type="published" when="2012-03-01" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b760">
	<analytic>
		<title level="a" type="main">Resolving entity morphs in censored data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hongzhao</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhen</forename><surname>Wen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dian</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Heng</forename><surname>Ji</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yizhou</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiawei</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">He</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 51st Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="1083" to="1093" />
		</imprint>
	</monogr>
	<note>Long Papers). Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b761">
	<analytic>
		<title level="a" type="main">Cross-lingual syntactic variation over age and gender</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anders</forename><surname>Johannsen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dirk</forename><surname>Hovy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anders</forename><surname>Søgaard</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of CoNLL</title>
		<meeting>CoNLL</meeting>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b762">
	<analytic>
		<title level="a" type="main">The Imperative of Responsibility: Foundations of an Ethics for the Technological Age</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hans</forename><forename type="middle">Jonas</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Original in German: Prinzip Verantwortung</title>
		<imprint>
			<date type="published" when="1984" />
			<publisher>University of Chicago Press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b763">
	<analytic>
		<title level="a" type="main">Challenges of studying and processing dialects in social media</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anna</forename><surname>Jørgensen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dirk</forename><surname>Hovy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anders</forename><surname>Søgaard</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Workshop on Noisy Usergenerated Text</title>
		<imprint>
			<publisher>W-NUT</publisher>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b764">
	<monogr>
		<title level="m" type="main">The Doomsday Invention: Will artificial intelligence bring us utopia or destruction? The New Yorker (magazine)</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Raffi</forename><surname>Khatchadourian</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2015-11-23" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b765">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hatim</forename><surname>Khouzami</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Romain</forename><surname>Laroche</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fabrice</forename><surname>Lefevre</surname></persName>
		</author>
		<title level="m">Proceedings of the 16th Annual Meeting of the Special Interest Group on Discourse and Dialogue, chapter Optimising TurnTaking Strategies With Reinforcement Learning</title>
		<meeting>the 16th Annual Meeting of the Special Interest Group on Discourse and Dialogue, chapter Optimising TurnTaking Strategies With Reinforcement Learning</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="315" to="324" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b766">
	<analytic>
		<title level="a" type="main">Experimental evidence of massivescale emotional contagion through social networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">I</forename><surname>Adam</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jamie</forename><forename type="middle">E</forename><surname>Kramer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeffrey T</forename><surname>Guillory</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Hancock</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Proceedings of the National Academy of Sciences</title>
		<imprint>
			<biblScope unit="volume">111</biblScope>
			<biblScope unit="issue">24</biblScope>
			<biblScope unit="page" from="8788" to="8790" />
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b767">
	<analytic>
		<title level="a" type="main">Modeling norms of turntaking in multi-party conversation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kornel</forename><surname>Laskowski</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 48th Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2010" />
			<biblScope unit="page" from="999" to="1008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b768">
	<analytic>
		<title level="a" type="main">What&apos;s in a name? using first names as features for gender inference in twitter</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wendy</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Derek</forename><surname>Ruths</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Analyzing Microtext: 2013 AAAI Spring Symposium</title>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b769">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Benjamin</forename><surname>Mandel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aron</forename><surname>Culotta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Boulahanis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Danielle</forename><surname>Stark</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bonnie</forename><surname>Lewis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeremy</forename><surname>Rodrigue</surname></persName>
		</author>
		<title level="m">Proceedings of the Second Workshop on Language in Social Media, chapter A Demographic Analysis of Online Sentiment during Hurricane Irene</title>
		<meeting>the Second Workshop on Language in Social Media, chapter A Demographic Analysis of Online Sentiment during Hurricane Irene</meeting>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="page" from="27" to="36" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b770">
	<analytic>
		<title level="a" type="main">Ethical and legal issues in corpus construction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tony</forename><surname>Mcenery</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Third International Conference on Language Resources and Evaluation (LREC&apos;02). European Language Resources Association (ELRA)</title>
		<meeting>the Third International Conference on Language Resources and Evaluation (LREC&apos;02). European Language Resources Association (ELRA)</meeting>
		<imprint>
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b771">
	<monogr>
		<title level="m" type="main">The normative structure of science. The sociology of science: Theoretical and empirical investigations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Robert K Merton</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1973" />
			<biblScope unit="page">267</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b772">
	<monogr>
		<title level="m" type="main">Gender matters: Feminist linguistic analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sara</forename><surname>Mills</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2012" />
			<publisher>Equinox Pub</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b773">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ehsan</forename><surname>Mohammady</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aron</forename><surname>Culotta</surname></persName>
		</author>
		<title level="m">Proceedings of the Joint Workshop on Social Dynamics and Personal Attributes in Social Media, chapter Using County Demographics to Infer Attributes of Twitter Users</title>
		<meeting>the Joint Workshop on Social Dynamics and Personal Attributes in Social Media, chapter Using County Demographics to Infer Attributes of Twitter Users</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2014" />
			<biblScope unit="page" from="7" to="16" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b774">
	<analytic>
		<title level="a" type="main">Inference in an authorship problem: A comparative study of discrimination methods applied to the authorship of the disputed federalist papers</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Frederick</forename><surname>Mosteller</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>David</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Wallace</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of the American Statistical Association</title>
		<imprint>
			<biblScope unit="volume">58</biblScope>
			<biblScope unit="issue">302</biblScope>
			<biblScope unit="page" from="275" to="309" />
			<date type="published" when="1963" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b775">
	<analytic>
		<title level="a" type="main">NLP for all languages</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Robert</forename><surname>Munro</surname></persName>
		</author>
		<ptr target="http://idibon.com/nlp-for-allRe-trieved" />
	</analytic>
	<monogr>
		<title level="j">Idibon Blog</title>
		<imprint>
			<date type="published" when="2013-05-22" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b776">
	<analytic>
		<title level="a" type="main">Author age prediction from text using linear regression</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dong</forename><surname>Nguyen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Noah</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Carolyn</forename><forename type="middle">P</forename><surname>Smith</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Rosé</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 5th ACL-HLT Workshop on Language Technology for Cultural Heritage, Social Sciences, and Humanities</title>
		<meeting>the 5th ACL-HLT Workshop on Language Technology for Cultural Heritage, Social Sciences, and Humanities</meeting>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="page" from="115" to="123" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b777">
	<analytic>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O&amp;apos;</forename><surname>Cathy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Neil</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The Ethical Data Scientist. Slate</title>
		<imprint>
			<date type="published" when="2016-02-04" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b778">
	<analytic>
		<title level="a" type="main">Finding deceptive opinion spam by any stretch of the imagination</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Myle</forename><surname>Ott</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yejin</forename><surname>Choi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Claire</forename><surname>Cardie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">Jeffrey</forename><surname>Hancock</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies</title>
		<meeting>the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2011" />
			<biblScope unit="page" from="309" to="319" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b779">
	<analytic>
		<title level="a" type="main">The language demographics of amazon mechanical turk</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ellie</forename><surname>Pavlick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matt</forename><surname>Post</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ann</forename><surname>Irvine</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dmitry</forename><surname>Kachaev</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Callison-Burch</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Transactions of the Association of Computational Linguistics</title>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="79" to="92" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b780">
	<analytic>
		<title level="a" type="main">Personality traits on twitterorhow to get 1,500 personality tests in a week</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Barbara</forename><surname>Plank</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dirk</forename><surname>Hovy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 6th Workshop on Computational Approaches to Subjectivity, Sentiment and Social Media Analysis</title>
		<meeting>the 6th Workshop on Computational Approaches to Subjectivity, Sentiment and Social Media Analysis</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="92" to="98" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b781">
	<analytic>
		<title level="a" type="main">Written dialog and social power: Manifestations of different types of power in dialog behavior</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vinodkumar</forename><surname>Prabhakaran</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Owen</forename><surname>Rambow</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Sixth International Joint Conference on Natural Language Processing</title>
		<meeting>the Sixth International Joint Conference on Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="216" to="224" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b782">
	<monogr>
		<title level="m" type="main">Asian Federation of Natural Language Processing</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b783">
	<analytic>
		<title level="a" type="main">Staying on topic: An indicator of power in political debates</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ashima</forename><surname>Vinodkumar Prabhakaran</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Owen</forename><surname>Arora</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Rambow</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP)</title>
		<meeting>the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP)</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2014" />
			<biblScope unit="page" from="1481" to="1486" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b784">
	<analytic>
		<title level="a" type="main">An analysis of the user occupational class through twitter content</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Preotiuc-Pietro</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vasileios</forename><surname>Lampos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nikolaos</forename><surname>Aletras</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b785">
	<analytic>
		<title level="a" type="main">Studying user income through language, behaviour and affect in social media</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Preoţiuc-Pietro</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Svitlana</forename><surname>Volkova</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">PloS one</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page">138717</biblScope>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
	<note>Vasileios Lampos, Yoram Bachrach, and Nikolaos Aletras</note>
</biblStruct>

<biblStruct xml:id="b786">
	<analytic>
		<title level="a" type="main">Staking out the unclear ethical terrain of online social experiments</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cornelius</forename><surname>Puschmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Engin</forename><surname>Bozdag</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Internet Policy Review</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="issue">4</biblScope>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b787">
	<monogr>
		<title level="m" type="main">The moral character of cryptographic work</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Phillip</forename><surname>Rogaway</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
		<respStmt>
			<orgName>IACR-Cryptology ePrint Archive</orgName>
		</respStmt>
	</monogr>
<note type="report_type">Technical report</note>
</biblStruct>

<biblStruct xml:id="b788">
	<analytic>
		<title level="a" type="main">Age prediction in blogs: A study of style, content, and online behavior in pre-and post-social media generations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sara</forename><surname>Rosenthal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kathleen</forename><surname>Mckeown</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies</title>
		<meeting>the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2011" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="763" to="772" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b789">
	<monogr>
		<title level="m" type="main">Research priorities for robust and beneficial artificial intelligence</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stuart</forename><surname>Russell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Dewey</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Max</forename><surname>Tegmark</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Janos</forename><surname>Kramar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Mallah</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
		<respStmt>
			<orgName>Future of Life Institute</orgName>
		</respStmt>
	</monogr>
<note type="report_type">Technical report</note>
</biblStruct>

<biblStruct xml:id="b790">
	<analytic>
		<title level="a" type="main">The weirdest languages</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tyler</forename><surname>Schnoebelen</surname></persName>
		</author>
		<ptr target="http://idibon.com/the-weirdest-languages" />
	</analytic>
	<monogr>
		<title level="j">Idibon Blog</title>
		<imprint>
			<date type="published" when="2013-06-21" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b791">
	<analytic>
		<title level="a" type="main">Indexical order and the dialectics of sociolinguistic life</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Silverstein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Language &amp; Communication</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="193" to="229" />
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b792">
	<analytic>
		<title level="a" type="main">The affect heuristic</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Paul</forename><surname>Slovic</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Melissa</forename><forename type="middle">L</forename><surname>Finucane</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ellen</forename><surname>Peters</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Donald</forename><forename type="middle">G</forename><surname>Macgregor</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">European Journal of Operational Research</title>
		<imprint>
			<biblScope unit="volume">177</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="1333" to="1352" />
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b793">
	<analytic>
		<title level="a" type="main">Inverted indexing for cross-lingual nlp</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anders</forename><surname>Søgaard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Željko</forename><surname>Agić</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Barbara</forename><surname>Héctor Martínez Alonso</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bernd</forename><surname>Plank</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anders</forename><surname>Bohnet</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Johannsen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 53rd annual meeting of the ACL</title>
		<meeting>the 53rd annual meeting of the ACL</meeting>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b794">
	<analytic>
		<title level="a" type="main">Data point selection for crosslanguage adaptation of dependency parsers</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anders</forename><surname>Søgaard</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ACL</title>
		<meeting>ACL</meeting>
		<imprint>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b795">
	<monogr>
		<title level="m" type="main">It is never as simple as it seems: The wide-ranging impacts of ethics violations. Ethical Challenges in the Behavioral and Brain Sciences</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Strube</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page">126</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b796">
	<analytic>
		<title level="a" type="main">Precautions against what? the availability heuristic and cross-cultural risk perceptions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Cass R Sunstein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">U Chicago Law &amp; Economics, Olin Working Paper</title>
		<imprint>
			<biblScope unit="issue">220</biblScope>
			<biblScope unit="page" from="4" to="22" />
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b797">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joel</forename><surname>Tetreault</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jill</forename><surname>Burstein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Claudia</forename><surname>Leacock</surname></persName>
		</author>
		<title level="m">Proceedings of the Tenth Workshop on Innovative Use of NLP for Building Educational Applications, chapter Proceedings of the Tenth Workshop on Innovative Use of NLP for Building Educational Applications. Association for Computational Linguistics</title>
		<meeting>the Tenth Workshop on Innovative Use of NLP for Building Educational Applications, chapter the Tenth Workshop on Innovative Use of NLP for Building Educational Applications. Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b798">
	<analytic>
		<title level="a" type="main">A bibliometric analysis of privacy and ethics in ieee security and privacy</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathan</forename><surname>Tse</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dawn</forename><forename type="middle">E</forename><surname>Schrader</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dipayan</forename><surname>Ghosh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tony</forename><surname>Liao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Lundie</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Ethics and Information Technology</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="153" to="163" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b799">
	<analytic>
		<title level="a" type="main">A frame of mind: Using statistical models for detection of framing and agenda setting campaigns</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oren</forename><surname>Tsur</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Calacci</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Lazer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing</title>
		<meeting>the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2015" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="1629" to="1638" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b800">
	<analytic>
		<title level="a" type="main">Availability: A heuristic for judging frequency and probability</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Amos</forename><surname>Tversky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Kahneman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Cognitive psychology</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="207" to="232" />
			<date type="published" when="1973" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b801">
	<analytic>
		<title level="a" type="main">Exploring demographic language variations to improve multilingual sentiment analysis in social media</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Svitlana</forename><surname>Volkova</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Theresa</forename><surname>Wilson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Yarowsky</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of EMNLP</title>
		<meeting>EMNLP</meeting>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="1815" to="1827" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b802">
	<analytic>
		<title level="a" type="main">Inferring user political preferences from streaming communications</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Svitlana</forename><surname>Volkova</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Glen</forename><surname>Coppersmith</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Benjamin</forename><surname>Van Durme</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 52nd annual meeting of the ACL</title>
		<meeting>the 52nd annual meeting of the ACL</meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="186" to="196" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b803">
	<analytic>
		<title level="a" type="main">Inferring latent user properties from texts published in social media (demo)</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Svitlana</forename><surname>Volkova</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoram</forename><surname>Bachrach</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Armstrong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vijay</forename><surname>Sharma</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Twenty-Ninth Conference on Artificial Intelligence (AAAI)</title>
		<meeting>the Twenty-Ninth Conference on Artificial Intelligence (AAAI)<address><addrLine>Austin, TX</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2015-01" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b804">
	<analytic>
		<title level="a" type="main">Big Data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hanna</forename><surname>Wallach</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Machine Learning, and the Social Sciences: Fairness, Accountability, and Transparency</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b805">
	<analytic>
		<title level="a" type="main">Inducing multilingual POS taggers and NP bracketers via robust projection across aligned corpora</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Yarowsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Grace</forename><surname>Ngai</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of NAACL</title>
		<meeting>NAACL</meeting>
		<imprint>
			<date type="published" when="2001" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b806">
	<analytic>
		<title level="a" type="main">Gene similarity networks provide tools for understanding eukaryote origins and evolution</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Alvarez-Ponce</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philippe</forename><surname>Lopez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eric</forename><surname>Bapteste</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">James</forename><forename type="middle">O</forename><surname>Mcinerney</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Proceedings of the National Academy of Sciences of the United States of America</title>
		<imprint>
			<biblScope unit="volume">110</biblScope>
			<biblScope unit="issue">17</biblScope>
			<biblScope unit="page" from="1594" to="1603" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b807">
	<analytic>
		<title level="a" type="main">How old is the Indo-European language family? Illumination or more moths to the flame?</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Quentin</forename><forename type="middle">D</forename><surname>Atkinson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Russell</forename><forename type="middle">D</forename><surname>Gray</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Phylogenetic methods and the prehistory of languages</title>
		<editor>Peter Forster and Colin Renfrew</editor>
		<meeting><address><addrLine>Cambridge</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2006" />
			<biblScope unit="page" from="91" to="109" />
		</imprint>
		<respStmt>
			<orgName>McDonald Institute for Archaeological Research</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b808">
	<analytic>
		<title level="a" type="main">Entitybased cross-document coreferencing using the vector space model</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Amit</forename><surname>Bagga</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Breck</forename><surname>Baldwin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 36th Annual Meeting of the ACL</title>
		<meeting>the 36th Annual Meeting of the ACL</meeting>
		<imprint>
			<date type="published" when="1998" />
			<biblScope unit="page" from="79" to="85" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b809">
	<analytic>
		<title level="a" type="main">Stuck in the forest: Trees, networks and Chinese dialects</title>
	</analytic>
	<monogr>
		<title level="j">Diachronica</title>
		<editor>Mahe Ben Hamed and Feng Wang</editor>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="page" from="29" to="60" />
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b810">
	<monogr>
		<title level="m" type="main">Hànyǔ fāngyán cíhuì 汉 语 方 言 词 汇</title>
		<editor>Běijīng Dàxué 北 京 大 学</editor>
		<imprint>
			<date type="published" when="1964" />
		</imprint>
	</monogr>
	<note>Chinese dialect vocabularies</note>
</biblStruct>

<biblStruct xml:id="b811">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wénzì</forename><surname>Gǎigé</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">文字改革</forename><surname>Běijing</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">北京</forename></persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b812">
	<analytic>
		<title level="a" type="main">Network-thinking: Graphs to analyze microbial complexity and evolution</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eduardo</forename><surname>Corel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philippe</forename><surname>Lopez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Raphaël</forename><surname>Méheust</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eric</forename><surname>Bapteste</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Trends Microbiology</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="224" to="237" />
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b813">
	<monogr>
		<title level="m" type="main">The igraph software package for complex network research. InterJournal Complex Systems page 1695</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gábor</forename><surname>Csárdi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tamás</forename><surname>Nepusz</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b814">
	<analytic>
		<title level="a" type="main">Clustering by passing messages between data points</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Brendan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Delbert</forename><surname>Frey</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Dueck</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Science</title>
		<imprint>
			<biblScope unit="volume">315</biblScope>
			<biblScope unit="page" from="972" to="976" />
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b815">
	<analytic>
		<title level="a" type="main">A pluralistic account of homology: adapting the models to the data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Leanne</forename><forename type="middle">S</forename><surname>Haggerty</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Pierre-Alain</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">William</forename><forename type="middle">P</forename><surname>Jachiet</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><forename type="middle">A</forename><surname>Hanage</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philippe</forename><surname>Fitzpatrick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mary</forename><forename type="middle">J</forename><surname>Lopez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Davide</forename><surname>O&amp;apos;connell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mark</forename><surname>Pisani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eric</forename><surname>Wilkinson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">James</forename><forename type="middle">O</forename><surname>Bapteste</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Mcinerney</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Mol. Biol. Evol</title>
		<imprint>
			<biblScope unit="volume">31</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="501" to="516" />
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b816">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Harald</forename><surname>Hammarström</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Robert</forename><surname>Forkel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Martin</forename><surname>Haspelmath</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sebastian</forename><surname>Bank</surname></persName>
		</author>
		<title level="m">Glottolog</title>
		<meeting><address><addrLine>Leipzig</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
		<respStmt>
			<orgName>Max Planck Institute for Evolutionary Anthropology</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b817">
	<analytic>
		<title level="a" type="main">Clustering semantically equivalent words into cognate sets in multilingual lists</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bradley</forename><surname>Hauer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Grzegorz</forename><surname>Kondrak</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 5th International Joint NLP conference</title>
		<meeting>the 5th International Joint NLP conference</meeting>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="page" from="865" to="873" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b818">
	<monogr>
		<title level="m" type="main">Xiàndài Hànyǔ fāngyán yīnkù 现代汉语方言音库</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jīngyī</forename><surname>Hóu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>侯精一</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2004" />
		</imprint>
	</monogr>
	<note>Phonological database of Chinese dialects</note>
</biblStruct>

<biblStruct xml:id="b819">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">上海教育</forename><surname>Shànghǎi Jiàoyù</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">上海</forename><surname>Shànghǎi</surname></persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b820">
	<analytic>
		<title level="a" type="main">Phylogenetic inference from word lists using weighted alignment with empirical determined weights</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gerhard</forename><surname>Jäger</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Language Dynamics and Change</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="245" to="291" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b821">
	<analytic>
		<title level="a" type="main">Lexstat. automatic detection of cognates in multilingual wordlists</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Johann-Mattis</forename><surname>List</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the EACL 2012 Joint Workshop of LINGVIS and UNCLH</title>
		<meeting>the EACL 2012 Joint Workshop of LINGVIS and UNCLH<address><addrLine>Stroudsburg</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="page" from="117" to="125" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b822">
	<analytic>
		<title level="a" type="main">SCA. phonetic alignment based on sound classes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Johann-Mattis</forename><surname>List</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">New directions in logic, language, and computation</title>
		<editor>Marija Slavkovik and Dan Lassiter</editor>
		<meeting><address><addrLine>Berlin and Heidelberg</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2012" />
			<biblScope unit="page" from="32" to="51" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b823">
	<analytic>
		<title level="a" type="main">Investigating the impact of sample size on cognate detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Johann-Mattis</forename><surname>List</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Language Relationship</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="page" from="91" to="101" />
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b824">
	<monogr>
		<title level="m" type="main">Sequence comparison in historical linguistics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Johann-Mattis</forename><surname>List</surname></persName>
		</author>
		<ptr target="http://sequencecomparison.github.io" />
		<imprint>
			<date type="published" when="2014" />
			<publisher>Düsseldorf University Press</publisher>
			<pubPlace>Düsseldorf</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b825">
	<analytic>
		<title level="a" type="main">Beyond cognacy: Historical relations between words and their implication for phylogenetic reconstruction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Johann-Mattis</forename><surname>List</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Language Evolution</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="issue">2</biblScope>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
	<note>Published online before print</note>
</biblStruct>

<biblStruct xml:id="b826">
	<monogr>
		<title level="m" type="main">Concepticon: A resource for the linking of concept lists. Max Planck Institute for the Science of Human History</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Johann-Mattis</forename><surname>List</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Cysouw</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Robert</forename><surname>Forkel</surname></persName>
		</author>
		<idno>1.0</idno>
		<ptr target="http://concepticon.clld.org" />
		<imprint>
			<date type="published" when="2016" />
			<pubPlace>Jena</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b827">
	<monogr>
		<title level="m" type="main">LingPy. A Python library for historical linguistics. Max Planck Institute for the Science of Human History, Jena. Version 2.5</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Johann-Mattis</forename><surname>List</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Robert</forename><surname>Forkel</surname></persName>
		</author>
		<ptr target="http://lingpy.org" />
		<editor>Steven Moran, Peter Bouda, Johannes Dellert, Taraka Rama, Frank Nagel, and Simon Greenhill</editor>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b828">
	<monogr>
		<title level="m" type="main">The potential of automatic cognate detection for historical linguistics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Johann-Mattis</forename><surname>List</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Simon</forename><surname>Greenhill</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Russell</forename><surname>Gray</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
	<note>Manuscript in preparation</note>
</biblStruct>

<biblStruct xml:id="b829">
	<analytic>
		<title level="a" type="main">A preliminary case for exploratory networks in biology and linguistics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philippe</forename><surname>Lopez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Johann-Mattis</forename><surname>List</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eric</forename><surname>Bapteste</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Classification and evolution in biology, linguistics and the history of science</title>
		<editor>Heiner Fangerau, Hans Geisler, Thorsten Halling, and William Martin</editor>
		<meeting><address><addrLine>Stuttgart</addrLine></address></meeting>
		<imprint>
			<publisher>Franz Steiner Verlag</publisher>
			<date type="published" when="2013" />
			<biblScope unit="page" from="181" to="196" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b830">
	<monogr>
		<title level="m" type="main">Romanisches etymologisches Wörterbuch</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wilhelm</forename><surname>Meyer-Lübke</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1911" />
			<pubPlace>Winter, Heidelberg</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b831">
	<analytic>
		<title level="a" type="main">Protein networks identify novel symbiogenetic genes resulting from plastid endosymbiosis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Raphaël</forename><surname>Méheust</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ehud</forename><surname>Zelzion</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Debashish</forename><surname>Bhattacharya</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philippe</forename><surname>Lopez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eric</forename><surname>Bapteste</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Proceedings of the National Academy of Sciences of the United States of America</title>
		<imprint>
			<biblScope unit="volume">113</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="3579" to="3584" />
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b832">
	<analytic>
		<title level="a" type="main">Finding and evaluating community structure in networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">E J</forename><surname>Newman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Girvan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Physical Review E</title>
		<imprint>
			<biblScope unit="volume">69</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page">26113</biblScope>
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b833">
	<analytic>
		<title level="a" type="main">Maps of random walks on complex networks reveal community structure</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Martin</forename><surname>Rosvall</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Carl</forename><forename type="middle">T</forename><surname>Bergstrom</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the National Academy of Sciences of the United States of America</title>
		<meeting>the National Academy of Sciences of the United States of America</meeting>
		<imprint>
			<date type="published" when="2008" />
			<biblScope unit="volume">105</biblScope>
			<biblScope unit="page" from="1118" to="1123" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b834">
	<monogr>
		<title level="m" type="main">Phylogenetic inference of the Tibeto-Burman languages</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Damian</forename><surname>Satterthwaite-Phillips</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2011" />
			<pubPlace>Stanford</pubPlace>
		</imprint>
		<respStmt>
			<orgName>Stanford University</orgName>
		</respStmt>
	</monogr>
<note type="report_type">PhD Thesis</note>
</biblStruct>

<biblStruct xml:id="b835">
	<analytic>
		<title level="a" type="main">A statistical method for evaluating systematic relationships</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="middle">R</forename><surname>Robert</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Charles</forename><forename type="middle">D</forename><surname>Sokal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Michener</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">University of Kansas Scientific Bulletin</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="page" from="1409" to="1438" />
			<date type="published" when="1958" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b836">
	<analytic>
		<title level="a" type="main">Annotated Swadesh wordlists for the Tujia group</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">George</forename><forename type="middle">S</forename><surname>Starostin</surname></persName>
		</author>
		<ptr target="http://starling.rinet.ru/new100/tuj.xls" />
	</analytic>
	<monogr>
		<title level="m">The Global Lexicostatistical Database, RGGU, Moscow</title>
		<editor>George Starostin</editor>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b837">
	<monogr>
		<title level="m" type="main">Classification and evolution in biology, linguistics and the history of science</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">George</forename><forename type="middle">S</forename><surname>Starostin</surname></persName>
		</author>
		<editor>Heiner Fangerau, Hans Geisler, Thorsten Halling, and William Martin</editor>
		<imprint>
			<date type="published" when="2013" />
			<publisher>Franz Steiner Verlag</publisher>
			<biblScope unit="page" from="125" to="146" />
			<pubPlace>Stuttgart</pubPlace>
		</imprint>
	</monogr>
	<note>Lexicostatistics as a basis for language classification</note>
</biblStruct>

<biblStruct xml:id="b838">
	<monogr>
		<title level="m" type="main">The dictionary of historical and comparative linguistics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Robert</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Trask</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2000" />
			<publisher>Edinburgh University Press</publisher>
			<pubPlace>Edinburgh</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b839">
	<analytic>
		<title level="a" type="main">Analyzing genetic connections between languages by matching consonant classes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ilja</forename><surname>Peter Turchin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Murray</forename><surname>Peiros</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Gell-Mann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Language Relationship</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="117" to="126" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b840">
	<monogr>
		<title level="m" type="main">Graph clustering by flow simulation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Stijn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Van Dongen</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2000" />
		</imprint>
		<respStmt>
			<orgName>University of Utrecht</orgName>
		</respStmt>
	</monogr>
<note type="report_type">PhD Thesis</note>
</biblStruct>

<biblStruct xml:id="b841">
	<analytic>
		<title level="a" type="main">Markov clustering versus affinity propagation for the partitioning of protein interaction graphs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">James</forename><surname>Vlasblom</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shoshana</forename><forename type="middle">J</forename><surname>Wodak</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">BMC Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="page">99</biblScope>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b842">
	<analytic>
		<title level="a" type="main">Comparison of languages in contact</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Feng</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Academia Sinica</title>
		<imprint>
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
